{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collection of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "legitimate_urls = pd.read_csv(\"./extracted_csv_files/legitimate-urls.csv\")\n",
    "phishing_urls = pd.read_csv(\"./extracted_csv_files/phishing-urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Having_@_symbol</th>\n",
       "      <th>Having_IP</th>\n",
       "      <th>Path</th>\n",
       "      <th>Prefix_suffix_separation</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Redirection_//_symbol</th>\n",
       "      <th>Sub_domains</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>age_domain</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>http_tokens</th>\n",
       "      <th>statistical_report</th>\n",
       "      <th>tiny_url</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.liquidgeneration.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.onlineanime.org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.ceres.dti.ne.jp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/~nekoi/senno/senfirst.html</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.galeon.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kmh/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.fanworkrecs.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Domain  Having_@_symbol  Having_IP  \\\n",
       "0  www.liquidgeneration.com                0          0   \n",
       "1       www.onlineanime.org                0          0   \n",
       "2       www.ceres.dti.ne.jp                0          0   \n",
       "3            www.galeon.com                0          0   \n",
       "4       www.fanworkrecs.com                0          0   \n",
       "\n",
       "                          Path  Prefix_suffix_separation Protocol  \\\n",
       "0                            /                         0     http   \n",
       "1                            /                         0     http   \n",
       "2  /~nekoi/senno/senfirst.html                         0     http   \n",
       "3                        /kmh/                         0     http   \n",
       "4                            /                         0     http   \n",
       "\n",
       "   Redirection_//_symbol  Sub_domains  URL_Length  age_domain  dns_record  \\\n",
       "0                      0            0           0           0           0   \n",
       "1                      0            0           0           0           0   \n",
       "2                      0            1           0           1           0   \n",
       "3                      0            0           0           0           0   \n",
       "4                      0            0           0           1           1   \n",
       "\n",
       "   domain_registration_length  http_tokens  statistical_report  tiny_url  \\\n",
       "0                           1            0                   0         0   \n",
       "1                           1            0                   1         0   \n",
       "2                           1            0                   0         0   \n",
       "3                           0            0                   0         0   \n",
       "4                           1            0                   1         0   \n",
       "\n",
       "   web_traffic  label  \n",
       "0            2      0  \n",
       "1            1      0  \n",
       "2            0      0  \n",
       "3            0      0  \n",
       "4            1      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitimate_urls.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing\n",
    "#### Data is in two data frames so we merge them to make one dataframe\n",
    "Note: two dataframes has same column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = legitimate_urls.append(phishing_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Having_@_symbol</th>\n",
       "      <th>Having_IP</th>\n",
       "      <th>Path</th>\n",
       "      <th>Prefix_suffix_separation</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Redirection_//_symbol</th>\n",
       "      <th>Sub_domains</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>age_domain</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>http_tokens</th>\n",
       "      <th>statistical_report</th>\n",
       "      <th>tiny_url</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.liquidgeneration.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.onlineanime.org</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.ceres.dti.ne.jp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/~nekoi/senno/senfirst.html</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.galeon.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/kmh/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.fanworkrecs.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/</td>\n",
       "      <td>0</td>\n",
       "      <td>http</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Domain  Having_@_symbol  Having_IP  \\\n",
       "0  www.liquidgeneration.com                0          0   \n",
       "1       www.onlineanime.org                0          0   \n",
       "2       www.ceres.dti.ne.jp                0          0   \n",
       "3            www.galeon.com                0          0   \n",
       "4       www.fanworkrecs.com                0          0   \n",
       "\n",
       "                          Path  Prefix_suffix_separation Protocol  \\\n",
       "0                            /                         0     http   \n",
       "1                            /                         0     http   \n",
       "2  /~nekoi/senno/senfirst.html                         0     http   \n",
       "3                        /kmh/                         0     http   \n",
       "4                            /                         0     http   \n",
       "\n",
       "   Redirection_//_symbol  Sub_domains  URL_Length  age_domain  dns_record  \\\n",
       "0                      0            0           0           0           0   \n",
       "1                      0            0           0           0           0   \n",
       "2                      0            1           0           1           0   \n",
       "3                      0            0           0           0           0   \n",
       "4                      0            0           0           1           1   \n",
       "\n",
       "   domain_registration_length  http_tokens  statistical_report  tiny_url  \\\n",
       "0                           1            0                   0         0   \n",
       "1                           1            0                   1         0   \n",
       "2                           1            0                   0         0   \n",
       "3                           0            0                   0         0   \n",
       "4                           1            0                   1         0   \n",
       "\n",
       "   web_traffic  label  \n",
       "0            2      0  \n",
       "1            1      0  \n",
       "2            0      0  \n",
       "3            0      0  \n",
       "4            1      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Having_@_symbol', 'Having_IP', 'Prefix_suffix_separation',\n",
       "       'Redirection_//_symbol', 'Sub_domains', 'URL_Length', 'age_domain',\n",
       "       'dns_record', 'domain_registration_length', 'http_tokens',\n",
       "       'statistical_report', 'tiny_url', 'web_traffic', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = urls.drop(urls.columns[[0,3,5]],axis=1)\n",
    "urls.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suffle  rows\n",
    "Since we merged two dataframes top 1000 rows will have legitimate urls and bottom 1000 rows will have phishing urls. So if we split the data now and create a model for it will overfit so we need to shuffle the rows before splitting the data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n",
    "urls = urls.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Having_@_symbol</th>\n",
       "      <th>Having_IP</th>\n",
       "      <th>Prefix_suffix_separation</th>\n",
       "      <th>Redirection_//_symbol</th>\n",
       "      <th>Sub_domains</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>age_domain</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>http_tokens</th>\n",
       "      <th>statistical_report</th>\n",
       "      <th>tiny_url</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Having_@_symbol  Having_IP  Prefix_suffix_separation  \\\n",
       "0                0          0                         0   \n",
       "1                0          0                         0   \n",
       "2                0          0                         0   \n",
       "3                0          0                         0   \n",
       "4                0          0                         0   \n",
       "\n",
       "   Redirection_//_symbol  Sub_domains  URL_Length  age_domain  dns_record  \\\n",
       "0                      0            2           0           0           0   \n",
       "1                      0            2           0           0           0   \n",
       "2                      0            2           0           0           0   \n",
       "3                      0            0           0           0           0   \n",
       "4                      0            0           0           1           0   \n",
       "\n",
       "   domain_registration_length  http_tokens  statistical_report  tiny_url  \\\n",
       "0                           1            0                   0         0   \n",
       "1                           1            0                   0         0   \n",
       "2                           1            0                   1         0   \n",
       "3                           1            0                   0         0   \n",
       "4                           1            0                   0         0   \n",
       "\n",
       "   web_traffic  label  \n",
       "0            2      0  \n",
       "1            2      0  \n",
       "2            1      0  \n",
       "3            2      0  \n",
       "4            0      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12d9b0bd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(urls.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x12f041ad0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x2520 with 210 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(urls)\n",
    "# urls.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing class variable from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_without_labels = urls.drop('label',axis=1)\n",
    "labels = urls['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train data and test data\n",
    "\n",
    "Dividing the data in the ratio of 80:20 [train_data:test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(urls_without_labels, labels, test_size=0.20, random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612 403 1612 403\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train),len(data_test),len(labels_train),len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the split of labels in train and test data\n",
    "\n",
    "The split should be in equal proportion for both classes\n",
    "\n",
    "Phishing - 1\n",
    "\n",
    "Legitimate - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    811\n",
       "1    801\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initially checking the split of labels_train data \n",
    "labels_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By above results it is shown that the split of both classes are almost equal!\n",
    "\n",
    "Testing the same for labels of test data also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    206\n",
       "1    197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the split for labels_test data\n",
    "labels_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as the split is almost in equal proportion we can train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:0.8201315308732189,0.02352063608513457\n",
      "LR:0.7394977212853104,0.031926523263491616\n",
      "NB:0.5297848201065324,0.010833679404724642\n",
      "Tree:0.8300405745822357,0.012710853729019658\n",
      "RF:0.834390323635175,0.0172768467510033\n",
      "GDBT:0.8300521123781319,0.019002798684083638\n",
      "SVM:0.8201180701113397,0.015349579428829961\n",
      "xgb:0.8182624079380035,0.016552966015803427\n",
      "lgb:0.8306732303905544,0.020291232359570175\n"
     ]
    }
   ],
   "source": [
    "models=[KNeighborsClassifier(),LogisticRegression(),GaussianNB(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "       GradientBoostingClassifier(),SVC(), xgb.XGBClassifier(), lgb.LGBMClassifier()]\n",
    "# evaluate models by using cross-validation\n",
    "names=['KNN','LR','NB','Tree','RF','GDBT','SVM', 'xgb', 'lgb']\n",
    "for name, model in zip(names,models):\n",
    "    score=cross_val_score(model, data_train, labels_train, cv=5)\n",
    "    print(\"{}:{},{}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "kNN_classifier = KNeighborsClassifier()\n",
    "param_dist = {'n_neighbors':range(1,100)}\n",
    "grid = RandomizedSearchCV(kNN_classifier, param_dist, cv = 5, scoring = 'accuracy', n_jobs = -1)\n",
    "grid.fit(data_train, labels_train)\n",
    "best_estimator = grid.best_estimator_\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181  25]\n",
      " [ 40 157]]\n",
      "AC and RS is: 0.8387096774193549 and 0.7969543147208121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13556ef50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kNN_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "kNN_classifier.fit(data_train, labels_train)\n",
    "kNN_predict = kNN_classifier.predict(data_test)\n",
    "cmkNN = confusion_matrix(labels_test, kNN_predict)\n",
    "print(cmkNN)\n",
    "print('AC and RS is: {} and {}'.format(accuracy_score(labels_test, kNN_predict),\n",
    "                                       recall_score(labels_test, kNN_predict)))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, kNN_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)\n",
    "plt.minorticks_on()\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.heatmap(cmkNN, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=28.287171717171717, break_ties=False, cache_size=200, class_weight=None,\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma=30.81191919191919,\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "param_dist = {'C': np.linspace(0.01, 50, 100),\n",
    "             'gamma': np.linspace(0.01, 50, 100)}\n",
    "grid = RandomizedSearchCV(svm_classifier, param_dist, cv = 5, scoring = 'accuracy', n_jobs = -1)\n",
    "grid.fit(data_train, labels_train)\n",
    "best_estimator = grid.best_estimator_\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[171  35]\n",
      " [ 33 164]]\n",
      "AC and RS is: 0.8312655086848635 and 0.8324873096446701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12ed0dcd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_classifier = SVC(C=28.28, gamma=30.8)\n",
    "svm_classifier.fit(data_train, labels_train)\n",
    "SVC_predict = svm_classifier.predict(data_test)\n",
    "cmSVC = confusion_matrix(labels_test, SVC_predict)\n",
    "print(cmSVC)\n",
    "print('AC and RS is: {} and {}'.format(accuracy_score(labels_test, SVC_predict),\n",
    "                                       recall_score(labels_test, SVC_predict)))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, SVC_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)\n",
    "plt.minorticks_on()\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.heatmap(cmSVC, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=10, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1600,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200,stop = 2000,num = 10)]\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,4]\n",
    "max_depth = [5,8,10]\n",
    "max_features = ['auto','sqrt']\n",
    "bootstrap = [True,False]\n",
    "random_params_group = {'n_estimators':n_estimators,\n",
    "                      'min_samples_split':min_samples_split,\n",
    "                      'min_samples_leaf':min_samples_leaf,\n",
    "                      'max_depth':max_depth,\n",
    "                      'max_features':max_features,\n",
    "                      'bootstrap':bootstrap}\n",
    "random_model =RandomizedSearchCV(RF,param_distributions = random_params_group, n_iter = 100,\n",
    "scoring = 'accuracy', verbose = 2, n_jobs = -1, cv = 10, random_state = 0)\n",
    "random_model.fit(data_train, labels_train)\n",
    "best_estimator = random_model.best_estimator_\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181  20]\n",
      " [ 46 156]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8362282878411911"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_classifier = RandomForestClassifier(bootstrap=False, max_depth=10, max_features='sqrt',\n",
    "                       min_samples_split=2, n_estimators=1600)\n",
    "RF_classifier.fit(data_train, labels_train)\n",
    "RF_predict = RF_classifier.predict(data_test)\n",
    "cmRF = confusion_matrix(labels_test, RF_predict)\n",
    "print(cmRF)\n",
    "accuracy_score(labels_test, RF_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.836870949752899\n",
      "best parameters: \n",
      "\tcolsample_bytree: 0.9\n",
      "\tlearning_rate: 0.1\n",
      "\tmax_delta_step: 2\n",
      "\tmax_depth: 15\n",
      "\tmin_child_weight: 2\n",
      "\tn_estimators: 5000\n",
      "\treg_alpha: 1\n",
      "\treg_lambda: 0.4\n",
      "\tscale_pos_weight: 0.6\n",
      "\tsubsample: 0.7\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "              'max_depth': [5, 10, 15, 20, 25],\n",
    "              'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],\n",
    "              'n_estimators': [500, 1000, 2000, 3000, 5000],\n",
    "              'min_child_weight': [0, 2, 5, 10, 20],\n",
    "              'max_delta_step': [0, 0.2, 0.6, 1, 2],\n",
    "              'subsample': [0.6, 0.7, 0.8, 0.85, 0.95],\n",
    "              'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "              'reg_alpha': [0, 0.25, 0.5, 0.75, 1],\n",
    "              'reg_lambda': [0.2, 0.4, 0.6, 0.8, 1],\n",
    "              'scale_pos_weight': [0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "}\n",
    "xlf = xgb.XGBClassifier(max_depth=10,\n",
    "            learning_rate=0.01,\n",
    "            n_estimators=2000,\n",
    "            objective='binary:logistic',\n",
    "            nthread=-1,\n",
    "            gamma=0,\n",
    "            min_child_weight=1,\n",
    "            max_delta_step=0,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.7,\n",
    "            colsample_bylevel=1,\n",
    "            reg_alpha=0,\n",
    "            reg_lambda=1,\n",
    "            scale_pos_weight=1,\n",
    "            seed=1440,\n",
    "            missing=None)\n",
    "\n",
    "gsearch = RandomizedSearchCV(xlf, param_distributions=parameters, scoring='accuracy', cv=5)\n",
    "gsearch.fit(data_train, labels_train)\n",
    "\n",
    "print(\"best score: \",gsearch.best_score_)\n",
    "print(\"best parameters: \")\n",
    "best_parameters = gsearch.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181  25]\n",
      " [ 37 160]]\n",
      "AC and RS is: 0.8461538461538461 and 0.8121827411167513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x137426990>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(max_depth=15,\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=5000,\n",
    "            objective='binary:logistic',\n",
    "            nthread=-1,\n",
    "            gamma=0,\n",
    "            min_child_weight=2,\n",
    "            max_delta_step=2,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.9,\n",
    "            colsample_bylevel=1,\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=0.4,\n",
    "            scale_pos_weight=0.6,\n",
    "            seed=1440,\n",
    "            missing=None)\n",
    "\n",
    "xgb_classifier.fit(data_train, labels_train)\n",
    "xgb_predict = xgb_classifier.predict(data_test)\n",
    "cmXgb = confusion_matrix(labels_test, xgb_predict)\n",
    "print(cmXgb)\n",
    "print('AC and RS is: {} and {}'.format(accuracy_score(labels_test, xgb_predict), recall_score(labels_test, xgb_predict)))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, xgb_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)\n",
    "plt.minorticks_on()\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.heatmap(cmXgb, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[20]\ttraining's auc: 0.898561\ttraining's binary_logloss: 0.526693\tvalid_1's auc: 0.880854\tvalid_1's binary_logloss: 0.536009\n",
      "[40]\ttraining's auc: 0.902838\ttraining's binary_logloss: 0.4546\tvalid_1's auc: 0.88331\tvalid_1's binary_logloss: 0.471654\n",
      "[60]\ttraining's auc: 0.904336\ttraining's binary_logloss: 0.420819\tvalid_1's auc: 0.884692\tvalid_1's binary_logloss: 0.442274\n",
      "[80]\ttraining's auc: 0.907594\ttraining's binary_logloss: 0.400055\tvalid_1's auc: 0.885863\tvalid_1's binary_logloss: 0.42431\n",
      "[100]\ttraining's auc: 0.911647\ttraining's binary_logloss: 0.388567\tvalid_1's auc: 0.88997\tvalid_1's binary_logloss: 0.415329\n",
      "[120]\ttraining's auc: 0.913094\ttraining's binary_logloss: 0.381443\tvalid_1's auc: 0.89116\tvalid_1's binary_logloss: 0.411865\n",
      "[140]\ttraining's auc: 0.914088\ttraining's binary_logloss: 0.376672\tvalid_1's auc: 0.892734\tvalid_1's binary_logloss: 0.409108\n",
      "[160]\ttraining's auc: 0.914926\ttraining's binary_logloss: 0.372629\tvalid_1's auc: 0.893118\tvalid_1's binary_logloss: 0.407043\n",
      "[180]\ttraining's auc: 0.916326\ttraining's binary_logloss: 0.369244\tvalid_1's auc: 0.893271\tvalid_1's binary_logloss: 0.405342\n",
      "[200]\ttraining's auc: 0.917289\ttraining's binary_logloss: 0.366489\tvalid_1's auc: 0.893463\tvalid_1's binary_logloss: 0.404449\n",
      "[220]\ttraining's auc: 0.918411\ttraining's binary_logloss: 0.363665\tvalid_1's auc: 0.894653\tvalid_1's binary_logloss: 0.402394\n",
      "[240]\ttraining's auc: 0.919379\ttraining's binary_logloss: 0.361342\tvalid_1's auc: 0.89638\tvalid_1's binary_logloss: 0.400849\n",
      "[260]\ttraining's auc: 0.920386\ttraining's binary_logloss: 0.358952\tvalid_1's auc: 0.896918\tvalid_1's binary_logloss: 0.399978\n",
      "[280]\ttraining's auc: 0.921313\ttraining's binary_logloss: 0.357174\tvalid_1's auc: 0.897033\tvalid_1's binary_logloss: 0.399093\n",
      "[300]\ttraining's auc: 0.922021\ttraining's binary_logloss: 0.3555\tvalid_1's auc: 0.897877\tvalid_1's binary_logloss: 0.398971\n",
      "[320]\ttraining's auc: 0.922302\ttraining's binary_logloss: 0.354194\tvalid_1's auc: 0.898568\tvalid_1's binary_logloss: 0.397554\n",
      "[340]\ttraining's auc: 0.923408\ttraining's binary_logloss: 0.352658\tvalid_1's auc: 0.900027\tvalid_1's binary_logloss: 0.397306\n",
      "[360]\ttraining's auc: 0.924474\ttraining's binary_logloss: 0.351118\tvalid_1's auc: 0.90114\tvalid_1's binary_logloss: 0.39716\n",
      "[380]\ttraining's auc: 0.924544\ttraining's binary_logloss: 0.349913\tvalid_1's auc: 0.90018\tvalid_1's binary_logloss: 0.397117\n",
      "[400]\ttraining's auc: 0.924775\ttraining's binary_logloss: 0.348909\tvalid_1's auc: 0.899988\tvalid_1's binary_logloss: 0.397415\n",
      "[420]\ttraining's auc: 0.924995\ttraining's binary_logloss: 0.347922\tvalid_1's auc: 0.900027\tvalid_1's binary_logloss: 0.397609\n",
      "[440]\ttraining's auc: 0.925621\ttraining's binary_logloss: 0.346792\tvalid_1's auc: 0.901332\tvalid_1's binary_logloss: 0.396949\n",
      "[460]\ttraining's auc: 0.925775\ttraining's binary_logloss: 0.34583\tvalid_1's auc: 0.901677\tvalid_1's binary_logloss: 0.397026\n",
      "[480]\ttraining's auc: 0.92616\ttraining's binary_logloss: 0.345041\tvalid_1's auc: 0.901639\tvalid_1's binary_logloss: 0.397405\n",
      "[500]\ttraining's auc: 0.926305\ttraining's binary_logloss: 0.344155\tvalid_1's auc: 0.901524\tvalid_1's binary_logloss: 0.39638\n",
      "[520]\ttraining's auc: 0.926574\ttraining's binary_logloss: 0.343442\tvalid_1's auc: 0.901409\tvalid_1's binary_logloss: 0.3964\n",
      "[540]\ttraining's auc: 0.926719\ttraining's binary_logloss: 0.342679\tvalid_1's auc: 0.90137\tvalid_1's binary_logloss: 0.396571\n",
      "[560]\ttraining's auc: 0.927405\ttraining's binary_logloss: 0.34195\tvalid_1's auc: 0.901639\tvalid_1's binary_logloss: 0.395275\n",
      "[580]\ttraining's auc: 0.927434\ttraining's binary_logloss: 0.341301\tvalid_1's auc: 0.901409\tvalid_1's binary_logloss: 0.396639\n",
      "[600]\ttraining's auc: 0.927747\ttraining's binary_logloss: 0.340723\tvalid_1's auc: 0.901639\tvalid_1's binary_logloss: 0.396202\n",
      "[620]\ttraining's auc: 0.927863\ttraining's binary_logloss: 0.340003\tvalid_1's auc: 0.901793\tvalid_1's binary_logloss: 0.395272\n",
      "[640]\ttraining's auc: 0.927853\ttraining's binary_logloss: 0.339422\tvalid_1's auc: 0.901102\tvalid_1's binary_logloss: 0.395082\n",
      "[660]\ttraining's auc: 0.928323\ttraining's binary_logloss: 0.338869\tvalid_1's auc: 0.902023\tvalid_1's binary_logloss: 0.395022\n",
      "[680]\ttraining's auc: 0.928522\ttraining's binary_logloss: 0.338218\tvalid_1's auc: 0.901294\tvalid_1's binary_logloss: 0.39624\n",
      "[700]\ttraining's auc: 0.928539\ttraining's binary_logloss: 0.337739\tvalid_1's auc: 0.90137\tvalid_1's binary_logloss: 0.396363\n",
      "[720]\ttraining's auc: 0.929189\ttraining's binary_logloss: 0.337274\tvalid_1's auc: 0.90114\tvalid_1's binary_logloss: 0.396753\n",
      "[740]\ttraining's auc: 0.929401\ttraining's binary_logloss: 0.336784\tvalid_1's auc: 0.901217\tvalid_1's binary_logloss: 0.396032\n",
      "[760]\ttraining's auc: 0.929565\ttraining's binary_logloss: 0.3363\tvalid_1's auc: 0.901102\tvalid_1's binary_logloss: 0.396679\n",
      "[780]\ttraining's auc: 0.929418\ttraining's binary_logloss: 0.335808\tvalid_1's auc: 0.899489\tvalid_1's binary_logloss: 0.396111\n",
      "[800]\ttraining's auc: 0.929832\ttraining's binary_logloss: 0.33528\tvalid_1's auc: 0.900296\tvalid_1's binary_logloss: 0.3959\n",
      "[820]\ttraining's auc: 0.930037\ttraining's binary_logloss: 0.334924\tvalid_1's auc: 0.902061\tvalid_1's binary_logloss: 0.396292\n",
      "[840]\ttraining's auc: 0.930068\ttraining's binary_logloss: 0.334425\tvalid_1's auc: 0.901562\tvalid_1's binary_logloss: 0.396543\n",
      "[860]\ttraining's auc: 0.930263\ttraining's binary_logloss: 0.333976\tvalid_1's auc: 0.901639\tvalid_1's binary_logloss: 0.395919\n",
      "[880]\ttraining's auc: 0.930393\ttraining's binary_logloss: 0.333656\tvalid_1's auc: 0.901869\tvalid_1's binary_logloss: 0.396134\n",
      "[900]\ttraining's auc: 0.930543\ttraining's binary_logloss: 0.33326\tvalid_1's auc: 0.901793\tvalid_1's binary_logloss: 0.396937\n",
      "[920]\ttraining's auc: 0.930538\ttraining's binary_logloss: 0.332842\tvalid_1's auc: 0.901639\tvalid_1's binary_logloss: 0.396945\n",
      "[940]\ttraining's auc: 0.930716\ttraining's binary_logloss: 0.332541\tvalid_1's auc: 0.902407\tvalid_1's binary_logloss: 0.396544\n",
      "[960]\ttraining's auc: 0.930957\ttraining's binary_logloss: 0.332276\tvalid_1's auc: 0.900449\tvalid_1's binary_logloss: 0.397105\n",
      "[980]\ttraining's auc: 0.930779\ttraining's binary_logloss: 0.331887\tvalid_1's auc: 0.900641\tvalid_1's binary_logloss: 0.397329\n",
      "[1000]\ttraining's auc: 0.931024\ttraining's binary_logloss: 0.33161\tvalid_1's auc: 0.900564\tvalid_1's binary_logloss: 0.397261\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[995]\ttraining's auc: 0.931174\ttraining's binary_logloss: 0.331694\tvalid_1's auc: 0.900871\tvalid_1's binary_logloss: 0.397216\n",
      "fold 2\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[20]\ttraining's auc: 0.896453\ttraining's binary_logloss: 0.528664\tvalid_1's auc: 0.880142\tvalid_1's binary_logloss: 0.540512\n",
      "[40]\ttraining's auc: 0.901214\ttraining's binary_logloss: 0.457298\tvalid_1's auc: 0.880488\tvalid_1's binary_logloss: 0.479041\n",
      "[60]\ttraining's auc: 0.904633\ttraining's binary_logloss: 0.420626\tvalid_1's auc: 0.881584\tvalid_1's binary_logloss: 0.452626\n",
      "[80]\ttraining's auc: 0.906892\ttraining's binary_logloss: 0.399649\tvalid_1's auc: 0.886582\tvalid_1's binary_logloss: 0.434765\n",
      "[100]\ttraining's auc: 0.90948\ttraining's binary_logloss: 0.386948\tvalid_1's auc: 0.890523\tvalid_1's binary_logloss: 0.426707\n",
      "[120]\ttraining's auc: 0.912136\ttraining's binary_logloss: 0.379721\tvalid_1's auc: 0.894022\tvalid_1's binary_logloss: 0.423396\n",
      "[140]\ttraining's auc: 0.913474\ttraining's binary_logloss: 0.373622\tvalid_1's auc: 0.894983\tvalid_1's binary_logloss: 0.419986\n",
      "[160]\ttraining's auc: 0.915634\ttraining's binary_logloss: 0.369209\tvalid_1's auc: 0.89679\tvalid_1's binary_logloss: 0.417276\n",
      "[180]\ttraining's auc: 0.916751\ttraining's binary_logloss: 0.3657\tvalid_1's auc: 0.897943\tvalid_1's binary_logloss: 0.415782\n",
      "[200]\ttraining's auc: 0.918012\ttraining's binary_logloss: 0.362536\tvalid_1's auc: 0.896674\tvalid_1's binary_logloss: 0.414136\n",
      "[220]\ttraining's auc: 0.91951\ttraining's binary_logloss: 0.359698\tvalid_1's auc: 0.897366\tvalid_1's binary_logloss: 0.4126\n",
      "[240]\ttraining's auc: 0.919979\ttraining's binary_logloss: 0.357189\tvalid_1's auc: 0.897712\tvalid_1's binary_logloss: 0.41197\n",
      "[260]\ttraining's auc: 0.920861\ttraining's binary_logloss: 0.355177\tvalid_1's auc: 0.898558\tvalid_1's binary_logloss: 0.410545\n",
      "[280]\ttraining's auc: 0.921674\ttraining's binary_logloss: 0.353402\tvalid_1's auc: 0.896751\tvalid_1's binary_logloss: 0.410824\n",
      "[300]\ttraining's auc: 0.922579\ttraining's binary_logloss: 0.35181\tvalid_1's auc: 0.897828\tvalid_1's binary_logloss: 0.411107\n",
      "[320]\ttraining's auc: 0.92353\ttraining's binary_logloss: 0.350248\tvalid_1's auc: 0.898904\tvalid_1's binary_logloss: 0.410555\n",
      "[340]\ttraining's auc: 0.923969\ttraining's binary_logloss: 0.348777\tvalid_1's auc: 0.898904\tvalid_1's binary_logloss: 0.409733\n",
      "[360]\ttraining's auc: 0.9249\ttraining's binary_logloss: 0.347257\tvalid_1's auc: 0.898366\tvalid_1's binary_logloss: 0.410462\n",
      "[380]\ttraining's auc: 0.925418\ttraining's binary_logloss: 0.345967\tvalid_1's auc: 0.897905\tvalid_1's binary_logloss: 0.410477\n",
      "[400]\ttraining's auc: 0.926294\ttraining's binary_logloss: 0.344927\tvalid_1's auc: 0.898674\tvalid_1's binary_logloss: 0.410331\n",
      "[420]\ttraining's auc: 0.926619\ttraining's binary_logloss: 0.343454\tvalid_1's auc: 0.898481\tvalid_1's binary_logloss: 0.410765\n",
      "[440]\ttraining's auc: 0.926773\ttraining's binary_logloss: 0.342372\tvalid_1's auc: 0.899058\tvalid_1's binary_logloss: 0.411858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460]\ttraining's auc: 0.926742\ttraining's binary_logloss: 0.34151\tvalid_1's auc: 0.89902\tvalid_1's binary_logloss: 0.411489\n",
      "[480]\ttraining's auc: 0.927606\ttraining's binary_logloss: 0.34069\tvalid_1's auc: 0.898943\tvalid_1's binary_logloss: 0.411367\n",
      "[500]\ttraining's auc: 0.928028\ttraining's binary_logloss: 0.339922\tvalid_1's auc: 0.899097\tvalid_1's binary_logloss: 0.411429\n",
      "[520]\ttraining's auc: 0.927792\ttraining's binary_logloss: 0.338933\tvalid_1's auc: 0.898827\tvalid_1's binary_logloss: 0.41049\n",
      "[540]\ttraining's auc: 0.928861\ttraining's binary_logloss: 0.337998\tvalid_1's auc: 0.899404\tvalid_1's binary_logloss: 0.410406\n",
      "[560]\ttraining's auc: 0.929073\ttraining's binary_logloss: 0.337051\tvalid_1's auc: 0.898827\tvalid_1's binary_logloss: 0.410313\n",
      "[580]\ttraining's auc: 0.929465\ttraining's binary_logloss: 0.336233\tvalid_1's auc: 0.899712\tvalid_1's binary_logloss: 0.410275\n",
      "[600]\ttraining's auc: 0.929595\ttraining's binary_logloss: 0.335563\tvalid_1's auc: 0.899404\tvalid_1's binary_logloss: 0.410399\n",
      "[620]\ttraining's auc: 0.929951\ttraining's binary_logloss: 0.334871\tvalid_1's auc: 0.899904\tvalid_1's binary_logloss: 0.410316\n",
      "[640]\ttraining's auc: 0.930101\ttraining's binary_logloss: 0.334335\tvalid_1's auc: 0.899865\tvalid_1's binary_logloss: 0.411023\n",
      "[660]\ttraining's auc: 0.930317\ttraining's binary_logloss: 0.33373\tvalid_1's auc: 0.900404\tvalid_1's binary_logloss: 0.410381\n",
      "[680]\ttraining's auc: 0.930358\ttraining's binary_logloss: 0.333214\tvalid_1's auc: 0.90025\tvalid_1's binary_logloss: 0.410644\n",
      "[700]\ttraining's auc: 0.930628\ttraining's binary_logloss: 0.332676\tvalid_1's auc: 0.900788\tvalid_1's binary_logloss: 0.410019\n",
      "[720]\ttraining's auc: 0.930859\ttraining's binary_logloss: 0.332135\tvalid_1's auc: 0.900596\tvalid_1's binary_logloss: 0.411189\n",
      "[740]\ttraining's auc: 0.930931\ttraining's binary_logloss: 0.33165\tvalid_1's auc: 0.900173\tvalid_1's binary_logloss: 0.411446\n",
      "[760]\ttraining's auc: 0.931208\ttraining's binary_logloss: 0.331223\tvalid_1's auc: 0.900442\tvalid_1's binary_logloss: 0.410534\n",
      "[780]\ttraining's auc: 0.931256\ttraining's binary_logloss: 0.330738\tvalid_1's auc: 0.900711\tvalid_1's binary_logloss: 0.410757\n",
      "[800]\ttraining's auc: 0.931576\ttraining's binary_logloss: 0.330297\tvalid_1's auc: 0.900519\tvalid_1's binary_logloss: 0.412289\n",
      "[820]\ttraining's auc: 0.931473\ttraining's binary_logloss: 0.329927\tvalid_1's auc: 0.900404\tvalid_1's binary_logloss: 0.412021\n",
      "[840]\ttraining's auc: 0.931742\ttraining's binary_logloss: 0.329508\tvalid_1's auc: 0.900327\tvalid_1's binary_logloss: 0.411806\n",
      "[860]\ttraining's auc: 0.931658\ttraining's binary_logloss: 0.329184\tvalid_1's auc: 0.90025\tvalid_1's binary_logloss: 0.412089\n",
      "[880]\ttraining's auc: 0.931803\ttraining's binary_logloss: 0.328789\tvalid_1's auc: 0.900481\tvalid_1's binary_logloss: 0.411655\n",
      "[900]\ttraining's auc: 0.93201\ttraining's binary_logloss: 0.328346\tvalid_1's auc: 0.900058\tvalid_1's binary_logloss: 0.412515\n",
      "[920]\ttraining's auc: 0.931954\ttraining's binary_logloss: 0.327983\tvalid_1's auc: 0.900019\tvalid_1's binary_logloss: 0.412641\n",
      "[940]\ttraining's auc: 0.932164\ttraining's binary_logloss: 0.327491\tvalid_1's auc: 0.900481\tvalid_1's binary_logloss: 0.412116\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's auc: 0.923969\ttraining's binary_logloss: 0.348777\tvalid_1's auc: 0.898904\tvalid_1's binary_logloss: 0.409733\n",
      "fold 3\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[20]\ttraining's auc: 0.89895\ttraining's binary_logloss: 0.526151\tvalid_1's auc: 0.878497\tvalid_1's binary_logloss: 0.548621\n",
      "[40]\ttraining's auc: 0.902338\ttraining's binary_logloss: 0.455906\tvalid_1's auc: 0.882206\tvalid_1's binary_logloss: 0.484416\n",
      "[60]\ttraining's auc: 0.905802\ttraining's binary_logloss: 0.420122\tvalid_1's auc: 0.884849\tvalid_1's binary_logloss: 0.454659\n",
      "[80]\ttraining's auc: 0.907181\ttraining's binary_logloss: 0.399632\tvalid_1's auc: 0.887493\tvalid_1's binary_logloss: 0.439121\n",
      "[100]\ttraining's auc: 0.909769\ttraining's binary_logloss: 0.387914\tvalid_1's auc: 0.890491\tvalid_1's binary_logloss: 0.428585\n",
      "[120]\ttraining's auc: 0.913664\ttraining's binary_logloss: 0.379872\tvalid_1's auc: 0.89274\tvalid_1's binary_logloss: 0.420542\n",
      "[140]\ttraining's auc: 0.915313\ttraining's binary_logloss: 0.373202\tvalid_1's auc: 0.896252\tvalid_1's binary_logloss: 0.414764\n",
      "[160]\ttraining's auc: 0.916111\ttraining's binary_logloss: 0.369015\tvalid_1's auc: 0.897869\tvalid_1's binary_logloss: 0.411333\n",
      "[180]\ttraining's auc: 0.918339\ttraining's binary_logloss: 0.365274\tvalid_1's auc: 0.898895\tvalid_1's binary_logloss: 0.407716\n",
      "[200]\ttraining's auc: 0.918871\ttraining's binary_logloss: 0.36234\tvalid_1's auc: 0.900947\tvalid_1's binary_logloss: 0.404645\n",
      "[220]\ttraining's auc: 0.920107\ttraining's binary_logloss: 0.360084\tvalid_1's auc: 0.903038\tvalid_1's binary_logloss: 0.401767\n",
      "[240]\ttraining's auc: 0.920815\ttraining's binary_logloss: 0.357995\tvalid_1's auc: 0.903788\tvalid_1's binary_logloss: 0.401174\n",
      "[260]\ttraining's auc: 0.921282\ttraining's binary_logloss: 0.355804\tvalid_1's auc: 0.904143\tvalid_1's binary_logloss: 0.400592\n",
      "[280]\ttraining's auc: 0.92292\ttraining's binary_logloss: 0.354099\tvalid_1's auc: 0.904419\tvalid_1's binary_logloss: 0.400038\n",
      "[300]\ttraining's auc: 0.9235\ttraining's binary_logloss: 0.352449\tvalid_1's auc: 0.905642\tvalid_1's binary_logloss: 0.398868\n",
      "[320]\ttraining's auc: 0.924052\ttraining's binary_logloss: 0.35107\tvalid_1's auc: 0.906234\tvalid_1's binary_logloss: 0.398012\n",
      "[340]\ttraining's auc: 0.924163\ttraining's binary_logloss: 0.350081\tvalid_1's auc: 0.907181\tvalid_1's binary_logloss: 0.397519\n",
      "[360]\ttraining's auc: 0.924981\ttraining's binary_logloss: 0.348649\tvalid_1's auc: 0.907536\tvalid_1's binary_logloss: 0.396133\n",
      "[380]\ttraining's auc: 0.925333\ttraining's binary_logloss: 0.347528\tvalid_1's auc: 0.908562\tvalid_1's binary_logloss: 0.394984\n",
      "[400]\ttraining's auc: 0.926034\ttraining's binary_logloss: 0.346453\tvalid_1's auc: 0.908009\tvalid_1's binary_logloss: 0.394776\n",
      "[420]\ttraining's auc: 0.926398\ttraining's binary_logloss: 0.345487\tvalid_1's auc: 0.908562\tvalid_1's binary_logloss: 0.394315\n",
      "[440]\ttraining's auc: 0.926378\ttraining's binary_logloss: 0.344707\tvalid_1's auc: 0.908799\tvalid_1's binary_logloss: 0.394186\n",
      "[460]\ttraining's auc: 0.926783\ttraining's binary_logloss: 0.343826\tvalid_1's auc: 0.910022\tvalid_1's binary_logloss: 0.392191\n",
      "[480]\ttraining's auc: 0.926952\ttraining's binary_logloss: 0.342918\tvalid_1's auc: 0.909706\tvalid_1's binary_logloss: 0.391428\n",
      "[500]\ttraining's auc: 0.92719\ttraining's binary_logloss: 0.34218\tvalid_1's auc: 0.909509\tvalid_1's binary_logloss: 0.391029\n",
      "[520]\ttraining's auc: 0.927655\ttraining's binary_logloss: 0.341576\tvalid_1's auc: 0.909824\tvalid_1's binary_logloss: 0.390601\n",
      "[540]\ttraining's auc: 0.92804\ttraining's binary_logloss: 0.340718\tvalid_1's auc: 0.909864\tvalid_1's binary_logloss: 0.390442\n",
      "[560]\ttraining's auc: 0.928245\ttraining's binary_logloss: 0.340176\tvalid_1's auc: 0.910653\tvalid_1's binary_logloss: 0.38969\n",
      "[580]\ttraining's auc: 0.928664\ttraining's binary_logloss: 0.339525\tvalid_1's auc: 0.910061\tvalid_1's binary_logloss: 0.389546\n",
      "[600]\ttraining's auc: 0.928847\ttraining's binary_logloss: 0.339035\tvalid_1's auc: 0.910377\tvalid_1's binary_logloss: 0.389247\n",
      "[620]\ttraining's auc: 0.929054\ttraining's binary_logloss: 0.338399\tvalid_1's auc: 0.910258\tvalid_1's binary_logloss: 0.389478\n",
      "[640]\ttraining's auc: 0.929057\ttraining's binary_logloss: 0.337882\tvalid_1's auc: 0.911087\tvalid_1's binary_logloss: 0.388482\n",
      "[660]\ttraining's auc: 0.929254\ttraining's binary_logloss: 0.337334\tvalid_1's auc: 0.911008\tvalid_1's binary_logloss: 0.388319\n",
      "[680]\ttraining's auc: 0.929437\ttraining's binary_logloss: 0.336705\tvalid_1's auc: 0.911087\tvalid_1's binary_logloss: 0.387631\n",
      "[700]\ttraining's auc: 0.92957\ttraining's binary_logloss: 0.336252\tvalid_1's auc: 0.910614\tvalid_1's binary_logloss: 0.389163\n",
      "[720]\ttraining's auc: 0.929529\ttraining's binary_logloss: 0.335844\tvalid_1's auc: 0.910929\tvalid_1's binary_logloss: 0.388678\n",
      "[740]\ttraining's auc: 0.929567\ttraining's binary_logloss: 0.335309\tvalid_1's auc: 0.911087\tvalid_1's binary_logloss: 0.387965\n",
      "[760]\ttraining's auc: 0.929623\ttraining's binary_logloss: 0.334847\tvalid_1's auc: 0.911166\tvalid_1's binary_logloss: 0.387923\n",
      "[780]\ttraining's auc: 0.929823\ttraining's binary_logloss: 0.334276\tvalid_1's auc: 0.911442\tvalid_1's binary_logloss: 0.387078\n",
      "[800]\ttraining's auc: 0.930129\ttraining's binary_logloss: 0.333811\tvalid_1's auc: 0.911087\tvalid_1's binary_logloss: 0.386908\n",
      "[820]\ttraining's auc: 0.930039\ttraining's binary_logloss: 0.333475\tvalid_1's auc: 0.911442\tvalid_1's binary_logloss: 0.386474\n",
      "[840]\ttraining's auc: 0.930292\ttraining's binary_logloss: 0.33313\tvalid_1's auc: 0.911324\tvalid_1's binary_logloss: 0.386071\n",
      "[860]\ttraining's auc: 0.930235\ttraining's binary_logloss: 0.332822\tvalid_1's auc: 0.9116\tvalid_1's binary_logloss: 0.386119\n",
      "[880]\ttraining's auc: 0.930309\ttraining's binary_logloss: 0.332402\tvalid_1's auc: 0.911166\tvalid_1's binary_logloss: 0.386546\n",
      "[900]\ttraining's auc: 0.930687\ttraining's binary_logloss: 0.332004\tvalid_1's auc: 0.911679\tvalid_1's binary_logloss: 0.386152\n",
      "[920]\ttraining's auc: 0.930969\ttraining's binary_logloss: 0.331602\tvalid_1's auc: 0.912113\tvalid_1's binary_logloss: 0.385723\n",
      "[940]\ttraining's auc: 0.931237\ttraining's binary_logloss: 0.3312\tvalid_1's auc: 0.912547\tvalid_1's binary_logloss: 0.386045\n",
      "[960]\ttraining's auc: 0.931388\ttraining's binary_logloss: 0.330929\tvalid_1's auc: 0.912547\tvalid_1's binary_logloss: 0.385006\n",
      "[980]\ttraining's auc: 0.931436\ttraining's binary_logloss: 0.330653\tvalid_1's auc: 0.912428\tvalid_1's binary_logloss: 0.385172\n",
      "[1000]\ttraining's auc: 0.931323\ttraining's binary_logloss: 0.330335\tvalid_1's auc: 0.912192\tvalid_1's binary_logloss: 0.384582\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\ttraining's auc: 0.931627\ttraining's binary_logloss: 0.330705\tvalid_1's auc: 0.912428\tvalid_1's binary_logloss: 0.385287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[20]\ttraining's auc: 0.892875\ttraining's binary_logloss: 0.531261\tvalid_1's auc: 0.897902\tvalid_1's binary_logloss: 0.5288\n",
      "[40]\ttraining's auc: 0.897329\ttraining's binary_logloss: 0.459105\tvalid_1's auc: 0.901366\tvalid_1's binary_logloss: 0.458016\n",
      "[60]\ttraining's auc: 0.902772\ttraining's binary_logloss: 0.424952\tvalid_1's auc: 0.908799\tvalid_1's binary_logloss: 0.422189\n",
      "[80]\ttraining's auc: 0.905452\ttraining's binary_logloss: 0.403571\tvalid_1's auc: 0.912282\tvalid_1's binary_logloss: 0.399416\n",
      "[100]\ttraining's auc: 0.907343\ttraining's binary_logloss: 0.392739\tvalid_1's auc: 0.914675\tvalid_1's binary_logloss: 0.389148\n",
      "[120]\ttraining's auc: 0.909011\ttraining's binary_logloss: 0.386294\tvalid_1's auc: 0.914948\tvalid_1's binary_logloss: 0.383171\n",
      "[140]\ttraining's auc: 0.909882\ttraining's binary_logloss: 0.380437\tvalid_1's auc: 0.91522\tvalid_1's binary_logloss: 0.379407\n",
      "[160]\ttraining's auc: 0.911663\ttraining's binary_logloss: 0.375672\tvalid_1's auc: 0.915687\tvalid_1's binary_logloss: 0.376768\n",
      "[180]\ttraining's auc: 0.912844\ttraining's binary_logloss: 0.37281\tvalid_1's auc: 0.915104\tvalid_1's binary_logloss: 0.375795\n",
      "[200]\ttraining's auc: 0.91369\ttraining's binary_logloss: 0.370617\tvalid_1's auc: 0.915648\tvalid_1's binary_logloss: 0.374901\n",
      "[220]\ttraining's auc: 0.91437\ttraining's binary_logloss: 0.368519\tvalid_1's auc: 0.91596\tvalid_1's binary_logloss: 0.373643\n",
      "[240]\ttraining's auc: 0.914697\ttraining's binary_logloss: 0.36659\tvalid_1's auc: 0.914948\tvalid_1's binary_logloss: 0.372251\n",
      "[260]\ttraining's auc: 0.915447\ttraining's binary_logloss: 0.365116\tvalid_1's auc: 0.915571\tvalid_1's binary_logloss: 0.370735\n",
      "[280]\ttraining's auc: 0.915948\ttraining's binary_logloss: 0.363744\tvalid_1's auc: 0.915648\tvalid_1's binary_logloss: 0.369848\n",
      "[300]\ttraining's auc: 0.916407\ttraining's binary_logloss: 0.362604\tvalid_1's auc: 0.916505\tvalid_1's binary_logloss: 0.368796\n",
      "[320]\ttraining's auc: 0.916575\ttraining's binary_logloss: 0.36155\tvalid_1's auc: 0.916349\tvalid_1's binary_logloss: 0.367309\n",
      "[340]\ttraining's auc: 0.916847\ttraining's binary_logloss: 0.360697\tvalid_1's auc: 0.91775\tvalid_1's binary_logloss: 0.366258\n",
      "[360]\ttraining's auc: 0.917323\ttraining's binary_logloss: 0.359592\tvalid_1's auc: 0.918801\tvalid_1's binary_logloss: 0.365288\n",
      "[380]\ttraining's auc: 0.917501\ttraining's binary_logloss: 0.35885\tvalid_1's auc: 0.919423\tvalid_1's binary_logloss: 0.36492\n",
      "[400]\ttraining's auc: 0.917489\ttraining's binary_logloss: 0.357985\tvalid_1's auc: 0.918061\tvalid_1's binary_logloss: 0.365109\n",
      "[420]\ttraining's auc: 0.918381\ttraining's binary_logloss: 0.35706\tvalid_1's auc: 0.919851\tvalid_1's binary_logloss: 0.364592\n",
      "[440]\ttraining's auc: 0.918624\ttraining's binary_logloss: 0.356252\tvalid_1's auc: 0.920279\tvalid_1's binary_logloss: 0.363626\n",
      "[460]\ttraining's auc: 0.918987\ttraining's binary_logloss: 0.355624\tvalid_1's auc: 0.920396\tvalid_1's binary_logloss: 0.363317\n",
      "[480]\ttraining's auc: 0.919253\ttraining's binary_logloss: 0.354851\tvalid_1's auc: 0.92063\tvalid_1's binary_logloss: 0.362656\n",
      "[500]\ttraining's auc: 0.91941\ttraining's binary_logloss: 0.354022\tvalid_1's auc: 0.919968\tvalid_1's binary_logloss: 0.363077\n",
      "[520]\ttraining's auc: 0.919689\ttraining's binary_logloss: 0.353255\tvalid_1's auc: 0.921097\tvalid_1's binary_logloss: 0.362498\n",
      "[540]\ttraining's auc: 0.920008\ttraining's binary_logloss: 0.35266\tvalid_1's auc: 0.92133\tvalid_1's binary_logloss: 0.361251\n",
      "[560]\ttraining's auc: 0.920073\ttraining's binary_logloss: 0.352117\tvalid_1's auc: 0.921642\tvalid_1's binary_logloss: 0.360821\n",
      "[580]\ttraining's auc: 0.92029\ttraining's binary_logloss: 0.351537\tvalid_1's auc: 0.922186\tvalid_1's binary_logloss: 0.360083\n",
      "[600]\ttraining's auc: 0.920434\ttraining's binary_logloss: 0.351019\tvalid_1's auc: 0.922537\tvalid_1's binary_logloss: 0.359803\n",
      "[620]\ttraining's auc: 0.920448\ttraining's binary_logloss: 0.350505\tvalid_1's auc: 0.922147\tvalid_1's binary_logloss: 0.360051\n",
      "[640]\ttraining's auc: 0.920876\ttraining's binary_logloss: 0.350046\tvalid_1's auc: 0.922303\tvalid_1's binary_logloss: 0.359721\n",
      "[660]\ttraining's auc: 0.921083\ttraining's binary_logloss: 0.349401\tvalid_1's auc: 0.921992\tvalid_1's binary_logloss: 0.359363\n",
      "[680]\ttraining's auc: 0.921042\ttraining's binary_logloss: 0.348818\tvalid_1's auc: 0.92168\tvalid_1's binary_logloss: 0.358725\n",
      "[700]\ttraining's auc: 0.921456\ttraining's binary_logloss: 0.348416\tvalid_1's auc: 0.922692\tvalid_1's binary_logloss: 0.357555\n",
      "[720]\ttraining's auc: 0.921441\ttraining's binary_logloss: 0.348054\tvalid_1's auc: 0.923042\tvalid_1's binary_logloss: 0.357244\n",
      "[740]\ttraining's auc: 0.921867\ttraining's binary_logloss: 0.347514\tvalid_1's auc: 0.924054\tvalid_1's binary_logloss: 0.356693\n",
      "[760]\ttraining's auc: 0.922131\ttraining's binary_logloss: 0.347058\tvalid_1's auc: 0.925455\tvalid_1's binary_logloss: 0.356377\n",
      "[780]\ttraining's auc: 0.922059\ttraining's binary_logloss: 0.346644\tvalid_1's auc: 0.924327\tvalid_1's binary_logloss: 0.355241\n",
      "[800]\ttraining's auc: 0.92216\ttraining's binary_logloss: 0.346154\tvalid_1's auc: 0.923665\tvalid_1's binary_logloss: 0.355612\n",
      "[820]\ttraining's auc: 0.922487\ttraining's binary_logloss: 0.34569\tvalid_1's auc: 0.924366\tvalid_1's binary_logloss: 0.355435\n",
      "[840]\ttraining's auc: 0.922449\ttraining's binary_logloss: 0.345324\tvalid_1's auc: 0.923665\tvalid_1's binary_logloss: 0.355219\n",
      "[860]\ttraining's auc: 0.922557\ttraining's binary_logloss: 0.344938\tvalid_1's auc: 0.924405\tvalid_1's binary_logloss: 0.355043\n",
      "[880]\ttraining's auc: 0.923007\ttraining's binary_logloss: 0.344567\tvalid_1's auc: 0.925066\tvalid_1's binary_logloss: 0.354265\n",
      "[900]\ttraining's auc: 0.922788\ttraining's binary_logloss: 0.344156\tvalid_1's auc: 0.924599\tvalid_1's binary_logloss: 0.353396\n",
      "[920]\ttraining's auc: 0.923064\ttraining's binary_logloss: 0.343782\tvalid_1's auc: 0.924482\tvalid_1's binary_logloss: 0.35269\n",
      "[940]\ttraining's auc: 0.922968\ttraining's binary_logloss: 0.343503\tvalid_1's auc: 0.92491\tvalid_1's binary_logloss: 0.352254\n",
      "[960]\ttraining's auc: 0.923194\ttraining's binary_logloss: 0.343183\tvalid_1's auc: 0.924716\tvalid_1's binary_logloss: 0.352366\n",
      "[980]\ttraining's auc: 0.923261\ttraining's binary_logloss: 0.342851\tvalid_1's auc: 0.924443\tvalid_1's binary_logloss: 0.352365\n",
      "[1000]\ttraining's auc: 0.92337\ttraining's binary_logloss: 0.342483\tvalid_1's auc: 0.925144\tvalid_1's binary_logloss: 0.3525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\ttraining's auc: 0.923444\ttraining's binary_logloss: 0.342489\tvalid_1's auc: 0.925455\tvalid_1's binary_logloss: 0.352555\n",
      "fold 5\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[20]\ttraining's auc: 0.890908\ttraining's binary_logloss: 0.534921\tvalid_1's auc: 0.887558\tvalid_1's binary_logloss: 0.540104\n",
      "[40]\ttraining's auc: 0.899376\ttraining's binary_logloss: 0.463484\tvalid_1's auc: 0.894922\tvalid_1's binary_logloss: 0.471906\n",
      "[60]\ttraining's auc: 0.903304\ttraining's binary_logloss: 0.427596\tvalid_1's auc: 0.895581\tvalid_1's binary_logloss: 0.439613\n",
      "[80]\ttraining's auc: 0.907047\ttraining's binary_logloss: 0.404827\tvalid_1's auc: 0.896899\tvalid_1's binary_logloss: 0.422707\n",
      "[100]\ttraining's auc: 0.910602\ttraining's binary_logloss: 0.392104\tvalid_1's auc: 0.896667\tvalid_1's binary_logloss: 0.413238\n",
      "[120]\ttraining's auc: 0.912335\ttraining's binary_logloss: 0.384486\tvalid_1's auc: 0.897829\tvalid_1's binary_logloss: 0.408364\n",
      "[140]\ttraining's auc: 0.913595\ttraining's binary_logloss: 0.378408\tvalid_1's auc: 0.900039\tvalid_1's binary_logloss: 0.403593\n",
      "[160]\ttraining's auc: 0.915218\ttraining's binary_logloss: 0.371924\tvalid_1's auc: 0.901512\tvalid_1's binary_logloss: 0.399198\n",
      "[180]\ttraining's auc: 0.917105\ttraining's binary_logloss: 0.368194\tvalid_1's auc: 0.902442\tvalid_1's binary_logloss: 0.39627\n",
      "[200]\ttraining's auc: 0.91761\ttraining's binary_logloss: 0.365578\tvalid_1's auc: 0.902171\tvalid_1's binary_logloss: 0.395198\n",
      "[220]\ttraining's auc: 0.918461\ttraining's binary_logloss: 0.363186\tvalid_1's auc: 0.901512\tvalid_1's binary_logloss: 0.393884\n",
      "[240]\ttraining's auc: 0.919715\ttraining's binary_logloss: 0.360721\tvalid_1's auc: 0.902519\tvalid_1's binary_logloss: 0.392119\n",
      "[260]\ttraining's auc: 0.920189\ttraining's binary_logloss: 0.35891\tvalid_1's auc: 0.901667\tvalid_1's binary_logloss: 0.390172\n",
      "[280]\ttraining's auc: 0.920237\ttraining's binary_logloss: 0.357176\tvalid_1's auc: 0.902016\tvalid_1's binary_logloss: 0.390279\n",
      "[300]\ttraining's auc: 0.920929\ttraining's binary_logloss: 0.355104\tvalid_1's auc: 0.902868\tvalid_1's binary_logloss: 0.388956\n",
      "[320]\ttraining's auc: 0.922338\ttraining's binary_logloss: 0.353609\tvalid_1's auc: 0.903953\tvalid_1's binary_logloss: 0.387653\n",
      "[340]\ttraining's auc: 0.922788\ttraining's binary_logloss: 0.352285\tvalid_1's auc: 0.903953\tvalid_1's binary_logloss: 0.386736\n",
      "[360]\ttraining's auc: 0.9236\ttraining's binary_logloss: 0.350912\tvalid_1's auc: 0.904729\tvalid_1's binary_logloss: 0.386482\n",
      "[380]\ttraining's auc: 0.923773\ttraining's binary_logloss: 0.349769\tvalid_1's auc: 0.90686\tvalid_1's binary_logloss: 0.385884\n",
      "[400]\ttraining's auc: 0.924295\ttraining's binary_logloss: 0.348586\tvalid_1's auc: 0.906163\tvalid_1's binary_logloss: 0.385271\n",
      "[420]\ttraining's auc: 0.924653\ttraining's binary_logloss: 0.347461\tvalid_1's auc: 0.905853\tvalid_1's binary_logloss: 0.386476\n",
      "[440]\ttraining's auc: 0.924939\ttraining's binary_logloss: 0.346354\tvalid_1's auc: 0.90562\tvalid_1's binary_logloss: 0.386332\n",
      "[460]\ttraining's auc: 0.925201\ttraining's binary_logloss: 0.345514\tvalid_1's auc: 0.905194\tvalid_1's binary_logloss: 0.386095\n",
      "[480]\ttraining's auc: 0.92541\ttraining's binary_logloss: 0.344705\tvalid_1's auc: 0.906395\tvalid_1's binary_logloss: 0.385442\n",
      "[500]\ttraining's auc: 0.926006\ttraining's binary_logloss: 0.343819\tvalid_1's auc: 0.903953\tvalid_1's binary_logloss: 0.385897\n",
      "[520]\ttraining's auc: 0.92618\ttraining's binary_logloss: 0.343085\tvalid_1's auc: 0.905465\tvalid_1's binary_logloss: 0.386157\n",
      "[540]\ttraining's auc: 0.9268\ttraining's binary_logloss: 0.342194\tvalid_1's auc: 0.905465\tvalid_1's binary_logloss: 0.385516\n",
      "[560]\ttraining's auc: 0.926855\ttraining's binary_logloss: 0.341441\tvalid_1's auc: 0.904225\tvalid_1's binary_logloss: 0.385333\n",
      "[580]\ttraining's auc: 0.927043\ttraining's binary_logloss: 0.340781\tvalid_1's auc: 0.905581\tvalid_1's binary_logloss: 0.385123\n",
      "[600]\ttraining's auc: 0.927415\ttraining's binary_logloss: 0.340062\tvalid_1's auc: 0.906318\tvalid_1's binary_logloss: 0.385301\n",
      "[620]\ttraining's auc: 0.927439\ttraining's binary_logloss: 0.339424\tvalid_1's auc: 0.906202\tvalid_1's binary_logloss: 0.385308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[640]\ttraining's auc: 0.927807\ttraining's binary_logloss: 0.338808\tvalid_1's auc: 0.907054\tvalid_1's binary_logloss: 0.385103\n",
      "[660]\ttraining's auc: 0.927896\ttraining's binary_logloss: 0.338235\tvalid_1's auc: 0.905659\tvalid_1's binary_logloss: 0.385181\n",
      "[680]\ttraining's auc: 0.928242\ttraining's binary_logloss: 0.337659\tvalid_1's auc: 0.905271\tvalid_1's binary_logloss: 0.384767\n",
      "[700]\ttraining's auc: 0.928579\ttraining's binary_logloss: 0.337124\tvalid_1's auc: 0.90686\tvalid_1's binary_logloss: 0.384449\n",
      "[720]\ttraining's auc: 0.928874\ttraining's binary_logloss: 0.336577\tvalid_1's auc: 0.907519\tvalid_1's binary_logloss: 0.383824\n",
      "[740]\ttraining's auc: 0.929016\ttraining's binary_logloss: 0.336066\tvalid_1's auc: 0.907752\tvalid_1's binary_logloss: 0.383779\n",
      "[760]\ttraining's auc: 0.929245\ttraining's binary_logloss: 0.335616\tvalid_1's auc: 0.907868\tvalid_1's binary_logloss: 0.383294\n",
      "[780]\ttraining's auc: 0.929228\ttraining's binary_logloss: 0.335167\tvalid_1's auc: 0.908217\tvalid_1's binary_logloss: 0.383601\n",
      "[800]\ttraining's auc: 0.929372\ttraining's binary_logloss: 0.334682\tvalid_1's auc: 0.908101\tvalid_1's binary_logloss: 0.383091\n",
      "[820]\ttraining's auc: 0.929591\ttraining's binary_logloss: 0.334284\tvalid_1's auc: 0.908101\tvalid_1's binary_logloss: 0.382414\n",
      "[840]\ttraining's auc: 0.929562\ttraining's binary_logloss: 0.333804\tvalid_1's auc: 0.907519\tvalid_1's binary_logloss: 0.383083\n",
      "[860]\ttraining's auc: 0.929778\ttraining's binary_logloss: 0.333309\tvalid_1's auc: 0.907209\tvalid_1's binary_logloss: 0.383131\n",
      "[880]\ttraining's auc: 0.929939\ttraining's binary_logloss: 0.332827\tvalid_1's auc: 0.906899\tvalid_1's binary_logloss: 0.382679\n",
      "[900]\ttraining's auc: 0.930103\ttraining's binary_logloss: 0.332418\tvalid_1's auc: 0.907713\tvalid_1's binary_logloss: 0.382124\n",
      "[920]\ttraining's auc: 0.93024\ttraining's binary_logloss: 0.332076\tvalid_1's auc: 0.907597\tvalid_1's binary_logloss: 0.38227\n",
      "[940]\ttraining's auc: 0.930288\ttraining's binary_logloss: 0.331755\tvalid_1's auc: 0.907597\tvalid_1's binary_logloss: 0.382587\n",
      "[960]\ttraining's auc: 0.930454\ttraining's binary_logloss: 0.331328\tvalid_1's auc: 0.906628\tvalid_1's binary_logloss: 0.383496\n",
      "[980]\ttraining's auc: 0.93055\ttraining's binary_logloss: 0.330945\tvalid_1's auc: 0.906163\tvalid_1's binary_logloss: 0.383622\n",
      "[1000]\ttraining's auc: 0.930593\ttraining's binary_logloss: 0.330638\tvalid_1's auc: 0.905891\tvalid_1's binary_logloss: 0.383916\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[975]\ttraining's auc: 0.93073\ttraining's binary_logloss: 0.331077\tvalid_1's auc: 0.906512\tvalid_1's binary_logloss: 0.383384\n",
      "\n",
      " This following info is confusion matrix and accuracy score:\n",
      "[[166  40]\n",
      " [ 32 165]]\n",
      "AC and RS is: 0.8213399503722084 and 0.8375634517766497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13946c390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {'num_leaves': 60, #结果对最终效果影响较大，越大值越好，太大会出现过拟合\n",
    "          'min_data_in_leaf': 30,\n",
    "          'objective': 'binary', #定义的目标函数\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.03,\n",
    "          \"min_sum_hessian_in_leaf\": 6,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.9,  #提取的特征比率\n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.8,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"lambda_l1\": 0.1,             #l1正则\n",
    "          # 'lambda_l2': 0.001,     #l2正则\n",
    "          \"verbosity\": -1,\n",
    "          \"nthread\": -1,                #线程数量，-1表示全部线程，线程越多，运行的速度越快\n",
    "          'metric': {'binary_logloss', 'auc'},  ##评价函数选择\n",
    "          \"random_state\": 2021, #随机数种子，可以防止每次运行的结果不一致\n",
    "          # 'device': 'gpu' ##如果安装的事gpu版本的lightgbm,可以加快运算\n",
    "          }\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2021)\n",
    "prob_oof = np.zeros((data_train.shape[0], ))\n",
    "test_pred_prob = np.zeros((data_test.shape[0], ))\n",
    "\n",
    "\n",
    "## train and predict\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(data_train)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(data_train.iloc[trn_idx], label=labels_train.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(data_train.iloc[val_idx], label=labels_train.iloc[val_idx])\n",
    "\n",
    "\n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    num_boost_round=1000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=20,\n",
    "                    early_stopping_rounds=600)\n",
    "    prob_oof[val_idx] = clf.predict(data_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = urls_without_labels.columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    test_pred_prob += clf.predict(data_test[urls_without_labels.columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "threshold = 0.5\n",
    "for pred in test_pred_prob:\n",
    "    result = 1 if pred > threshold else 0\n",
    "    \n",
    "# save model\n",
    "savepath = '/Users/gexueren/Desktop/Phishing Websites Detection/PhishingWebsiteDefenseApp/model'\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "joblib.dump(clf, os.path.join(savepath, 'lgb_model.pkl'))\n",
    "\n",
    "predicts = clf.predict(data_test)\n",
    "lgb_predict = []\n",
    "for pred in predicts:\n",
    "    if pred > threshold: \n",
    "        lgb_predict.append(1)\n",
    "    else:\n",
    "        lgb_predict.append(0)\n",
    "\n",
    "print('\\n This following info is confusion matrix and accuracy score:')\n",
    "cmlgb = confusion_matrix(labels_test, lgb_predict)\n",
    "print(cmlgb)\n",
    "print('AC and RS is: {} and {}'.format(accuracy_score(labels_test, lgb_predict),\n",
    "                                       recall_score(labels_test, lgb_predict)))\n",
    "fpr, tpr, thresholds = roc_curve(labels_test, lgb_predict)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(roc_auc), lw=2)\n",
    "plt.minorticks_on()\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.heatmap(cmlgb, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "lgb.plot_importance(clf, max_num_features=30)\n",
    "plt.title(\"Featurertances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  31]\n",
      " [ 37 160]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8312655086848635"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    level0 = []\n",
    "    level0.append(('xgb', xgb.XGBClassifier()))\n",
    "    level0.append(('lgb', lgb.LGBMClassifier()))\n",
    "    level0.append(('RF', RandomForestClassifier()))\n",
    "    level0.append(('SVC', SVC()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level1 = GradientBoostingClassifier()\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "stack_model = get_stacking()\n",
    "stack_model.fit(data_train, labels_train)\n",
    "stack_model_predict = stack_model.predict(data_test)\n",
    "cmStack = confusion_matrix(labels_test, stack_model_predict)\n",
    "print(cmStack)\n",
    "accuracy_score(labels_test, stack_model_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/gexueren/Desktop/Phishing Websites Detection/PhishingWebsiteDefenseApp/model/xgb_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savepath = '/Users/gexueren/Desktop/Phishing Websites Detection/PhishingWebsiteDefenseApp/model'\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(max_depth=15,\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=5000,\n",
    "            objective='binary:logistic',\n",
    "            nthread=-1,\n",
    "            gamma=0,\n",
    "            min_child_weight=2,\n",
    "            max_delta_step=2,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.9,\n",
    "            colsample_bylevel=1,\n",
    "            reg_alpha=1,\n",
    "            reg_lambda=0.4,\n",
    "            scale_pos_weight=0.6,\n",
    "            seed=1440,\n",
    "            missing=None)\n",
    "\n",
    "xgb_classifier.fit(data_train, labels_train)\n",
    "joblib.dump(xgb_classifier, os.path.join(savepath, \"xgb_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is 1612 \n",
      "Test data is 403\n"
     ]
    }
   ],
   "source": [
    "legitimate_urls = pd.read_csv(\"./extracted_csv_files/legitimate-urls.csv\")\n",
    "phishing_urls = pd.read_csv(\"./extracted_csv_files/phishing-urls.csv\")\n",
    "urls = legitimate_urls.append(phishing_urls)\n",
    "urls = urls.drop(urls.columns[[0,3,5]],axis=1)\n",
    "urls_without_labels = urls.drop('label',axis=1)\n",
    "labels = urls['label']\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(urls_without_labels, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "data_train = data_train.values\n",
    "labels_train = labels_train.values[:, np.newaxis]\n",
    "\n",
    "data_test = data_test.values\n",
    "labels_test = labels_test.values[:, np.newaxis]\n",
    "\n",
    "class myData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = np.asarray(data)\n",
    "        self.label = np.asarray(label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        txt = torch.from_numpy(self.data[index])\n",
    "        label = torch.from_numpy(self.label[index])\n",
    "        return txt, label #返回标签\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "train_dataset = myData(data=data_train, label=labels_train)\n",
    "test_dataset = myData(data=data_test, label=labels_test)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "print('Training data is {} \\nTest data is {}'.format(train_dataset.__len__(), test_dataset.__len__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define DNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dnn, self).__init__()\n",
    "        self.l1 = nn.Linear(13, 32)\n",
    "        self.l2 = nn.Linear(32, 64)\n",
    "        self.l3 = nn.Linear(64, 30)\n",
    "        self.l4 = nn.Linear(30, 1)\n",
    "#         self.l5 = nn.Linear(15, 5)\n",
    "#         self.l6 = nn.Linear(5, 1)\n",
    "        self.dropout = nn.Dropout(p=0.5) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.l3(x))\n",
    "#         x = F.relu(self.l4(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = F.relu(self.l5(x))\n",
    "        return self.l4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dnn()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    L = 0\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = Variable(data).float(), Variable(label).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy_with_logits(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        L += loss.item()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return L/(batch_idx+1)\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data,volatile=True).float(), Variable(target).float()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.binary_cross_entropy_with_logits(output, target).data.item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1612 (0%)] Loss: 0.700074\n",
      "Train Epoch: 1 [160/1612 (10%)] Loss: 0.701498\n",
      "Train Epoch: 1 [320/1612 (20%)] Loss: 0.685195\n",
      "Train Epoch: 1 [480/1612 (30%)] Loss: 0.696389\n",
      "Train Epoch: 1 [640/1612 (40%)] Loss: 0.691091\n",
      "Train Epoch: 1 [800/1612 (50%)] Loss: 0.699648\n",
      "Train Epoch: 1 [960/1612 (59%)] Loss: 0.693768\n",
      "Train Epoch: 1 [1120/1612 (69%)] Loss: 0.690187\n",
      "Train Epoch: 1 [1280/1612 (79%)] Loss: 0.684470\n",
      "Train Epoch: 1 [1440/1612 (89%)] Loss: 0.683518\n",
      "Train Epoch: 1 [1200/1612 (99%)] Loss: 0.700793\n",
      "\n",
      "Test set: Average loss: 0.0446, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 2 [0/1612 (0%)] Loss: 0.698458\n",
      "Train Epoch: 2 [160/1612 (10%)] Loss: 0.684284\n",
      "Train Epoch: 2 [320/1612 (20%)] Loss: 0.688019\n",
      "Train Epoch: 2 [480/1612 (30%)] Loss: 0.690234\n",
      "Train Epoch: 2 [640/1612 (40%)] Loss: 0.684151\n",
      "Train Epoch: 2 [800/1612 (50%)] Loss: 0.676173\n",
      "Train Epoch: 2 [960/1612 (59%)] Loss: 0.693498\n",
      "Train Epoch: 2 [1120/1612 (69%)] Loss: 0.684513\n",
      "Train Epoch: 2 [1280/1612 (79%)] Loss: 0.696736\n",
      "Train Epoch: 2 [1440/1612 (89%)] Loss: 0.686573\n",
      "Train Epoch: 2 [1200/1612 (99%)] Loss: 0.691838\n",
      "\n",
      "Test set: Average loss: 0.0445, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 3 [0/1612 (0%)] Loss: 0.688436\n",
      "Train Epoch: 3 [160/1612 (10%)] Loss: 0.692214\n",
      "Train Epoch: 3 [320/1612 (20%)] Loss: 0.688838\n",
      "Train Epoch: 3 [480/1612 (30%)] Loss: 0.687598\n",
      "Train Epoch: 3 [640/1612 (40%)] Loss: 0.689396\n",
      "Train Epoch: 3 [800/1612 (50%)] Loss: 0.692060\n",
      "Train Epoch: 3 [960/1612 (59%)] Loss: 0.682565\n",
      "Train Epoch: 3 [1120/1612 (69%)] Loss: 0.685346\n",
      "Train Epoch: 3 [1280/1612 (79%)] Loss: 0.697639\n",
      "Train Epoch: 3 [1440/1612 (89%)] Loss: 0.682778\n",
      "Train Epoch: 3 [1200/1612 (99%)] Loss: 0.689366\n",
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 4 [0/1612 (0%)] Loss: 0.691300\n",
      "Train Epoch: 4 [160/1612 (10%)] Loss: 0.692471\n",
      "Train Epoch: 4 [320/1612 (20%)] Loss: 0.683794\n",
      "Train Epoch: 4 [480/1612 (30%)] Loss: 0.689042\n",
      "Train Epoch: 4 [640/1612 (40%)] Loss: 0.689004\n",
      "Train Epoch: 4 [800/1612 (50%)] Loss: 0.683085\n",
      "Train Epoch: 4 [960/1612 (59%)] Loss: 0.692828\n",
      "Train Epoch: 4 [1120/1612 (69%)] Loss: 0.694674\n",
      "Train Epoch: 4 [1280/1612 (79%)] Loss: 0.694767\n",
      "Train Epoch: 4 [1440/1612 (89%)] Loss: 0.694935\n",
      "Train Epoch: 4 [1200/1612 (99%)] Loss: 0.683739\n",
      "\n",
      "Test set: Average loss: 0.0443, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 5 [0/1612 (0%)] Loss: 0.685623\n",
      "Train Epoch: 5 [160/1612 (10%)] Loss: 0.680068\n",
      "Train Epoch: 5 [320/1612 (20%)] Loss: 0.689630\n",
      "Train Epoch: 5 [480/1612 (30%)] Loss: 0.689733\n",
      "Train Epoch: 5 [640/1612 (40%)] Loss: 0.688348\n",
      "Train Epoch: 5 [800/1612 (50%)] Loss: 0.688884\n",
      "Train Epoch: 5 [960/1612 (59%)] Loss: 0.690288\n",
      "Train Epoch: 5 [1120/1612 (69%)] Loss: 0.699274\n",
      "Train Epoch: 5 [1280/1612 (79%)] Loss: 0.694660\n",
      "Train Epoch: 5 [1440/1612 (89%)] Loss: 0.681953\n",
      "Train Epoch: 5 [1200/1612 (99%)] Loss: 0.686557\n",
      "\n",
      "Test set: Average loss: 0.0442, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 6 [0/1612 (0%)] Loss: 0.692592\n",
      "Train Epoch: 6 [160/1612 (10%)] Loss: 0.677859\n",
      "Train Epoch: 6 [320/1612 (20%)] Loss: 0.681774\n",
      "Train Epoch: 6 [480/1612 (30%)] Loss: 0.691663\n",
      "Train Epoch: 6 [640/1612 (40%)] Loss: 0.702154\n",
      "Train Epoch: 6 [800/1612 (50%)] Loss: 0.695845\n",
      "Train Epoch: 6 [960/1612 (59%)] Loss: 0.693031\n",
      "Train Epoch: 6 [1120/1612 (69%)] Loss: 0.692148\n",
      "Train Epoch: 6 [1280/1612 (79%)] Loss: 0.698696\n",
      "Train Epoch: 6 [1440/1612 (89%)] Loss: 0.686626\n",
      "Train Epoch: 6 [1200/1612 (99%)] Loss: 0.690716\n",
      "\n",
      "Test set: Average loss: 0.0440, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 7 [0/1612 (0%)] Loss: 0.678997\n",
      "Train Epoch: 7 [160/1612 (10%)] Loss: 0.673740\n",
      "Train Epoch: 7 [320/1612 (20%)] Loss: 0.679892\n",
      "Train Epoch: 7 [480/1612 (30%)] Loss: 0.679260\n",
      "Train Epoch: 7 [640/1612 (40%)] Loss: 0.679021\n",
      "Train Epoch: 7 [800/1612 (50%)] Loss: 0.684064\n",
      "Train Epoch: 7 [960/1612 (59%)] Loss: 0.687116\n",
      "Train Epoch: 7 [1120/1612 (69%)] Loss: 0.673852\n",
      "Train Epoch: 7 [1280/1612 (79%)] Loss: 0.697129\n",
      "Train Epoch: 7 [1440/1612 (89%)] Loss: 0.690647\n",
      "Train Epoch: 7 [1200/1612 (99%)] Loss: 0.669622\n",
      "\n",
      "Test set: Average loss: 0.0439, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 8 [0/1612 (0%)] Loss: 0.665236\n",
      "Train Epoch: 8 [160/1612 (10%)] Loss: 0.671497\n",
      "Train Epoch: 8 [320/1612 (20%)] Loss: 0.677065\n",
      "Train Epoch: 8 [480/1612 (30%)] Loss: 0.673492\n",
      "Train Epoch: 8 [640/1612 (40%)] Loss: 0.680766\n",
      "Train Epoch: 8 [800/1612 (50%)] Loss: 0.675759\n",
      "Train Epoch: 8 [960/1612 (59%)] Loss: 0.705430\n",
      "Train Epoch: 8 [1120/1612 (69%)] Loss: 0.664697\n",
      "Train Epoch: 8 [1280/1612 (79%)] Loss: 0.685397\n",
      "Train Epoch: 8 [1440/1612 (89%)] Loss: 0.682535\n",
      "Train Epoch: 8 [1200/1612 (99%)] Loss: 0.669957\n",
      "\n",
      "Test set: Average loss: 0.0436, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 9 [0/1612 (0%)] Loss: 0.672130\n",
      "Train Epoch: 9 [160/1612 (10%)] Loss: 0.683860\n",
      "Train Epoch: 9 [320/1612 (20%)] Loss: 0.683012\n",
      "Train Epoch: 9 [480/1612 (30%)] Loss: 0.672088\n",
      "Train Epoch: 9 [640/1612 (40%)] Loss: 0.678757\n",
      "Train Epoch: 9 [800/1612 (50%)] Loss: 0.699019\n",
      "Train Epoch: 9 [960/1612 (59%)] Loss: 0.672542\n",
      "Train Epoch: 9 [1120/1612 (69%)] Loss: 0.642972\n",
      "Train Epoch: 9 [1280/1612 (79%)] Loss: 0.688506\n",
      "Train Epoch: 9 [1440/1612 (89%)] Loss: 0.683705\n",
      "Train Epoch: 9 [1200/1612 (99%)] Loss: 0.709538\n",
      "\n",
      "Test set: Average loss: 0.0434, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 10 [0/1612 (0%)] Loss: 0.660905\n",
      "Train Epoch: 10 [160/1612 (10%)] Loss: 0.681815\n",
      "Train Epoch: 10 [320/1612 (20%)] Loss: 0.699266\n",
      "Train Epoch: 10 [480/1612 (30%)] Loss: 0.685676\n",
      "Train Epoch: 10 [640/1612 (40%)] Loss: 0.692575\n",
      "Train Epoch: 10 [800/1612 (50%)] Loss: 0.670946\n",
      "Train Epoch: 10 [960/1612 (59%)] Loss: 0.658433\n",
      "Train Epoch: 10 [1120/1612 (69%)] Loss: 0.684318\n",
      "Train Epoch: 10 [1280/1612 (79%)] Loss: 0.687200\n",
      "Train Epoch: 10 [1440/1612 (89%)] Loss: 0.668901\n",
      "Train Epoch: 10 [1200/1612 (99%)] Loss: 0.677976\n",
      "\n",
      "Test set: Average loss: 0.0431, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 11 [0/1612 (0%)] Loss: 0.675917\n",
      "Train Epoch: 11 [160/1612 (10%)] Loss: 0.669210\n",
      "Train Epoch: 11 [320/1612 (20%)] Loss: 0.658769\n",
      "Train Epoch: 11 [480/1612 (30%)] Loss: 0.653036\n",
      "Train Epoch: 11 [640/1612 (40%)] Loss: 0.673175\n",
      "Train Epoch: 11 [800/1612 (50%)] Loss: 0.674168\n",
      "Train Epoch: 11 [960/1612 (59%)] Loss: 0.681315\n",
      "Train Epoch: 11 [1120/1612 (69%)] Loss: 0.675174\n",
      "Train Epoch: 11 [1280/1612 (79%)] Loss: 0.690798\n",
      "Train Epoch: 11 [1440/1612 (89%)] Loss: 0.691854\n",
      "Train Epoch: 11 [1200/1612 (99%)] Loss: 0.690473\n",
      "\n",
      "Test set: Average loss: 0.0427, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 12 [0/1612 (0%)] Loss: 0.699872\n",
      "Train Epoch: 12 [160/1612 (10%)] Loss: 0.658034\n",
      "Train Epoch: 12 [320/1612 (20%)] Loss: 0.651246\n",
      "Train Epoch: 12 [480/1612 (30%)] Loss: 0.658766\n",
      "Train Epoch: 12 [640/1612 (40%)] Loss: 0.670014\n",
      "Train Epoch: 12 [800/1612 (50%)] Loss: 0.667459\n",
      "Train Epoch: 12 [960/1612 (59%)] Loss: 0.651818\n",
      "Train Epoch: 12 [1120/1612 (69%)] Loss: 0.673418\n",
      "Train Epoch: 12 [1280/1612 (79%)] Loss: 0.660420\n",
      "Train Epoch: 12 [1440/1612 (89%)] Loss: 0.667695\n",
      "Train Epoch: 12 [1200/1612 (99%)] Loss: 0.621749\n",
      "\n",
      "Test set: Average loss: 0.0422, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 13 [0/1612 (0%)] Loss: 0.653244\n",
      "Train Epoch: 13 [160/1612 (10%)] Loss: 0.655329\n",
      "Train Epoch: 13 [320/1612 (20%)] Loss: 0.610512\n",
      "Train Epoch: 13 [480/1612 (30%)] Loss: 0.643235\n",
      "Train Epoch: 13 [640/1612 (40%)] Loss: 0.663383\n",
      "Train Epoch: 13 [800/1612 (50%)] Loss: 0.653380\n",
      "Train Epoch: 13 [960/1612 (59%)] Loss: 0.651863\n",
      "Train Epoch: 13 [1120/1612 (69%)] Loss: 0.642716\n",
      "Train Epoch: 13 [1280/1612 (79%)] Loss: 0.661812\n",
      "Train Epoch: 13 [1440/1612 (89%)] Loss: 0.650997\n",
      "Train Epoch: 13 [1200/1612 (99%)] Loss: 0.645428\n",
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 14 [0/1612 (0%)] Loss: 0.677566\n",
      "Train Epoch: 14 [160/1612 (10%)] Loss: 0.663526\n",
      "Train Epoch: 14 [320/1612 (20%)] Loss: 0.633692\n",
      "Train Epoch: 14 [480/1612 (30%)] Loss: 0.670572\n",
      "Train Epoch: 14 [640/1612 (40%)] Loss: 0.630782\n",
      "Train Epoch: 14 [800/1612 (50%)] Loss: 0.655053\n",
      "Train Epoch: 14 [960/1612 (59%)] Loss: 0.623546\n",
      "Train Epoch: 14 [1120/1612 (69%)] Loss: 0.654032\n",
      "Train Epoch: 14 [1280/1612 (79%)] Loss: 0.642510\n",
      "Train Epoch: 14 [1440/1612 (89%)] Loss: 0.667970\n",
      "Train Epoch: 14 [1200/1612 (99%)] Loss: 0.653218\n",
      "\n",
      "Test set: Average loss: 0.0413, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 15 [0/1612 (0%)] Loss: 0.656054\n",
      "Train Epoch: 15 [160/1612 (10%)] Loss: 0.636260\n",
      "Train Epoch: 15 [320/1612 (20%)] Loss: 0.584947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [480/1612 (30%)] Loss: 0.626867\n",
      "Train Epoch: 15 [640/1612 (40%)] Loss: 0.680899\n",
      "Train Epoch: 15 [800/1612 (50%)] Loss: 0.667914\n",
      "Train Epoch: 15 [960/1612 (59%)] Loss: 0.698133\n",
      "Train Epoch: 15 [1120/1612 (69%)] Loss: 0.661751\n",
      "Train Epoch: 15 [1280/1612 (79%)] Loss: 0.624837\n",
      "Train Epoch: 15 [1440/1612 (89%)] Loss: 0.734289\n",
      "Train Epoch: 15 [1200/1612 (99%)] Loss: 0.657010\n",
      "\n",
      "Test set: Average loss: 0.0408, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 16 [0/1612 (0%)] Loss: 0.684817\n",
      "Train Epoch: 16 [160/1612 (10%)] Loss: 0.599656\n",
      "Train Epoch: 16 [320/1612 (20%)] Loss: 0.648255\n",
      "Train Epoch: 16 [480/1612 (30%)] Loss: 0.625121\n",
      "Train Epoch: 16 [640/1612 (40%)] Loss: 0.682848\n",
      "Train Epoch: 16 [800/1612 (50%)] Loss: 0.648326\n",
      "Train Epoch: 16 [960/1612 (59%)] Loss: 0.675334\n",
      "Train Epoch: 16 [1120/1612 (69%)] Loss: 0.684882\n",
      "Train Epoch: 16 [1280/1612 (79%)] Loss: 0.605962\n",
      "Train Epoch: 16 [1440/1612 (89%)] Loss: 0.707804\n",
      "Train Epoch: 16 [1200/1612 (99%)] Loss: 0.631380\n",
      "\n",
      "Test set: Average loss: 0.0401, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 17 [0/1612 (0%)] Loss: 0.620018\n",
      "Train Epoch: 17 [160/1612 (10%)] Loss: 0.613380\n",
      "Train Epoch: 17 [320/1612 (20%)] Loss: 0.579493\n",
      "Train Epoch: 17 [480/1612 (30%)] Loss: 0.653648\n",
      "Train Epoch: 17 [640/1612 (40%)] Loss: 0.617543\n",
      "Train Epoch: 17 [800/1612 (50%)] Loss: 0.604112\n",
      "Train Epoch: 17 [960/1612 (59%)] Loss: 0.573037\n",
      "Train Epoch: 17 [1120/1612 (69%)] Loss: 0.517816\n",
      "Train Epoch: 17 [1280/1612 (79%)] Loss: 0.629473\n",
      "Train Epoch: 17 [1440/1612 (89%)] Loss: 0.669737\n",
      "Train Epoch: 17 [1200/1612 (99%)] Loss: 0.607117\n",
      "\n",
      "Test set: Average loss: 0.0392, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 18 [0/1612 (0%)] Loss: 0.530863\n",
      "Train Epoch: 18 [160/1612 (10%)] Loss: 0.625489\n",
      "Train Epoch: 18 [320/1612 (20%)] Loss: 0.577247\n",
      "Train Epoch: 18 [480/1612 (30%)] Loss: 0.605054\n",
      "Train Epoch: 18 [640/1612 (40%)] Loss: 0.675321\n",
      "Train Epoch: 18 [800/1612 (50%)] Loss: 0.623576\n",
      "Train Epoch: 18 [960/1612 (59%)] Loss: 0.590502\n",
      "Train Epoch: 18 [1120/1612 (69%)] Loss: 0.644523\n",
      "Train Epoch: 18 [1280/1612 (79%)] Loss: 0.551553\n",
      "Train Epoch: 18 [1440/1612 (89%)] Loss: 0.619278\n",
      "Train Epoch: 18 [1200/1612 (99%)] Loss: 0.624395\n",
      "\n",
      "Test set: Average loss: 0.0386, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 19 [0/1612 (0%)] Loss: 0.634037\n",
      "Train Epoch: 19 [160/1612 (10%)] Loss: 0.632817\n",
      "Train Epoch: 19 [320/1612 (20%)] Loss: 0.595860\n",
      "Train Epoch: 19 [480/1612 (30%)] Loss: 0.644101\n",
      "Train Epoch: 19 [640/1612 (40%)] Loss: 0.534216\n",
      "Train Epoch: 19 [800/1612 (50%)] Loss: 0.563979\n",
      "Train Epoch: 19 [960/1612 (59%)] Loss: 0.501210\n",
      "Train Epoch: 19 [1120/1612 (69%)] Loss: 0.573921\n",
      "Train Epoch: 19 [1280/1612 (79%)] Loss: 0.640741\n",
      "Train Epoch: 19 [1440/1612 (89%)] Loss: 0.670137\n",
      "Train Epoch: 19 [1200/1612 (99%)] Loss: 0.520531\n",
      "\n",
      "Test set: Average loss: 0.0373, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 20 [0/1612 (0%)] Loss: 0.643908\n",
      "Train Epoch: 20 [160/1612 (10%)] Loss: 0.653673\n",
      "Train Epoch: 20 [320/1612 (20%)] Loss: 0.609858\n",
      "Train Epoch: 20 [480/1612 (30%)] Loss: 0.463950\n",
      "Train Epoch: 20 [640/1612 (40%)] Loss: 0.601403\n",
      "Train Epoch: 20 [800/1612 (50%)] Loss: 0.580822\n",
      "Train Epoch: 20 [960/1612 (59%)] Loss: 0.731885\n",
      "Train Epoch: 20 [1120/1612 (69%)] Loss: 0.690701\n",
      "Train Epoch: 20 [1280/1612 (79%)] Loss: 0.584155\n",
      "Train Epoch: 20 [1440/1612 (89%)] Loss: 0.560308\n",
      "Train Epoch: 20 [1200/1612 (99%)] Loss: 0.616530\n",
      "\n",
      "Test set: Average loss: 0.0367, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 21 [0/1612 (0%)] Loss: 0.620311\n",
      "Train Epoch: 21 [160/1612 (10%)] Loss: 0.566632\n",
      "Train Epoch: 21 [320/1612 (20%)] Loss: 0.505619\n",
      "Train Epoch: 21 [480/1612 (30%)] Loss: 0.536621\n",
      "Train Epoch: 21 [640/1612 (40%)] Loss: 0.520244\n",
      "Train Epoch: 21 [800/1612 (50%)] Loss: 0.654404\n",
      "Train Epoch: 21 [960/1612 (59%)] Loss: 0.615233\n",
      "Train Epoch: 21 [1120/1612 (69%)] Loss: 0.610869\n",
      "Train Epoch: 21 [1280/1612 (79%)] Loss: 0.622074\n",
      "Train Epoch: 21 [1440/1612 (89%)] Loss: 0.578679\n",
      "Train Epoch: 21 [1200/1612 (99%)] Loss: 0.586820\n",
      "\n",
      "Test set: Average loss: 0.0359, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 22 [0/1612 (0%)] Loss: 0.630148\n",
      "Train Epoch: 22 [160/1612 (10%)] Loss: 0.584708\n",
      "Train Epoch: 22 [320/1612 (20%)] Loss: 0.508641\n",
      "Train Epoch: 22 [480/1612 (30%)] Loss: 0.537763\n",
      "Train Epoch: 22 [640/1612 (40%)] Loss: 0.712853\n",
      "Train Epoch: 22 [800/1612 (50%)] Loss: 0.709260\n",
      "Train Epoch: 22 [960/1612 (59%)] Loss: 0.534592\n",
      "Train Epoch: 22 [1120/1612 (69%)] Loss: 0.521548\n",
      "Train Epoch: 22 [1280/1612 (79%)] Loss: 0.587212\n",
      "Train Epoch: 22 [1440/1612 (89%)] Loss: 0.718962\n",
      "Train Epoch: 22 [1200/1612 (99%)] Loss: 0.607053\n",
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 23 [0/1612 (0%)] Loss: 0.534090\n",
      "Train Epoch: 23 [160/1612 (10%)] Loss: 0.451819\n",
      "Train Epoch: 23 [320/1612 (20%)] Loss: 0.512250\n",
      "Train Epoch: 23 [480/1612 (30%)] Loss: 0.599498\n",
      "Train Epoch: 23 [640/1612 (40%)] Loss: 0.581244\n",
      "Train Epoch: 23 [800/1612 (50%)] Loss: 0.534898\n",
      "Train Epoch: 23 [960/1612 (59%)] Loss: 0.611243\n",
      "Train Epoch: 23 [1120/1612 (69%)] Loss: 0.685929\n",
      "Train Epoch: 23 [1280/1612 (79%)] Loss: 0.490688\n",
      "Train Epoch: 23 [1440/1612 (89%)] Loss: 0.691239\n",
      "Train Epoch: 23 [1200/1612 (99%)] Loss: 0.492022\n",
      "\n",
      "Test set: Average loss: 0.0345, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 24 [0/1612 (0%)] Loss: 0.662456\n",
      "Train Epoch: 24 [160/1612 (10%)] Loss: 0.616617\n",
      "Train Epoch: 24 [320/1612 (20%)] Loss: 0.518927\n",
      "Train Epoch: 24 [480/1612 (30%)] Loss: 0.421223\n",
      "Train Epoch: 24 [640/1612 (40%)] Loss: 0.714123\n",
      "Train Epoch: 24 [800/1612 (50%)] Loss: 0.521295\n",
      "Train Epoch: 24 [960/1612 (59%)] Loss: 0.514387\n",
      "Train Epoch: 24 [1120/1612 (69%)] Loss: 0.685361\n",
      "Train Epoch: 24 [1280/1612 (79%)] Loss: 0.535064\n",
      "Train Epoch: 24 [1440/1612 (89%)] Loss: 0.688687\n",
      "Train Epoch: 24 [1200/1612 (99%)] Loss: 0.645990\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 25 [0/1612 (0%)] Loss: 0.696878\n",
      "Train Epoch: 25 [160/1612 (10%)] Loss: 0.471267\n",
      "Train Epoch: 25 [320/1612 (20%)] Loss: 0.574805\n",
      "Train Epoch: 25 [480/1612 (30%)] Loss: 0.642964\n",
      "Train Epoch: 25 [640/1612 (40%)] Loss: 0.547740\n",
      "Train Epoch: 25 [800/1612 (50%)] Loss: 0.534738\n",
      "Train Epoch: 25 [960/1612 (59%)] Loss: 0.478449\n",
      "Train Epoch: 25 [1120/1612 (69%)] Loss: 0.499808\n",
      "Train Epoch: 25 [1280/1612 (79%)] Loss: 0.593724\n",
      "Train Epoch: 25 [1440/1612 (89%)] Loss: 0.484271\n",
      "Train Epoch: 25 [1200/1612 (99%)] Loss: 0.666879\n",
      "\n",
      "Test set: Average loss: 0.0348, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 26 [0/1612 (0%)] Loss: 0.630678\n",
      "Train Epoch: 26 [160/1612 (10%)] Loss: 0.660895\n",
      "Train Epoch: 26 [320/1612 (20%)] Loss: 0.539295\n",
      "Train Epoch: 26 [480/1612 (30%)] Loss: 0.639733\n",
      "Train Epoch: 26 [640/1612 (40%)] Loss: 0.598126\n",
      "Train Epoch: 26 [800/1612 (50%)] Loss: 0.539590\n",
      "Train Epoch: 26 [960/1612 (59%)] Loss: 0.566970\n",
      "Train Epoch: 26 [1120/1612 (69%)] Loss: 0.637833\n",
      "Train Epoch: 26 [1280/1612 (79%)] Loss: 0.652038\n",
      "Train Epoch: 26 [1440/1612 (89%)] Loss: 0.547758\n",
      "Train Epoch: 26 [1200/1612 (99%)] Loss: 0.500670\n",
      "\n",
      "Test set: Average loss: 0.0338, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 27 [0/1612 (0%)] Loss: 0.757626\n",
      "Train Epoch: 27 [160/1612 (10%)] Loss: 0.538377\n",
      "Train Epoch: 27 [320/1612 (20%)] Loss: 0.681247\n",
      "Train Epoch: 27 [480/1612 (30%)] Loss: 0.533200\n",
      "Train Epoch: 27 [640/1612 (40%)] Loss: 0.572829\n",
      "Train Epoch: 27 [800/1612 (50%)] Loss: 0.624596\n",
      "Train Epoch: 27 [960/1612 (59%)] Loss: 0.533218\n",
      "Train Epoch: 27 [1120/1612 (69%)] Loss: 0.545342\n",
      "Train Epoch: 27 [1280/1612 (79%)] Loss: 0.502277\n",
      "Train Epoch: 27 [1440/1612 (89%)] Loss: 0.418733\n",
      "Train Epoch: 27 [1200/1612 (99%)] Loss: 0.606305\n",
      "\n",
      "Test set: Average loss: 0.0334, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 28 [0/1612 (0%)] Loss: 0.756939\n",
      "Train Epoch: 28 [160/1612 (10%)] Loss: 0.543987\n",
      "Train Epoch: 28 [320/1612 (20%)] Loss: 0.574133\n",
      "Train Epoch: 28 [480/1612 (30%)] Loss: 0.595286\n",
      "Train Epoch: 28 [640/1612 (40%)] Loss: 0.514279\n",
      "Train Epoch: 28 [800/1612 (50%)] Loss: 0.525510\n",
      "Train Epoch: 28 [960/1612 (59%)] Loss: 0.646612\n",
      "Train Epoch: 28 [1120/1612 (69%)] Loss: 0.562694\n",
      "Train Epoch: 28 [1280/1612 (79%)] Loss: 0.618042\n",
      "Train Epoch: 28 [1440/1612 (89%)] Loss: 0.534379\n",
      "Train Epoch: 28 [1200/1612 (99%)] Loss: 0.501350\n",
      "\n",
      "Test set: Average loss: 0.0333, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 29 [0/1612 (0%)] Loss: 0.490035\n",
      "Train Epoch: 29 [160/1612 (10%)] Loss: 0.653980\n",
      "Train Epoch: 29 [320/1612 (20%)] Loss: 0.443268\n",
      "Train Epoch: 29 [480/1612 (30%)] Loss: 0.525615\n",
      "Train Epoch: 29 [640/1612 (40%)] Loss: 0.475506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [800/1612 (50%)] Loss: 0.614203\n",
      "Train Epoch: 29 [960/1612 (59%)] Loss: 0.476769\n",
      "Train Epoch: 29 [1120/1612 (69%)] Loss: 0.465707\n",
      "Train Epoch: 29 [1280/1612 (79%)] Loss: 0.577596\n",
      "Train Epoch: 29 [1440/1612 (89%)] Loss: 0.629090\n",
      "Train Epoch: 29 [1200/1612 (99%)] Loss: 0.519992\n",
      "\n",
      "Test set: Average loss: 0.0334, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 30 [0/1612 (0%)] Loss: 0.430618\n",
      "Train Epoch: 30 [160/1612 (10%)] Loss: 0.573275\n",
      "Train Epoch: 30 [320/1612 (20%)] Loss: 0.448782\n",
      "Train Epoch: 30 [480/1612 (30%)] Loss: 0.482654\n",
      "Train Epoch: 30 [640/1612 (40%)] Loss: 0.593916\n",
      "Train Epoch: 30 [800/1612 (50%)] Loss: 0.356016\n",
      "Train Epoch: 30 [960/1612 (59%)] Loss: 0.510216\n",
      "Train Epoch: 30 [1120/1612 (69%)] Loss: 0.570002\n",
      "Train Epoch: 30 [1280/1612 (79%)] Loss: 0.491733\n",
      "Train Epoch: 30 [1440/1612 (89%)] Loss: 0.606330\n",
      "Train Epoch: 30 [1200/1612 (99%)] Loss: 0.475233\n",
      "\n",
      "Test set: Average loss: 0.0336, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 31 [0/1612 (0%)] Loss: 0.433516\n",
      "Train Epoch: 31 [160/1612 (10%)] Loss: 0.516167\n",
      "Train Epoch: 31 [320/1612 (20%)] Loss: 0.335878\n",
      "Train Epoch: 31 [480/1612 (30%)] Loss: 0.664137\n",
      "Train Epoch: 31 [640/1612 (40%)] Loss: 0.495217\n",
      "Train Epoch: 31 [800/1612 (50%)] Loss: 0.404205\n",
      "Train Epoch: 31 [960/1612 (59%)] Loss: 0.707787\n",
      "Train Epoch: 31 [1120/1612 (69%)] Loss: 0.629864\n",
      "Train Epoch: 31 [1280/1612 (79%)] Loss: 0.381069\n",
      "Train Epoch: 31 [1440/1612 (89%)] Loss: 0.671433\n",
      "Train Epoch: 31 [1200/1612 (99%)] Loss: 0.511304\n",
      "\n",
      "Test set: Average loss: 0.0350, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 32 [0/1612 (0%)] Loss: 0.510929\n",
      "Train Epoch: 32 [160/1612 (10%)] Loss: 0.884647\n",
      "Train Epoch: 32 [320/1612 (20%)] Loss: 0.351888\n",
      "Train Epoch: 32 [480/1612 (30%)] Loss: 0.698860\n",
      "Train Epoch: 32 [640/1612 (40%)] Loss: 0.677011\n",
      "Train Epoch: 32 [800/1612 (50%)] Loss: 0.532723\n",
      "Train Epoch: 32 [960/1612 (59%)] Loss: 0.321697\n",
      "Train Epoch: 32 [1120/1612 (69%)] Loss: 0.357196\n",
      "Train Epoch: 32 [1280/1612 (79%)] Loss: 0.496223\n",
      "Train Epoch: 32 [1440/1612 (89%)] Loss: 0.519119\n",
      "Train Epoch: 32 [1200/1612 (99%)] Loss: 0.444216\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 33 [0/1612 (0%)] Loss: 0.556023\n",
      "Train Epoch: 33 [160/1612 (10%)] Loss: 0.603789\n",
      "Train Epoch: 33 [320/1612 (20%)] Loss: 0.554483\n",
      "Train Epoch: 33 [480/1612 (30%)] Loss: 0.438563\n",
      "Train Epoch: 33 [640/1612 (40%)] Loss: 0.345799\n",
      "Train Epoch: 33 [800/1612 (50%)] Loss: 0.602599\n",
      "Train Epoch: 33 [960/1612 (59%)] Loss: 0.560605\n",
      "Train Epoch: 33 [1120/1612 (69%)] Loss: 0.697420\n",
      "Train Epoch: 33 [1280/1612 (79%)] Loss: 0.596271\n",
      "Train Epoch: 33 [1440/1612 (89%)] Loss: 0.537497\n",
      "Train Epoch: 33 [1200/1612 (99%)] Loss: 0.508362\n",
      "\n",
      "Test set: Average loss: 0.0329, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 34 [0/1612 (0%)] Loss: 0.448923\n",
      "Train Epoch: 34 [160/1612 (10%)] Loss: 0.559378\n",
      "Train Epoch: 34 [320/1612 (20%)] Loss: 0.595982\n",
      "Train Epoch: 34 [480/1612 (30%)] Loss: 0.396984\n",
      "Train Epoch: 34 [640/1612 (40%)] Loss: 0.479763\n",
      "Train Epoch: 34 [800/1612 (50%)] Loss: 0.694257\n",
      "Train Epoch: 34 [960/1612 (59%)] Loss: 0.569306\n",
      "Train Epoch: 34 [1120/1612 (69%)] Loss: 0.452011\n",
      "Train Epoch: 34 [1280/1612 (79%)] Loss: 0.463344\n",
      "Train Epoch: 34 [1440/1612 (89%)] Loss: 0.516802\n",
      "Train Epoch: 34 [1200/1612 (99%)] Loss: 0.493271\n",
      "\n",
      "Test set: Average loss: 0.0326, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 35 [0/1612 (0%)] Loss: 0.449619\n",
      "Train Epoch: 35 [160/1612 (10%)] Loss: 0.498323\n",
      "Train Epoch: 35 [320/1612 (20%)] Loss: 0.569579\n",
      "Train Epoch: 35 [480/1612 (30%)] Loss: 0.674427\n",
      "Train Epoch: 35 [640/1612 (40%)] Loss: 0.729553\n",
      "Train Epoch: 35 [800/1612 (50%)] Loss: 0.595185\n",
      "Train Epoch: 35 [960/1612 (59%)] Loss: 0.767383\n",
      "Train Epoch: 35 [1120/1612 (69%)] Loss: 0.427890\n",
      "Train Epoch: 35 [1280/1612 (79%)] Loss: 0.408007\n",
      "Train Epoch: 35 [1440/1612 (89%)] Loss: 0.392335\n",
      "Train Epoch: 35 [1200/1612 (99%)] Loss: 0.580050\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 36 [0/1612 (0%)] Loss: 0.628070\n",
      "Train Epoch: 36 [160/1612 (10%)] Loss: 0.434947\n",
      "Train Epoch: 36 [320/1612 (20%)] Loss: 0.638255\n",
      "Train Epoch: 36 [480/1612 (30%)] Loss: 0.409442\n",
      "Train Epoch: 36 [640/1612 (40%)] Loss: 0.788335\n",
      "Train Epoch: 36 [800/1612 (50%)] Loss: 0.611163\n",
      "Train Epoch: 36 [960/1612 (59%)] Loss: 0.560725\n",
      "Train Epoch: 36 [1120/1612 (69%)] Loss: 0.612931\n",
      "Train Epoch: 36 [1280/1612 (79%)] Loss: 0.426785\n",
      "Train Epoch: 36 [1440/1612 (89%)] Loss: 0.443132\n",
      "Train Epoch: 36 [1200/1612 (99%)] Loss: 0.411189\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 37 [0/1612 (0%)] Loss: 0.712324\n",
      "Train Epoch: 37 [160/1612 (10%)] Loss: 0.468746\n",
      "Train Epoch: 37 [320/1612 (20%)] Loss: 0.767969\n",
      "Train Epoch: 37 [480/1612 (30%)] Loss: 0.559223\n",
      "Train Epoch: 37 [640/1612 (40%)] Loss: 0.596375\n",
      "Train Epoch: 37 [800/1612 (50%)] Loss: 0.527689\n",
      "Train Epoch: 37 [960/1612 (59%)] Loss: 0.505279\n",
      "Train Epoch: 37 [1120/1612 (69%)] Loss: 0.510398\n",
      "Train Epoch: 37 [1280/1612 (79%)] Loss: 0.434250\n",
      "Train Epoch: 37 [1440/1612 (89%)] Loss: 0.642258\n",
      "Train Epoch: 37 [1200/1612 (99%)] Loss: 0.517532\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 38 [0/1612 (0%)] Loss: 0.448586\n",
      "Train Epoch: 38 [160/1612 (10%)] Loss: 0.631232\n",
      "Train Epoch: 38 [320/1612 (20%)] Loss: 0.544427\n",
      "Train Epoch: 38 [480/1612 (30%)] Loss: 0.679634\n",
      "Train Epoch: 38 [640/1612 (40%)] Loss: 0.631090\n",
      "Train Epoch: 38 [800/1612 (50%)] Loss: 0.454632\n",
      "Train Epoch: 38 [960/1612 (59%)] Loss: 0.518881\n",
      "Train Epoch: 38 [1120/1612 (69%)] Loss: 0.356434\n",
      "Train Epoch: 38 [1280/1612 (79%)] Loss: 0.632464\n",
      "Train Epoch: 38 [1440/1612 (89%)] Loss: 0.404940\n",
      "Train Epoch: 38 [1200/1612 (99%)] Loss: 0.594542\n",
      "\n",
      "Test set: Average loss: 0.0330, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 39 [0/1612 (0%)] Loss: 0.415139\n",
      "Train Epoch: 39 [160/1612 (10%)] Loss: 0.430718\n",
      "Train Epoch: 39 [320/1612 (20%)] Loss: 0.486617\n",
      "Train Epoch: 39 [480/1612 (30%)] Loss: 0.575688\n",
      "Train Epoch: 39 [640/1612 (40%)] Loss: 0.429810\n",
      "Train Epoch: 39 [800/1612 (50%)] Loss: 0.505112\n",
      "Train Epoch: 39 [960/1612 (59%)] Loss: 0.452930\n",
      "Train Epoch: 39 [1120/1612 (69%)] Loss: 0.402629\n",
      "Train Epoch: 39 [1280/1612 (79%)] Loss: 0.599562\n",
      "Train Epoch: 39 [1440/1612 (89%)] Loss: 0.363833\n",
      "Train Epoch: 39 [1200/1612 (99%)] Loss: 0.374097\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 40 [0/1612 (0%)] Loss: 0.371694\n",
      "Train Epoch: 40 [160/1612 (10%)] Loss: 0.420295\n",
      "Train Epoch: 40 [320/1612 (20%)] Loss: 0.509188\n",
      "Train Epoch: 40 [480/1612 (30%)] Loss: 0.422686\n",
      "Train Epoch: 40 [640/1612 (40%)] Loss: 0.475947\n",
      "Train Epoch: 40 [800/1612 (50%)] Loss: 0.456187\n",
      "Train Epoch: 40 [960/1612 (59%)] Loss: 0.614834\n",
      "Train Epoch: 40 [1120/1612 (69%)] Loss: 0.543471\n",
      "Train Epoch: 40 [1280/1612 (79%)] Loss: 0.665474\n",
      "Train Epoch: 40 [1440/1612 (89%)] Loss: 0.634534\n",
      "Train Epoch: 40 [1200/1612 (99%)] Loss: 0.469746\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 41 [0/1612 (0%)] Loss: 0.465944\n",
      "Train Epoch: 41 [160/1612 (10%)] Loss: 0.486155\n",
      "Train Epoch: 41 [320/1612 (20%)] Loss: 0.624759\n",
      "Train Epoch: 41 [480/1612 (30%)] Loss: 0.458876\n",
      "Train Epoch: 41 [640/1612 (40%)] Loss: 0.372678\n",
      "Train Epoch: 41 [800/1612 (50%)] Loss: 0.536699\n",
      "Train Epoch: 41 [960/1612 (59%)] Loss: 0.563074\n",
      "Train Epoch: 41 [1120/1612 (69%)] Loss: 0.386457\n",
      "Train Epoch: 41 [1280/1612 (79%)] Loss: 0.555023\n",
      "Train Epoch: 41 [1440/1612 (89%)] Loss: 0.525370\n",
      "Train Epoch: 41 [1200/1612 (99%)] Loss: 0.424875\n",
      "\n",
      "Test set: Average loss: 0.0332, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 42 [0/1612 (0%)] Loss: 0.503525\n",
      "Train Epoch: 42 [160/1612 (10%)] Loss: 0.429014\n",
      "Train Epoch: 42 [320/1612 (20%)] Loss: 0.517506\n",
      "Train Epoch: 42 [480/1612 (30%)] Loss: 0.568158\n",
      "Train Epoch: 42 [640/1612 (40%)] Loss: 0.460810\n",
      "Train Epoch: 42 [800/1612 (50%)] Loss: 0.577900\n",
      "Train Epoch: 42 [960/1612 (59%)] Loss: 0.499071\n",
      "Train Epoch: 42 [1120/1612 (69%)] Loss: 0.538267\n",
      "Train Epoch: 42 [1280/1612 (79%)] Loss: 0.390355\n",
      "Train Epoch: 42 [1440/1612 (89%)] Loss: 0.612563\n",
      "Train Epoch: 42 [1200/1612 (99%)] Loss: 0.566522\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 43 [0/1612 (0%)] Loss: 0.588287\n",
      "Train Epoch: 43 [160/1612 (10%)] Loss: 0.447448\n",
      "Train Epoch: 43 [320/1612 (20%)] Loss: 0.617930\n",
      "Train Epoch: 43 [480/1612 (30%)] Loss: 0.417518\n",
      "Train Epoch: 43 [640/1612 (40%)] Loss: 0.705833\n",
      "Train Epoch: 43 [800/1612 (50%)] Loss: 0.673501\n",
      "Train Epoch: 43 [960/1612 (59%)] Loss: 0.460718\n",
      "Train Epoch: 43 [1120/1612 (69%)] Loss: 0.540998\n",
      "Train Epoch: 43 [1280/1612 (79%)] Loss: 0.416517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [1440/1612 (89%)] Loss: 0.476207\n",
      "Train Epoch: 43 [1200/1612 (99%)] Loss: 0.520386\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 44 [0/1612 (0%)] Loss: 0.448816\n",
      "Train Epoch: 44 [160/1612 (10%)] Loss: 0.488263\n",
      "Train Epoch: 44 [320/1612 (20%)] Loss: 0.613311\n",
      "Train Epoch: 44 [480/1612 (30%)] Loss: 0.380249\n",
      "Train Epoch: 44 [640/1612 (40%)] Loss: 0.439020\n",
      "Train Epoch: 44 [800/1612 (50%)] Loss: 0.608730\n",
      "Train Epoch: 44 [960/1612 (59%)] Loss: 0.388745\n",
      "Train Epoch: 44 [1120/1612 (69%)] Loss: 0.553439\n",
      "Train Epoch: 44 [1280/1612 (79%)] Loss: 0.461583\n",
      "Train Epoch: 44 [1440/1612 (89%)] Loss: 0.408933\n",
      "Train Epoch: 44 [1200/1612 (99%)] Loss: 0.777074\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 45 [0/1612 (0%)] Loss: 0.627396\n",
      "Train Epoch: 45 [160/1612 (10%)] Loss: 0.535067\n",
      "Train Epoch: 45 [320/1612 (20%)] Loss: 0.640106\n",
      "Train Epoch: 45 [480/1612 (30%)] Loss: 0.491545\n",
      "Train Epoch: 45 [640/1612 (40%)] Loss: 0.473342\n",
      "Train Epoch: 45 [800/1612 (50%)] Loss: 0.408879\n",
      "Train Epoch: 45 [960/1612 (59%)] Loss: 0.507092\n",
      "Train Epoch: 45 [1120/1612 (69%)] Loss: 0.984628\n",
      "Train Epoch: 45 [1280/1612 (79%)] Loss: 0.455066\n",
      "Train Epoch: 45 [1440/1612 (89%)] Loss: 0.544407\n",
      "Train Epoch: 45 [1200/1612 (99%)] Loss: 0.465528\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 46 [0/1612 (0%)] Loss: 0.422799\n",
      "Train Epoch: 46 [160/1612 (10%)] Loss: 0.499848\n",
      "Train Epoch: 46 [320/1612 (20%)] Loss: 0.495245\n",
      "Train Epoch: 46 [480/1612 (30%)] Loss: 0.461073\n",
      "Train Epoch: 46 [640/1612 (40%)] Loss: 0.537773\n",
      "Train Epoch: 46 [800/1612 (50%)] Loss: 0.520973\n",
      "Train Epoch: 46 [960/1612 (59%)] Loss: 0.437684\n",
      "Train Epoch: 46 [1120/1612 (69%)] Loss: 0.547980\n",
      "Train Epoch: 46 [1280/1612 (79%)] Loss: 0.616767\n",
      "Train Epoch: 46 [1440/1612 (89%)] Loss: 0.617849\n",
      "Train Epoch: 46 [1200/1612 (99%)] Loss: 0.517267\n",
      "\n",
      "Test set: Average loss: 0.0333, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 47 [0/1612 (0%)] Loss: 0.655415\n",
      "Train Epoch: 47 [160/1612 (10%)] Loss: 0.441271\n",
      "Train Epoch: 47 [320/1612 (20%)] Loss: 0.434845\n",
      "Train Epoch: 47 [480/1612 (30%)] Loss: 0.382246\n",
      "Train Epoch: 47 [640/1612 (40%)] Loss: 0.440213\n",
      "Train Epoch: 47 [800/1612 (50%)] Loss: 0.492811\n",
      "Train Epoch: 47 [960/1612 (59%)] Loss: 0.488510\n",
      "Train Epoch: 47 [1120/1612 (69%)] Loss: 0.503536\n",
      "Train Epoch: 47 [1280/1612 (79%)] Loss: 0.479337\n",
      "Train Epoch: 47 [1440/1612 (89%)] Loss: 0.349710\n",
      "Train Epoch: 47 [1200/1612 (99%)] Loss: 0.521496\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 48 [0/1612 (0%)] Loss: 0.545657\n",
      "Train Epoch: 48 [160/1612 (10%)] Loss: 0.440167\n",
      "Train Epoch: 48 [320/1612 (20%)] Loss: 0.526067\n",
      "Train Epoch: 48 [480/1612 (30%)] Loss: 0.457175\n",
      "Train Epoch: 48 [640/1612 (40%)] Loss: 0.660346\n",
      "Train Epoch: 48 [800/1612 (50%)] Loss: 0.671855\n",
      "Train Epoch: 48 [960/1612 (59%)] Loss: 0.693787\n",
      "Train Epoch: 48 [1120/1612 (69%)] Loss: 0.390234\n",
      "Train Epoch: 48 [1280/1612 (79%)] Loss: 0.466495\n",
      "Train Epoch: 48 [1440/1612 (89%)] Loss: 0.460950\n",
      "Train Epoch: 48 [1200/1612 (99%)] Loss: 0.349330\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 49 [0/1612 (0%)] Loss: 0.469206\n",
      "Train Epoch: 49 [160/1612 (10%)] Loss: 0.380183\n",
      "Train Epoch: 49 [320/1612 (20%)] Loss: 0.465559\n",
      "Train Epoch: 49 [480/1612 (30%)] Loss: 0.402149\n",
      "Train Epoch: 49 [640/1612 (40%)] Loss: 0.584045\n",
      "Train Epoch: 49 [800/1612 (50%)] Loss: 0.636111\n",
      "Train Epoch: 49 [960/1612 (59%)] Loss: 0.776110\n",
      "Train Epoch: 49 [1120/1612 (69%)] Loss: 0.353382\n",
      "Train Epoch: 49 [1280/1612 (79%)] Loss: 0.426363\n",
      "Train Epoch: 49 [1440/1612 (89%)] Loss: 0.814458\n",
      "Train Epoch: 49 [1200/1612 (99%)] Loss: 0.940136\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 50 [0/1612 (0%)] Loss: 0.561707\n",
      "Train Epoch: 50 [160/1612 (10%)] Loss: 0.473729\n",
      "Train Epoch: 50 [320/1612 (20%)] Loss: 0.471404\n",
      "Train Epoch: 50 [480/1612 (30%)] Loss: 0.333012\n",
      "Train Epoch: 50 [640/1612 (40%)] Loss: 0.514271\n",
      "Train Epoch: 50 [800/1612 (50%)] Loss: 0.708055\n",
      "Train Epoch: 50 [960/1612 (59%)] Loss: 0.453160\n",
      "Train Epoch: 50 [1120/1612 (69%)] Loss: 0.383793\n",
      "Train Epoch: 50 [1280/1612 (79%)] Loss: 0.405040\n",
      "Train Epoch: 50 [1440/1612 (89%)] Loss: 0.617650\n",
      "Train Epoch: 50 [1200/1612 (99%)] Loss: 0.289704\n",
      "\n",
      "Test set: Average loss: 0.0328, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 51 [0/1612 (0%)] Loss: 0.367800\n",
      "Train Epoch: 51 [160/1612 (10%)] Loss: 0.428021\n",
      "Train Epoch: 51 [320/1612 (20%)] Loss: 0.592004\n",
      "Train Epoch: 51 [480/1612 (30%)] Loss: 0.522752\n",
      "Train Epoch: 51 [640/1612 (40%)] Loss: 0.531635\n",
      "Train Epoch: 51 [800/1612 (50%)] Loss: 0.338239\n",
      "Train Epoch: 51 [960/1612 (59%)] Loss: 0.533351\n",
      "Train Epoch: 51 [1120/1612 (69%)] Loss: 0.546843\n",
      "Train Epoch: 51 [1280/1612 (79%)] Loss: 0.462475\n",
      "Train Epoch: 51 [1440/1612 (89%)] Loss: 0.376719\n",
      "Train Epoch: 51 [1200/1612 (99%)] Loss: 0.634833\n",
      "\n",
      "Test set: Average loss: 0.0328, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 52 [0/1612 (0%)] Loss: 0.482652\n",
      "Train Epoch: 52 [160/1612 (10%)] Loss: 0.644886\n",
      "Train Epoch: 52 [320/1612 (20%)] Loss: 0.773486\n",
      "Train Epoch: 52 [480/1612 (30%)] Loss: 0.412776\n",
      "Train Epoch: 52 [640/1612 (40%)] Loss: 0.511566\n",
      "Train Epoch: 52 [800/1612 (50%)] Loss: 0.633311\n",
      "Train Epoch: 52 [960/1612 (59%)] Loss: 0.383507\n",
      "Train Epoch: 52 [1120/1612 (69%)] Loss: 0.634583\n",
      "Train Epoch: 52 [1280/1612 (79%)] Loss: 0.419572\n",
      "Train Epoch: 52 [1440/1612 (89%)] Loss: 0.598569\n",
      "Train Epoch: 52 [1200/1612 (99%)] Loss: 0.560004\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 53 [0/1612 (0%)] Loss: 0.447670\n",
      "Train Epoch: 53 [160/1612 (10%)] Loss: 0.550847\n",
      "Train Epoch: 53 [320/1612 (20%)] Loss: 0.450616\n",
      "Train Epoch: 53 [480/1612 (30%)] Loss: 0.397938\n",
      "Train Epoch: 53 [640/1612 (40%)] Loss: 0.510608\n",
      "Train Epoch: 53 [800/1612 (50%)] Loss: 0.424449\n",
      "Train Epoch: 53 [960/1612 (59%)] Loss: 0.592194\n",
      "Train Epoch: 53 [1120/1612 (69%)] Loss: 0.600051\n",
      "Train Epoch: 53 [1280/1612 (79%)] Loss: 0.842159\n",
      "Train Epoch: 53 [1440/1612 (89%)] Loss: 0.471023\n",
      "Train Epoch: 53 [1200/1612 (99%)] Loss: 0.524950\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 54 [0/1612 (0%)] Loss: 0.394968\n",
      "Train Epoch: 54 [160/1612 (10%)] Loss: 0.376910\n",
      "Train Epoch: 54 [320/1612 (20%)] Loss: 0.611352\n",
      "Train Epoch: 54 [480/1612 (30%)] Loss: 0.745011\n",
      "Train Epoch: 54 [640/1612 (40%)] Loss: 0.468198\n",
      "Train Epoch: 54 [800/1612 (50%)] Loss: 0.591821\n",
      "Train Epoch: 54 [960/1612 (59%)] Loss: 0.533436\n",
      "Train Epoch: 54 [1120/1612 (69%)] Loss: 0.720617\n",
      "Train Epoch: 54 [1280/1612 (79%)] Loss: 0.351091\n",
      "Train Epoch: 54 [1440/1612 (89%)] Loss: 0.286297\n",
      "Train Epoch: 54 [1200/1612 (99%)] Loss: 0.304594\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 55 [0/1612 (0%)] Loss: 0.487484\n",
      "Train Epoch: 55 [160/1612 (10%)] Loss: 0.672258\n",
      "Train Epoch: 55 [320/1612 (20%)] Loss: 0.527103\n",
      "Train Epoch: 55 [480/1612 (30%)] Loss: 0.595040\n",
      "Train Epoch: 55 [640/1612 (40%)] Loss: 0.347379\n",
      "Train Epoch: 55 [800/1612 (50%)] Loss: 0.483969\n",
      "Train Epoch: 55 [960/1612 (59%)] Loss: 0.562267\n",
      "Train Epoch: 55 [1120/1612 (69%)] Loss: 0.473350\n",
      "Train Epoch: 55 [1280/1612 (79%)] Loss: 0.494084\n",
      "Train Epoch: 55 [1440/1612 (89%)] Loss: 0.399321\n",
      "Train Epoch: 55 [1200/1612 (99%)] Loss: 0.451367\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 56 [0/1612 (0%)] Loss: 0.369601\n",
      "Train Epoch: 56 [160/1612 (10%)] Loss: 0.437709\n",
      "Train Epoch: 56 [320/1612 (20%)] Loss: 0.423974\n",
      "Train Epoch: 56 [480/1612 (30%)] Loss: 0.747116\n",
      "Train Epoch: 56 [640/1612 (40%)] Loss: 0.479558\n",
      "Train Epoch: 56 [800/1612 (50%)] Loss: 0.449758\n",
      "Train Epoch: 56 [960/1612 (59%)] Loss: 0.507301\n",
      "Train Epoch: 56 [1120/1612 (69%)] Loss: 0.596909\n",
      "Train Epoch: 56 [1280/1612 (79%)] Loss: 0.394168\n",
      "Train Epoch: 56 [1440/1612 (89%)] Loss: 0.585305\n",
      "Train Epoch: 56 [1200/1612 (99%)] Loss: 0.491070\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 57 [0/1612 (0%)] Loss: 0.546993\n",
      "Train Epoch: 57 [160/1612 (10%)] Loss: 0.479379\n",
      "Train Epoch: 57 [320/1612 (20%)] Loss: 0.421387\n",
      "Train Epoch: 57 [480/1612 (30%)] Loss: 0.476705\n",
      "Train Epoch: 57 [640/1612 (40%)] Loss: 0.506718\n",
      "Train Epoch: 57 [800/1612 (50%)] Loss: 0.436330\n",
      "Train Epoch: 57 [960/1612 (59%)] Loss: 0.540600\n",
      "Train Epoch: 57 [1120/1612 (69%)] Loss: 0.319609\n",
      "Train Epoch: 57 [1280/1612 (79%)] Loss: 0.502168\n",
      "Train Epoch: 57 [1440/1612 (89%)] Loss: 0.522824\n",
      "Train Epoch: 57 [1200/1612 (99%)] Loss: 0.308060\n",
      "\n",
      "Test set: Average loss: 0.0322, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 58 [0/1612 (0%)] Loss: 0.575383\n",
      "Train Epoch: 58 [160/1612 (10%)] Loss: 0.562672\n",
      "Train Epoch: 58 [320/1612 (20%)] Loss: 0.345471\n",
      "Train Epoch: 58 [480/1612 (30%)] Loss: 0.719505\n",
      "Train Epoch: 58 [640/1612 (40%)] Loss: 0.416456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 58 [800/1612 (50%)] Loss: 0.409048\n",
      "Train Epoch: 58 [960/1612 (59%)] Loss: 0.638183\n",
      "Train Epoch: 58 [1120/1612 (69%)] Loss: 0.541800\n",
      "Train Epoch: 58 [1280/1612 (79%)] Loss: 0.449635\n",
      "Train Epoch: 58 [1440/1612 (89%)] Loss: 0.437762\n",
      "Train Epoch: 58 [1200/1612 (99%)] Loss: 0.349316\n",
      "\n",
      "Test set: Average loss: 0.0324, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 59 [0/1612 (0%)] Loss: 0.472439\n",
      "Train Epoch: 59 [160/1612 (10%)] Loss: 0.405613\n",
      "Train Epoch: 59 [320/1612 (20%)] Loss: 0.478838\n",
      "Train Epoch: 59 [480/1612 (30%)] Loss: 0.500531\n",
      "Train Epoch: 59 [640/1612 (40%)] Loss: 0.515365\n",
      "Train Epoch: 59 [800/1612 (50%)] Loss: 0.936760\n",
      "Train Epoch: 59 [960/1612 (59%)] Loss: 0.576713\n",
      "Train Epoch: 59 [1120/1612 (69%)] Loss: 0.559243\n",
      "Train Epoch: 59 [1280/1612 (79%)] Loss: 0.361325\n",
      "Train Epoch: 59 [1440/1612 (89%)] Loss: 0.558353\n",
      "Train Epoch: 59 [1200/1612 (99%)] Loss: 0.965056\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 60 [0/1612 (0%)] Loss: 0.751520\n",
      "Train Epoch: 60 [160/1612 (10%)] Loss: 0.453502\n",
      "Train Epoch: 60 [320/1612 (20%)] Loss: 0.530704\n",
      "Train Epoch: 60 [480/1612 (30%)] Loss: 0.352213\n",
      "Train Epoch: 60 [640/1612 (40%)] Loss: 0.404454\n",
      "Train Epoch: 60 [800/1612 (50%)] Loss: 0.332103\n",
      "Train Epoch: 60 [960/1612 (59%)] Loss: 0.522750\n",
      "Train Epoch: 60 [1120/1612 (69%)] Loss: 0.533492\n",
      "Train Epoch: 60 [1280/1612 (79%)] Loss: 0.485131\n",
      "Train Epoch: 60 [1440/1612 (89%)] Loss: 0.476800\n",
      "Train Epoch: 60 [1200/1612 (99%)] Loss: 0.539893\n",
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 61 [0/1612 (0%)] Loss: 0.650333\n",
      "Train Epoch: 61 [160/1612 (10%)] Loss: 0.581427\n",
      "Train Epoch: 61 [320/1612 (20%)] Loss: 0.505034\n",
      "Train Epoch: 61 [480/1612 (30%)] Loss: 0.475065\n",
      "Train Epoch: 61 [640/1612 (40%)] Loss: 0.697868\n",
      "Train Epoch: 61 [800/1612 (50%)] Loss: 0.412419\n",
      "Train Epoch: 61 [960/1612 (59%)] Loss: 0.379037\n",
      "Train Epoch: 61 [1120/1612 (69%)] Loss: 0.485969\n",
      "Train Epoch: 61 [1280/1612 (79%)] Loss: 0.619034\n",
      "Train Epoch: 61 [1440/1612 (89%)] Loss: 0.733044\n",
      "Train Epoch: 61 [1200/1612 (99%)] Loss: 0.401029\n",
      "\n",
      "Test set: Average loss: 0.0332, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 62 [0/1612 (0%)] Loss: 0.558213\n",
      "Train Epoch: 62 [160/1612 (10%)] Loss: 0.353942\n",
      "Train Epoch: 62 [320/1612 (20%)] Loss: 0.352323\n",
      "Train Epoch: 62 [480/1612 (30%)] Loss: 0.609190\n",
      "Train Epoch: 62 [640/1612 (40%)] Loss: 0.429815\n",
      "Train Epoch: 62 [800/1612 (50%)] Loss: 0.284455\n",
      "Train Epoch: 62 [960/1612 (59%)] Loss: 0.669204\n",
      "Train Epoch: 62 [1120/1612 (69%)] Loss: 0.775967\n",
      "Train Epoch: 62 [1280/1612 (79%)] Loss: 0.380388\n",
      "Train Epoch: 62 [1440/1612 (89%)] Loss: 0.561082\n",
      "Train Epoch: 62 [1200/1612 (99%)] Loss: 0.503992\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 63 [0/1612 (0%)] Loss: 0.471813\n",
      "Train Epoch: 63 [160/1612 (10%)] Loss: 0.546386\n",
      "Train Epoch: 63 [320/1612 (20%)] Loss: 0.365181\n",
      "Train Epoch: 63 [480/1612 (30%)] Loss: 0.596217\n",
      "Train Epoch: 63 [640/1612 (40%)] Loss: 0.587803\n",
      "Train Epoch: 63 [800/1612 (50%)] Loss: 0.750138\n",
      "Train Epoch: 63 [960/1612 (59%)] Loss: 0.443200\n",
      "Train Epoch: 63 [1120/1612 (69%)] Loss: 0.645170\n",
      "Train Epoch: 63 [1280/1612 (79%)] Loss: 0.492290\n",
      "Train Epoch: 63 [1440/1612 (89%)] Loss: 0.366983\n",
      "Train Epoch: 63 [1200/1612 (99%)] Loss: 0.503724\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 64 [0/1612 (0%)] Loss: 0.342048\n",
      "Train Epoch: 64 [160/1612 (10%)] Loss: 0.544111\n",
      "Train Epoch: 64 [320/1612 (20%)] Loss: 0.541362\n",
      "Train Epoch: 64 [480/1612 (30%)] Loss: 0.464803\n",
      "Train Epoch: 64 [640/1612 (40%)] Loss: 0.513348\n",
      "Train Epoch: 64 [800/1612 (50%)] Loss: 0.567013\n",
      "Train Epoch: 64 [960/1612 (59%)] Loss: 0.543449\n",
      "Train Epoch: 64 [1120/1612 (69%)] Loss: 0.368298\n",
      "Train Epoch: 64 [1280/1612 (79%)] Loss: 0.292620\n",
      "Train Epoch: 64 [1440/1612 (89%)] Loss: 0.480467\n",
      "Train Epoch: 64 [1200/1612 (99%)] Loss: 0.710895\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 65 [0/1612 (0%)] Loss: 0.480169\n",
      "Train Epoch: 65 [160/1612 (10%)] Loss: 0.443102\n",
      "Train Epoch: 65 [320/1612 (20%)] Loss: 0.567938\n",
      "Train Epoch: 65 [480/1612 (30%)] Loss: 0.466532\n",
      "Train Epoch: 65 [640/1612 (40%)] Loss: 0.364778\n",
      "Train Epoch: 65 [800/1612 (50%)] Loss: 0.400228\n",
      "Train Epoch: 65 [960/1612 (59%)] Loss: 0.701959\n",
      "Train Epoch: 65 [1120/1612 (69%)] Loss: 0.595372\n",
      "Train Epoch: 65 [1280/1612 (79%)] Loss: 0.578029\n",
      "Train Epoch: 65 [1440/1612 (89%)] Loss: 0.445391\n",
      "Train Epoch: 65 [1200/1612 (99%)] Loss: 0.219761\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 66 [0/1612 (0%)] Loss: 0.391036\n",
      "Train Epoch: 66 [160/1612 (10%)] Loss: 0.367668\n",
      "Train Epoch: 66 [320/1612 (20%)] Loss: 0.371307\n",
      "Train Epoch: 66 [480/1612 (30%)] Loss: 0.746372\n",
      "Train Epoch: 66 [640/1612 (40%)] Loss: 0.608246\n",
      "Train Epoch: 66 [800/1612 (50%)] Loss: 0.406777\n",
      "Train Epoch: 66 [960/1612 (59%)] Loss: 0.326967\n",
      "Train Epoch: 66 [1120/1612 (69%)] Loss: 0.714866\n",
      "Train Epoch: 66 [1280/1612 (79%)] Loss: 0.343123\n",
      "Train Epoch: 66 [1440/1612 (89%)] Loss: 0.393630\n",
      "Train Epoch: 66 [1200/1612 (99%)] Loss: 0.383631\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 67 [0/1612 (0%)] Loss: 0.477050\n",
      "Train Epoch: 67 [160/1612 (10%)] Loss: 0.652783\n",
      "Train Epoch: 67 [320/1612 (20%)] Loss: 0.407342\n",
      "Train Epoch: 67 [480/1612 (30%)] Loss: 0.438165\n",
      "Train Epoch: 67 [640/1612 (40%)] Loss: 0.476498\n",
      "Train Epoch: 67 [800/1612 (50%)] Loss: 0.685923\n",
      "Train Epoch: 67 [960/1612 (59%)] Loss: 0.382968\n",
      "Train Epoch: 67 [1120/1612 (69%)] Loss: 0.608782\n",
      "Train Epoch: 67 [1280/1612 (79%)] Loss: 0.601667\n",
      "Train Epoch: 67 [1440/1612 (89%)] Loss: 0.726411\n",
      "Train Epoch: 67 [1200/1612 (99%)] Loss: 0.546141\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 68 [0/1612 (0%)] Loss: 0.593099\n",
      "Train Epoch: 68 [160/1612 (10%)] Loss: 0.271258\n",
      "Train Epoch: 68 [320/1612 (20%)] Loss: 0.442491\n",
      "Train Epoch: 68 [480/1612 (30%)] Loss: 0.563770\n",
      "Train Epoch: 68 [640/1612 (40%)] Loss: 0.480906\n",
      "Train Epoch: 68 [800/1612 (50%)] Loss: 0.704085\n",
      "Train Epoch: 68 [960/1612 (59%)] Loss: 0.484705\n",
      "Train Epoch: 68 [1120/1612 (69%)] Loss: 0.400330\n",
      "Train Epoch: 68 [1280/1612 (79%)] Loss: 0.485750\n",
      "Train Epoch: 68 [1440/1612 (89%)] Loss: 0.451685\n",
      "Train Epoch: 68 [1200/1612 (99%)] Loss: 0.540030\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 69 [0/1612 (0%)] Loss: 0.430518\n",
      "Train Epoch: 69 [160/1612 (10%)] Loss: 0.553757\n",
      "Train Epoch: 69 [320/1612 (20%)] Loss: 0.539634\n",
      "Train Epoch: 69 [480/1612 (30%)] Loss: 0.695221\n",
      "Train Epoch: 69 [640/1612 (40%)] Loss: 0.400083\n",
      "Train Epoch: 69 [800/1612 (50%)] Loss: 0.524094\n",
      "Train Epoch: 69 [960/1612 (59%)] Loss: 0.930593\n",
      "Train Epoch: 69 [1120/1612 (69%)] Loss: 0.235463\n",
      "Train Epoch: 69 [1280/1612 (79%)] Loss: 0.760631\n",
      "Train Epoch: 69 [1440/1612 (89%)] Loss: 0.522248\n",
      "Train Epoch: 69 [1200/1612 (99%)] Loss: 0.361539\n",
      "\n",
      "Test set: Average loss: 0.0310, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 70 [0/1612 (0%)] Loss: 0.364359\n",
      "Train Epoch: 70 [160/1612 (10%)] Loss: 0.440678\n",
      "Train Epoch: 70 [320/1612 (20%)] Loss: 0.465745\n",
      "Train Epoch: 70 [480/1612 (30%)] Loss: 0.410115\n",
      "Train Epoch: 70 [640/1612 (40%)] Loss: 0.611338\n",
      "Train Epoch: 70 [800/1612 (50%)] Loss: 0.590249\n",
      "Train Epoch: 70 [960/1612 (59%)] Loss: 0.557713\n",
      "Train Epoch: 70 [1120/1612 (69%)] Loss: 0.604932\n",
      "Train Epoch: 70 [1280/1612 (79%)] Loss: 0.283474\n",
      "Train Epoch: 70 [1440/1612 (89%)] Loss: 0.518773\n",
      "Train Epoch: 70 [1200/1612 (99%)] Loss: 0.363803\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 71 [0/1612 (0%)] Loss: 0.510478\n",
      "Train Epoch: 71 [160/1612 (10%)] Loss: 0.474216\n",
      "Train Epoch: 71 [320/1612 (20%)] Loss: 0.572388\n",
      "Train Epoch: 71 [480/1612 (30%)] Loss: 0.521316\n",
      "Train Epoch: 71 [640/1612 (40%)] Loss: 0.485464\n",
      "Train Epoch: 71 [800/1612 (50%)] Loss: 0.323628\n",
      "Train Epoch: 71 [960/1612 (59%)] Loss: 0.431588\n",
      "Train Epoch: 71 [1120/1612 (69%)] Loss: 0.562323\n",
      "Train Epoch: 71 [1280/1612 (79%)] Loss: 0.443558\n",
      "Train Epoch: 71 [1440/1612 (89%)] Loss: 0.403102\n",
      "Train Epoch: 71 [1200/1612 (99%)] Loss: 0.479710\n",
      "\n",
      "Test set: Average loss: 0.0317, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 72 [0/1612 (0%)] Loss: 0.440920\n",
      "Train Epoch: 72 [160/1612 (10%)] Loss: 0.309446\n",
      "Train Epoch: 72 [320/1612 (20%)] Loss: 0.476160\n",
      "Train Epoch: 72 [480/1612 (30%)] Loss: 0.348696\n",
      "Train Epoch: 72 [640/1612 (40%)] Loss: 0.524099\n",
      "Train Epoch: 72 [800/1612 (50%)] Loss: 0.475153\n",
      "Train Epoch: 72 [960/1612 (59%)] Loss: 0.390453\n",
      "Train Epoch: 72 [1120/1612 (69%)] Loss: 0.565165\n",
      "Train Epoch: 72 [1280/1612 (79%)] Loss: 0.611665\n",
      "Train Epoch: 72 [1440/1612 (89%)] Loss: 0.371158\n",
      "Train Epoch: 72 [1200/1612 (99%)] Loss: 0.384477\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 73 [0/1612 (0%)] Loss: 0.438178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [160/1612 (10%)] Loss: 0.432825\n",
      "Train Epoch: 73 [320/1612 (20%)] Loss: 0.447127\n",
      "Train Epoch: 73 [480/1612 (30%)] Loss: 0.708764\n",
      "Train Epoch: 73 [640/1612 (40%)] Loss: 0.240035\n",
      "Train Epoch: 73 [800/1612 (50%)] Loss: 0.692828\n",
      "Train Epoch: 73 [960/1612 (59%)] Loss: 0.542776\n",
      "Train Epoch: 73 [1120/1612 (69%)] Loss: 0.563386\n",
      "Train Epoch: 73 [1280/1612 (79%)] Loss: 0.549819\n",
      "Train Epoch: 73 [1440/1612 (89%)] Loss: 0.477073\n",
      "Train Epoch: 73 [1200/1612 (99%)] Loss: 0.703493\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 74 [0/1612 (0%)] Loss: 0.378438\n",
      "Train Epoch: 74 [160/1612 (10%)] Loss: 0.465531\n",
      "Train Epoch: 74 [320/1612 (20%)] Loss: 0.547888\n",
      "Train Epoch: 74 [480/1612 (30%)] Loss: 0.570307\n",
      "Train Epoch: 74 [640/1612 (40%)] Loss: 0.477486\n",
      "Train Epoch: 74 [800/1612 (50%)] Loss: 0.449540\n",
      "Train Epoch: 74 [960/1612 (59%)] Loss: 0.592702\n",
      "Train Epoch: 74 [1120/1612 (69%)] Loss: 0.621875\n",
      "Train Epoch: 74 [1280/1612 (79%)] Loss: 0.476755\n",
      "Train Epoch: 74 [1440/1612 (89%)] Loss: 0.422270\n",
      "Train Epoch: 74 [1200/1612 (99%)] Loss: 0.208968\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 75 [0/1612 (0%)] Loss: 0.529784\n",
      "Train Epoch: 75 [160/1612 (10%)] Loss: 0.309615\n",
      "Train Epoch: 75 [320/1612 (20%)] Loss: 0.524904\n",
      "Train Epoch: 75 [480/1612 (30%)] Loss: 0.538297\n",
      "Train Epoch: 75 [640/1612 (40%)] Loss: 0.432880\n",
      "Train Epoch: 75 [800/1612 (50%)] Loss: 0.503080\n",
      "Train Epoch: 75 [960/1612 (59%)] Loss: 0.394458\n",
      "Train Epoch: 75 [1120/1612 (69%)] Loss: 0.703002\n",
      "Train Epoch: 75 [1280/1612 (79%)] Loss: 0.314447\n",
      "Train Epoch: 75 [1440/1612 (89%)] Loss: 0.520055\n",
      "Train Epoch: 75 [1200/1612 (99%)] Loss: 0.343952\n",
      "\n",
      "Test set: Average loss: 0.0310, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 76 [0/1612 (0%)] Loss: 0.442001\n",
      "Train Epoch: 76 [160/1612 (10%)] Loss: 0.350472\n",
      "Train Epoch: 76 [320/1612 (20%)] Loss: 0.509886\n",
      "Train Epoch: 76 [480/1612 (30%)] Loss: 0.480097\n",
      "Train Epoch: 76 [640/1612 (40%)] Loss: 0.394998\n",
      "Train Epoch: 76 [800/1612 (50%)] Loss: 0.551612\n",
      "Train Epoch: 76 [960/1612 (59%)] Loss: 0.729954\n",
      "Train Epoch: 76 [1120/1612 (69%)] Loss: 0.408535\n",
      "Train Epoch: 76 [1280/1612 (79%)] Loss: 0.728921\n",
      "Train Epoch: 76 [1440/1612 (89%)] Loss: 0.422502\n",
      "Train Epoch: 76 [1200/1612 (99%)] Loss: 0.696948\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 77 [0/1612 (0%)] Loss: 0.520789\n",
      "Train Epoch: 77 [160/1612 (10%)] Loss: 0.491548\n",
      "Train Epoch: 77 [320/1612 (20%)] Loss: 0.301850\n",
      "Train Epoch: 77 [480/1612 (30%)] Loss: 0.551911\n",
      "Train Epoch: 77 [640/1612 (40%)] Loss: 0.311692\n",
      "Train Epoch: 77 [800/1612 (50%)] Loss: 0.422535\n",
      "Train Epoch: 77 [960/1612 (59%)] Loss: 0.289136\n",
      "Train Epoch: 77 [1120/1612 (69%)] Loss: 0.415043\n",
      "Train Epoch: 77 [1280/1612 (79%)] Loss: 0.475542\n",
      "Train Epoch: 77 [1440/1612 (89%)] Loss: 0.534238\n",
      "Train Epoch: 77 [1200/1612 (99%)] Loss: 0.469171\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 78 [0/1612 (0%)] Loss: 0.346520\n",
      "Train Epoch: 78 [160/1612 (10%)] Loss: 0.559726\n",
      "Train Epoch: 78 [320/1612 (20%)] Loss: 0.313246\n",
      "Train Epoch: 78 [480/1612 (30%)] Loss: 0.405547\n",
      "Train Epoch: 78 [640/1612 (40%)] Loss: 0.340604\n",
      "Train Epoch: 78 [800/1612 (50%)] Loss: 0.332841\n",
      "Train Epoch: 78 [960/1612 (59%)] Loss: 0.481213\n",
      "Train Epoch: 78 [1120/1612 (69%)] Loss: 0.480074\n",
      "Train Epoch: 78 [1280/1612 (79%)] Loss: 0.444637\n",
      "Train Epoch: 78 [1440/1612 (89%)] Loss: 0.396367\n",
      "Train Epoch: 78 [1200/1612 (99%)] Loss: 0.222772\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 79 [0/1612 (0%)] Loss: 0.655856\n",
      "Train Epoch: 79 [160/1612 (10%)] Loss: 0.421310\n",
      "Train Epoch: 79 [320/1612 (20%)] Loss: 0.542749\n",
      "Train Epoch: 79 [480/1612 (30%)] Loss: 0.343537\n",
      "Train Epoch: 79 [640/1612 (40%)] Loss: 0.418713\n",
      "Train Epoch: 79 [800/1612 (50%)] Loss: 0.271473\n",
      "Train Epoch: 79 [960/1612 (59%)] Loss: 0.484254\n",
      "Train Epoch: 79 [1120/1612 (69%)] Loss: 0.577444\n",
      "Train Epoch: 79 [1280/1612 (79%)] Loss: 0.372959\n",
      "Train Epoch: 79 [1440/1612 (89%)] Loss: 0.452413\n",
      "Train Epoch: 79 [1200/1612 (99%)] Loss: 0.485384\n",
      "\n",
      "Test set: Average loss: 0.0316, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 80 [0/1612 (0%)] Loss: 0.725416\n",
      "Train Epoch: 80 [160/1612 (10%)] Loss: 0.552269\n",
      "Train Epoch: 80 [320/1612 (20%)] Loss: 0.429778\n",
      "Train Epoch: 80 [480/1612 (30%)] Loss: 0.570106\n",
      "Train Epoch: 80 [640/1612 (40%)] Loss: 0.219065\n",
      "Train Epoch: 80 [800/1612 (50%)] Loss: 0.639465\n",
      "Train Epoch: 80 [960/1612 (59%)] Loss: 0.271783\n",
      "Train Epoch: 80 [1120/1612 (69%)] Loss: 0.465697\n",
      "Train Epoch: 80 [1280/1612 (79%)] Loss: 0.464007\n",
      "Train Epoch: 80 [1440/1612 (89%)] Loss: 0.553143\n",
      "Train Epoch: 80 [1200/1612 (99%)] Loss: 0.494814\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 81 [0/1612 (0%)] Loss: 0.505252\n",
      "Train Epoch: 81 [160/1612 (10%)] Loss: 0.273870\n",
      "Train Epoch: 81 [320/1612 (20%)] Loss: 0.586662\n",
      "Train Epoch: 81 [480/1612 (30%)] Loss: 0.710436\n",
      "Train Epoch: 81 [640/1612 (40%)] Loss: 0.394120\n",
      "Train Epoch: 81 [800/1612 (50%)] Loss: 0.614464\n",
      "Train Epoch: 81 [960/1612 (59%)] Loss: 0.443700\n",
      "Train Epoch: 81 [1120/1612 (69%)] Loss: 0.344709\n",
      "Train Epoch: 81 [1280/1612 (79%)] Loss: 0.301425\n",
      "Train Epoch: 81 [1440/1612 (89%)] Loss: 0.314940\n",
      "Train Epoch: 81 [1200/1612 (99%)] Loss: 0.525008\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 82 [0/1612 (0%)] Loss: 0.597779\n",
      "Train Epoch: 82 [160/1612 (10%)] Loss: 0.588386\n",
      "Train Epoch: 82 [320/1612 (20%)] Loss: 0.482041\n",
      "Train Epoch: 82 [480/1612 (30%)] Loss: 0.618881\n",
      "Train Epoch: 82 [640/1612 (40%)] Loss: 0.468065\n",
      "Train Epoch: 82 [800/1612 (50%)] Loss: 0.711829\n",
      "Train Epoch: 82 [960/1612 (59%)] Loss: 0.386913\n",
      "Train Epoch: 82 [1120/1612 (69%)] Loss: 0.611376\n",
      "Train Epoch: 82 [1280/1612 (79%)] Loss: 0.671724\n",
      "Train Epoch: 82 [1440/1612 (89%)] Loss: 0.509348\n",
      "Train Epoch: 82 [1200/1612 (99%)] Loss: 0.238983\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 83 [0/1612 (0%)] Loss: 0.449595\n",
      "Train Epoch: 83 [160/1612 (10%)] Loss: 0.397887\n",
      "Train Epoch: 83 [320/1612 (20%)] Loss: 0.502230\n",
      "Train Epoch: 83 [480/1612 (30%)] Loss: 0.348093\n",
      "Train Epoch: 83 [640/1612 (40%)] Loss: 0.568797\n",
      "Train Epoch: 83 [800/1612 (50%)] Loss: 0.399053\n",
      "Train Epoch: 83 [960/1612 (59%)] Loss: 0.410592\n",
      "Train Epoch: 83 [1120/1612 (69%)] Loss: 0.554157\n",
      "Train Epoch: 83 [1280/1612 (79%)] Loss: 0.390372\n",
      "Train Epoch: 83 [1440/1612 (89%)] Loss: 0.479722\n",
      "Train Epoch: 83 [1200/1612 (99%)] Loss: 0.265525\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 84 [0/1612 (0%)] Loss: 0.615936\n",
      "Train Epoch: 84 [160/1612 (10%)] Loss: 0.364290\n",
      "Train Epoch: 84 [320/1612 (20%)] Loss: 0.968451\n",
      "Train Epoch: 84 [480/1612 (30%)] Loss: 0.364029\n",
      "Train Epoch: 84 [640/1612 (40%)] Loss: 0.260222\n",
      "Train Epoch: 84 [800/1612 (50%)] Loss: 0.396171\n",
      "Train Epoch: 84 [960/1612 (59%)] Loss: 0.578534\n",
      "Train Epoch: 84 [1120/1612 (69%)] Loss: 0.544576\n",
      "Train Epoch: 84 [1280/1612 (79%)] Loss: 0.455475\n",
      "Train Epoch: 84 [1440/1612 (89%)] Loss: 0.351325\n",
      "Train Epoch: 84 [1200/1612 (99%)] Loss: 0.591247\n",
      "\n",
      "Test set: Average loss: 0.0299, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 85 [0/1612 (0%)] Loss: 0.441663\n",
      "Train Epoch: 85 [160/1612 (10%)] Loss: 0.357935\n",
      "Train Epoch: 85 [320/1612 (20%)] Loss: 0.514758\n",
      "Train Epoch: 85 [480/1612 (30%)] Loss: 0.826250\n",
      "Train Epoch: 85 [640/1612 (40%)] Loss: 0.412428\n",
      "Train Epoch: 85 [800/1612 (50%)] Loss: 0.312557\n",
      "Train Epoch: 85 [960/1612 (59%)] Loss: 0.476652\n",
      "Train Epoch: 85 [1120/1612 (69%)] Loss: 0.230635\n",
      "Train Epoch: 85 [1280/1612 (79%)] Loss: 0.492282\n",
      "Train Epoch: 85 [1440/1612 (89%)] Loss: 0.438764\n",
      "Train Epoch: 85 [1200/1612 (99%)] Loss: 0.389876\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 86 [0/1612 (0%)] Loss: 0.560661\n",
      "Train Epoch: 86 [160/1612 (10%)] Loss: 0.364256\n",
      "Train Epoch: 86 [320/1612 (20%)] Loss: 0.368888\n",
      "Train Epoch: 86 [480/1612 (30%)] Loss: 0.540254\n",
      "Train Epoch: 86 [640/1612 (40%)] Loss: 0.420718\n",
      "Train Epoch: 86 [800/1612 (50%)] Loss: 0.544638\n",
      "Train Epoch: 86 [960/1612 (59%)] Loss: 0.546704\n",
      "Train Epoch: 86 [1120/1612 (69%)] Loss: 0.485586\n",
      "Train Epoch: 86 [1280/1612 (79%)] Loss: 0.532426\n",
      "Train Epoch: 86 [1440/1612 (89%)] Loss: 0.442650\n",
      "Train Epoch: 86 [1200/1612 (99%)] Loss: 0.489590\n",
      "\n",
      "Test set: Average loss: 0.0303, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 87 [0/1612 (0%)] Loss: 0.450482\n",
      "Train Epoch: 87 [160/1612 (10%)] Loss: 0.287235\n",
      "Train Epoch: 87 [320/1612 (20%)] Loss: 0.639407\n",
      "Train Epoch: 87 [480/1612 (30%)] Loss: 0.256203\n",
      "Train Epoch: 87 [640/1612 (40%)] Loss: 0.488994\n",
      "Train Epoch: 87 [800/1612 (50%)] Loss: 0.583892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87 [960/1612 (59%)] Loss: 0.571952\n",
      "Train Epoch: 87 [1120/1612 (69%)] Loss: 0.534409\n",
      "Train Epoch: 87 [1280/1612 (79%)] Loss: 0.600574\n",
      "Train Epoch: 87 [1440/1612 (89%)] Loss: 0.310859\n",
      "Train Epoch: 87 [1200/1612 (99%)] Loss: 0.291809\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 88 [0/1612 (0%)] Loss: 0.408898\n",
      "Train Epoch: 88 [160/1612 (10%)] Loss: 0.525629\n",
      "Train Epoch: 88 [320/1612 (20%)] Loss: 0.338479\n",
      "Train Epoch: 88 [480/1612 (30%)] Loss: 0.623145\n",
      "Train Epoch: 88 [640/1612 (40%)] Loss: 0.385450\n",
      "Train Epoch: 88 [800/1612 (50%)] Loss: 0.589608\n",
      "Train Epoch: 88 [960/1612 (59%)] Loss: 0.485623\n",
      "Train Epoch: 88 [1120/1612 (69%)] Loss: 0.561383\n",
      "Train Epoch: 88 [1280/1612 (79%)] Loss: 0.618426\n",
      "Train Epoch: 88 [1440/1612 (89%)] Loss: 0.481005\n",
      "Train Epoch: 88 [1200/1612 (99%)] Loss: 0.460500\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 89 [0/1612 (0%)] Loss: 0.537364\n",
      "Train Epoch: 89 [160/1612 (10%)] Loss: 0.310827\n",
      "Train Epoch: 89 [320/1612 (20%)] Loss: 0.411249\n",
      "Train Epoch: 89 [480/1612 (30%)] Loss: 0.526272\n",
      "Train Epoch: 89 [640/1612 (40%)] Loss: 0.506792\n",
      "Train Epoch: 89 [800/1612 (50%)] Loss: 0.338052\n",
      "Train Epoch: 89 [960/1612 (59%)] Loss: 0.438218\n",
      "Train Epoch: 89 [1120/1612 (69%)] Loss: 0.427354\n",
      "Train Epoch: 89 [1280/1612 (79%)] Loss: 0.271136\n",
      "Train Epoch: 89 [1440/1612 (89%)] Loss: 0.603459\n",
      "Train Epoch: 89 [1200/1612 (99%)] Loss: 0.387256\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 90 [0/1612 (0%)] Loss: 0.387820\n",
      "Train Epoch: 90 [160/1612 (10%)] Loss: 0.358639\n",
      "Train Epoch: 90 [320/1612 (20%)] Loss: 0.490138\n",
      "Train Epoch: 90 [480/1612 (30%)] Loss: 0.246226\n",
      "Train Epoch: 90 [640/1612 (40%)] Loss: 0.426386\n",
      "Train Epoch: 90 [800/1612 (50%)] Loss: 0.438258\n",
      "Train Epoch: 90 [960/1612 (59%)] Loss: 0.366227\n",
      "Train Epoch: 90 [1120/1612 (69%)] Loss: 0.393777\n",
      "Train Epoch: 90 [1280/1612 (79%)] Loss: 0.264337\n",
      "Train Epoch: 90 [1440/1612 (89%)] Loss: 0.418267\n",
      "Train Epoch: 90 [1200/1612 (99%)] Loss: 0.409291\n",
      "\n",
      "Test set: Average loss: 0.0303, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 91 [0/1612 (0%)] Loss: 0.541396\n",
      "Train Epoch: 91 [160/1612 (10%)] Loss: 0.315948\n",
      "Train Epoch: 91 [320/1612 (20%)] Loss: 0.526606\n",
      "Train Epoch: 91 [480/1612 (30%)] Loss: 0.523080\n",
      "Train Epoch: 91 [640/1612 (40%)] Loss: 0.218439\n",
      "Train Epoch: 91 [800/1612 (50%)] Loss: 0.473723\n",
      "Train Epoch: 91 [960/1612 (59%)] Loss: 0.218227\n",
      "Train Epoch: 91 [1120/1612 (69%)] Loss: 0.349497\n",
      "Train Epoch: 91 [1280/1612 (79%)] Loss: 0.564155\n",
      "Train Epoch: 91 [1440/1612 (89%)] Loss: 0.266140\n",
      "Train Epoch: 91 [1200/1612 (99%)] Loss: 0.326761\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 92 [0/1612 (0%)] Loss: 0.350044\n",
      "Train Epoch: 92 [160/1612 (10%)] Loss: 0.400672\n",
      "Train Epoch: 92 [320/1612 (20%)] Loss: 0.366998\n",
      "Train Epoch: 92 [480/1612 (30%)] Loss: 0.468735\n",
      "Train Epoch: 92 [640/1612 (40%)] Loss: 0.304032\n",
      "Train Epoch: 92 [800/1612 (50%)] Loss: 0.733818\n",
      "Train Epoch: 92 [960/1612 (59%)] Loss: 0.478066\n",
      "Train Epoch: 92 [1120/1612 (69%)] Loss: 0.402366\n",
      "Train Epoch: 92 [1280/1612 (79%)] Loss: 0.223839\n",
      "Train Epoch: 92 [1440/1612 (89%)] Loss: 0.391183\n",
      "Train Epoch: 92 [1200/1612 (99%)] Loss: 0.350265\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 93 [0/1612 (0%)] Loss: 0.525495\n",
      "Train Epoch: 93 [160/1612 (10%)] Loss: 0.462321\n",
      "Train Epoch: 93 [320/1612 (20%)] Loss: 0.470764\n",
      "Train Epoch: 93 [480/1612 (30%)] Loss: 0.460406\n",
      "Train Epoch: 93 [640/1612 (40%)] Loss: 0.408060\n",
      "Train Epoch: 93 [800/1612 (50%)] Loss: 0.477395\n",
      "Train Epoch: 93 [960/1612 (59%)] Loss: 0.370541\n",
      "Train Epoch: 93 [1120/1612 (69%)] Loss: 0.415730\n",
      "Train Epoch: 93 [1280/1612 (79%)] Loss: 0.579870\n",
      "Train Epoch: 93 [1440/1612 (89%)] Loss: 0.405101\n",
      "Train Epoch: 93 [1200/1612 (99%)] Loss: 0.402282\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 94 [0/1612 (0%)] Loss: 0.347003\n",
      "Train Epoch: 94 [160/1612 (10%)] Loss: 0.321424\n",
      "Train Epoch: 94 [320/1612 (20%)] Loss: 0.423541\n",
      "Train Epoch: 94 [480/1612 (30%)] Loss: 0.718216\n",
      "Train Epoch: 94 [640/1612 (40%)] Loss: 0.327349\n",
      "Train Epoch: 94 [800/1612 (50%)] Loss: 0.265695\n",
      "Train Epoch: 94 [960/1612 (59%)] Loss: 0.437123\n",
      "Train Epoch: 94 [1120/1612 (69%)] Loss: 0.385714\n",
      "Train Epoch: 94 [1280/1612 (79%)] Loss: 0.417518\n",
      "Train Epoch: 94 [1440/1612 (89%)] Loss: 0.380236\n",
      "Train Epoch: 94 [1200/1612 (99%)] Loss: 0.632893\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 95 [0/1612 (0%)] Loss: 0.738655\n",
      "Train Epoch: 95 [160/1612 (10%)] Loss: 0.292144\n",
      "Train Epoch: 95 [320/1612 (20%)] Loss: 0.303970\n",
      "Train Epoch: 95 [480/1612 (30%)] Loss: 0.310165\n",
      "Train Epoch: 95 [640/1612 (40%)] Loss: 0.450031\n",
      "Train Epoch: 95 [800/1612 (50%)] Loss: 0.924967\n",
      "Train Epoch: 95 [960/1612 (59%)] Loss: 0.373980\n",
      "Train Epoch: 95 [1120/1612 (69%)] Loss: 0.356365\n",
      "Train Epoch: 95 [1280/1612 (79%)] Loss: 0.608814\n",
      "Train Epoch: 95 [1440/1612 (89%)] Loss: 0.338807\n",
      "Train Epoch: 95 [1200/1612 (99%)] Loss: 0.272178\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 96 [0/1612 (0%)] Loss: 0.545810\n",
      "Train Epoch: 96 [160/1612 (10%)] Loss: 0.492760\n",
      "Train Epoch: 96 [320/1612 (20%)] Loss: 0.600466\n",
      "Train Epoch: 96 [480/1612 (30%)] Loss: 0.441923\n",
      "Train Epoch: 96 [640/1612 (40%)] Loss: 0.500925\n",
      "Train Epoch: 96 [800/1612 (50%)] Loss: 0.451762\n",
      "Train Epoch: 96 [960/1612 (59%)] Loss: 0.411805\n",
      "Train Epoch: 96 [1120/1612 (69%)] Loss: 0.225546\n",
      "Train Epoch: 96 [1280/1612 (79%)] Loss: 0.299818\n",
      "Train Epoch: 96 [1440/1612 (89%)] Loss: 0.625958\n",
      "Train Epoch: 96 [1200/1612 (99%)] Loss: 0.515534\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 97 [0/1612 (0%)] Loss: 0.415882\n",
      "Train Epoch: 97 [160/1612 (10%)] Loss: 0.409160\n",
      "Train Epoch: 97 [320/1612 (20%)] Loss: 0.402535\n",
      "Train Epoch: 97 [480/1612 (30%)] Loss: 0.431806\n",
      "Train Epoch: 97 [640/1612 (40%)] Loss: 0.527182\n",
      "Train Epoch: 97 [800/1612 (50%)] Loss: 0.546347\n",
      "Train Epoch: 97 [960/1612 (59%)] Loss: 0.524283\n",
      "Train Epoch: 97 [1120/1612 (69%)] Loss: 0.398428\n",
      "Train Epoch: 97 [1280/1612 (79%)] Loss: 0.236612\n",
      "Train Epoch: 97 [1440/1612 (89%)] Loss: 0.405082\n",
      "Train Epoch: 97 [1200/1612 (99%)] Loss: 0.338945\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 98 [0/1612 (0%)] Loss: 0.328281\n",
      "Train Epoch: 98 [160/1612 (10%)] Loss: 0.208811\n",
      "Train Epoch: 98 [320/1612 (20%)] Loss: 0.520992\n",
      "Train Epoch: 98 [480/1612 (30%)] Loss: 0.401004\n",
      "Train Epoch: 98 [640/1612 (40%)] Loss: 0.304958\n",
      "Train Epoch: 98 [800/1612 (50%)] Loss: 0.353631\n",
      "Train Epoch: 98 [960/1612 (59%)] Loss: 0.476534\n",
      "Train Epoch: 98 [1120/1612 (69%)] Loss: 0.411660\n",
      "Train Epoch: 98 [1280/1612 (79%)] Loss: 0.313864\n",
      "Train Epoch: 98 [1440/1612 (89%)] Loss: 0.585974\n",
      "Train Epoch: 98 [1200/1612 (99%)] Loss: 0.295028\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 99 [0/1612 (0%)] Loss: 0.362365\n",
      "Train Epoch: 99 [160/1612 (10%)] Loss: 0.358570\n",
      "Train Epoch: 99 [320/1612 (20%)] Loss: 0.377884\n",
      "Train Epoch: 99 [480/1612 (30%)] Loss: 0.601142\n",
      "Train Epoch: 99 [640/1612 (40%)] Loss: 0.354784\n",
      "Train Epoch: 99 [800/1612 (50%)] Loss: 0.566833\n",
      "Train Epoch: 99 [960/1612 (59%)] Loss: 0.422895\n",
      "Train Epoch: 99 [1120/1612 (69%)] Loss: 0.407379\n",
      "Train Epoch: 99 [1280/1612 (79%)] Loss: 0.466423\n",
      "Train Epoch: 99 [1440/1612 (89%)] Loss: 0.555169\n",
      "Train Epoch: 99 [1200/1612 (99%)] Loss: 0.316453\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 100 [0/1612 (0%)] Loss: 0.436954\n",
      "Train Epoch: 100 [160/1612 (10%)] Loss: 0.363743\n",
      "Train Epoch: 100 [320/1612 (20%)] Loss: 0.372871\n",
      "Train Epoch: 100 [480/1612 (30%)] Loss: 0.396112\n",
      "Train Epoch: 100 [640/1612 (40%)] Loss: 0.282400\n",
      "Train Epoch: 100 [800/1612 (50%)] Loss: 0.547227\n",
      "Train Epoch: 100 [960/1612 (59%)] Loss: 0.644941\n",
      "Train Epoch: 100 [1120/1612 (69%)] Loss: 0.551540\n",
      "Train Epoch: 100 [1280/1612 (79%)] Loss: 0.491757\n",
      "Train Epoch: 100 [1440/1612 (89%)] Loss: 0.441872\n",
      "Train Epoch: 100 [1200/1612 (99%)] Loss: 0.462890\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 101 [0/1612 (0%)] Loss: 0.416282\n",
      "Train Epoch: 101 [160/1612 (10%)] Loss: 0.480312\n",
      "Train Epoch: 101 [320/1612 (20%)] Loss: 0.425073\n",
      "Train Epoch: 101 [480/1612 (30%)] Loss: 0.743487\n",
      "Train Epoch: 101 [640/1612 (40%)] Loss: 0.419015\n",
      "Train Epoch: 101 [800/1612 (50%)] Loss: 0.619916\n",
      "Train Epoch: 101 [960/1612 (59%)] Loss: 0.349853\n",
      "Train Epoch: 101 [1120/1612 (69%)] Loss: 0.399249\n",
      "Train Epoch: 101 [1280/1612 (79%)] Loss: 0.466749\n",
      "Train Epoch: 101 [1440/1612 (89%)] Loss: 0.394456\n",
      "Train Epoch: 101 [1200/1612 (99%)] Loss: 0.549593\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 102 [0/1612 (0%)] Loss: 0.309943\n",
      "Train Epoch: 102 [160/1612 (10%)] Loss: 0.529130\n",
      "Train Epoch: 102 [320/1612 (20%)] Loss: 0.496649\n",
      "Train Epoch: 102 [480/1612 (30%)] Loss: 0.500618\n",
      "Train Epoch: 102 [640/1612 (40%)] Loss: 0.735666\n",
      "Train Epoch: 102 [800/1612 (50%)] Loss: 0.642668\n",
      "Train Epoch: 102 [960/1612 (59%)] Loss: 0.377510\n",
      "Train Epoch: 102 [1120/1612 (69%)] Loss: 0.337047\n",
      "Train Epoch: 102 [1280/1612 (79%)] Loss: 0.180972\n",
      "Train Epoch: 102 [1440/1612 (89%)] Loss: 0.352529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 102 [1200/1612 (99%)] Loss: 0.285732\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 103 [0/1612 (0%)] Loss: 0.281094\n",
      "Train Epoch: 103 [160/1612 (10%)] Loss: 0.466620\n",
      "Train Epoch: 103 [320/1612 (20%)] Loss: 0.312825\n",
      "Train Epoch: 103 [480/1612 (30%)] Loss: 0.391136\n",
      "Train Epoch: 103 [640/1612 (40%)] Loss: 0.395845\n",
      "Train Epoch: 103 [800/1612 (50%)] Loss: 0.383298\n",
      "Train Epoch: 103 [960/1612 (59%)] Loss: 0.380401\n",
      "Train Epoch: 103 [1120/1612 (69%)] Loss: 0.371131\n",
      "Train Epoch: 103 [1280/1612 (79%)] Loss: 0.670388\n",
      "Train Epoch: 103 [1440/1612 (89%)] Loss: 0.451358\n",
      "Train Epoch: 103 [1200/1612 (99%)] Loss: 0.391780\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 104 [0/1612 (0%)] Loss: 0.514012\n",
      "Train Epoch: 104 [160/1612 (10%)] Loss: 0.375032\n",
      "Train Epoch: 104 [320/1612 (20%)] Loss: 0.371753\n",
      "Train Epoch: 104 [480/1612 (30%)] Loss: 0.350080\n",
      "Train Epoch: 104 [640/1612 (40%)] Loss: 0.447900\n",
      "Train Epoch: 104 [800/1612 (50%)] Loss: 0.479116\n",
      "Train Epoch: 104 [960/1612 (59%)] Loss: 0.687429\n",
      "Train Epoch: 104 [1120/1612 (69%)] Loss: 0.286378\n",
      "Train Epoch: 104 [1280/1612 (79%)] Loss: 0.527492\n",
      "Train Epoch: 104 [1440/1612 (89%)] Loss: 0.643001\n",
      "Train Epoch: 104 [1200/1612 (99%)] Loss: 0.442215\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 105 [0/1612 (0%)] Loss: 0.683103\n",
      "Train Epoch: 105 [160/1612 (10%)] Loss: 0.391944\n",
      "Train Epoch: 105 [320/1612 (20%)] Loss: 0.333771\n",
      "Train Epoch: 105 [480/1612 (30%)] Loss: 0.489817\n",
      "Train Epoch: 105 [640/1612 (40%)] Loss: 0.376081\n",
      "Train Epoch: 105 [800/1612 (50%)] Loss: 0.347799\n",
      "Train Epoch: 105 [960/1612 (59%)] Loss: 0.453037\n",
      "Train Epoch: 105 [1120/1612 (69%)] Loss: 0.333741\n",
      "Train Epoch: 105 [1280/1612 (79%)] Loss: 0.447476\n",
      "Train Epoch: 105 [1440/1612 (89%)] Loss: 0.377650\n",
      "Train Epoch: 105 [1200/1612 (99%)] Loss: 0.272781\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 106 [0/1612 (0%)] Loss: 0.508718\n",
      "Train Epoch: 106 [160/1612 (10%)] Loss: 0.221937\n",
      "Train Epoch: 106 [320/1612 (20%)] Loss: 0.421218\n",
      "Train Epoch: 106 [480/1612 (30%)] Loss: 0.298704\n",
      "Train Epoch: 106 [640/1612 (40%)] Loss: 0.304625\n",
      "Train Epoch: 106 [800/1612 (50%)] Loss: 0.525112\n",
      "Train Epoch: 106 [960/1612 (59%)] Loss: 0.405680\n",
      "Train Epoch: 106 [1120/1612 (69%)] Loss: 0.231451\n",
      "Train Epoch: 106 [1280/1612 (79%)] Loss: 0.541243\n",
      "Train Epoch: 106 [1440/1612 (89%)] Loss: 0.340131\n",
      "Train Epoch: 106 [1200/1612 (99%)] Loss: 0.464692\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 107 [0/1612 (0%)] Loss: 0.372721\n",
      "Train Epoch: 107 [160/1612 (10%)] Loss: 0.347879\n",
      "Train Epoch: 107 [320/1612 (20%)] Loss: 0.591176\n",
      "Train Epoch: 107 [480/1612 (30%)] Loss: 0.673454\n",
      "Train Epoch: 107 [640/1612 (40%)] Loss: 0.326025\n",
      "Train Epoch: 107 [800/1612 (50%)] Loss: 0.639951\n",
      "Train Epoch: 107 [960/1612 (59%)] Loss: 0.380649\n",
      "Train Epoch: 107 [1120/1612 (69%)] Loss: 0.399646\n",
      "Train Epoch: 107 [1280/1612 (79%)] Loss: 0.817368\n",
      "Train Epoch: 107 [1440/1612 (89%)] Loss: 0.576047\n",
      "Train Epoch: 107 [1200/1612 (99%)] Loss: 0.294118\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 108 [0/1612 (0%)] Loss: 0.430333\n",
      "Train Epoch: 108 [160/1612 (10%)] Loss: 0.367533\n",
      "Train Epoch: 108 [320/1612 (20%)] Loss: 0.545417\n",
      "Train Epoch: 108 [480/1612 (30%)] Loss: 0.347587\n",
      "Train Epoch: 108 [640/1612 (40%)] Loss: 0.261718\n",
      "Train Epoch: 108 [800/1612 (50%)] Loss: 0.398825\n",
      "Train Epoch: 108 [960/1612 (59%)] Loss: 0.504158\n",
      "Train Epoch: 108 [1120/1612 (69%)] Loss: 0.557076\n",
      "Train Epoch: 108 [1280/1612 (79%)] Loss: 0.305093\n",
      "Train Epoch: 108 [1440/1612 (89%)] Loss: 0.245862\n",
      "Train Epoch: 108 [1200/1612 (99%)] Loss: 0.348753\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 109 [0/1612 (0%)] Loss: 0.265679\n",
      "Train Epoch: 109 [160/1612 (10%)] Loss: 0.730267\n",
      "Train Epoch: 109 [320/1612 (20%)] Loss: 0.660202\n",
      "Train Epoch: 109 [480/1612 (30%)] Loss: 0.288905\n",
      "Train Epoch: 109 [640/1612 (40%)] Loss: 0.372059\n",
      "Train Epoch: 109 [800/1612 (50%)] Loss: 0.367520\n",
      "Train Epoch: 109 [960/1612 (59%)] Loss: 0.321794\n",
      "Train Epoch: 109 [1120/1612 (69%)] Loss: 0.332292\n",
      "Train Epoch: 109 [1280/1612 (79%)] Loss: 0.515031\n",
      "Train Epoch: 109 [1440/1612 (89%)] Loss: 0.469985\n",
      "Train Epoch: 109 [1200/1612 (99%)] Loss: 0.478371\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 110 [0/1612 (0%)] Loss: 0.652511\n",
      "Train Epoch: 110 [160/1612 (10%)] Loss: 0.571301\n",
      "Train Epoch: 110 [320/1612 (20%)] Loss: 0.299455\n",
      "Train Epoch: 110 [480/1612 (30%)] Loss: 0.486160\n",
      "Train Epoch: 110 [640/1612 (40%)] Loss: 0.356215\n",
      "Train Epoch: 110 [800/1612 (50%)] Loss: 0.591903\n",
      "Train Epoch: 110 [960/1612 (59%)] Loss: 0.331726\n",
      "Train Epoch: 110 [1120/1612 (69%)] Loss: 0.489727\n",
      "Train Epoch: 110 [1280/1612 (79%)] Loss: 0.501547\n",
      "Train Epoch: 110 [1440/1612 (89%)] Loss: 0.346909\n",
      "Train Epoch: 110 [1200/1612 (99%)] Loss: 0.265531\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 111 [0/1612 (0%)] Loss: 0.331113\n",
      "Train Epoch: 111 [160/1612 (10%)] Loss: 0.669831\n",
      "Train Epoch: 111 [320/1612 (20%)] Loss: 0.514182\n",
      "Train Epoch: 111 [480/1612 (30%)] Loss: 0.339761\n",
      "Train Epoch: 111 [640/1612 (40%)] Loss: 0.335987\n",
      "Train Epoch: 111 [800/1612 (50%)] Loss: 0.373688\n",
      "Train Epoch: 111 [960/1612 (59%)] Loss: 0.302956\n",
      "Train Epoch: 111 [1120/1612 (69%)] Loss: 0.468004\n",
      "Train Epoch: 111 [1280/1612 (79%)] Loss: 0.290174\n",
      "Train Epoch: 111 [1440/1612 (89%)] Loss: 0.381756\n",
      "Train Epoch: 111 [1200/1612 (99%)] Loss: 0.405131\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 112 [0/1612 (0%)] Loss: 0.484744\n",
      "Train Epoch: 112 [160/1612 (10%)] Loss: 0.489704\n",
      "Train Epoch: 112 [320/1612 (20%)] Loss: 0.559778\n",
      "Train Epoch: 112 [480/1612 (30%)] Loss: 0.362836\n",
      "Train Epoch: 112 [640/1612 (40%)] Loss: 0.383574\n",
      "Train Epoch: 112 [800/1612 (50%)] Loss: 0.304932\n",
      "Train Epoch: 112 [960/1612 (59%)] Loss: 0.444135\n",
      "Train Epoch: 112 [1120/1612 (69%)] Loss: 0.327733\n",
      "Train Epoch: 112 [1280/1612 (79%)] Loss: 0.334603\n",
      "Train Epoch: 112 [1440/1612 (89%)] Loss: 0.369594\n",
      "Train Epoch: 112 [1200/1612 (99%)] Loss: 1.118209\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 113 [0/1612 (0%)] Loss: 0.379980\n",
      "Train Epoch: 113 [160/1612 (10%)] Loss: 0.390938\n",
      "Train Epoch: 113 [320/1612 (20%)] Loss: 0.422600\n",
      "Train Epoch: 113 [480/1612 (30%)] Loss: 0.413735\n",
      "Train Epoch: 113 [640/1612 (40%)] Loss: 0.294863\n",
      "Train Epoch: 113 [800/1612 (50%)] Loss: 0.392253\n",
      "Train Epoch: 113 [960/1612 (59%)] Loss: 0.465355\n",
      "Train Epoch: 113 [1120/1612 (69%)] Loss: 0.492302\n",
      "Train Epoch: 113 [1280/1612 (79%)] Loss: 0.517920\n",
      "Train Epoch: 113 [1440/1612 (89%)] Loss: 0.593976\n",
      "Train Epoch: 113 [1200/1612 (99%)] Loss: 0.311955\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 114 [0/1612 (0%)] Loss: 0.457021\n",
      "Train Epoch: 114 [160/1612 (10%)] Loss: 0.299324\n",
      "Train Epoch: 114 [320/1612 (20%)] Loss: 0.342554\n",
      "Train Epoch: 114 [480/1612 (30%)] Loss: 0.434517\n",
      "Train Epoch: 114 [640/1612 (40%)] Loss: 0.402849\n",
      "Train Epoch: 114 [800/1612 (50%)] Loss: 0.372263\n",
      "Train Epoch: 114 [960/1612 (59%)] Loss: 0.271019\n",
      "Train Epoch: 114 [1120/1612 (69%)] Loss: 0.684765\n",
      "Train Epoch: 114 [1280/1612 (79%)] Loss: 0.332311\n",
      "Train Epoch: 114 [1440/1612 (89%)] Loss: 0.361085\n",
      "Train Epoch: 114 [1200/1612 (99%)] Loss: 0.909002\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 115 [0/1612 (0%)] Loss: 0.459106\n",
      "Train Epoch: 115 [160/1612 (10%)] Loss: 0.303845\n",
      "Train Epoch: 115 [320/1612 (20%)] Loss: 0.356694\n",
      "Train Epoch: 115 [480/1612 (30%)] Loss: 0.500319\n",
      "Train Epoch: 115 [640/1612 (40%)] Loss: 0.511734\n",
      "Train Epoch: 115 [800/1612 (50%)] Loss: 0.330198\n",
      "Train Epoch: 115 [960/1612 (59%)] Loss: 0.239210\n",
      "Train Epoch: 115 [1120/1612 (69%)] Loss: 0.417462\n",
      "Train Epoch: 115 [1280/1612 (79%)] Loss: 0.291745\n",
      "Train Epoch: 115 [1440/1612 (89%)] Loss: 0.350707\n",
      "Train Epoch: 115 [1200/1612 (99%)] Loss: 0.650724\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 116 [0/1612 (0%)] Loss: 0.254455\n",
      "Train Epoch: 116 [160/1612 (10%)] Loss: 0.510706\n",
      "Train Epoch: 116 [320/1612 (20%)] Loss: 0.347360\n",
      "Train Epoch: 116 [480/1612 (30%)] Loss: 0.385166\n",
      "Train Epoch: 116 [640/1612 (40%)] Loss: 0.227947\n",
      "Train Epoch: 116 [800/1612 (50%)] Loss: 0.416551\n",
      "Train Epoch: 116 [960/1612 (59%)] Loss: 0.462379\n",
      "Train Epoch: 116 [1120/1612 (69%)] Loss: 0.348838\n",
      "Train Epoch: 116 [1280/1612 (79%)] Loss: 0.379767\n",
      "Train Epoch: 116 [1440/1612 (89%)] Loss: 0.663484\n",
      "Train Epoch: 116 [1200/1612 (99%)] Loss: 0.263619\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 117 [0/1612 (0%)] Loss: 0.204490\n",
      "Train Epoch: 117 [160/1612 (10%)] Loss: 0.329647\n",
      "Train Epoch: 117 [320/1612 (20%)] Loss: 0.191736\n",
      "Train Epoch: 117 [480/1612 (30%)] Loss: 1.000326\n",
      "Train Epoch: 117 [640/1612 (40%)] Loss: 0.348623\n",
      "Train Epoch: 117 [800/1612 (50%)] Loss: 0.404326\n",
      "Train Epoch: 117 [960/1612 (59%)] Loss: 0.426623\n",
      "Train Epoch: 117 [1120/1612 (69%)] Loss: 0.408183\n",
      "Train Epoch: 117 [1280/1612 (79%)] Loss: 0.518094\n",
      "Train Epoch: 117 [1440/1612 (89%)] Loss: 0.534935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 117 [1200/1612 (99%)] Loss: 0.284788\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 118 [0/1612 (0%)] Loss: 0.413295\n",
      "Train Epoch: 118 [160/1612 (10%)] Loss: 0.417921\n",
      "Train Epoch: 118 [320/1612 (20%)] Loss: 0.663717\n",
      "Train Epoch: 118 [480/1612 (30%)] Loss: 0.283034\n",
      "Train Epoch: 118 [640/1612 (40%)] Loss: 0.334501\n",
      "Train Epoch: 118 [800/1612 (50%)] Loss: 0.810274\n",
      "Train Epoch: 118 [960/1612 (59%)] Loss: 0.308392\n",
      "Train Epoch: 118 [1120/1612 (69%)] Loss: 0.400602\n",
      "Train Epoch: 118 [1280/1612 (79%)] Loss: 0.716037\n",
      "Train Epoch: 118 [1440/1612 (89%)] Loss: 0.436003\n",
      "Train Epoch: 118 [1200/1612 (99%)] Loss: 0.501329\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 119 [0/1612 (0%)] Loss: 0.258838\n",
      "Train Epoch: 119 [160/1612 (10%)] Loss: 0.297792\n",
      "Train Epoch: 119 [320/1612 (20%)] Loss: 0.514149\n",
      "Train Epoch: 119 [480/1612 (30%)] Loss: 0.488799\n",
      "Train Epoch: 119 [640/1612 (40%)] Loss: 0.277990\n",
      "Train Epoch: 119 [800/1612 (50%)] Loss: 0.302721\n",
      "Train Epoch: 119 [960/1612 (59%)] Loss: 0.545798\n",
      "Train Epoch: 119 [1120/1612 (69%)] Loss: 0.435544\n",
      "Train Epoch: 119 [1280/1612 (79%)] Loss: 0.546306\n",
      "Train Epoch: 119 [1440/1612 (89%)] Loss: 0.390468\n",
      "Train Epoch: 119 [1200/1612 (99%)] Loss: 0.316017\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 120 [0/1612 (0%)] Loss: 0.781219\n",
      "Train Epoch: 120 [160/1612 (10%)] Loss: 0.342613\n",
      "Train Epoch: 120 [320/1612 (20%)] Loss: 0.282708\n",
      "Train Epoch: 120 [480/1612 (30%)] Loss: 0.190093\n",
      "Train Epoch: 120 [640/1612 (40%)] Loss: 0.168700\n",
      "Train Epoch: 120 [800/1612 (50%)] Loss: 0.714637\n",
      "Train Epoch: 120 [960/1612 (59%)] Loss: 0.326664\n",
      "Train Epoch: 120 [1120/1612 (69%)] Loss: 0.541170\n",
      "Train Epoch: 120 [1280/1612 (79%)] Loss: 0.378678\n",
      "Train Epoch: 120 [1440/1612 (89%)] Loss: 0.294833\n",
      "Train Epoch: 120 [1200/1612 (99%)] Loss: 0.418413\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 121 [0/1612 (0%)] Loss: 0.518767\n",
      "Train Epoch: 121 [160/1612 (10%)] Loss: 0.484521\n",
      "Train Epoch: 121 [320/1612 (20%)] Loss: 0.302357\n",
      "Train Epoch: 121 [480/1612 (30%)] Loss: 0.572448\n",
      "Train Epoch: 121 [640/1612 (40%)] Loss: 0.194665\n",
      "Train Epoch: 121 [800/1612 (50%)] Loss: 0.405804\n",
      "Train Epoch: 121 [960/1612 (59%)] Loss: 0.351755\n",
      "Train Epoch: 121 [1120/1612 (69%)] Loss: 0.357690\n",
      "Train Epoch: 121 [1280/1612 (79%)] Loss: 0.368856\n",
      "Train Epoch: 121 [1440/1612 (89%)] Loss: 0.366671\n",
      "Train Epoch: 121 [1200/1612 (99%)] Loss: 0.575670\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 122 [0/1612 (0%)] Loss: 0.576438\n",
      "Train Epoch: 122 [160/1612 (10%)] Loss: 0.388556\n",
      "Train Epoch: 122 [320/1612 (20%)] Loss: 0.458233\n",
      "Train Epoch: 122 [480/1612 (30%)] Loss: 0.313243\n",
      "Train Epoch: 122 [640/1612 (40%)] Loss: 0.494469\n",
      "Train Epoch: 122 [800/1612 (50%)] Loss: 0.348684\n",
      "Train Epoch: 122 [960/1612 (59%)] Loss: 0.445067\n",
      "Train Epoch: 122 [1120/1612 (69%)] Loss: 0.267855\n",
      "Train Epoch: 122 [1280/1612 (79%)] Loss: 0.381246\n",
      "Train Epoch: 122 [1440/1612 (89%)] Loss: 0.572270\n",
      "Train Epoch: 122 [1200/1612 (99%)] Loss: 0.286322\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 123 [0/1612 (0%)] Loss: 0.468558\n",
      "Train Epoch: 123 [160/1612 (10%)] Loss: 0.267758\n",
      "Train Epoch: 123 [320/1612 (20%)] Loss: 0.148121\n",
      "Train Epoch: 123 [480/1612 (30%)] Loss: 0.434334\n",
      "Train Epoch: 123 [640/1612 (40%)] Loss: 0.198361\n",
      "Train Epoch: 123 [800/1612 (50%)] Loss: 0.567659\n",
      "Train Epoch: 123 [960/1612 (59%)] Loss: 0.216630\n",
      "Train Epoch: 123 [1120/1612 (69%)] Loss: 0.444593\n",
      "Train Epoch: 123 [1280/1612 (79%)] Loss: 0.170827\n",
      "Train Epoch: 123 [1440/1612 (89%)] Loss: 0.539907\n",
      "Train Epoch: 123 [1200/1612 (99%)] Loss: 0.288878\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 124 [0/1612 (0%)] Loss: 0.371087\n",
      "Train Epoch: 124 [160/1612 (10%)] Loss: 0.368376\n",
      "Train Epoch: 124 [320/1612 (20%)] Loss: 0.448932\n",
      "Train Epoch: 124 [480/1612 (30%)] Loss: 0.366832\n",
      "Train Epoch: 124 [640/1612 (40%)] Loss: 0.410025\n",
      "Train Epoch: 124 [800/1612 (50%)] Loss: 0.549642\n",
      "Train Epoch: 124 [960/1612 (59%)] Loss: 0.369750\n",
      "Train Epoch: 124 [1120/1612 (69%)] Loss: 0.333796\n",
      "Train Epoch: 124 [1280/1612 (79%)] Loss: 0.244937\n",
      "Train Epoch: 124 [1440/1612 (89%)] Loss: 0.332713\n",
      "Train Epoch: 124 [1200/1612 (99%)] Loss: 0.589360\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 125 [0/1612 (0%)] Loss: 0.328070\n",
      "Train Epoch: 125 [160/1612 (10%)] Loss: 0.416187\n",
      "Train Epoch: 125 [320/1612 (20%)] Loss: 0.225448\n",
      "Train Epoch: 125 [480/1612 (30%)] Loss: 0.557095\n",
      "Train Epoch: 125 [640/1612 (40%)] Loss: 0.361716\n",
      "Train Epoch: 125 [800/1612 (50%)] Loss: 0.464833\n",
      "Train Epoch: 125 [960/1612 (59%)] Loss: 0.249866\n",
      "Train Epoch: 125 [1120/1612 (69%)] Loss: 0.312520\n",
      "Train Epoch: 125 [1280/1612 (79%)] Loss: 0.468880\n",
      "Train Epoch: 125 [1440/1612 (89%)] Loss: 0.254429\n",
      "Train Epoch: 125 [1200/1612 (99%)] Loss: 0.301325\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 126 [0/1612 (0%)] Loss: 0.318709\n",
      "Train Epoch: 126 [160/1612 (10%)] Loss: 0.223275\n",
      "Train Epoch: 126 [320/1612 (20%)] Loss: 0.442513\n",
      "Train Epoch: 126 [480/1612 (30%)] Loss: 0.503688\n",
      "Train Epoch: 126 [640/1612 (40%)] Loss: 0.528873\n",
      "Train Epoch: 126 [800/1612 (50%)] Loss: 0.563350\n",
      "Train Epoch: 126 [960/1612 (59%)] Loss: 0.448984\n",
      "Train Epoch: 126 [1120/1612 (69%)] Loss: 0.276287\n",
      "Train Epoch: 126 [1280/1612 (79%)] Loss: 0.363736\n",
      "Train Epoch: 126 [1440/1612 (89%)] Loss: 0.497142\n",
      "Train Epoch: 126 [1200/1612 (99%)] Loss: 0.290980\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 127 [0/1612 (0%)] Loss: 0.467677\n",
      "Train Epoch: 127 [160/1612 (10%)] Loss: 0.424671\n",
      "Train Epoch: 127 [320/1612 (20%)] Loss: 0.224629\n",
      "Train Epoch: 127 [480/1612 (30%)] Loss: 0.341176\n",
      "Train Epoch: 127 [640/1612 (40%)] Loss: 0.279270\n",
      "Train Epoch: 127 [800/1612 (50%)] Loss: 0.515156\n",
      "Train Epoch: 127 [960/1612 (59%)] Loss: 0.265832\n",
      "Train Epoch: 127 [1120/1612 (69%)] Loss: 0.243275\n",
      "Train Epoch: 127 [1280/1612 (79%)] Loss: 0.178796\n",
      "Train Epoch: 127 [1440/1612 (89%)] Loss: 0.278938\n",
      "Train Epoch: 127 [1200/1612 (99%)] Loss: 0.280280\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 128 [0/1612 (0%)] Loss: 0.231750\n",
      "Train Epoch: 128 [160/1612 (10%)] Loss: 0.305115\n",
      "Train Epoch: 128 [320/1612 (20%)] Loss: 0.616068\n",
      "Train Epoch: 128 [480/1612 (30%)] Loss: 0.412268\n",
      "Train Epoch: 128 [640/1612 (40%)] Loss: 0.368402\n",
      "Train Epoch: 128 [800/1612 (50%)] Loss: 0.886201\n",
      "Train Epoch: 128 [960/1612 (59%)] Loss: 0.282079\n",
      "Train Epoch: 128 [1120/1612 (69%)] Loss: 0.697113\n",
      "Train Epoch: 128 [1280/1612 (79%)] Loss: 0.346746\n",
      "Train Epoch: 128 [1440/1612 (89%)] Loss: 0.338489\n",
      "Train Epoch: 128 [1200/1612 (99%)] Loss: 0.240574\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 129 [0/1612 (0%)] Loss: 0.307408\n",
      "Train Epoch: 129 [160/1612 (10%)] Loss: 0.426555\n",
      "Train Epoch: 129 [320/1612 (20%)] Loss: 0.242373\n",
      "Train Epoch: 129 [480/1612 (30%)] Loss: 0.198699\n",
      "Train Epoch: 129 [640/1612 (40%)] Loss: 0.440833\n",
      "Train Epoch: 129 [800/1612 (50%)] Loss: 0.391610\n",
      "Train Epoch: 129 [960/1612 (59%)] Loss: 0.348703\n",
      "Train Epoch: 129 [1120/1612 (69%)] Loss: 0.359061\n",
      "Train Epoch: 129 [1280/1612 (79%)] Loss: 0.448004\n",
      "Train Epoch: 129 [1440/1612 (89%)] Loss: 0.324631\n",
      "Train Epoch: 129 [1200/1612 (99%)] Loss: 0.357566\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 130 [0/1612 (0%)] Loss: 0.288226\n",
      "Train Epoch: 130 [160/1612 (10%)] Loss: 0.228121\n",
      "Train Epoch: 130 [320/1612 (20%)] Loss: 0.389515\n",
      "Train Epoch: 130 [480/1612 (30%)] Loss: 0.291433\n",
      "Train Epoch: 130 [640/1612 (40%)] Loss: 0.351950\n",
      "Train Epoch: 130 [800/1612 (50%)] Loss: 0.483239\n",
      "Train Epoch: 130 [960/1612 (59%)] Loss: 0.182398\n",
      "Train Epoch: 130 [1120/1612 (69%)] Loss: 0.306765\n",
      "Train Epoch: 130 [1280/1612 (79%)] Loss: 0.558155\n",
      "Train Epoch: 130 [1440/1612 (89%)] Loss: 0.516595\n",
      "Train Epoch: 130 [1200/1612 (99%)] Loss: 0.404113\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 131 [0/1612 (0%)] Loss: 0.295456\n",
      "Train Epoch: 131 [160/1612 (10%)] Loss: 0.324252\n",
      "Train Epoch: 131 [320/1612 (20%)] Loss: 0.354918\n",
      "Train Epoch: 131 [480/1612 (30%)] Loss: 0.626118\n",
      "Train Epoch: 131 [640/1612 (40%)] Loss: 0.344172\n",
      "Train Epoch: 131 [800/1612 (50%)] Loss: 0.687300\n",
      "Train Epoch: 131 [960/1612 (59%)] Loss: 0.311735\n",
      "Train Epoch: 131 [1120/1612 (69%)] Loss: 0.469177\n",
      "Train Epoch: 131 [1280/1612 (79%)] Loss: 0.407033\n",
      "Train Epoch: 131 [1440/1612 (89%)] Loss: 0.455915\n",
      "Train Epoch: 131 [1200/1612 (99%)] Loss: 0.327981\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 132 [0/1612 (0%)] Loss: 0.445134\n",
      "Train Epoch: 132 [160/1612 (10%)] Loss: 0.310786\n",
      "Train Epoch: 132 [320/1612 (20%)] Loss: 0.332269\n",
      "Train Epoch: 132 [480/1612 (30%)] Loss: 0.597185\n",
      "Train Epoch: 132 [640/1612 (40%)] Loss: 0.404927\n",
      "Train Epoch: 132 [800/1612 (50%)] Loss: 0.447716\n",
      "Train Epoch: 132 [960/1612 (59%)] Loss: 0.313181\n",
      "Train Epoch: 132 [1120/1612 (69%)] Loss: 0.316450\n",
      "Train Epoch: 132 [1280/1612 (79%)] Loss: 0.252058\n",
      "Train Epoch: 132 [1440/1612 (89%)] Loss: 0.634878\n",
      "Train Epoch: 132 [1200/1612 (99%)] Loss: 0.496147\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 133 [0/1612 (0%)] Loss: 0.427757\n",
      "Train Epoch: 133 [160/1612 (10%)] Loss: 0.603154\n",
      "Train Epoch: 133 [320/1612 (20%)] Loss: 0.563699\n",
      "Train Epoch: 133 [480/1612 (30%)] Loss: 0.304949\n",
      "Train Epoch: 133 [640/1612 (40%)] Loss: 0.448567\n",
      "Train Epoch: 133 [800/1612 (50%)] Loss: 0.276009\n",
      "Train Epoch: 133 [960/1612 (59%)] Loss: 0.397901\n",
      "Train Epoch: 133 [1120/1612 (69%)] Loss: 0.599867\n",
      "Train Epoch: 133 [1280/1612 (79%)] Loss: 0.475855\n",
      "Train Epoch: 133 [1440/1612 (89%)] Loss: 0.499460\n",
      "Train Epoch: 133 [1200/1612 (99%)] Loss: 0.503341\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 134 [0/1612 (0%)] Loss: 0.318130\n",
      "Train Epoch: 134 [160/1612 (10%)] Loss: 0.395762\n",
      "Train Epoch: 134 [320/1612 (20%)] Loss: 0.418520\n",
      "Train Epoch: 134 [480/1612 (30%)] Loss: 0.376415\n",
      "Train Epoch: 134 [640/1612 (40%)] Loss: 0.381998\n",
      "Train Epoch: 134 [800/1612 (50%)] Loss: 0.491674\n",
      "Train Epoch: 134 [960/1612 (59%)] Loss: 0.316957\n",
      "Train Epoch: 134 [1120/1612 (69%)] Loss: 0.177635\n",
      "Train Epoch: 134 [1280/1612 (79%)] Loss: 0.570476\n",
      "Train Epoch: 134 [1440/1612 (89%)] Loss: 0.402532\n",
      "Train Epoch: 134 [1200/1612 (99%)] Loss: 0.326366\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 135 [0/1612 (0%)] Loss: 0.491864\n",
      "Train Epoch: 135 [160/1612 (10%)] Loss: 0.350800\n",
      "Train Epoch: 135 [320/1612 (20%)] Loss: 0.470158\n",
      "Train Epoch: 135 [480/1612 (30%)] Loss: 0.248799\n",
      "Train Epoch: 135 [640/1612 (40%)] Loss: 0.366076\n",
      "Train Epoch: 135 [800/1612 (50%)] Loss: 0.324020\n",
      "Train Epoch: 135 [960/1612 (59%)] Loss: 0.477898\n",
      "Train Epoch: 135 [1120/1612 (69%)] Loss: 0.622406\n",
      "Train Epoch: 135 [1280/1612 (79%)] Loss: 0.295152\n",
      "Train Epoch: 135 [1440/1612 (89%)] Loss: 0.101913\n",
      "Train Epoch: 135 [1200/1612 (99%)] Loss: 0.533057\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 136 [0/1612 (0%)] Loss: 0.334986\n",
      "Train Epoch: 136 [160/1612 (10%)] Loss: 0.446115\n",
      "Train Epoch: 136 [320/1612 (20%)] Loss: 0.242399\n",
      "Train Epoch: 136 [480/1612 (30%)] Loss: 0.220497\n",
      "Train Epoch: 136 [640/1612 (40%)] Loss: 0.406722\n",
      "Train Epoch: 136 [800/1612 (50%)] Loss: 0.403749\n",
      "Train Epoch: 136 [960/1612 (59%)] Loss: 0.329327\n",
      "Train Epoch: 136 [1120/1612 (69%)] Loss: 0.594591\n",
      "Train Epoch: 136 [1280/1612 (79%)] Loss: 0.303098\n",
      "Train Epoch: 136 [1440/1612 (89%)] Loss: 0.237050\n",
      "Train Epoch: 136 [1200/1612 (99%)] Loss: 0.444237\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 137 [0/1612 (0%)] Loss: 0.215299\n",
      "Train Epoch: 137 [160/1612 (10%)] Loss: 0.122051\n",
      "Train Epoch: 137 [320/1612 (20%)] Loss: 0.409833\n",
      "Train Epoch: 137 [480/1612 (30%)] Loss: 0.476983\n",
      "Train Epoch: 137 [640/1612 (40%)] Loss: 0.630459\n",
      "Train Epoch: 137 [800/1612 (50%)] Loss: 0.441573\n",
      "Train Epoch: 137 [960/1612 (59%)] Loss: 0.309517\n",
      "Train Epoch: 137 [1120/1612 (69%)] Loss: 0.280695\n",
      "Train Epoch: 137 [1280/1612 (79%)] Loss: 0.194422\n",
      "Train Epoch: 137 [1440/1612 (89%)] Loss: 0.405491\n",
      "Train Epoch: 137 [1200/1612 (99%)] Loss: 0.286594\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 138 [0/1612 (0%)] Loss: 0.405030\n",
      "Train Epoch: 138 [160/1612 (10%)] Loss: 0.288210\n",
      "Train Epoch: 138 [320/1612 (20%)] Loss: 0.421206\n",
      "Train Epoch: 138 [480/1612 (30%)] Loss: 0.281850\n",
      "Train Epoch: 138 [640/1612 (40%)] Loss: 0.337751\n",
      "Train Epoch: 138 [800/1612 (50%)] Loss: 0.462590\n",
      "Train Epoch: 138 [960/1612 (59%)] Loss: 0.235584\n",
      "Train Epoch: 138 [1120/1612 (69%)] Loss: 0.541903\n",
      "Train Epoch: 138 [1280/1612 (79%)] Loss: 0.351307\n",
      "Train Epoch: 138 [1440/1612 (89%)] Loss: 0.252080\n",
      "Train Epoch: 138 [1200/1612 (99%)] Loss: 0.635892\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 139 [0/1612 (0%)] Loss: 0.381831\n",
      "Train Epoch: 139 [160/1612 (10%)] Loss: 0.283396\n",
      "Train Epoch: 139 [320/1612 (20%)] Loss: 0.375113\n",
      "Train Epoch: 139 [480/1612 (30%)] Loss: 0.239677\n",
      "Train Epoch: 139 [640/1612 (40%)] Loss: 0.484824\n",
      "Train Epoch: 139 [800/1612 (50%)] Loss: 0.420821\n",
      "Train Epoch: 139 [960/1612 (59%)] Loss: 0.779675\n",
      "Train Epoch: 139 [1120/1612 (69%)] Loss: 0.307110\n",
      "Train Epoch: 139 [1280/1612 (79%)] Loss: 0.279101\n",
      "Train Epoch: 139 [1440/1612 (89%)] Loss: 0.378814\n",
      "Train Epoch: 139 [1200/1612 (99%)] Loss: 0.234534\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 140 [0/1612 (0%)] Loss: 0.372041\n",
      "Train Epoch: 140 [160/1612 (10%)] Loss: 0.340299\n",
      "Train Epoch: 140 [320/1612 (20%)] Loss: 0.276320\n",
      "Train Epoch: 140 [480/1612 (30%)] Loss: 0.404589\n",
      "Train Epoch: 140 [640/1612 (40%)] Loss: 0.316243\n",
      "Train Epoch: 140 [800/1612 (50%)] Loss: 0.539181\n",
      "Train Epoch: 140 [960/1612 (59%)] Loss: 0.265266\n",
      "Train Epoch: 140 [1120/1612 (69%)] Loss: 0.426425\n",
      "Train Epoch: 140 [1280/1612 (79%)] Loss: 0.266884\n",
      "Train Epoch: 140 [1440/1612 (89%)] Loss: 0.275470\n",
      "Train Epoch: 140 [1200/1612 (99%)] Loss: 0.359958\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 141 [0/1612 (0%)] Loss: 0.517648\n",
      "Train Epoch: 141 [160/1612 (10%)] Loss: 0.297228\n",
      "Train Epoch: 141 [320/1612 (20%)] Loss: 0.467780\n",
      "Train Epoch: 141 [480/1612 (30%)] Loss: 0.317931\n",
      "Train Epoch: 141 [640/1612 (40%)] Loss: 0.390825\n",
      "Train Epoch: 141 [800/1612 (50%)] Loss: 0.203550\n",
      "Train Epoch: 141 [960/1612 (59%)] Loss: 0.404239\n",
      "Train Epoch: 141 [1120/1612 (69%)] Loss: 0.535536\n",
      "Train Epoch: 141 [1280/1612 (79%)] Loss: 0.124529\n",
      "Train Epoch: 141 [1440/1612 (89%)] Loss: 0.415482\n",
      "Train Epoch: 141 [1200/1612 (99%)] Loss: 0.855145\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 142 [0/1612 (0%)] Loss: 0.262051\n",
      "Train Epoch: 142 [160/1612 (10%)] Loss: 0.214275\n",
      "Train Epoch: 142 [320/1612 (20%)] Loss: 0.467258\n",
      "Train Epoch: 142 [480/1612 (30%)] Loss: 0.753451\n",
      "Train Epoch: 142 [640/1612 (40%)] Loss: 0.225741\n",
      "Train Epoch: 142 [800/1612 (50%)] Loss: 0.619270\n",
      "Train Epoch: 142 [960/1612 (59%)] Loss: 0.302270\n",
      "Train Epoch: 142 [1120/1612 (69%)] Loss: 0.408408\n",
      "Train Epoch: 142 [1280/1612 (79%)] Loss: 0.320129\n",
      "Train Epoch: 142 [1440/1612 (89%)] Loss: 0.325249\n",
      "Train Epoch: 142 [1200/1612 (99%)] Loss: 0.379762\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 143 [0/1612 (0%)] Loss: 0.409474\n",
      "Train Epoch: 143 [160/1612 (10%)] Loss: 0.237880\n",
      "Train Epoch: 143 [320/1612 (20%)] Loss: 0.382163\n",
      "Train Epoch: 143 [480/1612 (30%)] Loss: 0.227130\n",
      "Train Epoch: 143 [640/1612 (40%)] Loss: 0.203911\n",
      "Train Epoch: 143 [800/1612 (50%)] Loss: 0.242522\n",
      "Train Epoch: 143 [960/1612 (59%)] Loss: 0.211471\n",
      "Train Epoch: 143 [1120/1612 (69%)] Loss: 0.345178\n",
      "Train Epoch: 143 [1280/1612 (79%)] Loss: 0.251723\n",
      "Train Epoch: 143 [1440/1612 (89%)] Loss: 0.293814\n",
      "Train Epoch: 143 [1200/1612 (99%)] Loss: 0.287616\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 144 [0/1612 (0%)] Loss: 0.203785\n",
      "Train Epoch: 144 [160/1612 (10%)] Loss: 0.267750\n",
      "Train Epoch: 144 [320/1612 (20%)] Loss: 0.502824\n",
      "Train Epoch: 144 [480/1612 (30%)] Loss: 0.394722\n",
      "Train Epoch: 144 [640/1612 (40%)] Loss: 0.273249\n",
      "Train Epoch: 144 [800/1612 (50%)] Loss: 0.391903\n",
      "Train Epoch: 144 [960/1612 (59%)] Loss: 0.338550\n",
      "Train Epoch: 144 [1120/1612 (69%)] Loss: 0.285156\n",
      "Train Epoch: 144 [1280/1612 (79%)] Loss: 0.205888\n",
      "Train Epoch: 144 [1440/1612 (89%)] Loss: 0.610123\n",
      "Train Epoch: 144 [1200/1612 (99%)] Loss: 0.435018\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 145 [0/1612 (0%)] Loss: 0.427902\n",
      "Train Epoch: 145 [160/1612 (10%)] Loss: 0.327143\n",
      "Train Epoch: 145 [320/1612 (20%)] Loss: 0.243512\n",
      "Train Epoch: 145 [480/1612 (30%)] Loss: 0.548277\n",
      "Train Epoch: 145 [640/1612 (40%)] Loss: 0.308074\n",
      "Train Epoch: 145 [800/1612 (50%)] Loss: 0.493220\n",
      "Train Epoch: 145 [960/1612 (59%)] Loss: 0.381103\n",
      "Train Epoch: 145 [1120/1612 (69%)] Loss: 0.242270\n",
      "Train Epoch: 145 [1280/1612 (79%)] Loss: 0.440484\n",
      "Train Epoch: 145 [1440/1612 (89%)] Loss: 0.326795\n",
      "Train Epoch: 145 [1200/1612 (99%)] Loss: 0.225743\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 146 [0/1612 (0%)] Loss: 0.326430\n",
      "Train Epoch: 146 [160/1612 (10%)] Loss: 0.373241\n",
      "Train Epoch: 146 [320/1612 (20%)] Loss: 0.289186\n",
      "Train Epoch: 146 [480/1612 (30%)] Loss: 0.304873\n",
      "Train Epoch: 146 [640/1612 (40%)] Loss: 0.297977\n",
      "Train Epoch: 146 [800/1612 (50%)] Loss: 0.322265\n",
      "Train Epoch: 146 [960/1612 (59%)] Loss: 0.385766\n",
      "Train Epoch: 146 [1120/1612 (69%)] Loss: 0.580182\n",
      "Train Epoch: 146 [1280/1612 (79%)] Loss: 0.369482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 146 [1440/1612 (89%)] Loss: 0.572466\n",
      "Train Epoch: 146 [1200/1612 (99%)] Loss: 0.334876\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 147 [0/1612 (0%)] Loss: 0.429830\n",
      "Train Epoch: 147 [160/1612 (10%)] Loss: 0.506299\n",
      "Train Epoch: 147 [320/1612 (20%)] Loss: 0.423751\n",
      "Train Epoch: 147 [480/1612 (30%)] Loss: 0.198553\n",
      "Train Epoch: 147 [640/1612 (40%)] Loss: 0.133618\n",
      "Train Epoch: 147 [800/1612 (50%)] Loss: 0.330275\n",
      "Train Epoch: 147 [960/1612 (59%)] Loss: 0.579938\n",
      "Train Epoch: 147 [1120/1612 (69%)] Loss: 0.365865\n",
      "Train Epoch: 147 [1280/1612 (79%)] Loss: 0.293368\n",
      "Train Epoch: 147 [1440/1612 (89%)] Loss: 0.435115\n",
      "Train Epoch: 147 [1200/1612 (99%)] Loss: 0.350524\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 148 [0/1612 (0%)] Loss: 0.285106\n",
      "Train Epoch: 148 [160/1612 (10%)] Loss: 0.590058\n",
      "Train Epoch: 148 [320/1612 (20%)] Loss: 0.484493\n",
      "Train Epoch: 148 [480/1612 (30%)] Loss: 0.633423\n",
      "Train Epoch: 148 [640/1612 (40%)] Loss: 0.576661\n",
      "Train Epoch: 148 [800/1612 (50%)] Loss: 0.394349\n",
      "Train Epoch: 148 [960/1612 (59%)] Loss: 0.226323\n",
      "Train Epoch: 148 [1120/1612 (69%)] Loss: 0.341020\n",
      "Train Epoch: 148 [1280/1612 (79%)] Loss: 0.294251\n",
      "Train Epoch: 148 [1440/1612 (89%)] Loss: 0.616452\n",
      "Train Epoch: 148 [1200/1612 (99%)] Loss: 0.253740\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 149 [0/1612 (0%)] Loss: 0.494624\n",
      "Train Epoch: 149 [160/1612 (10%)] Loss: 0.320105\n",
      "Train Epoch: 149 [320/1612 (20%)] Loss: 0.482735\n",
      "Train Epoch: 149 [480/1612 (30%)] Loss: 0.352181\n",
      "Train Epoch: 149 [640/1612 (40%)] Loss: 0.278936\n",
      "Train Epoch: 149 [800/1612 (50%)] Loss: 0.241246\n",
      "Train Epoch: 149 [960/1612 (59%)] Loss: 0.422878\n",
      "Train Epoch: 149 [1120/1612 (69%)] Loss: 0.542790\n",
      "Train Epoch: 149 [1280/1612 (79%)] Loss: 0.278649\n",
      "Train Epoch: 149 [1440/1612 (89%)] Loss: 0.253633\n",
      "Train Epoch: 149 [1200/1612 (99%)] Loss: 0.582236\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 150 [0/1612 (0%)] Loss: 0.682756\n",
      "Train Epoch: 150 [160/1612 (10%)] Loss: 0.338903\n",
      "Train Epoch: 150 [320/1612 (20%)] Loss: 0.517556\n",
      "Train Epoch: 150 [480/1612 (30%)] Loss: 0.359028\n",
      "Train Epoch: 150 [640/1612 (40%)] Loss: 0.344527\n",
      "Train Epoch: 150 [800/1612 (50%)] Loss: 0.448927\n",
      "Train Epoch: 150 [960/1612 (59%)] Loss: 0.403107\n",
      "Train Epoch: 150 [1120/1612 (69%)] Loss: 0.303317\n",
      "Train Epoch: 150 [1280/1612 (79%)] Loss: 0.279843\n",
      "Train Epoch: 150 [1440/1612 (89%)] Loss: 0.226376\n",
      "Train Epoch: 150 [1200/1612 (99%)] Loss: 0.413396\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 151 [0/1612 (0%)] Loss: 0.567873\n",
      "Train Epoch: 151 [160/1612 (10%)] Loss: 0.599525\n",
      "Train Epoch: 151 [320/1612 (20%)] Loss: 0.358786\n",
      "Train Epoch: 151 [480/1612 (30%)] Loss: 0.347950\n",
      "Train Epoch: 151 [640/1612 (40%)] Loss: 0.530481\n",
      "Train Epoch: 151 [800/1612 (50%)] Loss: 0.424876\n",
      "Train Epoch: 151 [960/1612 (59%)] Loss: 0.572494\n",
      "Train Epoch: 151 [1120/1612 (69%)] Loss: 0.670396\n",
      "Train Epoch: 151 [1280/1612 (79%)] Loss: 0.205112\n",
      "Train Epoch: 151 [1440/1612 (89%)] Loss: 0.357252\n",
      "Train Epoch: 151 [1200/1612 (99%)] Loss: 0.411063\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 152 [0/1612 (0%)] Loss: 0.326870\n",
      "Train Epoch: 152 [160/1612 (10%)] Loss: 0.222425\n",
      "Train Epoch: 152 [320/1612 (20%)] Loss: 0.286094\n",
      "Train Epoch: 152 [480/1612 (30%)] Loss: 0.389842\n",
      "Train Epoch: 152 [640/1612 (40%)] Loss: 0.299741\n",
      "Train Epoch: 152 [800/1612 (50%)] Loss: 0.243402\n",
      "Train Epoch: 152 [960/1612 (59%)] Loss: 0.409486\n",
      "Train Epoch: 152 [1120/1612 (69%)] Loss: 0.151910\n",
      "Train Epoch: 152 [1280/1612 (79%)] Loss: 0.610714\n",
      "Train Epoch: 152 [1440/1612 (89%)] Loss: 0.264970\n",
      "Train Epoch: 152 [1200/1612 (99%)] Loss: 0.317593\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 153 [0/1612 (0%)] Loss: 0.362702\n",
      "Train Epoch: 153 [160/1612 (10%)] Loss: 0.451842\n",
      "Train Epoch: 153 [320/1612 (20%)] Loss: 0.492465\n",
      "Train Epoch: 153 [480/1612 (30%)] Loss: 0.829910\n",
      "Train Epoch: 153 [640/1612 (40%)] Loss: 0.486138\n",
      "Train Epoch: 153 [800/1612 (50%)] Loss: 0.438494\n",
      "Train Epoch: 153 [960/1612 (59%)] Loss: 0.277799\n",
      "Train Epoch: 153 [1120/1612 (69%)] Loss: 0.341393\n",
      "Train Epoch: 153 [1280/1612 (79%)] Loss: 0.239705\n",
      "Train Epoch: 153 [1440/1612 (89%)] Loss: 0.179837\n",
      "Train Epoch: 153 [1200/1612 (99%)] Loss: 0.246316\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 154 [0/1612 (0%)] Loss: 0.400894\n",
      "Train Epoch: 154 [160/1612 (10%)] Loss: 0.434704\n",
      "Train Epoch: 154 [320/1612 (20%)] Loss: 0.346839\n",
      "Train Epoch: 154 [480/1612 (30%)] Loss: 0.419801\n",
      "Train Epoch: 154 [640/1612 (40%)] Loss: 0.241784\n",
      "Train Epoch: 154 [800/1612 (50%)] Loss: 0.403945\n",
      "Train Epoch: 154 [960/1612 (59%)] Loss: 0.455343\n",
      "Train Epoch: 154 [1120/1612 (69%)] Loss: 0.274279\n",
      "Train Epoch: 154 [1280/1612 (79%)] Loss: 0.797259\n",
      "Train Epoch: 154 [1440/1612 (89%)] Loss: 0.688382\n",
      "Train Epoch: 154 [1200/1612 (99%)] Loss: 0.128956\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 155 [0/1612 (0%)] Loss: 0.487298\n",
      "Train Epoch: 155 [160/1612 (10%)] Loss: 0.223377\n",
      "Train Epoch: 155 [320/1612 (20%)] Loss: 0.208081\n",
      "Train Epoch: 155 [480/1612 (30%)] Loss: 0.439483\n",
      "Train Epoch: 155 [640/1612 (40%)] Loss: 0.495736\n",
      "Train Epoch: 155 [800/1612 (50%)] Loss: 0.521954\n",
      "Train Epoch: 155 [960/1612 (59%)] Loss: 0.450792\n",
      "Train Epoch: 155 [1120/1612 (69%)] Loss: 0.344188\n",
      "Train Epoch: 155 [1280/1612 (79%)] Loss: 0.480359\n",
      "Train Epoch: 155 [1440/1612 (89%)] Loss: 0.521616\n",
      "Train Epoch: 155 [1200/1612 (99%)] Loss: 0.175713\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 156 [0/1612 (0%)] Loss: 0.503019\n",
      "Train Epoch: 156 [160/1612 (10%)] Loss: 0.469746\n",
      "Train Epoch: 156 [320/1612 (20%)] Loss: 0.308730\n",
      "Train Epoch: 156 [480/1612 (30%)] Loss: 0.432261\n",
      "Train Epoch: 156 [640/1612 (40%)] Loss: 0.259913\n",
      "Train Epoch: 156 [800/1612 (50%)] Loss: 0.335211\n",
      "Train Epoch: 156 [960/1612 (59%)] Loss: 0.345463\n",
      "Train Epoch: 156 [1120/1612 (69%)] Loss: 0.349922\n",
      "Train Epoch: 156 [1280/1612 (79%)] Loss: 0.313183\n",
      "Train Epoch: 156 [1440/1612 (89%)] Loss: 0.325203\n",
      "Train Epoch: 156 [1200/1612 (99%)] Loss: 0.286773\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 157 [0/1612 (0%)] Loss: 0.252578\n",
      "Train Epoch: 157 [160/1612 (10%)] Loss: 0.269336\n",
      "Train Epoch: 157 [320/1612 (20%)] Loss: 0.449510\n",
      "Train Epoch: 157 [480/1612 (30%)] Loss: 0.218329\n",
      "Train Epoch: 157 [640/1612 (40%)] Loss: 0.405899\n",
      "Train Epoch: 157 [800/1612 (50%)] Loss: 0.345207\n",
      "Train Epoch: 157 [960/1612 (59%)] Loss: 0.312325\n",
      "Train Epoch: 157 [1120/1612 (69%)] Loss: 0.353402\n",
      "Train Epoch: 157 [1280/1612 (79%)] Loss: 0.241860\n",
      "Train Epoch: 157 [1440/1612 (89%)] Loss: 0.488797\n",
      "Train Epoch: 157 [1200/1612 (99%)] Loss: 0.586033\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 158 [0/1612 (0%)] Loss: 0.376628\n",
      "Train Epoch: 158 [160/1612 (10%)] Loss: 0.353349\n",
      "Train Epoch: 158 [320/1612 (20%)] Loss: 0.206997\n",
      "Train Epoch: 158 [480/1612 (30%)] Loss: 0.359388\n",
      "Train Epoch: 158 [640/1612 (40%)] Loss: 0.305751\n",
      "Train Epoch: 158 [800/1612 (50%)] Loss: 0.636228\n",
      "Train Epoch: 158 [960/1612 (59%)] Loss: 0.561612\n",
      "Train Epoch: 158 [1120/1612 (69%)] Loss: 0.226472\n",
      "Train Epoch: 158 [1280/1612 (79%)] Loss: 0.413370\n",
      "Train Epoch: 158 [1440/1612 (89%)] Loss: 0.691323\n",
      "Train Epoch: 158 [1200/1612 (99%)] Loss: 0.609674\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 159 [0/1612 (0%)] Loss: 0.488227\n",
      "Train Epoch: 159 [160/1612 (10%)] Loss: 0.283797\n",
      "Train Epoch: 159 [320/1612 (20%)] Loss: 0.223538\n",
      "Train Epoch: 159 [480/1612 (30%)] Loss: 0.259354\n",
      "Train Epoch: 159 [640/1612 (40%)] Loss: 0.276193\n",
      "Train Epoch: 159 [800/1612 (50%)] Loss: 0.284856\n",
      "Train Epoch: 159 [960/1612 (59%)] Loss: 0.497587\n",
      "Train Epoch: 159 [1120/1612 (69%)] Loss: 0.451016\n",
      "Train Epoch: 159 [1280/1612 (79%)] Loss: 0.625099\n",
      "Train Epoch: 159 [1440/1612 (89%)] Loss: 0.346418\n",
      "Train Epoch: 159 [1200/1612 (99%)] Loss: 0.166539\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 160 [0/1612 (0%)] Loss: 0.266280\n",
      "Train Epoch: 160 [160/1612 (10%)] Loss: 0.478929\n",
      "Train Epoch: 160 [320/1612 (20%)] Loss: 0.401197\n",
      "Train Epoch: 160 [480/1612 (30%)] Loss: 0.276599\n",
      "Train Epoch: 160 [640/1612 (40%)] Loss: 0.573329\n",
      "Train Epoch: 160 [800/1612 (50%)] Loss: 0.222533\n",
      "Train Epoch: 160 [960/1612 (59%)] Loss: 0.233649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 160 [1120/1612 (69%)] Loss: 0.286751\n",
      "Train Epoch: 160 [1280/1612 (79%)] Loss: 0.490954\n",
      "Train Epoch: 160 [1440/1612 (89%)] Loss: 0.268104\n",
      "Train Epoch: 160 [1200/1612 (99%)] Loss: 0.327715\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 161 [0/1612 (0%)] Loss: 0.073275\n",
      "Train Epoch: 161 [160/1612 (10%)] Loss: 0.277115\n",
      "Train Epoch: 161 [320/1612 (20%)] Loss: 0.248496\n",
      "Train Epoch: 161 [480/1612 (30%)] Loss: 0.336673\n",
      "Train Epoch: 161 [640/1612 (40%)] Loss: 0.327672\n",
      "Train Epoch: 161 [800/1612 (50%)] Loss: 0.283004\n",
      "Train Epoch: 161 [960/1612 (59%)] Loss: 0.343604\n",
      "Train Epoch: 161 [1120/1612 (69%)] Loss: 0.294863\n",
      "Train Epoch: 161 [1280/1612 (79%)] Loss: 0.476476\n",
      "Train Epoch: 161 [1440/1612 (89%)] Loss: 0.288342\n",
      "Train Epoch: 161 [1200/1612 (99%)] Loss: 0.568019\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 162 [0/1612 (0%)] Loss: 0.223509\n",
      "Train Epoch: 162 [160/1612 (10%)] Loss: 0.464868\n",
      "Train Epoch: 162 [320/1612 (20%)] Loss: 0.389145\n",
      "Train Epoch: 162 [480/1612 (30%)] Loss: 0.771998\n",
      "Train Epoch: 162 [640/1612 (40%)] Loss: 0.297438\n",
      "Train Epoch: 162 [800/1612 (50%)] Loss: 0.571032\n",
      "Train Epoch: 162 [960/1612 (59%)] Loss: 0.318802\n",
      "Train Epoch: 162 [1120/1612 (69%)] Loss: 0.401632\n",
      "Train Epoch: 162 [1280/1612 (79%)] Loss: 0.517117\n",
      "Train Epoch: 162 [1440/1612 (89%)] Loss: 0.182263\n",
      "Train Epoch: 162 [1200/1612 (99%)] Loss: 0.309230\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 163 [0/1612 (0%)] Loss: 0.353811\n",
      "Train Epoch: 163 [160/1612 (10%)] Loss: 0.280286\n",
      "Train Epoch: 163 [320/1612 (20%)] Loss: 0.485744\n",
      "Train Epoch: 163 [480/1612 (30%)] Loss: 0.410044\n",
      "Train Epoch: 163 [640/1612 (40%)] Loss: 0.370747\n",
      "Train Epoch: 163 [800/1612 (50%)] Loss: 0.309726\n",
      "Train Epoch: 163 [960/1612 (59%)] Loss: 0.498574\n",
      "Train Epoch: 163 [1120/1612 (69%)] Loss: 0.250411\n",
      "Train Epoch: 163 [1280/1612 (79%)] Loss: 0.263244\n",
      "Train Epoch: 163 [1440/1612 (89%)] Loss: 0.556919\n",
      "Train Epoch: 163 [1200/1612 (99%)] Loss: 0.483814\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 164 [0/1612 (0%)] Loss: 0.418196\n",
      "Train Epoch: 164 [160/1612 (10%)] Loss: 0.423295\n",
      "Train Epoch: 164 [320/1612 (20%)] Loss: 0.399111\n",
      "Train Epoch: 164 [480/1612 (30%)] Loss: 0.386019\n",
      "Train Epoch: 164 [640/1612 (40%)] Loss: 1.165480\n",
      "Train Epoch: 164 [800/1612 (50%)] Loss: 0.258372\n",
      "Train Epoch: 164 [960/1612 (59%)] Loss: 0.483230\n",
      "Train Epoch: 164 [1120/1612 (69%)] Loss: 0.514215\n",
      "Train Epoch: 164 [1280/1612 (79%)] Loss: 0.479476\n",
      "Train Epoch: 164 [1440/1612 (89%)] Loss: 0.344829\n",
      "Train Epoch: 164 [1200/1612 (99%)] Loss: 0.341851\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 165 [0/1612 (0%)] Loss: 0.268675\n",
      "Train Epoch: 165 [160/1612 (10%)] Loss: 0.666693\n",
      "Train Epoch: 165 [320/1612 (20%)] Loss: 0.232768\n",
      "Train Epoch: 165 [480/1612 (30%)] Loss: 0.464302\n",
      "Train Epoch: 165 [640/1612 (40%)] Loss: 0.364436\n",
      "Train Epoch: 165 [800/1612 (50%)] Loss: 0.345531\n",
      "Train Epoch: 165 [960/1612 (59%)] Loss: 0.233075\n",
      "Train Epoch: 165 [1120/1612 (69%)] Loss: 0.190232\n",
      "Train Epoch: 165 [1280/1612 (79%)] Loss: 0.160441\n",
      "Train Epoch: 165 [1440/1612 (89%)] Loss: 0.363937\n",
      "Train Epoch: 165 [1200/1612 (99%)] Loss: 0.174336\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 166 [0/1612 (0%)] Loss: 0.353217\n",
      "Train Epoch: 166 [160/1612 (10%)] Loss: 0.407076\n",
      "Train Epoch: 166 [320/1612 (20%)] Loss: 0.459164\n",
      "Train Epoch: 166 [480/1612 (30%)] Loss: 0.245655\n",
      "Train Epoch: 166 [640/1612 (40%)] Loss: 0.202886\n",
      "Train Epoch: 166 [800/1612 (50%)] Loss: 0.771119\n",
      "Train Epoch: 166 [960/1612 (59%)] Loss: 0.364728\n",
      "Train Epoch: 166 [1120/1612 (69%)] Loss: 0.358318\n",
      "Train Epoch: 166 [1280/1612 (79%)] Loss: 0.518766\n",
      "Train Epoch: 166 [1440/1612 (89%)] Loss: 0.298600\n",
      "Train Epoch: 166 [1200/1612 (99%)] Loss: 0.741348\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 167 [0/1612 (0%)] Loss: 0.357206\n",
      "Train Epoch: 167 [160/1612 (10%)] Loss: 0.327367\n",
      "Train Epoch: 167 [320/1612 (20%)] Loss: 0.361122\n",
      "Train Epoch: 167 [480/1612 (30%)] Loss: 0.244852\n",
      "Train Epoch: 167 [640/1612 (40%)] Loss: 0.390218\n",
      "Train Epoch: 167 [800/1612 (50%)] Loss: 0.211690\n",
      "Train Epoch: 167 [960/1612 (59%)] Loss: 0.379383\n",
      "Train Epoch: 167 [1120/1612 (69%)] Loss: 0.508532\n",
      "Train Epoch: 167 [1280/1612 (79%)] Loss: 0.370277\n",
      "Train Epoch: 167 [1440/1612 (89%)] Loss: 0.513634\n",
      "Train Epoch: 167 [1200/1612 (99%)] Loss: 0.291453\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 168 [0/1612 (0%)] Loss: 0.150248\n",
      "Train Epoch: 168 [160/1612 (10%)] Loss: 0.464707\n",
      "Train Epoch: 168 [320/1612 (20%)] Loss: 0.328626\n",
      "Train Epoch: 168 [480/1612 (30%)] Loss: 0.351960\n",
      "Train Epoch: 168 [640/1612 (40%)] Loss: 0.436967\n",
      "Train Epoch: 168 [800/1612 (50%)] Loss: 0.442244\n",
      "Train Epoch: 168 [960/1612 (59%)] Loss: 0.264146\n",
      "Train Epoch: 168 [1120/1612 (69%)] Loss: 0.502655\n",
      "Train Epoch: 168 [1280/1612 (79%)] Loss: 0.293437\n",
      "Train Epoch: 168 [1440/1612 (89%)] Loss: 0.225237\n",
      "Train Epoch: 168 [1200/1612 (99%)] Loss: 0.344170\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 169 [0/1612 (0%)] Loss: 0.406868\n",
      "Train Epoch: 169 [160/1612 (10%)] Loss: 0.464755\n",
      "Train Epoch: 169 [320/1612 (20%)] Loss: 0.136758\n",
      "Train Epoch: 169 [480/1612 (30%)] Loss: 0.214394\n",
      "Train Epoch: 169 [640/1612 (40%)] Loss: 0.466691\n",
      "Train Epoch: 169 [800/1612 (50%)] Loss: 0.422344\n",
      "Train Epoch: 169 [960/1612 (59%)] Loss: 0.137243\n",
      "Train Epoch: 169 [1120/1612 (69%)] Loss: 0.231710\n",
      "Train Epoch: 169 [1280/1612 (79%)] Loss: 0.357231\n",
      "Train Epoch: 169 [1440/1612 (89%)] Loss: 0.390376\n",
      "Train Epoch: 169 [1200/1612 (99%)] Loss: 0.407039\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 170 [0/1612 (0%)] Loss: 0.201496\n",
      "Train Epoch: 170 [160/1612 (10%)] Loss: 0.556075\n",
      "Train Epoch: 170 [320/1612 (20%)] Loss: 0.300926\n",
      "Train Epoch: 170 [480/1612 (30%)] Loss: 0.379761\n",
      "Train Epoch: 170 [640/1612 (40%)] Loss: 0.260728\n",
      "Train Epoch: 170 [800/1612 (50%)] Loss: 0.304450\n",
      "Train Epoch: 170 [960/1612 (59%)] Loss: 0.473953\n",
      "Train Epoch: 170 [1120/1612 (69%)] Loss: 0.630410\n",
      "Train Epoch: 170 [1280/1612 (79%)] Loss: 0.618295\n",
      "Train Epoch: 170 [1440/1612 (89%)] Loss: 0.377017\n",
      "Train Epoch: 170 [1200/1612 (99%)] Loss: 0.222778\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 171 [0/1612 (0%)] Loss: 0.305570\n",
      "Train Epoch: 171 [160/1612 (10%)] Loss: 0.275632\n",
      "Train Epoch: 171 [320/1612 (20%)] Loss: 0.343913\n",
      "Train Epoch: 171 [480/1612 (30%)] Loss: 0.298164\n",
      "Train Epoch: 171 [640/1612 (40%)] Loss: 0.298997\n",
      "Train Epoch: 171 [800/1612 (50%)] Loss: 0.314610\n",
      "Train Epoch: 171 [960/1612 (59%)] Loss: 0.224715\n",
      "Train Epoch: 171 [1120/1612 (69%)] Loss: 0.341557\n",
      "Train Epoch: 171 [1280/1612 (79%)] Loss: 0.419464\n",
      "Train Epoch: 171 [1440/1612 (89%)] Loss: 0.233150\n",
      "Train Epoch: 171 [1200/1612 (99%)] Loss: 0.220713\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 172 [0/1612 (0%)] Loss: 0.279833\n",
      "Train Epoch: 172 [160/1612 (10%)] Loss: 0.440389\n",
      "Train Epoch: 172 [320/1612 (20%)] Loss: 0.299446\n",
      "Train Epoch: 172 [480/1612 (30%)] Loss: 0.332957\n",
      "Train Epoch: 172 [640/1612 (40%)] Loss: 0.400400\n",
      "Train Epoch: 172 [800/1612 (50%)] Loss: 0.386868\n",
      "Train Epoch: 172 [960/1612 (59%)] Loss: 0.237407\n",
      "Train Epoch: 172 [1120/1612 (69%)] Loss: 0.371448\n",
      "Train Epoch: 172 [1280/1612 (79%)] Loss: 0.261876\n",
      "Train Epoch: 172 [1440/1612 (89%)] Loss: 0.478119\n",
      "Train Epoch: 172 [1200/1612 (99%)] Loss: 0.299532\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 173 [0/1612 (0%)] Loss: 0.323818\n",
      "Train Epoch: 173 [160/1612 (10%)] Loss: 0.455103\n",
      "Train Epoch: 173 [320/1612 (20%)] Loss: 0.347128\n",
      "Train Epoch: 173 [480/1612 (30%)] Loss: 0.509790\n",
      "Train Epoch: 173 [640/1612 (40%)] Loss: 0.664250\n",
      "Train Epoch: 173 [800/1612 (50%)] Loss: 0.215287\n",
      "Train Epoch: 173 [960/1612 (59%)] Loss: 0.359275\n",
      "Train Epoch: 173 [1120/1612 (69%)] Loss: 0.263540\n",
      "Train Epoch: 173 [1280/1612 (79%)] Loss: 0.526475\n",
      "Train Epoch: 173 [1440/1612 (89%)] Loss: 0.190495\n",
      "Train Epoch: 173 [1200/1612 (99%)] Loss: 0.379091\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 174 [0/1612 (0%)] Loss: 0.369909\n",
      "Train Epoch: 174 [160/1612 (10%)] Loss: 0.313190\n",
      "Train Epoch: 174 [320/1612 (20%)] Loss: 0.256373\n",
      "Train Epoch: 174 [480/1612 (30%)] Loss: 0.152820\n",
      "Train Epoch: 174 [640/1612 (40%)] Loss: 0.136761\n",
      "Train Epoch: 174 [800/1612 (50%)] Loss: 0.604376\n",
      "Train Epoch: 174 [960/1612 (59%)] Loss: 0.365945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 174 [1120/1612 (69%)] Loss: 0.307521\n",
      "Train Epoch: 174 [1280/1612 (79%)] Loss: 0.469680\n",
      "Train Epoch: 174 [1440/1612 (89%)] Loss: 0.512233\n",
      "Train Epoch: 174 [1200/1612 (99%)] Loss: 0.457829\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 175 [0/1612 (0%)] Loss: 0.645040\n",
      "Train Epoch: 175 [160/1612 (10%)] Loss: 0.203466\n",
      "Train Epoch: 175 [320/1612 (20%)] Loss: 0.179719\n",
      "Train Epoch: 175 [480/1612 (30%)] Loss: 0.229327\n",
      "Train Epoch: 175 [640/1612 (40%)] Loss: 0.344788\n",
      "Train Epoch: 175 [800/1612 (50%)] Loss: 0.474419\n",
      "Train Epoch: 175 [960/1612 (59%)] Loss: 0.302972\n",
      "Train Epoch: 175 [1120/1612 (69%)] Loss: 0.527748\n",
      "Train Epoch: 175 [1280/1612 (79%)] Loss: 0.443740\n",
      "Train Epoch: 175 [1440/1612 (89%)] Loss: 0.379746\n",
      "Train Epoch: 175 [1200/1612 (99%)] Loss: 0.322533\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 176 [0/1612 (0%)] Loss: 0.345755\n",
      "Train Epoch: 176 [160/1612 (10%)] Loss: 0.282495\n",
      "Train Epoch: 176 [320/1612 (20%)] Loss: 0.616591\n",
      "Train Epoch: 176 [480/1612 (30%)] Loss: 0.199018\n",
      "Train Epoch: 176 [640/1612 (40%)] Loss: 0.311729\n",
      "Train Epoch: 176 [800/1612 (50%)] Loss: 0.256623\n",
      "Train Epoch: 176 [960/1612 (59%)] Loss: 0.578060\n",
      "Train Epoch: 176 [1120/1612 (69%)] Loss: 0.448212\n",
      "Train Epoch: 176 [1280/1612 (79%)] Loss: 0.381218\n",
      "Train Epoch: 176 [1440/1612 (89%)] Loss: 0.314112\n",
      "Train Epoch: 176 [1200/1612 (99%)] Loss: 0.209880\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 177 [0/1612 (0%)] Loss: 0.338928\n",
      "Train Epoch: 177 [160/1612 (10%)] Loss: 0.378685\n",
      "Train Epoch: 177 [320/1612 (20%)] Loss: 0.348896\n",
      "Train Epoch: 177 [480/1612 (30%)] Loss: 0.228355\n",
      "Train Epoch: 177 [640/1612 (40%)] Loss: 0.336635\n",
      "Train Epoch: 177 [800/1612 (50%)] Loss: 0.333052\n",
      "Train Epoch: 177 [960/1612 (59%)] Loss: 0.373768\n",
      "Train Epoch: 177 [1120/1612 (69%)] Loss: 0.379978\n",
      "Train Epoch: 177 [1280/1612 (79%)] Loss: 0.187073\n",
      "Train Epoch: 177 [1440/1612 (89%)] Loss: 0.447074\n",
      "Train Epoch: 177 [1200/1612 (99%)] Loss: 0.368721\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 178 [0/1612 (0%)] Loss: 0.156745\n",
      "Train Epoch: 178 [160/1612 (10%)] Loss: 0.437619\n",
      "Train Epoch: 178 [320/1612 (20%)] Loss: 0.186177\n",
      "Train Epoch: 178 [480/1612 (30%)] Loss: 0.239744\n",
      "Train Epoch: 178 [640/1612 (40%)] Loss: 0.288172\n",
      "Train Epoch: 178 [800/1612 (50%)] Loss: 0.429303\n",
      "Train Epoch: 178 [960/1612 (59%)] Loss: 0.167267\n",
      "Train Epoch: 178 [1120/1612 (69%)] Loss: 0.324768\n",
      "Train Epoch: 178 [1280/1612 (79%)] Loss: 0.248625\n",
      "Train Epoch: 178 [1440/1612 (89%)] Loss: 0.392383\n",
      "Train Epoch: 178 [1200/1612 (99%)] Loss: 0.128101\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 179 [0/1612 (0%)] Loss: 0.377700\n",
      "Train Epoch: 179 [160/1612 (10%)] Loss: 0.498429\n",
      "Train Epoch: 179 [320/1612 (20%)] Loss: 0.490679\n",
      "Train Epoch: 179 [480/1612 (30%)] Loss: 0.354091\n",
      "Train Epoch: 179 [640/1612 (40%)] Loss: 1.029627\n",
      "Train Epoch: 179 [800/1612 (50%)] Loss: 0.264325\n",
      "Train Epoch: 179 [960/1612 (59%)] Loss: 0.151228\n",
      "Train Epoch: 179 [1120/1612 (69%)] Loss: 0.470606\n",
      "Train Epoch: 179 [1280/1612 (79%)] Loss: 0.383050\n",
      "Train Epoch: 179 [1440/1612 (89%)] Loss: 0.523781\n",
      "Train Epoch: 179 [1200/1612 (99%)] Loss: 0.493385\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 180 [0/1612 (0%)] Loss: 0.294337\n",
      "Train Epoch: 180 [160/1612 (10%)] Loss: 0.190101\n",
      "Train Epoch: 180 [320/1612 (20%)] Loss: 0.265670\n",
      "Train Epoch: 180 [480/1612 (30%)] Loss: 0.279097\n",
      "Train Epoch: 180 [640/1612 (40%)] Loss: 0.515285\n",
      "Train Epoch: 180 [800/1612 (50%)] Loss: 0.366814\n",
      "Train Epoch: 180 [960/1612 (59%)] Loss: 0.322198\n",
      "Train Epoch: 180 [1120/1612 (69%)] Loss: 0.454973\n",
      "Train Epoch: 180 [1280/1612 (79%)] Loss: 0.478508\n",
      "Train Epoch: 180 [1440/1612 (89%)] Loss: 0.307880\n",
      "Train Epoch: 180 [1200/1612 (99%)] Loss: 0.495097\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 181 [0/1612 (0%)] Loss: 0.345007\n",
      "Train Epoch: 181 [160/1612 (10%)] Loss: 0.661009\n",
      "Train Epoch: 181 [320/1612 (20%)] Loss: 0.546560\n",
      "Train Epoch: 181 [480/1612 (30%)] Loss: 0.493458\n",
      "Train Epoch: 181 [640/1612 (40%)] Loss: 0.163886\n",
      "Train Epoch: 181 [800/1612 (50%)] Loss: 0.247337\n",
      "Train Epoch: 181 [960/1612 (59%)] Loss: 0.230827\n",
      "Train Epoch: 181 [1120/1612 (69%)] Loss: 0.480516\n",
      "Train Epoch: 181 [1280/1612 (79%)] Loss: 0.530176\n",
      "Train Epoch: 181 [1440/1612 (89%)] Loss: 0.358317\n",
      "Train Epoch: 181 [1200/1612 (99%)] Loss: 0.270337\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 182 [0/1612 (0%)] Loss: 0.198162\n",
      "Train Epoch: 182 [160/1612 (10%)] Loss: 0.394673\n",
      "Train Epoch: 182 [320/1612 (20%)] Loss: 0.330418\n",
      "Train Epoch: 182 [480/1612 (30%)] Loss: 0.569341\n",
      "Train Epoch: 182 [640/1612 (40%)] Loss: 0.445574\n",
      "Train Epoch: 182 [800/1612 (50%)] Loss: 0.429152\n",
      "Train Epoch: 182 [960/1612 (59%)] Loss: 0.330442\n",
      "Train Epoch: 182 [1120/1612 (69%)] Loss: 0.408576\n",
      "Train Epoch: 182 [1280/1612 (79%)] Loss: 0.335629\n",
      "Train Epoch: 182 [1440/1612 (89%)] Loss: 0.382258\n",
      "Train Epoch: 182 [1200/1612 (99%)] Loss: 0.373242\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 183 [0/1612 (0%)] Loss: 0.499381\n",
      "Train Epoch: 183 [160/1612 (10%)] Loss: 0.343688\n",
      "Train Epoch: 183 [320/1612 (20%)] Loss: 0.285058\n",
      "Train Epoch: 183 [480/1612 (30%)] Loss: 0.177823\n",
      "Train Epoch: 183 [640/1612 (40%)] Loss: 0.377246\n",
      "Train Epoch: 183 [800/1612 (50%)] Loss: 0.276797\n",
      "Train Epoch: 183 [960/1612 (59%)] Loss: 0.311099\n",
      "Train Epoch: 183 [1120/1612 (69%)] Loss: 0.339377\n",
      "Train Epoch: 183 [1280/1612 (79%)] Loss: 0.320055\n",
      "Train Epoch: 183 [1440/1612 (89%)] Loss: 0.415739\n",
      "Train Epoch: 183 [1200/1612 (99%)] Loss: 0.439518\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 184 [0/1612 (0%)] Loss: 0.305773\n",
      "Train Epoch: 184 [160/1612 (10%)] Loss: 0.302514\n",
      "Train Epoch: 184 [320/1612 (20%)] Loss: 0.338456\n",
      "Train Epoch: 184 [480/1612 (30%)] Loss: 0.339899\n",
      "Train Epoch: 184 [640/1612 (40%)] Loss: 0.340786\n",
      "Train Epoch: 184 [800/1612 (50%)] Loss: 0.332010\n",
      "Train Epoch: 184 [960/1612 (59%)] Loss: 0.163838\n",
      "Train Epoch: 184 [1120/1612 (69%)] Loss: 0.261303\n",
      "Train Epoch: 184 [1280/1612 (79%)] Loss: 0.455591\n",
      "Train Epoch: 184 [1440/1612 (89%)] Loss: 0.337726\n",
      "Train Epoch: 184 [1200/1612 (99%)] Loss: 0.177727\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 185 [0/1612 (0%)] Loss: 0.358252\n",
      "Train Epoch: 185 [160/1612 (10%)] Loss: 0.329726\n",
      "Train Epoch: 185 [320/1612 (20%)] Loss: 0.394249\n",
      "Train Epoch: 185 [480/1612 (30%)] Loss: 0.311915\n",
      "Train Epoch: 185 [640/1612 (40%)] Loss: 0.329925\n",
      "Train Epoch: 185 [800/1612 (50%)] Loss: 0.260654\n",
      "Train Epoch: 185 [960/1612 (59%)] Loss: 0.278953\n",
      "Train Epoch: 185 [1120/1612 (69%)] Loss: 0.457253\n",
      "Train Epoch: 185 [1280/1612 (79%)] Loss: 0.247064\n",
      "Train Epoch: 185 [1440/1612 (89%)] Loss: 0.419873\n",
      "Train Epoch: 185 [1200/1612 (99%)] Loss: 0.553586\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 186 [0/1612 (0%)] Loss: 0.401754\n",
      "Train Epoch: 186 [160/1612 (10%)] Loss: 0.325303\n",
      "Train Epoch: 186 [320/1612 (20%)] Loss: 0.291988\n",
      "Train Epoch: 186 [480/1612 (30%)] Loss: 0.418909\n",
      "Train Epoch: 186 [640/1612 (40%)] Loss: 0.545420\n",
      "Train Epoch: 186 [800/1612 (50%)] Loss: 0.310319\n",
      "Train Epoch: 186 [960/1612 (59%)] Loss: 0.524410\n",
      "Train Epoch: 186 [1120/1612 (69%)] Loss: 0.437650\n",
      "Train Epoch: 186 [1280/1612 (79%)] Loss: 0.358984\n",
      "Train Epoch: 186 [1440/1612 (89%)] Loss: 0.159402\n",
      "Train Epoch: 186 [1200/1612 (99%)] Loss: 0.383242\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 187 [0/1612 (0%)] Loss: 0.430178\n",
      "Train Epoch: 187 [160/1612 (10%)] Loss: 0.130771\n",
      "Train Epoch: 187 [320/1612 (20%)] Loss: 0.327668\n",
      "Train Epoch: 187 [480/1612 (30%)] Loss: 0.520021\n",
      "Train Epoch: 187 [640/1612 (40%)] Loss: 0.240252\n",
      "Train Epoch: 187 [800/1612 (50%)] Loss: 0.363442\n",
      "Train Epoch: 187 [960/1612 (59%)] Loss: 0.534176\n",
      "Train Epoch: 187 [1120/1612 (69%)] Loss: 0.434573\n",
      "Train Epoch: 187 [1280/1612 (79%)] Loss: 0.335247\n",
      "Train Epoch: 187 [1440/1612 (89%)] Loss: 0.403149\n",
      "Train Epoch: 187 [1200/1612 (99%)] Loss: 0.233392\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 188 [0/1612 (0%)] Loss: 0.344780\n",
      "Train Epoch: 188 [160/1612 (10%)] Loss: 0.239121\n",
      "Train Epoch: 188 [320/1612 (20%)] Loss: 0.273007\n",
      "Train Epoch: 188 [480/1612 (30%)] Loss: 0.362983\n",
      "Train Epoch: 188 [640/1612 (40%)] Loss: 0.484077\n",
      "Train Epoch: 188 [800/1612 (50%)] Loss: 0.520666\n",
      "Train Epoch: 188 [960/1612 (59%)] Loss: 0.378811\n",
      "Train Epoch: 188 [1120/1612 (69%)] Loss: 0.262013\n",
      "Train Epoch: 188 [1280/1612 (79%)] Loss: 0.359581\n",
      "Train Epoch: 188 [1440/1612 (89%)] Loss: 0.237573\n",
      "Train Epoch: 188 [1200/1612 (99%)] Loss: 0.143603\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 189 [0/1612 (0%)] Loss: 0.425349\n",
      "Train Epoch: 189 [160/1612 (10%)] Loss: 0.371367\n",
      "Train Epoch: 189 [320/1612 (20%)] Loss: 0.180428\n",
      "Train Epoch: 189 [480/1612 (30%)] Loss: 0.149199\n",
      "Train Epoch: 189 [640/1612 (40%)] Loss: 0.275050\n",
      "Train Epoch: 189 [800/1612 (50%)] Loss: 0.261275\n",
      "Train Epoch: 189 [960/1612 (59%)] Loss: 0.545132\n",
      "Train Epoch: 189 [1120/1612 (69%)] Loss: 0.518000\n",
      "Train Epoch: 189 [1280/1612 (79%)] Loss: 0.500540\n",
      "Train Epoch: 189 [1440/1612 (89%)] Loss: 0.259544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 189 [1200/1612 (99%)] Loss: 0.443359\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 190 [0/1612 (0%)] Loss: 0.376546\n",
      "Train Epoch: 190 [160/1612 (10%)] Loss: 0.209710\n",
      "Train Epoch: 190 [320/1612 (20%)] Loss: 0.334704\n",
      "Train Epoch: 190 [480/1612 (30%)] Loss: 0.318826\n",
      "Train Epoch: 190 [640/1612 (40%)] Loss: 0.361170\n",
      "Train Epoch: 190 [800/1612 (50%)] Loss: 0.170906\n",
      "Train Epoch: 190 [960/1612 (59%)] Loss: 0.369556\n",
      "Train Epoch: 190 [1120/1612 (69%)] Loss: 0.173106\n",
      "Train Epoch: 190 [1280/1612 (79%)] Loss: 0.196060\n",
      "Train Epoch: 190 [1440/1612 (89%)] Loss: 0.487390\n",
      "Train Epoch: 190 [1200/1612 (99%)] Loss: 0.908430\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 191 [0/1612 (0%)] Loss: 0.273279\n",
      "Train Epoch: 191 [160/1612 (10%)] Loss: 0.313104\n",
      "Train Epoch: 191 [320/1612 (20%)] Loss: 0.178620\n",
      "Train Epoch: 191 [480/1612 (30%)] Loss: 0.395401\n",
      "Train Epoch: 191 [640/1612 (40%)] Loss: 0.302735\n",
      "Train Epoch: 191 [800/1612 (50%)] Loss: 0.169980\n",
      "Train Epoch: 191 [960/1612 (59%)] Loss: 0.285828\n",
      "Train Epoch: 191 [1120/1612 (69%)] Loss: 0.343806\n",
      "Train Epoch: 191 [1280/1612 (79%)] Loss: 0.272348\n",
      "Train Epoch: 191 [1440/1612 (89%)] Loss: 0.504966\n",
      "Train Epoch: 191 [1200/1612 (99%)] Loss: 0.644563\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 192 [0/1612 (0%)] Loss: 0.766414\n",
      "Train Epoch: 192 [160/1612 (10%)] Loss: 0.354824\n",
      "Train Epoch: 192 [320/1612 (20%)] Loss: 0.462075\n",
      "Train Epoch: 192 [480/1612 (30%)] Loss: 0.353448\n",
      "Train Epoch: 192 [640/1612 (40%)] Loss: 0.391684\n",
      "Train Epoch: 192 [800/1612 (50%)] Loss: 0.339915\n",
      "Train Epoch: 192 [960/1612 (59%)] Loss: 0.440312\n",
      "Train Epoch: 192 [1120/1612 (69%)] Loss: 0.472352\n",
      "Train Epoch: 192 [1280/1612 (79%)] Loss: 0.314820\n",
      "Train Epoch: 192 [1440/1612 (89%)] Loss: 0.483595\n",
      "Train Epoch: 192 [1200/1612 (99%)] Loss: 0.270848\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 193 [0/1612 (0%)] Loss: 0.303639\n",
      "Train Epoch: 193 [160/1612 (10%)] Loss: 0.522251\n",
      "Train Epoch: 193 [320/1612 (20%)] Loss: 0.404323\n",
      "Train Epoch: 193 [480/1612 (30%)] Loss: 0.391448\n",
      "Train Epoch: 193 [640/1612 (40%)] Loss: 0.328181\n",
      "Train Epoch: 193 [800/1612 (50%)] Loss: 0.316199\n",
      "Train Epoch: 193 [960/1612 (59%)] Loss: 0.485305\n",
      "Train Epoch: 193 [1120/1612 (69%)] Loss: 0.380283\n",
      "Train Epoch: 193 [1280/1612 (79%)] Loss: 0.275626\n",
      "Train Epoch: 193 [1440/1612 (89%)] Loss: 0.262459\n",
      "Train Epoch: 193 [1200/1612 (99%)] Loss: 0.656693\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 194 [0/1612 (0%)] Loss: 0.338982\n",
      "Train Epoch: 194 [160/1612 (10%)] Loss: 0.267304\n",
      "Train Epoch: 194 [320/1612 (20%)] Loss: 0.270195\n",
      "Train Epoch: 194 [480/1612 (30%)] Loss: 0.275458\n",
      "Train Epoch: 194 [640/1612 (40%)] Loss: 0.239107\n",
      "Train Epoch: 194 [800/1612 (50%)] Loss: 0.208265\n",
      "Train Epoch: 194 [960/1612 (59%)] Loss: 0.352641\n",
      "Train Epoch: 194 [1120/1612 (69%)] Loss: 0.329341\n",
      "Train Epoch: 194 [1280/1612 (79%)] Loss: 0.384731\n",
      "Train Epoch: 194 [1440/1612 (89%)] Loss: 0.222693\n",
      "Train Epoch: 194 [1200/1612 (99%)] Loss: 0.129637\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 195 [0/1612 (0%)] Loss: 0.592970\n",
      "Train Epoch: 195 [160/1612 (10%)] Loss: 0.346483\n",
      "Train Epoch: 195 [320/1612 (20%)] Loss: 0.392659\n",
      "Train Epoch: 195 [480/1612 (30%)] Loss: 0.242756\n",
      "Train Epoch: 195 [640/1612 (40%)] Loss: 0.247029\n",
      "Train Epoch: 195 [800/1612 (50%)] Loss: 0.552125\n",
      "Train Epoch: 195 [960/1612 (59%)] Loss: 0.361518\n",
      "Train Epoch: 195 [1120/1612 (69%)] Loss: 0.275913\n",
      "Train Epoch: 195 [1280/1612 (79%)] Loss: 0.313339\n",
      "Train Epoch: 195 [1440/1612 (89%)] Loss: 0.488517\n",
      "Train Epoch: 195 [1200/1612 (99%)] Loss: 0.508149\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 196 [0/1612 (0%)] Loss: 0.292131\n",
      "Train Epoch: 196 [160/1612 (10%)] Loss: 0.415907\n",
      "Train Epoch: 196 [320/1612 (20%)] Loss: 0.317481\n",
      "Train Epoch: 196 [480/1612 (30%)] Loss: 0.329001\n",
      "Train Epoch: 196 [640/1612 (40%)] Loss: 0.373338\n",
      "Train Epoch: 196 [800/1612 (50%)] Loss: 0.338278\n",
      "Train Epoch: 196 [960/1612 (59%)] Loss: 0.330640\n",
      "Train Epoch: 196 [1120/1612 (69%)] Loss: 0.350202\n",
      "Train Epoch: 196 [1280/1612 (79%)] Loss: 0.200001\n",
      "Train Epoch: 196 [1440/1612 (89%)] Loss: 0.764961\n",
      "Train Epoch: 196 [1200/1612 (99%)] Loss: 0.426535\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 197 [0/1612 (0%)] Loss: 0.855853\n",
      "Train Epoch: 197 [160/1612 (10%)] Loss: 0.280889\n",
      "Train Epoch: 197 [320/1612 (20%)] Loss: 0.297683\n",
      "Train Epoch: 197 [480/1612 (30%)] Loss: 0.314946\n",
      "Train Epoch: 197 [640/1612 (40%)] Loss: 0.267483\n",
      "Train Epoch: 197 [800/1612 (50%)] Loss: 0.183290\n",
      "Train Epoch: 197 [960/1612 (59%)] Loss: 0.425687\n",
      "Train Epoch: 197 [1120/1612 (69%)] Loss: 0.285834\n",
      "Train Epoch: 197 [1280/1612 (79%)] Loss: 0.237351\n",
      "Train Epoch: 197 [1440/1612 (89%)] Loss: 0.155126\n",
      "Train Epoch: 197 [1200/1612 (99%)] Loss: 0.265384\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 198 [0/1612 (0%)] Loss: 0.238520\n",
      "Train Epoch: 198 [160/1612 (10%)] Loss: 0.367041\n",
      "Train Epoch: 198 [320/1612 (20%)] Loss: 0.613170\n",
      "Train Epoch: 198 [480/1612 (30%)] Loss: 0.507605\n",
      "Train Epoch: 198 [640/1612 (40%)] Loss: 0.361540\n",
      "Train Epoch: 198 [800/1612 (50%)] Loss: 0.085329\n",
      "Train Epoch: 198 [960/1612 (59%)] Loss: 0.368232\n",
      "Train Epoch: 198 [1120/1612 (69%)] Loss: 0.447359\n",
      "Train Epoch: 198 [1280/1612 (79%)] Loss: 0.626318\n",
      "Train Epoch: 198 [1440/1612 (89%)] Loss: 0.371297\n",
      "Train Epoch: 198 [1200/1612 (99%)] Loss: 0.218207\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 199 [0/1612 (0%)] Loss: 0.443422\n",
      "Train Epoch: 199 [160/1612 (10%)] Loss: 0.118820\n",
      "Train Epoch: 199 [320/1612 (20%)] Loss: 0.357741\n",
      "Train Epoch: 199 [480/1612 (30%)] Loss: 0.263894\n",
      "Train Epoch: 199 [640/1612 (40%)] Loss: 0.224592\n",
      "Train Epoch: 199 [800/1612 (50%)] Loss: 0.444938\n",
      "Train Epoch: 199 [960/1612 (59%)] Loss: 0.213239\n",
      "Train Epoch: 199 [1120/1612 (69%)] Loss: 0.494310\n",
      "Train Epoch: 199 [1280/1612 (79%)] Loss: 0.426718\n",
      "Train Epoch: 199 [1440/1612 (89%)] Loss: 0.233014\n",
      "Train Epoch: 199 [1200/1612 (99%)] Loss: 0.341838\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 200 [0/1612 (0%)] Loss: 0.383706\n",
      "Train Epoch: 200 [160/1612 (10%)] Loss: 0.410241\n",
      "Train Epoch: 200 [320/1612 (20%)] Loss: 0.520990\n",
      "Train Epoch: 200 [480/1612 (30%)] Loss: 0.465611\n",
      "Train Epoch: 200 [640/1612 (40%)] Loss: 0.434898\n",
      "Train Epoch: 200 [800/1612 (50%)] Loss: 0.205416\n",
      "Train Epoch: 200 [960/1612 (59%)] Loss: 0.313847\n",
      "Train Epoch: 200 [1120/1612 (69%)] Loss: 0.357452\n",
      "Train Epoch: 200 [1280/1612 (79%)] Loss: 0.479135\n",
      "Train Epoch: 200 [1440/1612 (89%)] Loss: 0.441854\n",
      "Train Epoch: 200 [1200/1612 (99%)] Loss: 0.673010\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 201 [0/1612 (0%)] Loss: 0.210436\n",
      "Train Epoch: 201 [160/1612 (10%)] Loss: 0.270081\n",
      "Train Epoch: 201 [320/1612 (20%)] Loss: 0.213696\n",
      "Train Epoch: 201 [480/1612 (30%)] Loss: 0.503651\n",
      "Train Epoch: 201 [640/1612 (40%)] Loss: 0.373253\n",
      "Train Epoch: 201 [800/1612 (50%)] Loss: 0.311039\n",
      "Train Epoch: 201 [960/1612 (59%)] Loss: 0.612574\n",
      "Train Epoch: 201 [1120/1612 (69%)] Loss: 0.314514\n",
      "Train Epoch: 201 [1280/1612 (79%)] Loss: 0.286724\n",
      "Train Epoch: 201 [1440/1612 (89%)] Loss: 0.296478\n",
      "Train Epoch: 201 [1200/1612 (99%)] Loss: 0.225690\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 202 [0/1612 (0%)] Loss: 0.403702\n",
      "Train Epoch: 202 [160/1612 (10%)] Loss: 0.401768\n",
      "Train Epoch: 202 [320/1612 (20%)] Loss: 0.274155\n",
      "Train Epoch: 202 [480/1612 (30%)] Loss: 0.365327\n",
      "Train Epoch: 202 [640/1612 (40%)] Loss: 0.339098\n",
      "Train Epoch: 202 [800/1612 (50%)] Loss: 0.435264\n",
      "Train Epoch: 202 [960/1612 (59%)] Loss: 0.327898\n",
      "Train Epoch: 202 [1120/1612 (69%)] Loss: 0.522521\n",
      "Train Epoch: 202 [1280/1612 (79%)] Loss: 0.412857\n",
      "Train Epoch: 202 [1440/1612 (89%)] Loss: 0.248369\n",
      "Train Epoch: 202 [1200/1612 (99%)] Loss: 0.217772\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 203 [0/1612 (0%)] Loss: 0.403384\n",
      "Train Epoch: 203 [160/1612 (10%)] Loss: 0.130332\n",
      "Train Epoch: 203 [320/1612 (20%)] Loss: 0.448438\n",
      "Train Epoch: 203 [480/1612 (30%)] Loss: 0.292444\n",
      "Train Epoch: 203 [640/1612 (40%)] Loss: 0.337056\n",
      "Train Epoch: 203 [800/1612 (50%)] Loss: 0.202786\n",
      "Train Epoch: 203 [960/1612 (59%)] Loss: 0.328902\n",
      "Train Epoch: 203 [1120/1612 (69%)] Loss: 0.565836\n",
      "Train Epoch: 203 [1280/1612 (79%)] Loss: 0.337755\n",
      "Train Epoch: 203 [1440/1612 (89%)] Loss: 0.323882\n",
      "Train Epoch: 203 [1200/1612 (99%)] Loss: 0.222809\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 204 [0/1612 (0%)] Loss: 0.188649\n",
      "Train Epoch: 204 [160/1612 (10%)] Loss: 0.316741\n",
      "Train Epoch: 204 [320/1612 (20%)] Loss: 0.263018\n",
      "Train Epoch: 204 [480/1612 (30%)] Loss: 0.360790\n",
      "Train Epoch: 204 [640/1612 (40%)] Loss: 0.300153\n",
      "Train Epoch: 204 [800/1612 (50%)] Loss: 0.238293\n",
      "Train Epoch: 204 [960/1612 (59%)] Loss: 0.447464\n",
      "Train Epoch: 204 [1120/1612 (69%)] Loss: 0.193178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 204 [1280/1612 (79%)] Loss: 0.537137\n",
      "Train Epoch: 204 [1440/1612 (89%)] Loss: 0.380612\n",
      "Train Epoch: 204 [1200/1612 (99%)] Loss: 0.353130\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 205 [0/1612 (0%)] Loss: 0.209097\n",
      "Train Epoch: 205 [160/1612 (10%)] Loss: 0.365266\n",
      "Train Epoch: 205 [320/1612 (20%)] Loss: 0.397504\n",
      "Train Epoch: 205 [480/1612 (30%)] Loss: 0.341842\n",
      "Train Epoch: 205 [640/1612 (40%)] Loss: 0.339650\n",
      "Train Epoch: 205 [800/1612 (50%)] Loss: 0.540733\n",
      "Train Epoch: 205 [960/1612 (59%)] Loss: 0.434662\n",
      "Train Epoch: 205 [1120/1612 (69%)] Loss: 0.493625\n",
      "Train Epoch: 205 [1280/1612 (79%)] Loss: 0.465048\n",
      "Train Epoch: 205 [1440/1612 (89%)] Loss: 0.375975\n",
      "Train Epoch: 205 [1200/1612 (99%)] Loss: 0.373403\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 206 [0/1612 (0%)] Loss: 0.316911\n",
      "Train Epoch: 206 [160/1612 (10%)] Loss: 0.286756\n",
      "Train Epoch: 206 [320/1612 (20%)] Loss: 0.147183\n",
      "Train Epoch: 206 [480/1612 (30%)] Loss: 0.479886\n",
      "Train Epoch: 206 [640/1612 (40%)] Loss: 0.301917\n",
      "Train Epoch: 206 [800/1612 (50%)] Loss: 0.095909\n",
      "Train Epoch: 206 [960/1612 (59%)] Loss: 0.461987\n",
      "Train Epoch: 206 [1120/1612 (69%)] Loss: 0.349103\n",
      "Train Epoch: 206 [1280/1612 (79%)] Loss: 0.209331\n",
      "Train Epoch: 206 [1440/1612 (89%)] Loss: 0.520718\n",
      "Train Epoch: 206 [1200/1612 (99%)] Loss: 0.290022\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 207 [0/1612 (0%)] Loss: 0.314413\n",
      "Train Epoch: 207 [160/1612 (10%)] Loss: 0.809547\n",
      "Train Epoch: 207 [320/1612 (20%)] Loss: 0.426344\n",
      "Train Epoch: 207 [480/1612 (30%)] Loss: 0.346551\n",
      "Train Epoch: 207 [640/1612 (40%)] Loss: 0.316872\n",
      "Train Epoch: 207 [800/1612 (50%)] Loss: 0.286994\n",
      "Train Epoch: 207 [960/1612 (59%)] Loss: 0.357325\n",
      "Train Epoch: 207 [1120/1612 (69%)] Loss: 0.233663\n",
      "Train Epoch: 207 [1280/1612 (79%)] Loss: 0.459810\n",
      "Train Epoch: 207 [1440/1612 (89%)] Loss: 0.309036\n",
      "Train Epoch: 207 [1200/1612 (99%)] Loss: 0.535258\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 208 [0/1612 (0%)] Loss: 0.120694\n",
      "Train Epoch: 208 [160/1612 (10%)] Loss: 0.307188\n",
      "Train Epoch: 208 [320/1612 (20%)] Loss: 0.405364\n",
      "Train Epoch: 208 [480/1612 (30%)] Loss: 0.623576\n",
      "Train Epoch: 208 [640/1612 (40%)] Loss: 0.368683\n",
      "Train Epoch: 208 [800/1612 (50%)] Loss: 0.369685\n",
      "Train Epoch: 208 [960/1612 (59%)] Loss: 0.481113\n",
      "Train Epoch: 208 [1120/1612 (69%)] Loss: 0.312103\n",
      "Train Epoch: 208 [1280/1612 (79%)] Loss: 0.181206\n",
      "Train Epoch: 208 [1440/1612 (89%)] Loss: 0.464163\n",
      "Train Epoch: 208 [1200/1612 (99%)] Loss: 0.293164\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 209 [0/1612 (0%)] Loss: 0.644839\n",
      "Train Epoch: 209 [160/1612 (10%)] Loss: 0.311628\n",
      "Train Epoch: 209 [320/1612 (20%)] Loss: 0.469720\n",
      "Train Epoch: 209 [480/1612 (30%)] Loss: 0.264902\n",
      "Train Epoch: 209 [640/1612 (40%)] Loss: 0.385635\n",
      "Train Epoch: 209 [800/1612 (50%)] Loss: 0.615990\n",
      "Train Epoch: 209 [960/1612 (59%)] Loss: 0.478198\n",
      "Train Epoch: 209 [1120/1612 (69%)] Loss: 0.523172\n",
      "Train Epoch: 209 [1280/1612 (79%)] Loss: 0.508796\n",
      "Train Epoch: 209 [1440/1612 (89%)] Loss: 0.207844\n",
      "Train Epoch: 209 [1200/1612 (99%)] Loss: 0.226821\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 210 [0/1612 (0%)] Loss: 0.206816\n",
      "Train Epoch: 210 [160/1612 (10%)] Loss: 0.729892\n",
      "Train Epoch: 210 [320/1612 (20%)] Loss: 0.289547\n",
      "Train Epoch: 210 [480/1612 (30%)] Loss: 0.387457\n",
      "Train Epoch: 210 [640/1612 (40%)] Loss: 0.451868\n",
      "Train Epoch: 210 [800/1612 (50%)] Loss: 0.099407\n",
      "Train Epoch: 210 [960/1612 (59%)] Loss: 0.541964\n",
      "Train Epoch: 210 [1120/1612 (69%)] Loss: 0.177246\n",
      "Train Epoch: 210 [1280/1612 (79%)] Loss: 0.337235\n",
      "Train Epoch: 210 [1440/1612 (89%)] Loss: 0.277238\n",
      "Train Epoch: 210 [1200/1612 (99%)] Loss: 0.634779\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 211 [0/1612 (0%)] Loss: 0.185736\n",
      "Train Epoch: 211 [160/1612 (10%)] Loss: 0.515805\n",
      "Train Epoch: 211 [320/1612 (20%)] Loss: 0.351651\n",
      "Train Epoch: 211 [480/1612 (30%)] Loss: 0.454922\n",
      "Train Epoch: 211 [640/1612 (40%)] Loss: 0.423773\n",
      "Train Epoch: 211 [800/1612 (50%)] Loss: 0.149206\n",
      "Train Epoch: 211 [960/1612 (59%)] Loss: 0.171026\n",
      "Train Epoch: 211 [1120/1612 (69%)] Loss: 0.514918\n",
      "Train Epoch: 211 [1280/1612 (79%)] Loss: 0.677412\n",
      "Train Epoch: 211 [1440/1612 (89%)] Loss: 0.226441\n",
      "Train Epoch: 211 [1200/1612 (99%)] Loss: 0.141489\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 212 [0/1612 (0%)] Loss: 0.265996\n",
      "Train Epoch: 212 [160/1612 (10%)] Loss: 0.250379\n",
      "Train Epoch: 212 [320/1612 (20%)] Loss: 0.302682\n",
      "Train Epoch: 212 [480/1612 (30%)] Loss: 0.311628\n",
      "Train Epoch: 212 [640/1612 (40%)] Loss: 0.374644\n",
      "Train Epoch: 212 [800/1612 (50%)] Loss: 0.297644\n",
      "Train Epoch: 212 [960/1612 (59%)] Loss: 0.343589\n",
      "Train Epoch: 212 [1120/1612 (69%)] Loss: 0.297755\n",
      "Train Epoch: 212 [1280/1612 (79%)] Loss: 0.233163\n",
      "Train Epoch: 212 [1440/1612 (89%)] Loss: 0.237648\n",
      "Train Epoch: 212 [1200/1612 (99%)] Loss: 0.664421\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 213 [0/1612 (0%)] Loss: 0.315263\n",
      "Train Epoch: 213 [160/1612 (10%)] Loss: 0.227498\n",
      "Train Epoch: 213 [320/1612 (20%)] Loss: 0.329542\n",
      "Train Epoch: 213 [480/1612 (30%)] Loss: 0.324781\n",
      "Train Epoch: 213 [640/1612 (40%)] Loss: 0.299030\n",
      "Train Epoch: 213 [800/1612 (50%)] Loss: 0.306794\n",
      "Train Epoch: 213 [960/1612 (59%)] Loss: 0.581104\n",
      "Train Epoch: 213 [1120/1612 (69%)] Loss: 0.453282\n",
      "Train Epoch: 213 [1280/1612 (79%)] Loss: 0.442968\n",
      "Train Epoch: 213 [1440/1612 (89%)] Loss: 0.461863\n",
      "Train Epoch: 213 [1200/1612 (99%)] Loss: 0.467032\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 214 [0/1612 (0%)] Loss: 0.104362\n",
      "Train Epoch: 214 [160/1612 (10%)] Loss: 0.317353\n",
      "Train Epoch: 214 [320/1612 (20%)] Loss: 0.402843\n",
      "Train Epoch: 214 [480/1612 (30%)] Loss: 0.379004\n",
      "Train Epoch: 214 [640/1612 (40%)] Loss: 0.281488\n",
      "Train Epoch: 214 [800/1612 (50%)] Loss: 0.439395\n",
      "Train Epoch: 214 [960/1612 (59%)] Loss: 0.102879\n",
      "Train Epoch: 214 [1120/1612 (69%)] Loss: 0.210708\n",
      "Train Epoch: 214 [1280/1612 (79%)] Loss: 0.402141\n",
      "Train Epoch: 214 [1440/1612 (89%)] Loss: 0.300896\n",
      "Train Epoch: 214 [1200/1612 (99%)] Loss: 0.540611\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 215 [0/1612 (0%)] Loss: 0.196186\n",
      "Train Epoch: 215 [160/1612 (10%)] Loss: 0.452061\n",
      "Train Epoch: 215 [320/1612 (20%)] Loss: 0.351400\n",
      "Train Epoch: 215 [480/1612 (30%)] Loss: 0.219669\n",
      "Train Epoch: 215 [640/1612 (40%)] Loss: 0.528436\n",
      "Train Epoch: 215 [800/1612 (50%)] Loss: 0.342670\n",
      "Train Epoch: 215 [960/1612 (59%)] Loss: 0.271281\n",
      "Train Epoch: 215 [1120/1612 (69%)] Loss: 0.280854\n",
      "Train Epoch: 215 [1280/1612 (79%)] Loss: 0.367176\n",
      "Train Epoch: 215 [1440/1612 (89%)] Loss: 0.441275\n",
      "Train Epoch: 215 [1200/1612 (99%)] Loss: 0.316049\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 216 [0/1612 (0%)] Loss: 0.327631\n",
      "Train Epoch: 216 [160/1612 (10%)] Loss: 0.577287\n",
      "Train Epoch: 216 [320/1612 (20%)] Loss: 0.703853\n",
      "Train Epoch: 216 [480/1612 (30%)] Loss: 0.427686\n",
      "Train Epoch: 216 [640/1612 (40%)] Loss: 0.176056\n",
      "Train Epoch: 216 [800/1612 (50%)] Loss: 0.169046\n",
      "Train Epoch: 216 [960/1612 (59%)] Loss: 0.476512\n",
      "Train Epoch: 216 [1120/1612 (69%)] Loss: 0.205242\n",
      "Train Epoch: 216 [1280/1612 (79%)] Loss: 0.174939\n",
      "Train Epoch: 216 [1440/1612 (89%)] Loss: 0.588799\n",
      "Train Epoch: 216 [1200/1612 (99%)] Loss: 0.309692\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 217 [0/1612 (0%)] Loss: 0.201965\n",
      "Train Epoch: 217 [160/1612 (10%)] Loss: 0.397700\n",
      "Train Epoch: 217 [320/1612 (20%)] Loss: 0.351084\n",
      "Train Epoch: 217 [480/1612 (30%)] Loss: 0.304883\n",
      "Train Epoch: 217 [640/1612 (40%)] Loss: 0.183850\n",
      "Train Epoch: 217 [800/1612 (50%)] Loss: 0.494600\n",
      "Train Epoch: 217 [960/1612 (59%)] Loss: 0.226135\n",
      "Train Epoch: 217 [1120/1612 (69%)] Loss: 0.204126\n",
      "Train Epoch: 217 [1280/1612 (79%)] Loss: 0.282331\n",
      "Train Epoch: 217 [1440/1612 (89%)] Loss: 0.374749\n",
      "Train Epoch: 217 [1200/1612 (99%)] Loss: 0.407081\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 218 [0/1612 (0%)] Loss: 0.356386\n",
      "Train Epoch: 218 [160/1612 (10%)] Loss: 0.323345\n",
      "Train Epoch: 218 [320/1612 (20%)] Loss: 0.389059\n",
      "Train Epoch: 218 [480/1612 (30%)] Loss: 0.401309\n",
      "Train Epoch: 218 [640/1612 (40%)] Loss: 0.482244\n",
      "Train Epoch: 218 [800/1612 (50%)] Loss: 0.291363\n",
      "Train Epoch: 218 [960/1612 (59%)] Loss: 0.672232\n",
      "Train Epoch: 218 [1120/1612 (69%)] Loss: 0.360526\n",
      "Train Epoch: 218 [1280/1612 (79%)] Loss: 0.273477\n",
      "Train Epoch: 218 [1440/1612 (89%)] Loss: 0.195270\n",
      "Train Epoch: 218 [1200/1612 (99%)] Loss: 0.351046\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 219 [0/1612 (0%)] Loss: 0.222678\n",
      "Train Epoch: 219 [160/1612 (10%)] Loss: 0.269330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 219 [320/1612 (20%)] Loss: 0.673045\n",
      "Train Epoch: 219 [480/1612 (30%)] Loss: 0.162245\n",
      "Train Epoch: 219 [640/1612 (40%)] Loss: 0.302646\n",
      "Train Epoch: 219 [800/1612 (50%)] Loss: 0.391804\n",
      "Train Epoch: 219 [960/1612 (59%)] Loss: 0.274103\n",
      "Train Epoch: 219 [1120/1612 (69%)] Loss: 0.467881\n",
      "Train Epoch: 219 [1280/1612 (79%)] Loss: 0.427599\n",
      "Train Epoch: 219 [1440/1612 (89%)] Loss: 0.447843\n",
      "Train Epoch: 219 [1200/1612 (99%)] Loss: 0.826473\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 220 [0/1612 (0%)] Loss: 0.261125\n",
      "Train Epoch: 220 [160/1612 (10%)] Loss: 0.393673\n",
      "Train Epoch: 220 [320/1612 (20%)] Loss: 0.286814\n",
      "Train Epoch: 220 [480/1612 (30%)] Loss: 0.419263\n",
      "Train Epoch: 220 [640/1612 (40%)] Loss: 0.418923\n",
      "Train Epoch: 220 [800/1612 (50%)] Loss: 0.360063\n",
      "Train Epoch: 220 [960/1612 (59%)] Loss: 0.265667\n",
      "Train Epoch: 220 [1120/1612 (69%)] Loss: 0.413648\n",
      "Train Epoch: 220 [1280/1612 (79%)] Loss: 0.439398\n",
      "Train Epoch: 220 [1440/1612 (89%)] Loss: 0.208692\n",
      "Train Epoch: 220 [1200/1612 (99%)] Loss: 0.222172\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 221 [0/1612 (0%)] Loss: 0.342319\n",
      "Train Epoch: 221 [160/1612 (10%)] Loss: 0.296562\n",
      "Train Epoch: 221 [320/1612 (20%)] Loss: 0.626143\n",
      "Train Epoch: 221 [480/1612 (30%)] Loss: 0.256820\n",
      "Train Epoch: 221 [640/1612 (40%)] Loss: 0.375144\n",
      "Train Epoch: 221 [800/1612 (50%)] Loss: 0.239790\n",
      "Train Epoch: 221 [960/1612 (59%)] Loss: 0.428310\n",
      "Train Epoch: 221 [1120/1612 (69%)] Loss: 0.326502\n",
      "Train Epoch: 221 [1280/1612 (79%)] Loss: 0.373976\n",
      "Train Epoch: 221 [1440/1612 (89%)] Loss: 0.537117\n",
      "Train Epoch: 221 [1200/1612 (99%)] Loss: 0.368871\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 222 [0/1612 (0%)] Loss: 0.543701\n",
      "Train Epoch: 222 [160/1612 (10%)] Loss: 0.380184\n",
      "Train Epoch: 222 [320/1612 (20%)] Loss: 0.197269\n",
      "Train Epoch: 222 [480/1612 (30%)] Loss: 0.147898\n",
      "Train Epoch: 222 [640/1612 (40%)] Loss: 0.444677\n",
      "Train Epoch: 222 [800/1612 (50%)] Loss: 0.325486\n",
      "Train Epoch: 222 [960/1612 (59%)] Loss: 0.299087\n",
      "Train Epoch: 222 [1120/1612 (69%)] Loss: 0.578410\n",
      "Train Epoch: 222 [1280/1612 (79%)] Loss: 0.289710\n",
      "Train Epoch: 222 [1440/1612 (89%)] Loss: 0.282099\n",
      "Train Epoch: 222 [1200/1612 (99%)] Loss: 0.464980\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 223 [0/1612 (0%)] Loss: 0.276185\n",
      "Train Epoch: 223 [160/1612 (10%)] Loss: 0.400817\n",
      "Train Epoch: 223 [320/1612 (20%)] Loss: 0.291024\n",
      "Train Epoch: 223 [480/1612 (30%)] Loss: 0.251521\n",
      "Train Epoch: 223 [640/1612 (40%)] Loss: 0.413100\n",
      "Train Epoch: 223 [800/1612 (50%)] Loss: 0.280724\n",
      "Train Epoch: 223 [960/1612 (59%)] Loss: 0.401182\n",
      "Train Epoch: 223 [1120/1612 (69%)] Loss: 0.394933\n",
      "Train Epoch: 223 [1280/1612 (79%)] Loss: 0.302670\n",
      "Train Epoch: 223 [1440/1612 (89%)] Loss: 0.371690\n",
      "Train Epoch: 223 [1200/1612 (99%)] Loss: 0.283847\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 224 [0/1612 (0%)] Loss: 0.335071\n",
      "Train Epoch: 224 [160/1612 (10%)] Loss: 0.317369\n",
      "Train Epoch: 224 [320/1612 (20%)] Loss: 0.398484\n",
      "Train Epoch: 224 [480/1612 (30%)] Loss: 0.402870\n",
      "Train Epoch: 224 [640/1612 (40%)] Loss: 0.475812\n",
      "Train Epoch: 224 [800/1612 (50%)] Loss: 0.373248\n",
      "Train Epoch: 224 [960/1612 (59%)] Loss: 0.254658\n",
      "Train Epoch: 224 [1120/1612 (69%)] Loss: 0.277971\n",
      "Train Epoch: 224 [1280/1612 (79%)] Loss: 0.499417\n",
      "Train Epoch: 224 [1440/1612 (89%)] Loss: 0.221957\n",
      "Train Epoch: 224 [1200/1612 (99%)] Loss: 0.571164\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 225 [0/1612 (0%)] Loss: 0.420790\n",
      "Train Epoch: 225 [160/1612 (10%)] Loss: 0.438796\n",
      "Train Epoch: 225 [320/1612 (20%)] Loss: 0.353768\n",
      "Train Epoch: 225 [480/1612 (30%)] Loss: 0.353682\n",
      "Train Epoch: 225 [640/1612 (40%)] Loss: 0.329601\n",
      "Train Epoch: 225 [800/1612 (50%)] Loss: 0.300253\n",
      "Train Epoch: 225 [960/1612 (59%)] Loss: 0.268268\n",
      "Train Epoch: 225 [1120/1612 (69%)] Loss: 0.246172\n",
      "Train Epoch: 225 [1280/1612 (79%)] Loss: 0.330225\n",
      "Train Epoch: 225 [1440/1612 (89%)] Loss: 0.213304\n",
      "Train Epoch: 225 [1200/1612 (99%)] Loss: 0.472841\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 226 [0/1612 (0%)] Loss: 0.342317\n",
      "Train Epoch: 226 [160/1612 (10%)] Loss: 0.294947\n",
      "Train Epoch: 226 [320/1612 (20%)] Loss: 0.476548\n",
      "Train Epoch: 226 [480/1612 (30%)] Loss: 0.219023\n",
      "Train Epoch: 226 [640/1612 (40%)] Loss: 0.335299\n",
      "Train Epoch: 226 [800/1612 (50%)] Loss: 0.455657\n",
      "Train Epoch: 226 [960/1612 (59%)] Loss: 0.333536\n",
      "Train Epoch: 226 [1120/1612 (69%)] Loss: 0.141763\n",
      "Train Epoch: 226 [1280/1612 (79%)] Loss: 0.429487\n",
      "Train Epoch: 226 [1440/1612 (89%)] Loss: 0.273523\n",
      "Train Epoch: 226 [1200/1612 (99%)] Loss: 0.426644\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 227 [0/1612 (0%)] Loss: 0.536082\n",
      "Train Epoch: 227 [160/1612 (10%)] Loss: 0.217885\n",
      "Train Epoch: 227 [320/1612 (20%)] Loss: 0.216285\n",
      "Train Epoch: 227 [480/1612 (30%)] Loss: 0.215676\n",
      "Train Epoch: 227 [640/1612 (40%)] Loss: 0.491482\n",
      "Train Epoch: 227 [800/1612 (50%)] Loss: 0.296501\n",
      "Train Epoch: 227 [960/1612 (59%)] Loss: 0.310352\n",
      "Train Epoch: 227 [1120/1612 (69%)] Loss: 0.387669\n",
      "Train Epoch: 227 [1280/1612 (79%)] Loss: 0.434646\n",
      "Train Epoch: 227 [1440/1612 (89%)] Loss: 0.186571\n",
      "Train Epoch: 227 [1200/1612 (99%)] Loss: 0.311905\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 228 [0/1612 (0%)] Loss: 0.368618\n",
      "Train Epoch: 228 [160/1612 (10%)] Loss: 0.449589\n",
      "Train Epoch: 228 [320/1612 (20%)] Loss: 0.381824\n",
      "Train Epoch: 228 [480/1612 (30%)] Loss: 0.234297\n",
      "Train Epoch: 228 [640/1612 (40%)] Loss: 0.222571\n",
      "Train Epoch: 228 [800/1612 (50%)] Loss: 0.188784\n",
      "Train Epoch: 228 [960/1612 (59%)] Loss: 0.426316\n",
      "Train Epoch: 228 [1120/1612 (69%)] Loss: 0.348036\n",
      "Train Epoch: 228 [1280/1612 (79%)] Loss: 0.110252\n",
      "Train Epoch: 228 [1440/1612 (89%)] Loss: 0.397050\n",
      "Train Epoch: 228 [1200/1612 (99%)] Loss: 0.341205\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 229 [0/1612 (0%)] Loss: 0.190304\n",
      "Train Epoch: 229 [160/1612 (10%)] Loss: 0.260136\n",
      "Train Epoch: 229 [320/1612 (20%)] Loss: 0.441407\n",
      "Train Epoch: 229 [480/1612 (30%)] Loss: 0.310340\n",
      "Train Epoch: 229 [640/1612 (40%)] Loss: 0.700299\n",
      "Train Epoch: 229 [800/1612 (50%)] Loss: 0.385622\n",
      "Train Epoch: 229 [960/1612 (59%)] Loss: 0.374868\n",
      "Train Epoch: 229 [1120/1612 (69%)] Loss: 0.369834\n",
      "Train Epoch: 229 [1280/1612 (79%)] Loss: 0.346244\n",
      "Train Epoch: 229 [1440/1612 (89%)] Loss: 0.287978\n",
      "Train Epoch: 229 [1200/1612 (99%)] Loss: 0.422429\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 230 [0/1612 (0%)] Loss: 0.282242\n",
      "Train Epoch: 230 [160/1612 (10%)] Loss: 0.387390\n",
      "Train Epoch: 230 [320/1612 (20%)] Loss: 0.271970\n",
      "Train Epoch: 230 [480/1612 (30%)] Loss: 0.351401\n",
      "Train Epoch: 230 [640/1612 (40%)] Loss: 0.342845\n",
      "Train Epoch: 230 [800/1612 (50%)] Loss: 0.292408\n",
      "Train Epoch: 230 [960/1612 (59%)] Loss: 0.235855\n",
      "Train Epoch: 230 [1120/1612 (69%)] Loss: 0.230391\n",
      "Train Epoch: 230 [1280/1612 (79%)] Loss: 0.319795\n",
      "Train Epoch: 230 [1440/1612 (89%)] Loss: 0.461406\n",
      "Train Epoch: 230 [1200/1612 (99%)] Loss: 0.335827\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 231 [0/1612 (0%)] Loss: 0.503210\n",
      "Train Epoch: 231 [160/1612 (10%)] Loss: 0.156561\n",
      "Train Epoch: 231 [320/1612 (20%)] Loss: 0.608632\n",
      "Train Epoch: 231 [480/1612 (30%)] Loss: 0.386900\n",
      "Train Epoch: 231 [640/1612 (40%)] Loss: 0.321267\n",
      "Train Epoch: 231 [800/1612 (50%)] Loss: 0.487732\n",
      "Train Epoch: 231 [960/1612 (59%)] Loss: 0.453549\n",
      "Train Epoch: 231 [1120/1612 (69%)] Loss: 0.387155\n",
      "Train Epoch: 231 [1280/1612 (79%)] Loss: 0.150260\n",
      "Train Epoch: 231 [1440/1612 (89%)] Loss: 0.520825\n",
      "Train Epoch: 231 [1200/1612 (99%)] Loss: 0.284265\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 232 [0/1612 (0%)] Loss: 0.530603\n",
      "Train Epoch: 232 [160/1612 (10%)] Loss: 0.209324\n",
      "Train Epoch: 232 [320/1612 (20%)] Loss: 0.423698\n",
      "Train Epoch: 232 [480/1612 (30%)] Loss: 0.301019\n",
      "Train Epoch: 232 [640/1612 (40%)] Loss: 0.142436\n",
      "Train Epoch: 232 [800/1612 (50%)] Loss: 0.252275\n",
      "Train Epoch: 232 [960/1612 (59%)] Loss: 0.284385\n",
      "Train Epoch: 232 [1120/1612 (69%)] Loss: 0.459915\n",
      "Train Epoch: 232 [1280/1612 (79%)] Loss: 0.270821\n",
      "Train Epoch: 232 [1440/1612 (89%)] Loss: 0.484260\n",
      "Train Epoch: 232 [1200/1612 (99%)] Loss: 0.308050\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 233 [0/1612 (0%)] Loss: 0.423087\n",
      "Train Epoch: 233 [160/1612 (10%)] Loss: 0.403208\n",
      "Train Epoch: 233 [320/1612 (20%)] Loss: 0.544696\n",
      "Train Epoch: 233 [480/1612 (30%)] Loss: 0.824706\n",
      "Train Epoch: 233 [640/1612 (40%)] Loss: 0.336892\n",
      "Train Epoch: 233 [800/1612 (50%)] Loss: 0.381915\n",
      "Train Epoch: 233 [960/1612 (59%)] Loss: 0.290040\n",
      "Train Epoch: 233 [1120/1612 (69%)] Loss: 0.353189\n",
      "Train Epoch: 233 [1280/1612 (79%)] Loss: 0.234895\n",
      "Train Epoch: 233 [1440/1612 (89%)] Loss: 0.305864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 233 [1200/1612 (99%)] Loss: 0.476589\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 234 [0/1612 (0%)] Loss: 0.226014\n",
      "Train Epoch: 234 [160/1612 (10%)] Loss: 0.309066\n",
      "Train Epoch: 234 [320/1612 (20%)] Loss: 0.365364\n",
      "Train Epoch: 234 [480/1612 (30%)] Loss: 0.333231\n",
      "Train Epoch: 234 [640/1612 (40%)] Loss: 0.521305\n",
      "Train Epoch: 234 [800/1612 (50%)] Loss: 0.358767\n",
      "Train Epoch: 234 [960/1612 (59%)] Loss: 0.224751\n",
      "Train Epoch: 234 [1120/1612 (69%)] Loss: 0.354233\n",
      "Train Epoch: 234 [1280/1612 (79%)] Loss: 0.285605\n",
      "Train Epoch: 234 [1440/1612 (89%)] Loss: 0.251194\n",
      "Train Epoch: 234 [1200/1612 (99%)] Loss: 0.331026\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 235 [0/1612 (0%)] Loss: 0.366254\n",
      "Train Epoch: 235 [160/1612 (10%)] Loss: 0.359304\n",
      "Train Epoch: 235 [320/1612 (20%)] Loss: 0.364129\n",
      "Train Epoch: 235 [480/1612 (30%)] Loss: 0.480629\n",
      "Train Epoch: 235 [640/1612 (40%)] Loss: 0.073681\n",
      "Train Epoch: 235 [800/1612 (50%)] Loss: 0.208174\n",
      "Train Epoch: 235 [960/1612 (59%)] Loss: 0.388714\n",
      "Train Epoch: 235 [1120/1612 (69%)] Loss: 0.222655\n",
      "Train Epoch: 235 [1280/1612 (79%)] Loss: 0.341413\n",
      "Train Epoch: 235 [1440/1612 (89%)] Loss: 0.362039\n",
      "Train Epoch: 235 [1200/1612 (99%)] Loss: 0.317732\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 236 [0/1612 (0%)] Loss: 0.239287\n",
      "Train Epoch: 236 [160/1612 (10%)] Loss: 0.224299\n",
      "Train Epoch: 236 [320/1612 (20%)] Loss: 0.310493\n",
      "Train Epoch: 236 [480/1612 (30%)] Loss: 0.258561\n",
      "Train Epoch: 236 [640/1612 (40%)] Loss: 0.384068\n",
      "Train Epoch: 236 [800/1612 (50%)] Loss: 0.297239\n",
      "Train Epoch: 236 [960/1612 (59%)] Loss: 0.387923\n",
      "Train Epoch: 236 [1120/1612 (69%)] Loss: 0.359205\n",
      "Train Epoch: 236 [1280/1612 (79%)] Loss: 0.384197\n",
      "Train Epoch: 236 [1440/1612 (89%)] Loss: 0.388352\n",
      "Train Epoch: 236 [1200/1612 (99%)] Loss: 0.429983\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 237 [0/1612 (0%)] Loss: 0.190823\n",
      "Train Epoch: 237 [160/1612 (10%)] Loss: 0.345141\n",
      "Train Epoch: 237 [320/1612 (20%)] Loss: 0.507247\n",
      "Train Epoch: 237 [480/1612 (30%)] Loss: 0.152079\n",
      "Train Epoch: 237 [640/1612 (40%)] Loss: 0.363877\n",
      "Train Epoch: 237 [800/1612 (50%)] Loss: 0.590146\n",
      "Train Epoch: 237 [960/1612 (59%)] Loss: 0.241183\n",
      "Train Epoch: 237 [1120/1612 (69%)] Loss: 0.525479\n",
      "Train Epoch: 237 [1280/1612 (79%)] Loss: 0.402279\n",
      "Train Epoch: 237 [1440/1612 (89%)] Loss: 0.350386\n",
      "Train Epoch: 237 [1200/1612 (99%)] Loss: 0.640235\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 238 [0/1612 (0%)] Loss: 0.484540\n",
      "Train Epoch: 238 [160/1612 (10%)] Loss: 0.525015\n",
      "Train Epoch: 238 [320/1612 (20%)] Loss: 0.273895\n",
      "Train Epoch: 238 [480/1612 (30%)] Loss: 0.226020\n",
      "Train Epoch: 238 [640/1612 (40%)] Loss: 0.333484\n",
      "Train Epoch: 238 [800/1612 (50%)] Loss: 0.319481\n",
      "Train Epoch: 238 [960/1612 (59%)] Loss: 0.339056\n",
      "Train Epoch: 238 [1120/1612 (69%)] Loss: 0.306835\n",
      "Train Epoch: 238 [1280/1612 (79%)] Loss: 0.774814\n",
      "Train Epoch: 238 [1440/1612 (89%)] Loss: 0.297221\n",
      "Train Epoch: 238 [1200/1612 (99%)] Loss: 0.355937\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 239 [0/1612 (0%)] Loss: 0.224098\n",
      "Train Epoch: 239 [160/1612 (10%)] Loss: 0.457285\n",
      "Train Epoch: 239 [320/1612 (20%)] Loss: 0.492374\n",
      "Train Epoch: 239 [480/1612 (30%)] Loss: 0.383664\n",
      "Train Epoch: 239 [640/1612 (40%)] Loss: 0.559844\n",
      "Train Epoch: 239 [800/1612 (50%)] Loss: 0.359173\n",
      "Train Epoch: 239 [960/1612 (59%)] Loss: 0.235775\n",
      "Train Epoch: 239 [1120/1612 (69%)] Loss: 0.330756\n",
      "Train Epoch: 239 [1280/1612 (79%)] Loss: 0.330918\n",
      "Train Epoch: 239 [1440/1612 (89%)] Loss: 0.425003\n",
      "Train Epoch: 239 [1200/1612 (99%)] Loss: 0.250487\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 240 [0/1612 (0%)] Loss: 0.308170\n",
      "Train Epoch: 240 [160/1612 (10%)] Loss: 0.483222\n",
      "Train Epoch: 240 [320/1612 (20%)] Loss: 0.136507\n",
      "Train Epoch: 240 [480/1612 (30%)] Loss: 0.641452\n",
      "Train Epoch: 240 [640/1612 (40%)] Loss: 0.380972\n",
      "Train Epoch: 240 [800/1612 (50%)] Loss: 0.249087\n",
      "Train Epoch: 240 [960/1612 (59%)] Loss: 0.497759\n",
      "Train Epoch: 240 [1120/1612 (69%)] Loss: 0.333375\n",
      "Train Epoch: 240 [1280/1612 (79%)] Loss: 0.245946\n",
      "Train Epoch: 240 [1440/1612 (89%)] Loss: 0.204712\n",
      "Train Epoch: 240 [1200/1612 (99%)] Loss: 0.268166\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 241 [0/1612 (0%)] Loss: 0.266493\n",
      "Train Epoch: 241 [160/1612 (10%)] Loss: 0.502736\n",
      "Train Epoch: 241 [320/1612 (20%)] Loss: 0.533235\n",
      "Train Epoch: 241 [480/1612 (30%)] Loss: 0.444025\n",
      "Train Epoch: 241 [640/1612 (40%)] Loss: 0.350575\n",
      "Train Epoch: 241 [800/1612 (50%)] Loss: 0.293497\n",
      "Train Epoch: 241 [960/1612 (59%)] Loss: 0.699768\n",
      "Train Epoch: 241 [1120/1612 (69%)] Loss: 0.224311\n",
      "Train Epoch: 241 [1280/1612 (79%)] Loss: 0.300341\n",
      "Train Epoch: 241 [1440/1612 (89%)] Loss: 0.221057\n",
      "Train Epoch: 241 [1200/1612 (99%)] Loss: 0.579390\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 242 [0/1612 (0%)] Loss: 0.079117\n",
      "Train Epoch: 242 [160/1612 (10%)] Loss: 0.384586\n",
      "Train Epoch: 242 [320/1612 (20%)] Loss: 0.262847\n",
      "Train Epoch: 242 [480/1612 (30%)] Loss: 0.339352\n",
      "Train Epoch: 242 [640/1612 (40%)] Loss: 0.346956\n",
      "Train Epoch: 242 [800/1612 (50%)] Loss: 0.535612\n",
      "Train Epoch: 242 [960/1612 (59%)] Loss: 0.231697\n",
      "Train Epoch: 242 [1120/1612 (69%)] Loss: 0.219146\n",
      "Train Epoch: 242 [1280/1612 (79%)] Loss: 0.350799\n",
      "Train Epoch: 242 [1440/1612 (89%)] Loss: 0.198713\n",
      "Train Epoch: 242 [1200/1612 (99%)] Loss: 0.154063\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 243 [0/1612 (0%)] Loss: 0.187853\n",
      "Train Epoch: 243 [160/1612 (10%)] Loss: 0.366347\n",
      "Train Epoch: 243 [320/1612 (20%)] Loss: 0.598876\n",
      "Train Epoch: 243 [480/1612 (30%)] Loss: 0.888164\n",
      "Train Epoch: 243 [640/1612 (40%)] Loss: 0.243326\n",
      "Train Epoch: 243 [800/1612 (50%)] Loss: 0.188997\n",
      "Train Epoch: 243 [960/1612 (59%)] Loss: 0.334446\n",
      "Train Epoch: 243 [1120/1612 (69%)] Loss: 0.343688\n",
      "Train Epoch: 243 [1280/1612 (79%)] Loss: 0.292004\n",
      "Train Epoch: 243 [1440/1612 (89%)] Loss: 0.258997\n",
      "Train Epoch: 243 [1200/1612 (99%)] Loss: 0.415380\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 244 [0/1612 (0%)] Loss: 0.519102\n",
      "Train Epoch: 244 [160/1612 (10%)] Loss: 0.366907\n",
      "Train Epoch: 244 [320/1612 (20%)] Loss: 0.723598\n",
      "Train Epoch: 244 [480/1612 (30%)] Loss: 0.478551\n",
      "Train Epoch: 244 [640/1612 (40%)] Loss: 0.360639\n",
      "Train Epoch: 244 [800/1612 (50%)] Loss: 0.324392\n",
      "Train Epoch: 244 [960/1612 (59%)] Loss: 0.309833\n",
      "Train Epoch: 244 [1120/1612 (69%)] Loss: 0.445299\n",
      "Train Epoch: 244 [1280/1612 (79%)] Loss: 0.198547\n",
      "Train Epoch: 244 [1440/1612 (89%)] Loss: 0.514555\n",
      "Train Epoch: 244 [1200/1612 (99%)] Loss: 0.223575\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 245 [0/1612 (0%)] Loss: 0.508808\n",
      "Train Epoch: 245 [160/1612 (10%)] Loss: 0.259106\n",
      "Train Epoch: 245 [320/1612 (20%)] Loss: 0.299232\n",
      "Train Epoch: 245 [480/1612 (30%)] Loss: 0.522975\n",
      "Train Epoch: 245 [640/1612 (40%)] Loss: 0.374586\n",
      "Train Epoch: 245 [800/1612 (50%)] Loss: 0.214207\n",
      "Train Epoch: 245 [960/1612 (59%)] Loss: 0.417968\n",
      "Train Epoch: 245 [1120/1612 (69%)] Loss: 0.222481\n",
      "Train Epoch: 245 [1280/1612 (79%)] Loss: 0.339600\n",
      "Train Epoch: 245 [1440/1612 (89%)] Loss: 0.663937\n",
      "Train Epoch: 245 [1200/1612 (99%)] Loss: 0.414445\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 246 [0/1612 (0%)] Loss: 0.321238\n",
      "Train Epoch: 246 [160/1612 (10%)] Loss: 0.263776\n",
      "Train Epoch: 246 [320/1612 (20%)] Loss: 0.321239\n",
      "Train Epoch: 246 [480/1612 (30%)] Loss: 0.489215\n",
      "Train Epoch: 246 [640/1612 (40%)] Loss: 0.157771\n",
      "Train Epoch: 246 [800/1612 (50%)] Loss: 0.368199\n",
      "Train Epoch: 246 [960/1612 (59%)] Loss: 0.366171\n",
      "Train Epoch: 246 [1120/1612 (69%)] Loss: 0.676083\n",
      "Train Epoch: 246 [1280/1612 (79%)] Loss: 0.487674\n",
      "Train Epoch: 246 [1440/1612 (89%)] Loss: 0.483321\n",
      "Train Epoch: 246 [1200/1612 (99%)] Loss: 0.338806\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 247 [0/1612 (0%)] Loss: 0.354200\n",
      "Train Epoch: 247 [160/1612 (10%)] Loss: 0.269013\n",
      "Train Epoch: 247 [320/1612 (20%)] Loss: 0.481178\n",
      "Train Epoch: 247 [480/1612 (30%)] Loss: 0.409368\n",
      "Train Epoch: 247 [640/1612 (40%)] Loss: 0.250741\n",
      "Train Epoch: 247 [800/1612 (50%)] Loss: 0.413198\n",
      "Train Epoch: 247 [960/1612 (59%)] Loss: 0.274577\n",
      "Train Epoch: 247 [1120/1612 (69%)] Loss: 0.248781\n",
      "Train Epoch: 247 [1280/1612 (79%)] Loss: 0.381499\n",
      "Train Epoch: 247 [1440/1612 (89%)] Loss: 0.435082\n",
      "Train Epoch: 247 [1200/1612 (99%)] Loss: 0.421118\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 248 [0/1612 (0%)] Loss: 0.245288\n",
      "Train Epoch: 248 [160/1612 (10%)] Loss: 0.279964\n",
      "Train Epoch: 248 [320/1612 (20%)] Loss: 0.305528\n",
      "Train Epoch: 248 [480/1612 (30%)] Loss: 0.423423\n",
      "Train Epoch: 248 [640/1612 (40%)] Loss: 0.568677\n",
      "Train Epoch: 248 [800/1612 (50%)] Loss: 0.717495\n",
      "Train Epoch: 248 [960/1612 (59%)] Loss: 0.418790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 248 [1120/1612 (69%)] Loss: 0.481105\n",
      "Train Epoch: 248 [1280/1612 (79%)] Loss: 0.209012\n",
      "Train Epoch: 248 [1440/1612 (89%)] Loss: 0.276036\n",
      "Train Epoch: 248 [1200/1612 (99%)] Loss: 0.472817\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 249 [0/1612 (0%)] Loss: 0.338487\n",
      "Train Epoch: 249 [160/1612 (10%)] Loss: 0.184705\n",
      "Train Epoch: 249 [320/1612 (20%)] Loss: 0.242386\n",
      "Train Epoch: 249 [480/1612 (30%)] Loss: 0.304587\n",
      "Train Epoch: 249 [640/1612 (40%)] Loss: 0.551713\n",
      "Train Epoch: 249 [800/1612 (50%)] Loss: 0.461097\n",
      "Train Epoch: 249 [960/1612 (59%)] Loss: 0.340535\n",
      "Train Epoch: 249 [1120/1612 (69%)] Loss: 0.402858\n",
      "Train Epoch: 249 [1280/1612 (79%)] Loss: 0.153057\n",
      "Train Epoch: 249 [1440/1612 (89%)] Loss: 0.315671\n",
      "Train Epoch: 249 [1200/1612 (99%)] Loss: 0.339434\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 250 [0/1612 (0%)] Loss: 0.278705\n",
      "Train Epoch: 250 [160/1612 (10%)] Loss: 0.350564\n",
      "Train Epoch: 250 [320/1612 (20%)] Loss: 0.335147\n",
      "Train Epoch: 250 [480/1612 (30%)] Loss: 0.304038\n",
      "Train Epoch: 250 [640/1612 (40%)] Loss: 0.398990\n",
      "Train Epoch: 250 [800/1612 (50%)] Loss: 0.225902\n",
      "Train Epoch: 250 [960/1612 (59%)] Loss: 0.449279\n",
      "Train Epoch: 250 [1120/1612 (69%)] Loss: 0.123276\n",
      "Train Epoch: 250 [1280/1612 (79%)] Loss: 0.216676\n",
      "Train Epoch: 250 [1440/1612 (89%)] Loss: 0.309560\n",
      "Train Epoch: 250 [1200/1612 (99%)] Loss: 0.546713\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 251 [0/1612 (0%)] Loss: 0.197504\n",
      "Train Epoch: 251 [160/1612 (10%)] Loss: 0.469533\n",
      "Train Epoch: 251 [320/1612 (20%)] Loss: 0.355396\n",
      "Train Epoch: 251 [480/1612 (30%)] Loss: 0.199479\n",
      "Train Epoch: 251 [640/1612 (40%)] Loss: 0.148436\n",
      "Train Epoch: 251 [800/1612 (50%)] Loss: 0.130728\n",
      "Train Epoch: 251 [960/1612 (59%)] Loss: 0.374775\n",
      "Train Epoch: 251 [1120/1612 (69%)] Loss: 0.453169\n",
      "Train Epoch: 251 [1280/1612 (79%)] Loss: 0.197319\n",
      "Train Epoch: 251 [1440/1612 (89%)] Loss: 0.225840\n",
      "Train Epoch: 251 [1200/1612 (99%)] Loss: 0.352702\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 252 [0/1612 (0%)] Loss: 0.297262\n",
      "Train Epoch: 252 [160/1612 (10%)] Loss: 0.337940\n",
      "Train Epoch: 252 [320/1612 (20%)] Loss: 0.250164\n",
      "Train Epoch: 252 [480/1612 (30%)] Loss: 0.212562\n",
      "Train Epoch: 252 [640/1612 (40%)] Loss: 0.397404\n",
      "Train Epoch: 252 [800/1612 (50%)] Loss: 0.153129\n",
      "Train Epoch: 252 [960/1612 (59%)] Loss: 0.327595\n",
      "Train Epoch: 252 [1120/1612 (69%)] Loss: 0.240941\n",
      "Train Epoch: 252 [1280/1612 (79%)] Loss: 0.094076\n",
      "Train Epoch: 252 [1440/1612 (89%)] Loss: 0.119406\n",
      "Train Epoch: 252 [1200/1612 (99%)] Loss: 0.260640\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 253 [0/1612 (0%)] Loss: 0.480876\n",
      "Train Epoch: 253 [160/1612 (10%)] Loss: 0.271993\n",
      "Train Epoch: 253 [320/1612 (20%)] Loss: 0.244300\n",
      "Train Epoch: 253 [480/1612 (30%)] Loss: 0.274756\n",
      "Train Epoch: 253 [640/1612 (40%)] Loss: 0.513508\n",
      "Train Epoch: 253 [800/1612 (50%)] Loss: 0.094855\n",
      "Train Epoch: 253 [960/1612 (59%)] Loss: 0.183210\n",
      "Train Epoch: 253 [1120/1612 (69%)] Loss: 0.615722\n",
      "Train Epoch: 253 [1280/1612 (79%)] Loss: 0.315385\n",
      "Train Epoch: 253 [1440/1612 (89%)] Loss: 0.228786\n",
      "Train Epoch: 253 [1200/1612 (99%)] Loss: 0.341204\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 254 [0/1612 (0%)] Loss: 0.261629\n",
      "Train Epoch: 254 [160/1612 (10%)] Loss: 0.316155\n",
      "Train Epoch: 254 [320/1612 (20%)] Loss: 0.572386\n",
      "Train Epoch: 254 [480/1612 (30%)] Loss: 0.319757\n",
      "Train Epoch: 254 [640/1612 (40%)] Loss: 0.307440\n",
      "Train Epoch: 254 [800/1612 (50%)] Loss: 0.176223\n",
      "Train Epoch: 254 [960/1612 (59%)] Loss: 0.197457\n",
      "Train Epoch: 254 [1120/1612 (69%)] Loss: 0.255491\n",
      "Train Epoch: 254 [1280/1612 (79%)] Loss: 0.425717\n",
      "Train Epoch: 254 [1440/1612 (89%)] Loss: 0.361979\n",
      "Train Epoch: 254 [1200/1612 (99%)] Loss: 0.178758\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 255 [0/1612 (0%)] Loss: 0.359246\n",
      "Train Epoch: 255 [160/1612 (10%)] Loss: 0.162180\n",
      "Train Epoch: 255 [320/1612 (20%)] Loss: 0.134664\n",
      "Train Epoch: 255 [480/1612 (30%)] Loss: 0.223057\n",
      "Train Epoch: 255 [640/1612 (40%)] Loss: 0.576082\n",
      "Train Epoch: 255 [800/1612 (50%)] Loss: 0.425318\n",
      "Train Epoch: 255 [960/1612 (59%)] Loss: 0.519650\n",
      "Train Epoch: 255 [1120/1612 (69%)] Loss: 0.125939\n",
      "Train Epoch: 255 [1280/1612 (79%)] Loss: 0.231399\n",
      "Train Epoch: 255 [1440/1612 (89%)] Loss: 0.072871\n",
      "Train Epoch: 255 [1200/1612 (99%)] Loss: 0.433509\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 256 [0/1612 (0%)] Loss: 0.327454\n",
      "Train Epoch: 256 [160/1612 (10%)] Loss: 0.345303\n",
      "Train Epoch: 256 [320/1612 (20%)] Loss: 0.482043\n",
      "Train Epoch: 256 [480/1612 (30%)] Loss: 0.192094\n",
      "Train Epoch: 256 [640/1612 (40%)] Loss: 0.370733\n",
      "Train Epoch: 256 [800/1612 (50%)] Loss: 0.572706\n",
      "Train Epoch: 256 [960/1612 (59%)] Loss: 0.319894\n",
      "Train Epoch: 256 [1120/1612 (69%)] Loss: 0.419390\n",
      "Train Epoch: 256 [1280/1612 (79%)] Loss: 0.208135\n",
      "Train Epoch: 256 [1440/1612 (89%)] Loss: 0.380045\n",
      "Train Epoch: 256 [1200/1612 (99%)] Loss: 0.522629\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 257 [0/1612 (0%)] Loss: 0.257055\n",
      "Train Epoch: 257 [160/1612 (10%)] Loss: 0.328461\n",
      "Train Epoch: 257 [320/1612 (20%)] Loss: 0.377813\n",
      "Train Epoch: 257 [480/1612 (30%)] Loss: 0.368239\n",
      "Train Epoch: 257 [640/1612 (40%)] Loss: 0.283627\n",
      "Train Epoch: 257 [800/1612 (50%)] Loss: 0.846936\n",
      "Train Epoch: 257 [960/1612 (59%)] Loss: 0.285650\n",
      "Train Epoch: 257 [1120/1612 (69%)] Loss: 0.302468\n",
      "Train Epoch: 257 [1280/1612 (79%)] Loss: 0.413575\n",
      "Train Epoch: 257 [1440/1612 (89%)] Loss: 0.343529\n",
      "Train Epoch: 257 [1200/1612 (99%)] Loss: 0.466951\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 258 [0/1612 (0%)] Loss: 0.333687\n",
      "Train Epoch: 258 [160/1612 (10%)] Loss: 0.223253\n",
      "Train Epoch: 258 [320/1612 (20%)] Loss: 0.352534\n",
      "Train Epoch: 258 [480/1612 (30%)] Loss: 0.233652\n",
      "Train Epoch: 258 [640/1612 (40%)] Loss: 0.319760\n",
      "Train Epoch: 258 [800/1612 (50%)] Loss: 0.196701\n",
      "Train Epoch: 258 [960/1612 (59%)] Loss: 0.225908\n",
      "Train Epoch: 258 [1120/1612 (69%)] Loss: 0.335715\n",
      "Train Epoch: 258 [1280/1612 (79%)] Loss: 0.629458\n",
      "Train Epoch: 258 [1440/1612 (89%)] Loss: 0.403608\n",
      "Train Epoch: 258 [1200/1612 (99%)] Loss: 0.270314\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 259 [0/1612 (0%)] Loss: 0.344218\n",
      "Train Epoch: 259 [160/1612 (10%)] Loss: 0.474387\n",
      "Train Epoch: 259 [320/1612 (20%)] Loss: 0.247241\n",
      "Train Epoch: 259 [480/1612 (30%)] Loss: 0.205616\n",
      "Train Epoch: 259 [640/1612 (40%)] Loss: 0.364295\n",
      "Train Epoch: 259 [800/1612 (50%)] Loss: 0.341106\n",
      "Train Epoch: 259 [960/1612 (59%)] Loss: 0.260159\n",
      "Train Epoch: 259 [1120/1612 (69%)] Loss: 0.152707\n",
      "Train Epoch: 259 [1280/1612 (79%)] Loss: 0.369357\n",
      "Train Epoch: 259 [1440/1612 (89%)] Loss: 0.261735\n",
      "Train Epoch: 259 [1200/1612 (99%)] Loss: 0.458622\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 260 [0/1612 (0%)] Loss: 0.431353\n",
      "Train Epoch: 260 [160/1612 (10%)] Loss: 0.363844\n",
      "Train Epoch: 260 [320/1612 (20%)] Loss: 0.377316\n",
      "Train Epoch: 260 [480/1612 (30%)] Loss: 0.487780\n",
      "Train Epoch: 260 [640/1612 (40%)] Loss: 0.279034\n",
      "Train Epoch: 260 [800/1612 (50%)] Loss: 0.157306\n",
      "Train Epoch: 260 [960/1612 (59%)] Loss: 0.174828\n",
      "Train Epoch: 260 [1120/1612 (69%)] Loss: 0.272332\n",
      "Train Epoch: 260 [1280/1612 (79%)] Loss: 0.905125\n",
      "Train Epoch: 260 [1440/1612 (89%)] Loss: 0.282142\n",
      "Train Epoch: 260 [1200/1612 (99%)] Loss: 0.271924\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 261 [0/1612 (0%)] Loss: 0.228352\n",
      "Train Epoch: 261 [160/1612 (10%)] Loss: 0.185624\n",
      "Train Epoch: 261 [320/1612 (20%)] Loss: 0.303534\n",
      "Train Epoch: 261 [480/1612 (30%)] Loss: 0.604640\n",
      "Train Epoch: 261 [640/1612 (40%)] Loss: 0.519859\n",
      "Train Epoch: 261 [800/1612 (50%)] Loss: 0.320407\n",
      "Train Epoch: 261 [960/1612 (59%)] Loss: 0.442687\n",
      "Train Epoch: 261 [1120/1612 (69%)] Loss: 0.489004\n",
      "Train Epoch: 261 [1280/1612 (79%)] Loss: 0.501493\n",
      "Train Epoch: 261 [1440/1612 (89%)] Loss: 0.311903\n",
      "Train Epoch: 261 [1200/1612 (99%)] Loss: 0.214083\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 262 [0/1612 (0%)] Loss: 0.403327\n",
      "Train Epoch: 262 [160/1612 (10%)] Loss: 0.288087\n",
      "Train Epoch: 262 [320/1612 (20%)] Loss: 0.343755\n",
      "Train Epoch: 262 [480/1612 (30%)] Loss: 0.310602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 262 [640/1612 (40%)] Loss: 0.258353\n",
      "Train Epoch: 262 [800/1612 (50%)] Loss: 0.464069\n",
      "Train Epoch: 262 [960/1612 (59%)] Loss: 0.385802\n",
      "Train Epoch: 262 [1120/1612 (69%)] Loss: 0.186794\n",
      "Train Epoch: 262 [1280/1612 (79%)] Loss: 0.399479\n",
      "Train Epoch: 262 [1440/1612 (89%)] Loss: 0.342704\n",
      "Train Epoch: 262 [1200/1612 (99%)] Loss: 0.313796\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 263 [0/1612 (0%)] Loss: 0.397562\n",
      "Train Epoch: 263 [160/1612 (10%)] Loss: 0.301083\n",
      "Train Epoch: 263 [320/1612 (20%)] Loss: 0.474451\n",
      "Train Epoch: 263 [480/1612 (30%)] Loss: 0.436881\n",
      "Train Epoch: 263 [640/1612 (40%)] Loss: 0.646857\n",
      "Train Epoch: 263 [800/1612 (50%)] Loss: 0.395461\n",
      "Train Epoch: 263 [960/1612 (59%)] Loss: 0.372741\n",
      "Train Epoch: 263 [1120/1612 (69%)] Loss: 0.237327\n",
      "Train Epoch: 263 [1280/1612 (79%)] Loss: 0.551782\n",
      "Train Epoch: 263 [1440/1612 (89%)] Loss: 0.274190\n",
      "Train Epoch: 263 [1200/1612 (99%)] Loss: 0.570290\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 264 [0/1612 (0%)] Loss: 0.177009\n",
      "Train Epoch: 264 [160/1612 (10%)] Loss: 0.409745\n",
      "Train Epoch: 264 [320/1612 (20%)] Loss: 0.212555\n",
      "Train Epoch: 264 [480/1612 (30%)] Loss: 0.326525\n",
      "Train Epoch: 264 [640/1612 (40%)] Loss: 0.409095\n",
      "Train Epoch: 264 [800/1612 (50%)] Loss: 0.222786\n",
      "Train Epoch: 264 [960/1612 (59%)] Loss: 0.369392\n",
      "Train Epoch: 264 [1120/1612 (69%)] Loss: 0.514670\n",
      "Train Epoch: 264 [1280/1612 (79%)] Loss: 0.475085\n",
      "Train Epoch: 264 [1440/1612 (89%)] Loss: 0.560715\n",
      "Train Epoch: 264 [1200/1612 (99%)] Loss: 0.334398\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 265 [0/1612 (0%)] Loss: 0.173875\n",
      "Train Epoch: 265 [160/1612 (10%)] Loss: 0.389185\n",
      "Train Epoch: 265 [320/1612 (20%)] Loss: 0.496170\n",
      "Train Epoch: 265 [480/1612 (30%)] Loss: 0.358199\n",
      "Train Epoch: 265 [640/1612 (40%)] Loss: 0.248434\n",
      "Train Epoch: 265 [800/1612 (50%)] Loss: 0.169885\n",
      "Train Epoch: 265 [960/1612 (59%)] Loss: 0.657738\n",
      "Train Epoch: 265 [1120/1612 (69%)] Loss: 0.415714\n",
      "Train Epoch: 265 [1280/1612 (79%)] Loss: 0.406983\n",
      "Train Epoch: 265 [1440/1612 (89%)] Loss: 0.645273\n",
      "Train Epoch: 265 [1200/1612 (99%)] Loss: 0.568563\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 266 [0/1612 (0%)] Loss: 0.307462\n",
      "Train Epoch: 266 [160/1612 (10%)] Loss: 0.318493\n",
      "Train Epoch: 266 [320/1612 (20%)] Loss: 0.661622\n",
      "Train Epoch: 266 [480/1612 (30%)] Loss: 0.370274\n",
      "Train Epoch: 266 [640/1612 (40%)] Loss: 0.227201\n",
      "Train Epoch: 266 [800/1612 (50%)] Loss: 0.397926\n",
      "Train Epoch: 266 [960/1612 (59%)] Loss: 0.355137\n",
      "Train Epoch: 266 [1120/1612 (69%)] Loss: 0.371175\n",
      "Train Epoch: 266 [1280/1612 (79%)] Loss: 0.512584\n",
      "Train Epoch: 266 [1440/1612 (89%)] Loss: 0.283677\n",
      "Train Epoch: 266 [1200/1612 (99%)] Loss: 0.215152\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 267 [0/1612 (0%)] Loss: 0.337148\n",
      "Train Epoch: 267 [160/1612 (10%)] Loss: 0.154111\n",
      "Train Epoch: 267 [320/1612 (20%)] Loss: 0.271317\n",
      "Train Epoch: 267 [480/1612 (30%)] Loss: 0.380470\n",
      "Train Epoch: 267 [640/1612 (40%)] Loss: 0.596041\n",
      "Train Epoch: 267 [800/1612 (50%)] Loss: 0.331948\n",
      "Train Epoch: 267 [960/1612 (59%)] Loss: 0.429080\n",
      "Train Epoch: 267 [1120/1612 (69%)] Loss: 0.412428\n",
      "Train Epoch: 267 [1280/1612 (79%)] Loss: 0.178362\n",
      "Train Epoch: 267 [1440/1612 (89%)] Loss: 0.103342\n",
      "Train Epoch: 267 [1200/1612 (99%)] Loss: 0.210027\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 268 [0/1612 (0%)] Loss: 0.441443\n",
      "Train Epoch: 268 [160/1612 (10%)] Loss: 0.352594\n",
      "Train Epoch: 268 [320/1612 (20%)] Loss: 0.363633\n",
      "Train Epoch: 268 [480/1612 (30%)] Loss: 0.510496\n",
      "Train Epoch: 268 [640/1612 (40%)] Loss: 0.626975\n",
      "Train Epoch: 268 [800/1612 (50%)] Loss: 0.583829\n",
      "Train Epoch: 268 [960/1612 (59%)] Loss: 0.319196\n",
      "Train Epoch: 268 [1120/1612 (69%)] Loss: 0.121803\n",
      "Train Epoch: 268 [1280/1612 (79%)] Loss: 0.431798\n",
      "Train Epoch: 268 [1440/1612 (89%)] Loss: 0.235708\n",
      "Train Epoch: 268 [1200/1612 (99%)] Loss: 0.339520\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 269 [0/1612 (0%)] Loss: 0.183799\n",
      "Train Epoch: 269 [160/1612 (10%)] Loss: 0.444730\n",
      "Train Epoch: 269 [320/1612 (20%)] Loss: 0.672264\n",
      "Train Epoch: 269 [480/1612 (30%)] Loss: 0.287869\n",
      "Train Epoch: 269 [640/1612 (40%)] Loss: 0.243615\n",
      "Train Epoch: 269 [800/1612 (50%)] Loss: 0.140283\n",
      "Train Epoch: 269 [960/1612 (59%)] Loss: 0.266496\n",
      "Train Epoch: 269 [1120/1612 (69%)] Loss: 0.309757\n",
      "Train Epoch: 269 [1280/1612 (79%)] Loss: 0.265439\n",
      "Train Epoch: 269 [1440/1612 (89%)] Loss: 0.459925\n",
      "Train Epoch: 269 [1200/1612 (99%)] Loss: 0.330848\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 270 [0/1612 (0%)] Loss: 0.441046\n",
      "Train Epoch: 270 [160/1612 (10%)] Loss: 0.313824\n",
      "Train Epoch: 270 [320/1612 (20%)] Loss: 0.505898\n",
      "Train Epoch: 270 [480/1612 (30%)] Loss: 0.319319\n",
      "Train Epoch: 270 [640/1612 (40%)] Loss: 0.387428\n",
      "Train Epoch: 270 [800/1612 (50%)] Loss: 0.175925\n",
      "Train Epoch: 270 [960/1612 (59%)] Loss: 0.305107\n",
      "Train Epoch: 270 [1120/1612 (69%)] Loss: 0.346077\n",
      "Train Epoch: 270 [1280/1612 (79%)] Loss: 0.382320\n",
      "Train Epoch: 270 [1440/1612 (89%)] Loss: 0.747220\n",
      "Train Epoch: 270 [1200/1612 (99%)] Loss: 0.430351\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 271 [0/1612 (0%)] Loss: 0.474760\n",
      "Train Epoch: 271 [160/1612 (10%)] Loss: 0.248344\n",
      "Train Epoch: 271 [320/1612 (20%)] Loss: 0.237028\n",
      "Train Epoch: 271 [480/1612 (30%)] Loss: 0.190952\n",
      "Train Epoch: 271 [640/1612 (40%)] Loss: 0.115747\n",
      "Train Epoch: 271 [800/1612 (50%)] Loss: 0.202108\n",
      "Train Epoch: 271 [960/1612 (59%)] Loss: 0.297867\n",
      "Train Epoch: 271 [1120/1612 (69%)] Loss: 0.478545\n",
      "Train Epoch: 271 [1280/1612 (79%)] Loss: 0.572440\n",
      "Train Epoch: 271 [1440/1612 (89%)] Loss: 0.257133\n",
      "Train Epoch: 271 [1200/1612 (99%)] Loss: 0.178196\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 272 [0/1612 (0%)] Loss: 0.656800\n",
      "Train Epoch: 272 [160/1612 (10%)] Loss: 0.422808\n",
      "Train Epoch: 272 [320/1612 (20%)] Loss: 0.384194\n",
      "Train Epoch: 272 [480/1612 (30%)] Loss: 0.322618\n",
      "Train Epoch: 272 [640/1612 (40%)] Loss: 0.293154\n",
      "Train Epoch: 272 [800/1612 (50%)] Loss: 0.216280\n",
      "Train Epoch: 272 [960/1612 (59%)] Loss: 0.346052\n",
      "Train Epoch: 272 [1120/1612 (69%)] Loss: 0.237716\n",
      "Train Epoch: 272 [1280/1612 (79%)] Loss: 0.090212\n",
      "Train Epoch: 272 [1440/1612 (89%)] Loss: 0.482692\n",
      "Train Epoch: 272 [1200/1612 (99%)] Loss: 0.249937\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 273 [0/1612 (0%)] Loss: 0.464466\n",
      "Train Epoch: 273 [160/1612 (10%)] Loss: 0.332838\n",
      "Train Epoch: 273 [320/1612 (20%)] Loss: 0.159818\n",
      "Train Epoch: 273 [480/1612 (30%)] Loss: 0.139872\n",
      "Train Epoch: 273 [640/1612 (40%)] Loss: 0.320661\n",
      "Train Epoch: 273 [800/1612 (50%)] Loss: 0.326839\n",
      "Train Epoch: 273 [960/1612 (59%)] Loss: 0.306013\n",
      "Train Epoch: 273 [1120/1612 (69%)] Loss: 0.297134\n",
      "Train Epoch: 273 [1280/1612 (79%)] Loss: 0.424703\n",
      "Train Epoch: 273 [1440/1612 (89%)] Loss: 0.405637\n",
      "Train Epoch: 273 [1200/1612 (99%)] Loss: 0.268440\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 274 [0/1612 (0%)] Loss: 0.196665\n",
      "Train Epoch: 274 [160/1612 (10%)] Loss: 0.421346\n",
      "Train Epoch: 274 [320/1612 (20%)] Loss: 0.568439\n",
      "Train Epoch: 274 [480/1612 (30%)] Loss: 0.305058\n",
      "Train Epoch: 274 [640/1612 (40%)] Loss: 0.312336\n",
      "Train Epoch: 274 [800/1612 (50%)] Loss: 0.201960\n",
      "Train Epoch: 274 [960/1612 (59%)] Loss: 0.383874\n",
      "Train Epoch: 274 [1120/1612 (69%)] Loss: 0.160312\n",
      "Train Epoch: 274 [1280/1612 (79%)] Loss: 0.273101\n",
      "Train Epoch: 274 [1440/1612 (89%)] Loss: 0.448489\n",
      "Train Epoch: 274 [1200/1612 (99%)] Loss: 0.330956\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 275 [0/1612 (0%)] Loss: 0.472981\n",
      "Train Epoch: 275 [160/1612 (10%)] Loss: 0.516797\n",
      "Train Epoch: 275 [320/1612 (20%)] Loss: 0.484416\n",
      "Train Epoch: 275 [480/1612 (30%)] Loss: 0.543078\n",
      "Train Epoch: 275 [640/1612 (40%)] Loss: 0.275802\n",
      "Train Epoch: 275 [800/1612 (50%)] Loss: 0.430257\n",
      "Train Epoch: 275 [960/1612 (59%)] Loss: 0.414706\n",
      "Train Epoch: 275 [1120/1612 (69%)] Loss: 0.265854\n",
      "Train Epoch: 275 [1280/1612 (79%)] Loss: 0.321956\n",
      "Train Epoch: 275 [1440/1612 (89%)] Loss: 0.247475\n",
      "Train Epoch: 275 [1200/1612 (99%)] Loss: 0.217366\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 276 [0/1612 (0%)] Loss: 0.378704\n",
      "Train Epoch: 276 [160/1612 (10%)] Loss: 0.577721\n",
      "Train Epoch: 276 [320/1612 (20%)] Loss: 0.458715\n",
      "Train Epoch: 276 [480/1612 (30%)] Loss: 0.430053\n",
      "Train Epoch: 276 [640/1612 (40%)] Loss: 0.408080\n",
      "Train Epoch: 276 [800/1612 (50%)] Loss: 0.367202\n",
      "Train Epoch: 276 [960/1612 (59%)] Loss: 0.143143\n",
      "Train Epoch: 276 [1120/1612 (69%)] Loss: 0.302275\n",
      "Train Epoch: 276 [1280/1612 (79%)] Loss: 0.433037\n",
      "Train Epoch: 276 [1440/1612 (89%)] Loss: 0.402282\n",
      "Train Epoch: 276 [1200/1612 (99%)] Loss: 0.504610\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 277 [0/1612 (0%)] Loss: 0.272125\n",
      "Train Epoch: 277 [160/1612 (10%)] Loss: 0.350510\n",
      "Train Epoch: 277 [320/1612 (20%)] Loss: 0.550785\n",
      "Train Epoch: 277 [480/1612 (30%)] Loss: 0.317630\n",
      "Train Epoch: 277 [640/1612 (40%)] Loss: 0.379524\n",
      "Train Epoch: 277 [800/1612 (50%)] Loss: 0.334964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 277 [960/1612 (59%)] Loss: 0.389257\n",
      "Train Epoch: 277 [1120/1612 (69%)] Loss: 0.421686\n",
      "Train Epoch: 277 [1280/1612 (79%)] Loss: 0.387656\n",
      "Train Epoch: 277 [1440/1612 (89%)] Loss: 0.351629\n",
      "Train Epoch: 277 [1200/1612 (99%)] Loss: 0.506808\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 278 [0/1612 (0%)] Loss: 0.354895\n",
      "Train Epoch: 278 [160/1612 (10%)] Loss: 0.477742\n",
      "Train Epoch: 278 [320/1612 (20%)] Loss: 0.248879\n",
      "Train Epoch: 278 [480/1612 (30%)] Loss: 0.320397\n",
      "Train Epoch: 278 [640/1612 (40%)] Loss: 0.377601\n",
      "Train Epoch: 278 [800/1612 (50%)] Loss: 0.303942\n",
      "Train Epoch: 278 [960/1612 (59%)] Loss: 0.281723\n",
      "Train Epoch: 278 [1120/1612 (69%)] Loss: 0.144017\n",
      "Train Epoch: 278 [1280/1612 (79%)] Loss: 0.523829\n",
      "Train Epoch: 278 [1440/1612 (89%)] Loss: 0.441856\n",
      "Train Epoch: 278 [1200/1612 (99%)] Loss: 0.588528\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 279 [0/1612 (0%)] Loss: 0.177148\n",
      "Train Epoch: 279 [160/1612 (10%)] Loss: 0.331784\n",
      "Train Epoch: 279 [320/1612 (20%)] Loss: 0.595005\n",
      "Train Epoch: 279 [480/1612 (30%)] Loss: 0.482210\n",
      "Train Epoch: 279 [640/1612 (40%)] Loss: 0.340341\n",
      "Train Epoch: 279 [800/1612 (50%)] Loss: 0.416373\n",
      "Train Epoch: 279 [960/1612 (59%)] Loss: 0.185553\n",
      "Train Epoch: 279 [1120/1612 (69%)] Loss: 0.264429\n",
      "Train Epoch: 279 [1280/1612 (79%)] Loss: 0.389284\n",
      "Train Epoch: 279 [1440/1612 (89%)] Loss: 0.292891\n",
      "Train Epoch: 279 [1200/1612 (99%)] Loss: 0.540236\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 280 [0/1612 (0%)] Loss: 0.413428\n",
      "Train Epoch: 280 [160/1612 (10%)] Loss: 0.228877\n",
      "Train Epoch: 280 [320/1612 (20%)] Loss: 0.539270\n",
      "Train Epoch: 280 [480/1612 (30%)] Loss: 0.484276\n",
      "Train Epoch: 280 [640/1612 (40%)] Loss: 0.326269\n",
      "Train Epoch: 280 [800/1612 (50%)] Loss: 0.475244\n",
      "Train Epoch: 280 [960/1612 (59%)] Loss: 0.309161\n",
      "Train Epoch: 280 [1120/1612 (69%)] Loss: 0.335720\n",
      "Train Epoch: 280 [1280/1612 (79%)] Loss: 0.474702\n",
      "Train Epoch: 280 [1440/1612 (89%)] Loss: 0.543472\n",
      "Train Epoch: 280 [1200/1612 (99%)] Loss: 0.467618\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 281 [0/1612 (0%)] Loss: 0.238627\n",
      "Train Epoch: 281 [160/1612 (10%)] Loss: 0.407802\n",
      "Train Epoch: 281 [320/1612 (20%)] Loss: 0.268835\n",
      "Train Epoch: 281 [480/1612 (30%)] Loss: 0.295074\n",
      "Train Epoch: 281 [640/1612 (40%)] Loss: 0.370475\n",
      "Train Epoch: 281 [800/1612 (50%)] Loss: 0.098581\n",
      "Train Epoch: 281 [960/1612 (59%)] Loss: 0.399821\n",
      "Train Epoch: 281 [1120/1612 (69%)] Loss: 0.531743\n",
      "Train Epoch: 281 [1280/1612 (79%)] Loss: 0.305149\n",
      "Train Epoch: 281 [1440/1612 (89%)] Loss: 0.532931\n",
      "Train Epoch: 281 [1200/1612 (99%)] Loss: 0.242241\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 282 [0/1612 (0%)] Loss: 0.394271\n",
      "Train Epoch: 282 [160/1612 (10%)] Loss: 0.565204\n",
      "Train Epoch: 282 [320/1612 (20%)] Loss: 0.372957\n",
      "Train Epoch: 282 [480/1612 (30%)] Loss: 0.390388\n",
      "Train Epoch: 282 [640/1612 (40%)] Loss: 0.319866\n",
      "Train Epoch: 282 [800/1612 (50%)] Loss: 0.409576\n",
      "Train Epoch: 282 [960/1612 (59%)] Loss: 0.601009\n",
      "Train Epoch: 282 [1120/1612 (69%)] Loss: 0.454974\n",
      "Train Epoch: 282 [1280/1612 (79%)] Loss: 0.143868\n",
      "Train Epoch: 282 [1440/1612 (89%)] Loss: 0.444858\n",
      "Train Epoch: 282 [1200/1612 (99%)] Loss: 0.376188\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 283 [0/1612 (0%)] Loss: 0.481319\n",
      "Train Epoch: 283 [160/1612 (10%)] Loss: 0.317347\n",
      "Train Epoch: 283 [320/1612 (20%)] Loss: 0.269480\n",
      "Train Epoch: 283 [480/1612 (30%)] Loss: 0.268834\n",
      "Train Epoch: 283 [640/1612 (40%)] Loss: 0.943436\n",
      "Train Epoch: 283 [800/1612 (50%)] Loss: 0.457532\n",
      "Train Epoch: 283 [960/1612 (59%)] Loss: 0.450169\n",
      "Train Epoch: 283 [1120/1612 (69%)] Loss: 0.588901\n",
      "Train Epoch: 283 [1280/1612 (79%)] Loss: 0.182135\n",
      "Train Epoch: 283 [1440/1612 (89%)] Loss: 0.127537\n",
      "Train Epoch: 283 [1200/1612 (99%)] Loss: 0.402782\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 284 [0/1612 (0%)] Loss: 0.860700\n",
      "Train Epoch: 284 [160/1612 (10%)] Loss: 0.737511\n",
      "Train Epoch: 284 [320/1612 (20%)] Loss: 0.127812\n",
      "Train Epoch: 284 [480/1612 (30%)] Loss: 0.323745\n",
      "Train Epoch: 284 [640/1612 (40%)] Loss: 0.208190\n",
      "Train Epoch: 284 [800/1612 (50%)] Loss: 0.458345\n",
      "Train Epoch: 284 [960/1612 (59%)] Loss: 0.219515\n",
      "Train Epoch: 284 [1120/1612 (69%)] Loss: 0.107427\n",
      "Train Epoch: 284 [1280/1612 (79%)] Loss: 0.149610\n",
      "Train Epoch: 284 [1440/1612 (89%)] Loss: 0.152309\n",
      "Train Epoch: 284 [1200/1612 (99%)] Loss: 0.696682\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 285 [0/1612 (0%)] Loss: 0.406990\n",
      "Train Epoch: 285 [160/1612 (10%)] Loss: 0.442936\n",
      "Train Epoch: 285 [320/1612 (20%)] Loss: 0.308231\n",
      "Train Epoch: 285 [480/1612 (30%)] Loss: 0.492135\n",
      "Train Epoch: 285 [640/1612 (40%)] Loss: 0.245899\n",
      "Train Epoch: 285 [800/1612 (50%)] Loss: 0.191443\n",
      "Train Epoch: 285 [960/1612 (59%)] Loss: 0.302325\n",
      "Train Epoch: 285 [1120/1612 (69%)] Loss: 0.334368\n",
      "Train Epoch: 285 [1280/1612 (79%)] Loss: 0.280218\n",
      "Train Epoch: 285 [1440/1612 (89%)] Loss: 0.468464\n",
      "Train Epoch: 285 [1200/1612 (99%)] Loss: 0.389591\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 286 [0/1612 (0%)] Loss: 0.369393\n",
      "Train Epoch: 286 [160/1612 (10%)] Loss: 0.482266\n",
      "Train Epoch: 286 [320/1612 (20%)] Loss: 0.316420\n",
      "Train Epoch: 286 [480/1612 (30%)] Loss: 0.309990\n",
      "Train Epoch: 286 [640/1612 (40%)] Loss: 0.414580\n",
      "Train Epoch: 286 [800/1612 (50%)] Loss: 0.343319\n",
      "Train Epoch: 286 [960/1612 (59%)] Loss: 0.261484\n",
      "Train Epoch: 286 [1120/1612 (69%)] Loss: 0.283428\n",
      "Train Epoch: 286 [1280/1612 (79%)] Loss: 0.210373\n",
      "Train Epoch: 286 [1440/1612 (89%)] Loss: 0.429842\n",
      "Train Epoch: 286 [1200/1612 (99%)] Loss: 0.221409\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 287 [0/1612 (0%)] Loss: 0.357730\n",
      "Train Epoch: 287 [160/1612 (10%)] Loss: 0.253161\n",
      "Train Epoch: 287 [320/1612 (20%)] Loss: 0.350596\n",
      "Train Epoch: 287 [480/1612 (30%)] Loss: 0.329804\n",
      "Train Epoch: 287 [640/1612 (40%)] Loss: 0.496313\n",
      "Train Epoch: 287 [800/1612 (50%)] Loss: 0.456377\n",
      "Train Epoch: 287 [960/1612 (59%)] Loss: 0.213103\n",
      "Train Epoch: 287 [1120/1612 (69%)] Loss: 0.492674\n",
      "Train Epoch: 287 [1280/1612 (79%)] Loss: 0.266521\n",
      "Train Epoch: 287 [1440/1612 (89%)] Loss: 0.245299\n",
      "Train Epoch: 287 [1200/1612 (99%)] Loss: 0.167970\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 288 [0/1612 (0%)] Loss: 0.250353\n",
      "Train Epoch: 288 [160/1612 (10%)] Loss: 0.412550\n",
      "Train Epoch: 288 [320/1612 (20%)] Loss: 0.391673\n",
      "Train Epoch: 288 [480/1612 (30%)] Loss: 0.253188\n",
      "Train Epoch: 288 [640/1612 (40%)] Loss: 0.301885\n",
      "Train Epoch: 288 [800/1612 (50%)] Loss: 0.449631\n",
      "Train Epoch: 288 [960/1612 (59%)] Loss: 0.282834\n",
      "Train Epoch: 288 [1120/1612 (69%)] Loss: 0.292930\n",
      "Train Epoch: 288 [1280/1612 (79%)] Loss: 0.556990\n",
      "Train Epoch: 288 [1440/1612 (89%)] Loss: 0.347610\n",
      "Train Epoch: 288 [1200/1612 (99%)] Loss: 0.465361\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 289 [0/1612 (0%)] Loss: 0.331816\n",
      "Train Epoch: 289 [160/1612 (10%)] Loss: 0.478906\n",
      "Train Epoch: 289 [320/1612 (20%)] Loss: 0.392229\n",
      "Train Epoch: 289 [480/1612 (30%)] Loss: 0.232743\n",
      "Train Epoch: 289 [640/1612 (40%)] Loss: 0.520316\n",
      "Train Epoch: 289 [800/1612 (50%)] Loss: 0.318565\n",
      "Train Epoch: 289 [960/1612 (59%)] Loss: 0.288900\n",
      "Train Epoch: 289 [1120/1612 (69%)] Loss: 0.603608\n",
      "Train Epoch: 289 [1280/1612 (79%)] Loss: 0.139446\n",
      "Train Epoch: 289 [1440/1612 (89%)] Loss: 0.186854\n",
      "Train Epoch: 289 [1200/1612 (99%)] Loss: 0.226206\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 290 [0/1612 (0%)] Loss: 0.115335\n",
      "Train Epoch: 290 [160/1612 (10%)] Loss: 0.453289\n",
      "Train Epoch: 290 [320/1612 (20%)] Loss: 0.309514\n",
      "Train Epoch: 290 [480/1612 (30%)] Loss: 0.593279\n",
      "Train Epoch: 290 [640/1612 (40%)] Loss: 0.316757\n",
      "Train Epoch: 290 [800/1612 (50%)] Loss: 0.467129\n",
      "Train Epoch: 290 [960/1612 (59%)] Loss: 0.653518\n",
      "Train Epoch: 290 [1120/1612 (69%)] Loss: 0.233869\n",
      "Train Epoch: 290 [1280/1612 (79%)] Loss: 0.327905\n",
      "Train Epoch: 290 [1440/1612 (89%)] Loss: 0.319154\n",
      "Train Epoch: 290 [1200/1612 (99%)] Loss: 0.165360\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 291 [0/1612 (0%)] Loss: 0.400907\n",
      "Train Epoch: 291 [160/1612 (10%)] Loss: 0.343917\n",
      "Train Epoch: 291 [320/1612 (20%)] Loss: 0.199735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 291 [480/1612 (30%)] Loss: 0.236643\n",
      "Train Epoch: 291 [640/1612 (40%)] Loss: 0.177989\n",
      "Train Epoch: 291 [800/1612 (50%)] Loss: 0.344722\n",
      "Train Epoch: 291 [960/1612 (59%)] Loss: 0.415782\n",
      "Train Epoch: 291 [1120/1612 (69%)] Loss: 0.334153\n",
      "Train Epoch: 291 [1280/1612 (79%)] Loss: 0.240007\n",
      "Train Epoch: 291 [1440/1612 (89%)] Loss: 0.189365\n",
      "Train Epoch: 291 [1200/1612 (99%)] Loss: 0.735498\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 292 [0/1612 (0%)] Loss: 0.325770\n",
      "Train Epoch: 292 [160/1612 (10%)] Loss: 0.368686\n",
      "Train Epoch: 292 [320/1612 (20%)] Loss: 0.882913\n",
      "Train Epoch: 292 [480/1612 (30%)] Loss: 0.073011\n",
      "Train Epoch: 292 [640/1612 (40%)] Loss: 0.616399\n",
      "Train Epoch: 292 [800/1612 (50%)] Loss: 0.338662\n",
      "Train Epoch: 292 [960/1612 (59%)] Loss: 0.274570\n",
      "Train Epoch: 292 [1120/1612 (69%)] Loss: 0.367050\n",
      "Train Epoch: 292 [1280/1612 (79%)] Loss: 0.259557\n",
      "Train Epoch: 292 [1440/1612 (89%)] Loss: 0.357633\n",
      "Train Epoch: 292 [1200/1612 (99%)] Loss: 0.359725\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 293 [0/1612 (0%)] Loss: 0.367558\n",
      "Train Epoch: 293 [160/1612 (10%)] Loss: 0.255724\n",
      "Train Epoch: 293 [320/1612 (20%)] Loss: 0.722543\n",
      "Train Epoch: 293 [480/1612 (30%)] Loss: 0.391668\n",
      "Train Epoch: 293 [640/1612 (40%)] Loss: 0.280858\n",
      "Train Epoch: 293 [800/1612 (50%)] Loss: 0.332972\n",
      "Train Epoch: 293 [960/1612 (59%)] Loss: 0.150077\n",
      "Train Epoch: 293 [1120/1612 (69%)] Loss: 0.428647\n",
      "Train Epoch: 293 [1280/1612 (79%)] Loss: 0.343174\n",
      "Train Epoch: 293 [1440/1612 (89%)] Loss: 0.300291\n",
      "Train Epoch: 293 [1200/1612 (99%)] Loss: 0.711331\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 294 [0/1612 (0%)] Loss: 0.227710\n",
      "Train Epoch: 294 [160/1612 (10%)] Loss: 0.149482\n",
      "Train Epoch: 294 [320/1612 (20%)] Loss: 0.211417\n",
      "Train Epoch: 294 [480/1612 (30%)] Loss: 0.335956\n",
      "Train Epoch: 294 [640/1612 (40%)] Loss: 0.422320\n",
      "Train Epoch: 294 [800/1612 (50%)] Loss: 0.316927\n",
      "Train Epoch: 294 [960/1612 (59%)] Loss: 0.593397\n",
      "Train Epoch: 294 [1120/1612 (69%)] Loss: 0.412794\n",
      "Train Epoch: 294 [1280/1612 (79%)] Loss: 0.164781\n",
      "Train Epoch: 294 [1440/1612 (89%)] Loss: 0.372509\n",
      "Train Epoch: 294 [1200/1612 (99%)] Loss: 0.213996\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 295 [0/1612 (0%)] Loss: 0.294585\n",
      "Train Epoch: 295 [160/1612 (10%)] Loss: 0.484827\n",
      "Train Epoch: 295 [320/1612 (20%)] Loss: 0.436601\n",
      "Train Epoch: 295 [480/1612 (30%)] Loss: 0.289479\n",
      "Train Epoch: 295 [640/1612 (40%)] Loss: 0.221398\n",
      "Train Epoch: 295 [800/1612 (50%)] Loss: 0.180500\n",
      "Train Epoch: 295 [960/1612 (59%)] Loss: 0.289872\n",
      "Train Epoch: 295 [1120/1612 (69%)] Loss: 0.336388\n",
      "Train Epoch: 295 [1280/1612 (79%)] Loss: 0.481676\n",
      "Train Epoch: 295 [1440/1612 (89%)] Loss: 0.201864\n",
      "Train Epoch: 295 [1200/1612 (99%)] Loss: 0.107950\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 296 [0/1612 (0%)] Loss: 0.453414\n",
      "Train Epoch: 296 [160/1612 (10%)] Loss: 0.176961\n",
      "Train Epoch: 296 [320/1612 (20%)] Loss: 0.197219\n",
      "Train Epoch: 296 [480/1612 (30%)] Loss: 0.637459\n",
      "Train Epoch: 296 [640/1612 (40%)] Loss: 0.383915\n",
      "Train Epoch: 296 [800/1612 (50%)] Loss: 0.294052\n",
      "Train Epoch: 296 [960/1612 (59%)] Loss: 0.394725\n",
      "Train Epoch: 296 [1120/1612 (69%)] Loss: 0.374591\n",
      "Train Epoch: 296 [1280/1612 (79%)] Loss: 0.244982\n",
      "Train Epoch: 296 [1440/1612 (89%)] Loss: 0.580321\n",
      "Train Epoch: 296 [1200/1612 (99%)] Loss: 0.377539\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 297 [0/1612 (0%)] Loss: 0.240531\n",
      "Train Epoch: 297 [160/1612 (10%)] Loss: 0.428885\n",
      "Train Epoch: 297 [320/1612 (20%)] Loss: 0.364809\n",
      "Train Epoch: 297 [480/1612 (30%)] Loss: 0.299388\n",
      "Train Epoch: 297 [640/1612 (40%)] Loss: 0.245270\n",
      "Train Epoch: 297 [800/1612 (50%)] Loss: 0.229637\n",
      "Train Epoch: 297 [960/1612 (59%)] Loss: 0.306763\n",
      "Train Epoch: 297 [1120/1612 (69%)] Loss: 0.357784\n",
      "Train Epoch: 297 [1280/1612 (79%)] Loss: 0.245440\n",
      "Train Epoch: 297 [1440/1612 (89%)] Loss: 0.340903\n",
      "Train Epoch: 297 [1200/1612 (99%)] Loss: 0.283413\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 298 [0/1612 (0%)] Loss: 0.306935\n",
      "Train Epoch: 298 [160/1612 (10%)] Loss: 0.320349\n",
      "Train Epoch: 298 [320/1612 (20%)] Loss: 0.246790\n",
      "Train Epoch: 298 [480/1612 (30%)] Loss: 0.290287\n",
      "Train Epoch: 298 [640/1612 (40%)] Loss: 0.394311\n",
      "Train Epoch: 298 [800/1612 (50%)] Loss: 0.176153\n",
      "Train Epoch: 298 [960/1612 (59%)] Loss: 0.378899\n",
      "Train Epoch: 298 [1120/1612 (69%)] Loss: 0.732380\n",
      "Train Epoch: 298 [1280/1612 (79%)] Loss: 0.210509\n",
      "Train Epoch: 298 [1440/1612 (89%)] Loss: 0.291147\n",
      "Train Epoch: 298 [1200/1612 (99%)] Loss: 0.527547\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 299 [0/1612 (0%)] Loss: 0.392842\n",
      "Train Epoch: 299 [160/1612 (10%)] Loss: 0.258838\n",
      "Train Epoch: 299 [320/1612 (20%)] Loss: 0.242021\n",
      "Train Epoch: 299 [480/1612 (30%)] Loss: 0.682737\n",
      "Train Epoch: 299 [640/1612 (40%)] Loss: 0.339857\n",
      "Train Epoch: 299 [800/1612 (50%)] Loss: 0.318910\n",
      "Train Epoch: 299 [960/1612 (59%)] Loss: 0.157273\n",
      "Train Epoch: 299 [1120/1612 (69%)] Loss: 0.481061\n",
      "Train Epoch: 299 [1280/1612 (79%)] Loss: 0.380449\n",
      "Train Epoch: 299 [1440/1612 (89%)] Loss: 0.257596\n",
      "Train Epoch: 299 [1200/1612 (99%)] Loss: 0.390639\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 300 [0/1612 (0%)] Loss: 0.375471\n",
      "Train Epoch: 300 [160/1612 (10%)] Loss: 0.314433\n",
      "Train Epoch: 300 [320/1612 (20%)] Loss: 0.374728\n",
      "Train Epoch: 300 [480/1612 (30%)] Loss: 0.458516\n",
      "Train Epoch: 300 [640/1612 (40%)] Loss: 0.116798\n",
      "Train Epoch: 300 [800/1612 (50%)] Loss: 0.425309\n",
      "Train Epoch: 300 [960/1612 (59%)] Loss: 0.249064\n",
      "Train Epoch: 300 [1120/1612 (69%)] Loss: 0.524674\n",
      "Train Epoch: 300 [1280/1612 (79%)] Loss: 0.402374\n",
      "Train Epoch: 300 [1440/1612 (89%)] Loss: 0.272125\n",
      "Train Epoch: 300 [1200/1612 (99%)] Loss: 0.213000\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 301 [0/1612 (0%)] Loss: 0.225038\n",
      "Train Epoch: 301 [160/1612 (10%)] Loss: 0.198747\n",
      "Train Epoch: 301 [320/1612 (20%)] Loss: 0.211700\n",
      "Train Epoch: 301 [480/1612 (30%)] Loss: 0.349052\n",
      "Train Epoch: 301 [640/1612 (40%)] Loss: 0.215016\n",
      "Train Epoch: 301 [800/1612 (50%)] Loss: 0.340537\n",
      "Train Epoch: 301 [960/1612 (59%)] Loss: 0.706280\n",
      "Train Epoch: 301 [1120/1612 (69%)] Loss: 0.382567\n",
      "Train Epoch: 301 [1280/1612 (79%)] Loss: 0.292080\n",
      "Train Epoch: 301 [1440/1612 (89%)] Loss: 0.449112\n",
      "Train Epoch: 301 [1200/1612 (99%)] Loss: 0.263153\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 302 [0/1612 (0%)] Loss: 0.348571\n",
      "Train Epoch: 302 [160/1612 (10%)] Loss: 0.399566\n",
      "Train Epoch: 302 [320/1612 (20%)] Loss: 0.286364\n",
      "Train Epoch: 302 [480/1612 (30%)] Loss: 0.321774\n",
      "Train Epoch: 302 [640/1612 (40%)] Loss: 0.313873\n",
      "Train Epoch: 302 [800/1612 (50%)] Loss: 0.295531\n",
      "Train Epoch: 302 [960/1612 (59%)] Loss: 0.298103\n",
      "Train Epoch: 302 [1120/1612 (69%)] Loss: 0.567690\n",
      "Train Epoch: 302 [1280/1612 (79%)] Loss: 0.462296\n",
      "Train Epoch: 302 [1440/1612 (89%)] Loss: 0.230129\n",
      "Train Epoch: 302 [1200/1612 (99%)] Loss: 0.329456\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 303 [0/1612 (0%)] Loss: 0.119661\n",
      "Train Epoch: 303 [160/1612 (10%)] Loss: 0.375663\n",
      "Train Epoch: 303 [320/1612 (20%)] Loss: 0.280639\n",
      "Train Epoch: 303 [480/1612 (30%)] Loss: 0.318540\n",
      "Train Epoch: 303 [640/1612 (40%)] Loss: 0.487005\n",
      "Train Epoch: 303 [800/1612 (50%)] Loss: 0.409882\n",
      "Train Epoch: 303 [960/1612 (59%)] Loss: 0.408993\n",
      "Train Epoch: 303 [1120/1612 (69%)] Loss: 0.197753\n",
      "Train Epoch: 303 [1280/1612 (79%)] Loss: 0.703691\n",
      "Train Epoch: 303 [1440/1612 (89%)] Loss: 0.342906\n",
      "Train Epoch: 303 [1200/1612 (99%)] Loss: 0.548880\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 304 [0/1612 (0%)] Loss: 0.424060\n",
      "Train Epoch: 304 [160/1612 (10%)] Loss: 0.276507\n",
      "Train Epoch: 304 [320/1612 (20%)] Loss: 0.336404\n",
      "Train Epoch: 304 [480/1612 (30%)] Loss: 0.301810\n",
      "Train Epoch: 304 [640/1612 (40%)] Loss: 0.216863\n",
      "Train Epoch: 304 [800/1612 (50%)] Loss: 0.314702\n",
      "Train Epoch: 304 [960/1612 (59%)] Loss: 0.192605\n",
      "Train Epoch: 304 [1120/1612 (69%)] Loss: 0.356517\n",
      "Train Epoch: 304 [1280/1612 (79%)] Loss: 0.256895\n",
      "Train Epoch: 304 [1440/1612 (89%)] Loss: 0.328050\n",
      "Train Epoch: 304 [1200/1612 (99%)] Loss: 0.334991\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 305 [0/1612 (0%)] Loss: 0.594260\n",
      "Train Epoch: 305 [160/1612 (10%)] Loss: 0.279074\n",
      "Train Epoch: 305 [320/1612 (20%)] Loss: 0.316124\n",
      "Train Epoch: 305 [480/1612 (30%)] Loss: 0.354943\n",
      "Train Epoch: 305 [640/1612 (40%)] Loss: 0.413377\n",
      "Train Epoch: 305 [800/1612 (50%)] Loss: 0.206514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 305 [960/1612 (59%)] Loss: 0.298901\n",
      "Train Epoch: 305 [1120/1612 (69%)] Loss: 0.386330\n",
      "Train Epoch: 305 [1280/1612 (79%)] Loss: 0.268789\n",
      "Train Epoch: 305 [1440/1612 (89%)] Loss: 0.456958\n",
      "Train Epoch: 305 [1200/1612 (99%)] Loss: 0.311061\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 306 [0/1612 (0%)] Loss: 0.168544\n",
      "Train Epoch: 306 [160/1612 (10%)] Loss: 0.451245\n",
      "Train Epoch: 306 [320/1612 (20%)] Loss: 0.307956\n",
      "Train Epoch: 306 [480/1612 (30%)] Loss: 0.278716\n",
      "Train Epoch: 306 [640/1612 (40%)] Loss: 0.184643\n",
      "Train Epoch: 306 [800/1612 (50%)] Loss: 0.091698\n",
      "Train Epoch: 306 [960/1612 (59%)] Loss: 0.138651\n",
      "Train Epoch: 306 [1120/1612 (69%)] Loss: 0.289785\n",
      "Train Epoch: 306 [1280/1612 (79%)] Loss: 0.389112\n",
      "Train Epoch: 306 [1440/1612 (89%)] Loss: 0.304127\n",
      "Train Epoch: 306 [1200/1612 (99%)] Loss: 0.348165\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 307 [0/1612 (0%)] Loss: 0.309792\n",
      "Train Epoch: 307 [160/1612 (10%)] Loss: 0.248407\n",
      "Train Epoch: 307 [320/1612 (20%)] Loss: 0.214297\n",
      "Train Epoch: 307 [480/1612 (30%)] Loss: 0.265357\n",
      "Train Epoch: 307 [640/1612 (40%)] Loss: 0.337379\n",
      "Train Epoch: 307 [800/1612 (50%)] Loss: 0.438418\n",
      "Train Epoch: 307 [960/1612 (59%)] Loss: 0.273239\n",
      "Train Epoch: 307 [1120/1612 (69%)] Loss: 0.491203\n",
      "Train Epoch: 307 [1280/1612 (79%)] Loss: 0.233343\n",
      "Train Epoch: 307 [1440/1612 (89%)] Loss: 0.165175\n",
      "Train Epoch: 307 [1200/1612 (99%)] Loss: 0.438758\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 308 [0/1612 (0%)] Loss: 0.372125\n",
      "Train Epoch: 308 [160/1612 (10%)] Loss: 0.273596\n",
      "Train Epoch: 308 [320/1612 (20%)] Loss: 0.408704\n",
      "Train Epoch: 308 [480/1612 (30%)] Loss: 0.240861\n",
      "Train Epoch: 308 [640/1612 (40%)] Loss: 0.480240\n",
      "Train Epoch: 308 [800/1612 (50%)] Loss: 0.377064\n",
      "Train Epoch: 308 [960/1612 (59%)] Loss: 0.373647\n",
      "Train Epoch: 308 [1120/1612 (69%)] Loss: 0.190125\n",
      "Train Epoch: 308 [1280/1612 (79%)] Loss: 0.297000\n",
      "Train Epoch: 308 [1440/1612 (89%)] Loss: 0.250131\n",
      "Train Epoch: 308 [1200/1612 (99%)] Loss: 0.367535\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 309 [0/1612 (0%)] Loss: 0.396999\n",
      "Train Epoch: 309 [160/1612 (10%)] Loss: 0.220164\n",
      "Train Epoch: 309 [320/1612 (20%)] Loss: 0.280483\n",
      "Train Epoch: 309 [480/1612 (30%)] Loss: 0.255999\n",
      "Train Epoch: 309 [640/1612 (40%)] Loss: 0.464079\n",
      "Train Epoch: 309 [800/1612 (50%)] Loss: 0.236515\n",
      "Train Epoch: 309 [960/1612 (59%)] Loss: 0.390274\n",
      "Train Epoch: 309 [1120/1612 (69%)] Loss: 0.356744\n",
      "Train Epoch: 309 [1280/1612 (79%)] Loss: 0.643110\n",
      "Train Epoch: 309 [1440/1612 (89%)] Loss: 0.239813\n",
      "Train Epoch: 309 [1200/1612 (99%)] Loss: 0.456531\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 310 [0/1612 (0%)] Loss: 0.157636\n",
      "Train Epoch: 310 [160/1612 (10%)] Loss: 0.197647\n",
      "Train Epoch: 310 [320/1612 (20%)] Loss: 0.268445\n",
      "Train Epoch: 310 [480/1612 (30%)] Loss: 0.284855\n",
      "Train Epoch: 310 [640/1612 (40%)] Loss: 0.380602\n",
      "Train Epoch: 310 [800/1612 (50%)] Loss: 0.738558\n",
      "Train Epoch: 310 [960/1612 (59%)] Loss: 0.581761\n",
      "Train Epoch: 310 [1120/1612 (69%)] Loss: 0.302671\n",
      "Train Epoch: 310 [1280/1612 (79%)] Loss: 0.386581\n",
      "Train Epoch: 310 [1440/1612 (89%)] Loss: 0.648548\n",
      "Train Epoch: 310 [1200/1612 (99%)] Loss: 0.219941\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 311 [0/1612 (0%)] Loss: 0.308781\n",
      "Train Epoch: 311 [160/1612 (10%)] Loss: 0.320646\n",
      "Train Epoch: 311 [320/1612 (20%)] Loss: 0.327246\n",
      "Train Epoch: 311 [480/1612 (30%)] Loss: 0.257303\n",
      "Train Epoch: 311 [640/1612 (40%)] Loss: 0.434500\n",
      "Train Epoch: 311 [800/1612 (50%)] Loss: 0.281441\n",
      "Train Epoch: 311 [960/1612 (59%)] Loss: 0.380602\n",
      "Train Epoch: 311 [1120/1612 (69%)] Loss: 0.263053\n",
      "Train Epoch: 311 [1280/1612 (79%)] Loss: 0.236339\n",
      "Train Epoch: 311 [1440/1612 (89%)] Loss: 0.376229\n",
      "Train Epoch: 311 [1200/1612 (99%)] Loss: 0.358930\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 312 [0/1612 (0%)] Loss: 0.299022\n",
      "Train Epoch: 312 [160/1612 (10%)] Loss: 0.210355\n",
      "Train Epoch: 312 [320/1612 (20%)] Loss: 0.497508\n",
      "Train Epoch: 312 [480/1612 (30%)] Loss: 0.174128\n",
      "Train Epoch: 312 [640/1612 (40%)] Loss: 0.378485\n",
      "Train Epoch: 312 [800/1612 (50%)] Loss: 0.522974\n",
      "Train Epoch: 312 [960/1612 (59%)] Loss: 0.361997\n",
      "Train Epoch: 312 [1120/1612 (69%)] Loss: 0.753186\n",
      "Train Epoch: 312 [1280/1612 (79%)] Loss: 0.269157\n",
      "Train Epoch: 312 [1440/1612 (89%)] Loss: 0.136621\n",
      "Train Epoch: 312 [1200/1612 (99%)] Loss: 0.271718\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 313 [0/1612 (0%)] Loss: 0.214569\n",
      "Train Epoch: 313 [160/1612 (10%)] Loss: 0.383849\n",
      "Train Epoch: 313 [320/1612 (20%)] Loss: 0.339509\n",
      "Train Epoch: 313 [480/1612 (30%)] Loss: 0.499675\n",
      "Train Epoch: 313 [640/1612 (40%)] Loss: 0.877405\n",
      "Train Epoch: 313 [800/1612 (50%)] Loss: 0.168362\n",
      "Train Epoch: 313 [960/1612 (59%)] Loss: 0.216156\n",
      "Train Epoch: 313 [1120/1612 (69%)] Loss: 0.169136\n",
      "Train Epoch: 313 [1280/1612 (79%)] Loss: 0.405866\n",
      "Train Epoch: 313 [1440/1612 (89%)] Loss: 0.278316\n",
      "Train Epoch: 313 [1200/1612 (99%)] Loss: 0.370671\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 314 [0/1612 (0%)] Loss: 0.424625\n",
      "Train Epoch: 314 [160/1612 (10%)] Loss: 0.280111\n",
      "Train Epoch: 314 [320/1612 (20%)] Loss: 0.248235\n",
      "Train Epoch: 314 [480/1612 (30%)] Loss: 0.340280\n",
      "Train Epoch: 314 [640/1612 (40%)] Loss: 0.580887\n",
      "Train Epoch: 314 [800/1612 (50%)] Loss: 0.245071\n",
      "Train Epoch: 314 [960/1612 (59%)] Loss: 0.273619\n",
      "Train Epoch: 314 [1120/1612 (69%)] Loss: 0.151702\n",
      "Train Epoch: 314 [1280/1612 (79%)] Loss: 0.296709\n",
      "Train Epoch: 314 [1440/1612 (89%)] Loss: 0.290443\n",
      "Train Epoch: 314 [1200/1612 (99%)] Loss: 0.501739\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 315 [0/1612 (0%)] Loss: 0.403326\n",
      "Train Epoch: 315 [160/1612 (10%)] Loss: 0.687721\n",
      "Train Epoch: 315 [320/1612 (20%)] Loss: 0.295805\n",
      "Train Epoch: 315 [480/1612 (30%)] Loss: 0.372843\n",
      "Train Epoch: 315 [640/1612 (40%)] Loss: 0.495406\n",
      "Train Epoch: 315 [800/1612 (50%)] Loss: 0.311757\n",
      "Train Epoch: 315 [960/1612 (59%)] Loss: 0.505982\n",
      "Train Epoch: 315 [1120/1612 (69%)] Loss: 0.302728\n",
      "Train Epoch: 315 [1280/1612 (79%)] Loss: 0.570381\n",
      "Train Epoch: 315 [1440/1612 (89%)] Loss: 0.238484\n",
      "Train Epoch: 315 [1200/1612 (99%)] Loss: 0.496217\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 316 [0/1612 (0%)] Loss: 0.183814\n",
      "Train Epoch: 316 [160/1612 (10%)] Loss: 0.402249\n",
      "Train Epoch: 316 [320/1612 (20%)] Loss: 0.163228\n",
      "Train Epoch: 316 [480/1612 (30%)] Loss: 0.440512\n",
      "Train Epoch: 316 [640/1612 (40%)] Loss: 0.613669\n",
      "Train Epoch: 316 [800/1612 (50%)] Loss: 0.207645\n",
      "Train Epoch: 316 [960/1612 (59%)] Loss: 0.613310\n",
      "Train Epoch: 316 [1120/1612 (69%)] Loss: 0.551800\n",
      "Train Epoch: 316 [1280/1612 (79%)] Loss: 0.205306\n",
      "Train Epoch: 316 [1440/1612 (89%)] Loss: 0.257831\n",
      "Train Epoch: 316 [1200/1612 (99%)] Loss: 0.351197\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 317 [0/1612 (0%)] Loss: 0.343518\n",
      "Train Epoch: 317 [160/1612 (10%)] Loss: 0.251463\n",
      "Train Epoch: 317 [320/1612 (20%)] Loss: 0.279369\n",
      "Train Epoch: 317 [480/1612 (30%)] Loss: 0.305256\n",
      "Train Epoch: 317 [640/1612 (40%)] Loss: 0.673191\n",
      "Train Epoch: 317 [800/1612 (50%)] Loss: 0.260554\n",
      "Train Epoch: 317 [960/1612 (59%)] Loss: 0.485836\n",
      "Train Epoch: 317 [1120/1612 (69%)] Loss: 0.243358\n",
      "Train Epoch: 317 [1280/1612 (79%)] Loss: 0.513829\n",
      "Train Epoch: 317 [1440/1612 (89%)] Loss: 0.358331\n",
      "Train Epoch: 317 [1200/1612 (99%)] Loss: 0.126460\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 318 [0/1612 (0%)] Loss: 0.485268\n",
      "Train Epoch: 318 [160/1612 (10%)] Loss: 0.430428\n",
      "Train Epoch: 318 [320/1612 (20%)] Loss: 0.399831\n",
      "Train Epoch: 318 [480/1612 (30%)] Loss: 0.388390\n",
      "Train Epoch: 318 [640/1612 (40%)] Loss: 0.400259\n",
      "Train Epoch: 318 [800/1612 (50%)] Loss: 0.292896\n",
      "Train Epoch: 318 [960/1612 (59%)] Loss: 0.139371\n",
      "Train Epoch: 318 [1120/1612 (69%)] Loss: 0.208076\n",
      "Train Epoch: 318 [1280/1612 (79%)] Loss: 0.296753\n",
      "Train Epoch: 318 [1440/1612 (89%)] Loss: 0.301876\n",
      "Train Epoch: 318 [1200/1612 (99%)] Loss: 0.247608\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 319 [0/1612 (0%)] Loss: 0.257867\n",
      "Train Epoch: 319 [160/1612 (10%)] Loss: 0.519262\n",
      "Train Epoch: 319 [320/1612 (20%)] Loss: 0.374857\n",
      "Train Epoch: 319 [480/1612 (30%)] Loss: 0.269497\n",
      "Train Epoch: 319 [640/1612 (40%)] Loss: 0.279740\n",
      "Train Epoch: 319 [800/1612 (50%)] Loss: 0.305293\n",
      "Train Epoch: 319 [960/1612 (59%)] Loss: 0.723629\n",
      "Train Epoch: 319 [1120/1612 (69%)] Loss: 0.431756\n",
      "Train Epoch: 319 [1280/1612 (79%)] Loss: 0.324482\n",
      "Train Epoch: 319 [1440/1612 (89%)] Loss: 0.277842\n",
      "Train Epoch: 319 [1200/1612 (99%)] Loss: 0.374252\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 320 [0/1612 (0%)] Loss: 0.479045\n",
      "Train Epoch: 320 [160/1612 (10%)] Loss: 0.603141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 320 [320/1612 (20%)] Loss: 0.247996\n",
      "Train Epoch: 320 [480/1612 (30%)] Loss: 0.381921\n",
      "Train Epoch: 320 [640/1612 (40%)] Loss: 1.283207\n",
      "Train Epoch: 320 [800/1612 (50%)] Loss: 0.264773\n",
      "Train Epoch: 320 [960/1612 (59%)] Loss: 0.323732\n",
      "Train Epoch: 320 [1120/1612 (69%)] Loss: 0.284252\n",
      "Train Epoch: 320 [1280/1612 (79%)] Loss: 0.181423\n",
      "Train Epoch: 320 [1440/1612 (89%)] Loss: 0.384493\n",
      "Train Epoch: 320 [1200/1612 (99%)] Loss: 0.723231\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 321 [0/1612 (0%)] Loss: 0.337981\n",
      "Train Epoch: 321 [160/1612 (10%)] Loss: 0.438922\n",
      "Train Epoch: 321 [320/1612 (20%)] Loss: 0.182344\n",
      "Train Epoch: 321 [480/1612 (30%)] Loss: 0.355410\n",
      "Train Epoch: 321 [640/1612 (40%)] Loss: 0.149443\n",
      "Train Epoch: 321 [800/1612 (50%)] Loss: 0.277015\n",
      "Train Epoch: 321 [960/1612 (59%)] Loss: 0.153115\n",
      "Train Epoch: 321 [1120/1612 (69%)] Loss: 0.243206\n",
      "Train Epoch: 321 [1280/1612 (79%)] Loss: 0.633728\n",
      "Train Epoch: 321 [1440/1612 (89%)] Loss: 0.394886\n",
      "Train Epoch: 321 [1200/1612 (99%)] Loss: 0.764895\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 322 [0/1612 (0%)] Loss: 0.276551\n",
      "Train Epoch: 322 [160/1612 (10%)] Loss: 0.496967\n",
      "Train Epoch: 322 [320/1612 (20%)] Loss: 0.135637\n",
      "Train Epoch: 322 [480/1612 (30%)] Loss: 0.165967\n",
      "Train Epoch: 322 [640/1612 (40%)] Loss: 0.287445\n",
      "Train Epoch: 322 [800/1612 (50%)] Loss: 0.134451\n",
      "Train Epoch: 322 [960/1612 (59%)] Loss: 0.469170\n",
      "Train Epoch: 322 [1120/1612 (69%)] Loss: 0.512065\n",
      "Train Epoch: 322 [1280/1612 (79%)] Loss: 0.321488\n",
      "Train Epoch: 322 [1440/1612 (89%)] Loss: 0.333122\n",
      "Train Epoch: 322 [1200/1612 (99%)] Loss: 0.250173\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 323 [0/1612 (0%)] Loss: 0.281139\n",
      "Train Epoch: 323 [160/1612 (10%)] Loss: 0.392593\n",
      "Train Epoch: 323 [320/1612 (20%)] Loss: 0.313217\n",
      "Train Epoch: 323 [480/1612 (30%)] Loss: 0.220390\n",
      "Train Epoch: 323 [640/1612 (40%)] Loss: 0.190871\n",
      "Train Epoch: 323 [800/1612 (50%)] Loss: 0.429607\n",
      "Train Epoch: 323 [960/1612 (59%)] Loss: 0.101940\n",
      "Train Epoch: 323 [1120/1612 (69%)] Loss: 0.169295\n",
      "Train Epoch: 323 [1280/1612 (79%)] Loss: 0.305781\n",
      "Train Epoch: 323 [1440/1612 (89%)] Loss: 0.268529\n",
      "Train Epoch: 323 [1200/1612 (99%)] Loss: 0.499887\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 324 [0/1612 (0%)] Loss: 0.274379\n",
      "Train Epoch: 324 [160/1612 (10%)] Loss: 0.330272\n",
      "Train Epoch: 324 [320/1612 (20%)] Loss: 0.508177\n",
      "Train Epoch: 324 [480/1612 (30%)] Loss: 0.278114\n",
      "Train Epoch: 324 [640/1612 (40%)] Loss: 0.181722\n",
      "Train Epoch: 324 [800/1612 (50%)] Loss: 0.226867\n",
      "Train Epoch: 324 [960/1612 (59%)] Loss: 0.422819\n",
      "Train Epoch: 324 [1120/1612 (69%)] Loss: 0.228309\n",
      "Train Epoch: 324 [1280/1612 (79%)] Loss: 0.339022\n",
      "Train Epoch: 324 [1440/1612 (89%)] Loss: 0.300777\n",
      "Train Epoch: 324 [1200/1612 (99%)] Loss: 0.184738\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 325 [0/1612 (0%)] Loss: 0.461541\n",
      "Train Epoch: 325 [160/1612 (10%)] Loss: 0.262996\n",
      "Train Epoch: 325 [320/1612 (20%)] Loss: 0.218731\n",
      "Train Epoch: 325 [480/1612 (30%)] Loss: 0.335849\n",
      "Train Epoch: 325 [640/1612 (40%)] Loss: 0.244471\n",
      "Train Epoch: 325 [800/1612 (50%)] Loss: 0.366292\n",
      "Train Epoch: 325 [960/1612 (59%)] Loss: 0.361878\n",
      "Train Epoch: 325 [1120/1612 (69%)] Loss: 0.293783\n",
      "Train Epoch: 325 [1280/1612 (79%)] Loss: 0.119883\n",
      "Train Epoch: 325 [1440/1612 (89%)] Loss: 0.145667\n",
      "Train Epoch: 325 [1200/1612 (99%)] Loss: 0.356775\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 326 [0/1612 (0%)] Loss: 0.477072\n",
      "Train Epoch: 326 [160/1612 (10%)] Loss: 0.406178\n",
      "Train Epoch: 326 [320/1612 (20%)] Loss: 0.512726\n",
      "Train Epoch: 326 [480/1612 (30%)] Loss: 0.539036\n",
      "Train Epoch: 326 [640/1612 (40%)] Loss: 0.337712\n",
      "Train Epoch: 326 [800/1612 (50%)] Loss: 0.267063\n",
      "Train Epoch: 326 [960/1612 (59%)] Loss: 0.336180\n",
      "Train Epoch: 326 [1120/1612 (69%)] Loss: 0.260568\n",
      "Train Epoch: 326 [1280/1612 (79%)] Loss: 0.226619\n",
      "Train Epoch: 326 [1440/1612 (89%)] Loss: 0.430245\n",
      "Train Epoch: 326 [1200/1612 (99%)] Loss: 0.358245\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 327 [0/1612 (0%)] Loss: 0.502809\n",
      "Train Epoch: 327 [160/1612 (10%)] Loss: 0.168243\n",
      "Train Epoch: 327 [320/1612 (20%)] Loss: 0.333273\n",
      "Train Epoch: 327 [480/1612 (30%)] Loss: 0.224746\n",
      "Train Epoch: 327 [640/1612 (40%)] Loss: 0.201235\n",
      "Train Epoch: 327 [800/1612 (50%)] Loss: 0.446933\n",
      "Train Epoch: 327 [960/1612 (59%)] Loss: 0.206035\n",
      "Train Epoch: 327 [1120/1612 (69%)] Loss: 0.320825\n",
      "Train Epoch: 327 [1280/1612 (79%)] Loss: 0.637155\n",
      "Train Epoch: 327 [1440/1612 (89%)] Loss: 0.178173\n",
      "Train Epoch: 327 [1200/1612 (99%)] Loss: 0.373717\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 328 [0/1612 (0%)] Loss: 0.306115\n",
      "Train Epoch: 328 [160/1612 (10%)] Loss: 0.446060\n",
      "Train Epoch: 328 [320/1612 (20%)] Loss: 0.342512\n",
      "Train Epoch: 328 [480/1612 (30%)] Loss: 0.706419\n",
      "Train Epoch: 328 [640/1612 (40%)] Loss: 0.331793\n",
      "Train Epoch: 328 [800/1612 (50%)] Loss: 0.206468\n",
      "Train Epoch: 328 [960/1612 (59%)] Loss: 0.458264\n",
      "Train Epoch: 328 [1120/1612 (69%)] Loss: 0.642138\n",
      "Train Epoch: 328 [1280/1612 (79%)] Loss: 0.204889\n",
      "Train Epoch: 328 [1440/1612 (89%)] Loss: 0.149645\n",
      "Train Epoch: 328 [1200/1612 (99%)] Loss: 0.445863\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 329 [0/1612 (0%)] Loss: 0.133806\n",
      "Train Epoch: 329 [160/1612 (10%)] Loss: 0.330199\n",
      "Train Epoch: 329 [320/1612 (20%)] Loss: 1.025657\n",
      "Train Epoch: 329 [480/1612 (30%)] Loss: 0.421484\n",
      "Train Epoch: 329 [640/1612 (40%)] Loss: 0.336889\n",
      "Train Epoch: 329 [800/1612 (50%)] Loss: 0.285806\n",
      "Train Epoch: 329 [960/1612 (59%)] Loss: 0.472185\n",
      "Train Epoch: 329 [1120/1612 (69%)] Loss: 0.632891\n",
      "Train Epoch: 329 [1280/1612 (79%)] Loss: 0.501639\n",
      "Train Epoch: 329 [1440/1612 (89%)] Loss: 0.339701\n",
      "Train Epoch: 329 [1200/1612 (99%)] Loss: 0.330869\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 330 [0/1612 (0%)] Loss: 0.147586\n",
      "Train Epoch: 330 [160/1612 (10%)] Loss: 0.374253\n",
      "Train Epoch: 330 [320/1612 (20%)] Loss: 0.234404\n",
      "Train Epoch: 330 [480/1612 (30%)] Loss: 0.492236\n",
      "Train Epoch: 330 [640/1612 (40%)] Loss: 0.341578\n",
      "Train Epoch: 330 [800/1612 (50%)] Loss: 0.226532\n",
      "Train Epoch: 330 [960/1612 (59%)] Loss: 0.426291\n",
      "Train Epoch: 330 [1120/1612 (69%)] Loss: 0.083313\n",
      "Train Epoch: 330 [1280/1612 (79%)] Loss: 0.335608\n",
      "Train Epoch: 330 [1440/1612 (89%)] Loss: 0.293087\n",
      "Train Epoch: 330 [1200/1612 (99%)] Loss: 0.411792\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 331 [0/1612 (0%)] Loss: 0.194416\n",
      "Train Epoch: 331 [160/1612 (10%)] Loss: 0.321236\n",
      "Train Epoch: 331 [320/1612 (20%)] Loss: 0.288223\n",
      "Train Epoch: 331 [480/1612 (30%)] Loss: 0.425712\n",
      "Train Epoch: 331 [640/1612 (40%)] Loss: 0.300420\n",
      "Train Epoch: 331 [800/1612 (50%)] Loss: 0.170830\n",
      "Train Epoch: 331 [960/1612 (59%)] Loss: 0.385109\n",
      "Train Epoch: 331 [1120/1612 (69%)] Loss: 0.544961\n",
      "Train Epoch: 331 [1280/1612 (79%)] Loss: 0.523357\n",
      "Train Epoch: 331 [1440/1612 (89%)] Loss: 0.343597\n",
      "Train Epoch: 331 [1200/1612 (99%)] Loss: 0.405933\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 332 [0/1612 (0%)] Loss: 0.255205\n",
      "Train Epoch: 332 [160/1612 (10%)] Loss: 0.234069\n",
      "Train Epoch: 332 [320/1612 (20%)] Loss: 0.246361\n",
      "Train Epoch: 332 [480/1612 (30%)] Loss: 0.419445\n",
      "Train Epoch: 332 [640/1612 (40%)] Loss: 0.276217\n",
      "Train Epoch: 332 [800/1612 (50%)] Loss: 0.331222\n",
      "Train Epoch: 332 [960/1612 (59%)] Loss: 0.320342\n",
      "Train Epoch: 332 [1120/1612 (69%)] Loss: 0.232141\n",
      "Train Epoch: 332 [1280/1612 (79%)] Loss: 0.359301\n",
      "Train Epoch: 332 [1440/1612 (89%)] Loss: 0.124136\n",
      "Train Epoch: 332 [1200/1612 (99%)] Loss: 0.521242\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 333 [0/1612 (0%)] Loss: 0.381033\n",
      "Train Epoch: 333 [160/1612 (10%)] Loss: 0.334547\n",
      "Train Epoch: 333 [320/1612 (20%)] Loss: 0.322171\n",
      "Train Epoch: 333 [480/1612 (30%)] Loss: 0.343438\n",
      "Train Epoch: 333 [640/1612 (40%)] Loss: 0.088565\n",
      "Train Epoch: 333 [800/1612 (50%)] Loss: 0.432443\n",
      "Train Epoch: 333 [960/1612 (59%)] Loss: 0.615336\n",
      "Train Epoch: 333 [1120/1612 (69%)] Loss: 0.200914\n",
      "Train Epoch: 333 [1280/1612 (79%)] Loss: 0.354740\n",
      "Train Epoch: 333 [1440/1612 (89%)] Loss: 0.425401\n",
      "Train Epoch: 333 [1200/1612 (99%)] Loss: 0.422187\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 334 [0/1612 (0%)] Loss: 0.244227\n",
      "Train Epoch: 334 [160/1612 (10%)] Loss: 0.454774\n",
      "Train Epoch: 334 [320/1612 (20%)] Loss: 0.347409\n",
      "Train Epoch: 334 [480/1612 (30%)] Loss: 0.342220\n",
      "Train Epoch: 334 [640/1612 (40%)] Loss: 0.359152\n",
      "Train Epoch: 334 [800/1612 (50%)] Loss: 0.190764\n",
      "Train Epoch: 334 [960/1612 (59%)] Loss: 0.173005\n",
      "Train Epoch: 334 [1120/1612 (69%)] Loss: 0.321215\n",
      "Train Epoch: 334 [1280/1612 (79%)] Loss: 0.421158\n",
      "Train Epoch: 334 [1440/1612 (89%)] Loss: 0.679752\n",
      "Train Epoch: 334 [1200/1612 (99%)] Loss: 0.256287\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 335 [0/1612 (0%)] Loss: 0.217152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 335 [160/1612 (10%)] Loss: 0.366639\n",
      "Train Epoch: 335 [320/1612 (20%)] Loss: 0.144341\n",
      "Train Epoch: 335 [480/1612 (30%)] Loss: 0.383027\n",
      "Train Epoch: 335 [640/1612 (40%)] Loss: 0.316834\n",
      "Train Epoch: 335 [800/1612 (50%)] Loss: 0.144566\n",
      "Train Epoch: 335 [960/1612 (59%)] Loss: 0.316629\n",
      "Train Epoch: 335 [1120/1612 (69%)] Loss: 0.628734\n",
      "Train Epoch: 335 [1280/1612 (79%)] Loss: 0.366909\n",
      "Train Epoch: 335 [1440/1612 (89%)] Loss: 0.495070\n",
      "Train Epoch: 335 [1200/1612 (99%)] Loss: 0.164451\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 336 [0/1612 (0%)] Loss: 0.379059\n",
      "Train Epoch: 336 [160/1612 (10%)] Loss: 0.473076\n",
      "Train Epoch: 336 [320/1612 (20%)] Loss: 0.420451\n",
      "Train Epoch: 336 [480/1612 (30%)] Loss: 0.187132\n",
      "Train Epoch: 336 [640/1612 (40%)] Loss: 0.169515\n",
      "Train Epoch: 336 [800/1612 (50%)] Loss: 0.189584\n",
      "Train Epoch: 336 [960/1612 (59%)] Loss: 0.228896\n",
      "Train Epoch: 336 [1120/1612 (69%)] Loss: 0.299357\n",
      "Train Epoch: 336 [1280/1612 (79%)] Loss: 0.400929\n",
      "Train Epoch: 336 [1440/1612 (89%)] Loss: 0.342233\n",
      "Train Epoch: 336 [1200/1612 (99%)] Loss: 0.699868\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 337 [0/1612 (0%)] Loss: 0.401415\n",
      "Train Epoch: 337 [160/1612 (10%)] Loss: 0.426431\n",
      "Train Epoch: 337 [320/1612 (20%)] Loss: 0.204063\n",
      "Train Epoch: 337 [480/1612 (30%)] Loss: 0.149446\n",
      "Train Epoch: 337 [640/1612 (40%)] Loss: 0.119180\n",
      "Train Epoch: 337 [800/1612 (50%)] Loss: 0.226052\n",
      "Train Epoch: 337 [960/1612 (59%)] Loss: 0.238512\n",
      "Train Epoch: 337 [1120/1612 (69%)] Loss: 0.414324\n",
      "Train Epoch: 337 [1280/1612 (79%)] Loss: 0.151717\n",
      "Train Epoch: 337 [1440/1612 (89%)] Loss: 0.426300\n",
      "Train Epoch: 337 [1200/1612 (99%)] Loss: 0.118382\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 338 [0/1612 (0%)] Loss: 0.227692\n",
      "Train Epoch: 338 [160/1612 (10%)] Loss: 0.225915\n",
      "Train Epoch: 338 [320/1612 (20%)] Loss: 0.415976\n",
      "Train Epoch: 338 [480/1612 (30%)] Loss: 0.323906\n",
      "Train Epoch: 338 [640/1612 (40%)] Loss: 0.470421\n",
      "Train Epoch: 338 [800/1612 (50%)] Loss: 0.529143\n",
      "Train Epoch: 338 [960/1612 (59%)] Loss: 0.244632\n",
      "Train Epoch: 338 [1120/1612 (69%)] Loss: 0.292457\n",
      "Train Epoch: 338 [1280/1612 (79%)] Loss: 0.268747\n",
      "Train Epoch: 338 [1440/1612 (89%)] Loss: 0.270843\n",
      "Train Epoch: 338 [1200/1612 (99%)] Loss: 0.212094\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 339 [0/1612 (0%)] Loss: 0.411668\n",
      "Train Epoch: 339 [160/1612 (10%)] Loss: 0.451432\n",
      "Train Epoch: 339 [320/1612 (20%)] Loss: 0.259745\n",
      "Train Epoch: 339 [480/1612 (30%)] Loss: 0.305875\n",
      "Train Epoch: 339 [640/1612 (40%)] Loss: 0.228865\n",
      "Train Epoch: 339 [800/1612 (50%)] Loss: 0.331659\n",
      "Train Epoch: 339 [960/1612 (59%)] Loss: 0.324088\n",
      "Train Epoch: 339 [1120/1612 (69%)] Loss: 0.350062\n",
      "Train Epoch: 339 [1280/1612 (79%)] Loss: 0.203544\n",
      "Train Epoch: 339 [1440/1612 (89%)] Loss: 0.561132\n",
      "Train Epoch: 339 [1200/1612 (99%)] Loss: 0.262284\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 340 [0/1612 (0%)] Loss: 0.307136\n",
      "Train Epoch: 340 [160/1612 (10%)] Loss: 0.317200\n",
      "Train Epoch: 340 [320/1612 (20%)] Loss: 0.224183\n",
      "Train Epoch: 340 [480/1612 (30%)] Loss: 0.490423\n",
      "Train Epoch: 340 [640/1612 (40%)] Loss: 0.269374\n",
      "Train Epoch: 340 [800/1612 (50%)] Loss: 0.274906\n",
      "Train Epoch: 340 [960/1612 (59%)] Loss: 0.193445\n",
      "Train Epoch: 340 [1120/1612 (69%)] Loss: 0.401236\n",
      "Train Epoch: 340 [1280/1612 (79%)] Loss: 0.480420\n",
      "Train Epoch: 340 [1440/1612 (89%)] Loss: 0.219043\n",
      "Train Epoch: 340 [1200/1612 (99%)] Loss: 0.308998\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 341 [0/1612 (0%)] Loss: 0.471159\n",
      "Train Epoch: 341 [160/1612 (10%)] Loss: 0.448088\n",
      "Train Epoch: 341 [320/1612 (20%)] Loss: 0.120158\n",
      "Train Epoch: 341 [480/1612 (30%)] Loss: 0.298398\n",
      "Train Epoch: 341 [640/1612 (40%)] Loss: 0.213738\n",
      "Train Epoch: 341 [800/1612 (50%)] Loss: 0.370512\n",
      "Train Epoch: 341 [960/1612 (59%)] Loss: 0.571469\n",
      "Train Epoch: 341 [1120/1612 (69%)] Loss: 0.260661\n",
      "Train Epoch: 341 [1280/1612 (79%)] Loss: 0.451427\n",
      "Train Epoch: 341 [1440/1612 (89%)] Loss: 0.832472\n",
      "Train Epoch: 341 [1200/1612 (99%)] Loss: 0.124951\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 342 [0/1612 (0%)] Loss: 0.253137\n",
      "Train Epoch: 342 [160/1612 (10%)] Loss: 0.302248\n",
      "Train Epoch: 342 [320/1612 (20%)] Loss: 0.313302\n",
      "Train Epoch: 342 [480/1612 (30%)] Loss: 0.501106\n",
      "Train Epoch: 342 [640/1612 (40%)] Loss: 0.521442\n",
      "Train Epoch: 342 [800/1612 (50%)] Loss: 0.203741\n",
      "Train Epoch: 342 [960/1612 (59%)] Loss: 0.287229\n",
      "Train Epoch: 342 [1120/1612 (69%)] Loss: 0.407104\n",
      "Train Epoch: 342 [1280/1612 (79%)] Loss: 0.168858\n",
      "Train Epoch: 342 [1440/1612 (89%)] Loss: 0.274245\n",
      "Train Epoch: 342 [1200/1612 (99%)] Loss: 0.338562\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 343 [0/1612 (0%)] Loss: 0.215762\n",
      "Train Epoch: 343 [160/1612 (10%)] Loss: 0.350529\n",
      "Train Epoch: 343 [320/1612 (20%)] Loss: 0.329079\n",
      "Train Epoch: 343 [480/1612 (30%)] Loss: 0.145150\n",
      "Train Epoch: 343 [640/1612 (40%)] Loss: 0.406336\n",
      "Train Epoch: 343 [800/1612 (50%)] Loss: 0.299285\n",
      "Train Epoch: 343 [960/1612 (59%)] Loss: 0.305568\n",
      "Train Epoch: 343 [1120/1612 (69%)] Loss: 0.393683\n",
      "Train Epoch: 343 [1280/1612 (79%)] Loss: 0.278822\n",
      "Train Epoch: 343 [1440/1612 (89%)] Loss: 0.285251\n",
      "Train Epoch: 343 [1200/1612 (99%)] Loss: 0.408534\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 344 [0/1612 (0%)] Loss: 0.280779\n",
      "Train Epoch: 344 [160/1612 (10%)] Loss: 0.275041\n",
      "Train Epoch: 344 [320/1612 (20%)] Loss: 0.378471\n",
      "Train Epoch: 344 [480/1612 (30%)] Loss: 0.570097\n",
      "Train Epoch: 344 [640/1612 (40%)] Loss: 0.319984\n",
      "Train Epoch: 344 [800/1612 (50%)] Loss: 0.663338\n",
      "Train Epoch: 344 [960/1612 (59%)] Loss: 0.328856\n",
      "Train Epoch: 344 [1120/1612 (69%)] Loss: 0.179826\n",
      "Train Epoch: 344 [1280/1612 (79%)] Loss: 0.157057\n",
      "Train Epoch: 344 [1440/1612 (89%)] Loss: 0.289194\n",
      "Train Epoch: 344 [1200/1612 (99%)] Loss: 0.273980\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 345 [0/1612 (0%)] Loss: 0.763803\n",
      "Train Epoch: 345 [160/1612 (10%)] Loss: 0.226494\n",
      "Train Epoch: 345 [320/1612 (20%)] Loss: 0.234349\n",
      "Train Epoch: 345 [480/1612 (30%)] Loss: 0.332592\n",
      "Train Epoch: 345 [640/1612 (40%)] Loss: 0.300912\n",
      "Train Epoch: 345 [800/1612 (50%)] Loss: 0.467734\n",
      "Train Epoch: 345 [960/1612 (59%)] Loss: 0.247286\n",
      "Train Epoch: 345 [1120/1612 (69%)] Loss: 0.418572\n",
      "Train Epoch: 345 [1280/1612 (79%)] Loss: 0.208438\n",
      "Train Epoch: 345 [1440/1612 (89%)] Loss: 0.341333\n",
      "Train Epoch: 345 [1200/1612 (99%)] Loss: 0.720286\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 346 [0/1612 (0%)] Loss: 0.167331\n",
      "Train Epoch: 346 [160/1612 (10%)] Loss: 0.462077\n",
      "Train Epoch: 346 [320/1612 (20%)] Loss: 0.128051\n",
      "Train Epoch: 346 [480/1612 (30%)] Loss: 0.280508\n",
      "Train Epoch: 346 [640/1612 (40%)] Loss: 0.358450\n",
      "Train Epoch: 346 [800/1612 (50%)] Loss: 0.290264\n",
      "Train Epoch: 346 [960/1612 (59%)] Loss: 0.425258\n",
      "Train Epoch: 346 [1120/1612 (69%)] Loss: 0.081661\n",
      "Train Epoch: 346 [1280/1612 (79%)] Loss: 0.267172\n",
      "Train Epoch: 346 [1440/1612 (89%)] Loss: 0.419200\n",
      "Train Epoch: 346 [1200/1612 (99%)] Loss: 0.102287\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 347 [0/1612 (0%)] Loss: 0.348767\n",
      "Train Epoch: 347 [160/1612 (10%)] Loss: 0.521538\n",
      "Train Epoch: 347 [320/1612 (20%)] Loss: 0.446462\n",
      "Train Epoch: 347 [480/1612 (30%)] Loss: 0.465870\n",
      "Train Epoch: 347 [640/1612 (40%)] Loss: 0.393383\n",
      "Train Epoch: 347 [800/1612 (50%)] Loss: 0.260468\n",
      "Train Epoch: 347 [960/1612 (59%)] Loss: 0.231357\n",
      "Train Epoch: 347 [1120/1612 (69%)] Loss: 0.394466\n",
      "Train Epoch: 347 [1280/1612 (79%)] Loss: 0.174390\n",
      "Train Epoch: 347 [1440/1612 (89%)] Loss: 0.185369\n",
      "Train Epoch: 347 [1200/1612 (99%)] Loss: 0.152914\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 348 [0/1612 (0%)] Loss: 0.306230\n",
      "Train Epoch: 348 [160/1612 (10%)] Loss: 0.265984\n",
      "Train Epoch: 348 [320/1612 (20%)] Loss: 0.294350\n",
      "Train Epoch: 348 [480/1612 (30%)] Loss: 0.273241\n",
      "Train Epoch: 348 [640/1612 (40%)] Loss: 0.425733\n",
      "Train Epoch: 348 [800/1612 (50%)] Loss: 0.350314\n",
      "Train Epoch: 348 [960/1612 (59%)] Loss: 0.171576\n",
      "Train Epoch: 348 [1120/1612 (69%)] Loss: 0.342758\n",
      "Train Epoch: 348 [1280/1612 (79%)] Loss: 0.204952\n",
      "Train Epoch: 348 [1440/1612 (89%)] Loss: 0.251237\n",
      "Train Epoch: 348 [1200/1612 (99%)] Loss: 0.353106\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 349 [0/1612 (0%)] Loss: 0.311508\n",
      "Train Epoch: 349 [160/1612 (10%)] Loss: 0.319994\n",
      "Train Epoch: 349 [320/1612 (20%)] Loss: 0.371892\n",
      "Train Epoch: 349 [480/1612 (30%)] Loss: 0.129939\n",
      "Train Epoch: 349 [640/1612 (40%)] Loss: 0.409258\n",
      "Train Epoch: 349 [800/1612 (50%)] Loss: 0.154836\n",
      "Train Epoch: 349 [960/1612 (59%)] Loss: 0.209108\n",
      "Train Epoch: 349 [1120/1612 (69%)] Loss: 0.272136\n",
      "Train Epoch: 349 [1280/1612 (79%)] Loss: 0.564701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 349 [1440/1612 (89%)] Loss: 0.365432\n",
      "Train Epoch: 349 [1200/1612 (99%)] Loss: 0.423799\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 350 [0/1612 (0%)] Loss: 0.322065\n",
      "Train Epoch: 350 [160/1612 (10%)] Loss: 0.439861\n",
      "Train Epoch: 350 [320/1612 (20%)] Loss: 0.371341\n",
      "Train Epoch: 350 [480/1612 (30%)] Loss: 0.250029\n",
      "Train Epoch: 350 [640/1612 (40%)] Loss: 0.436063\n",
      "Train Epoch: 350 [800/1612 (50%)] Loss: 0.344243\n",
      "Train Epoch: 350 [960/1612 (59%)] Loss: 0.452503\n",
      "Train Epoch: 350 [1120/1612 (69%)] Loss: 0.308016\n",
      "Train Epoch: 350 [1280/1612 (79%)] Loss: 0.320228\n",
      "Train Epoch: 350 [1440/1612 (89%)] Loss: 0.157911\n",
      "Train Epoch: 350 [1200/1612 (99%)] Loss: 0.402074\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 351 [0/1612 (0%)] Loss: 0.312128\n",
      "Train Epoch: 351 [160/1612 (10%)] Loss: 0.341467\n",
      "Train Epoch: 351 [320/1612 (20%)] Loss: 0.460966\n",
      "Train Epoch: 351 [480/1612 (30%)] Loss: 0.466722\n",
      "Train Epoch: 351 [640/1612 (40%)] Loss: 0.202808\n",
      "Train Epoch: 351 [800/1612 (50%)] Loss: 0.236651\n",
      "Train Epoch: 351 [960/1612 (59%)] Loss: 0.199384\n",
      "Train Epoch: 351 [1120/1612 (69%)] Loss: 0.200678\n",
      "Train Epoch: 351 [1280/1612 (79%)] Loss: 0.207171\n",
      "Train Epoch: 351 [1440/1612 (89%)] Loss: 0.451320\n",
      "Train Epoch: 351 [1200/1612 (99%)] Loss: 0.173158\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 352 [0/1612 (0%)] Loss: 0.357042\n",
      "Train Epoch: 352 [160/1612 (10%)] Loss: 0.245159\n",
      "Train Epoch: 352 [320/1612 (20%)] Loss: 0.410376\n",
      "Train Epoch: 352 [480/1612 (30%)] Loss: 0.277805\n",
      "Train Epoch: 352 [640/1612 (40%)] Loss: 0.237216\n",
      "Train Epoch: 352 [800/1612 (50%)] Loss: 0.105064\n",
      "Train Epoch: 352 [960/1612 (59%)] Loss: 0.228733\n",
      "Train Epoch: 352 [1120/1612 (69%)] Loss: 0.563036\n",
      "Train Epoch: 352 [1280/1612 (79%)] Loss: 0.482514\n",
      "Train Epoch: 352 [1440/1612 (89%)] Loss: 0.354330\n",
      "Train Epoch: 352 [1200/1612 (99%)] Loss: 0.291881\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 353 [0/1612 (0%)] Loss: 0.511835\n",
      "Train Epoch: 353 [160/1612 (10%)] Loss: 0.247493\n",
      "Train Epoch: 353 [320/1612 (20%)] Loss: 0.353907\n",
      "Train Epoch: 353 [480/1612 (30%)] Loss: 0.275900\n",
      "Train Epoch: 353 [640/1612 (40%)] Loss: 0.250473\n",
      "Train Epoch: 353 [800/1612 (50%)] Loss: 0.436702\n",
      "Train Epoch: 353 [960/1612 (59%)] Loss: 0.349494\n",
      "Train Epoch: 353 [1120/1612 (69%)] Loss: 0.471926\n",
      "Train Epoch: 353 [1280/1612 (79%)] Loss: 0.416773\n",
      "Train Epoch: 353 [1440/1612 (89%)] Loss: 0.316852\n",
      "Train Epoch: 353 [1200/1612 (99%)] Loss: 0.183421\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 354 [0/1612 (0%)] Loss: 0.236266\n",
      "Train Epoch: 354 [160/1612 (10%)] Loss: 0.242219\n",
      "Train Epoch: 354 [320/1612 (20%)] Loss: 0.294577\n",
      "Train Epoch: 354 [480/1612 (30%)] Loss: 0.350530\n",
      "Train Epoch: 354 [640/1612 (40%)] Loss: 0.151594\n",
      "Train Epoch: 354 [800/1612 (50%)] Loss: 0.392004\n",
      "Train Epoch: 354 [960/1612 (59%)] Loss: 0.360368\n",
      "Train Epoch: 354 [1120/1612 (69%)] Loss: 0.249258\n",
      "Train Epoch: 354 [1280/1612 (79%)] Loss: 0.374957\n",
      "Train Epoch: 354 [1440/1612 (89%)] Loss: 0.437037\n",
      "Train Epoch: 354 [1200/1612 (99%)] Loss: 0.166374\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 355 [0/1612 (0%)] Loss: 0.248989\n",
      "Train Epoch: 355 [160/1612 (10%)] Loss: 0.454630\n",
      "Train Epoch: 355 [320/1612 (20%)] Loss: 0.234792\n",
      "Train Epoch: 355 [480/1612 (30%)] Loss: 0.350552\n",
      "Train Epoch: 355 [640/1612 (40%)] Loss: 0.482466\n",
      "Train Epoch: 355 [800/1612 (50%)] Loss: 0.425015\n",
      "Train Epoch: 355 [960/1612 (59%)] Loss: 0.196312\n",
      "Train Epoch: 355 [1120/1612 (69%)] Loss: 0.382093\n",
      "Train Epoch: 355 [1280/1612 (79%)] Loss: 0.385048\n",
      "Train Epoch: 355 [1440/1612 (89%)] Loss: 0.173258\n",
      "Train Epoch: 355 [1200/1612 (99%)] Loss: 0.189611\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 356 [0/1612 (0%)] Loss: 0.207901\n",
      "Train Epoch: 356 [160/1612 (10%)] Loss: 0.420479\n",
      "Train Epoch: 356 [320/1612 (20%)] Loss: 0.266419\n",
      "Train Epoch: 356 [480/1612 (30%)] Loss: 0.552773\n",
      "Train Epoch: 356 [640/1612 (40%)] Loss: 0.496577\n",
      "Train Epoch: 356 [800/1612 (50%)] Loss: 0.287668\n",
      "Train Epoch: 356 [960/1612 (59%)] Loss: 0.423265\n",
      "Train Epoch: 356 [1120/1612 (69%)] Loss: 0.355872\n",
      "Train Epoch: 356 [1280/1612 (79%)] Loss: 0.314516\n",
      "Train Epoch: 356 [1440/1612 (89%)] Loss: 0.301638\n",
      "Train Epoch: 356 [1200/1612 (99%)] Loss: 0.297228\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 357 [0/1612 (0%)] Loss: 0.377545\n",
      "Train Epoch: 357 [160/1612 (10%)] Loss: 0.214705\n",
      "Train Epoch: 357 [320/1612 (20%)] Loss: 0.277460\n",
      "Train Epoch: 357 [480/1612 (30%)] Loss: 0.240650\n",
      "Train Epoch: 357 [640/1612 (40%)] Loss: 0.311896\n",
      "Train Epoch: 357 [800/1612 (50%)] Loss: 0.255530\n",
      "Train Epoch: 357 [960/1612 (59%)] Loss: 0.276409\n",
      "Train Epoch: 357 [1120/1612 (69%)] Loss: 0.459078\n",
      "Train Epoch: 357 [1280/1612 (79%)] Loss: 0.325772\n",
      "Train Epoch: 357 [1440/1612 (89%)] Loss: 0.267345\n",
      "Train Epoch: 357 [1200/1612 (99%)] Loss: 0.435811\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 358 [0/1612 (0%)] Loss: 0.238741\n",
      "Train Epoch: 358 [160/1612 (10%)] Loss: 0.244949\n",
      "Train Epoch: 358 [320/1612 (20%)] Loss: 0.177140\n",
      "Train Epoch: 358 [480/1612 (30%)] Loss: 0.288929\n",
      "Train Epoch: 358 [640/1612 (40%)] Loss: 0.708570\n",
      "Train Epoch: 358 [800/1612 (50%)] Loss: 0.334053\n",
      "Train Epoch: 358 [960/1612 (59%)] Loss: 0.288149\n",
      "Train Epoch: 358 [1120/1612 (69%)] Loss: 0.479752\n",
      "Train Epoch: 358 [1280/1612 (79%)] Loss: 0.239170\n",
      "Train Epoch: 358 [1440/1612 (89%)] Loss: 0.459925\n",
      "Train Epoch: 358 [1200/1612 (99%)] Loss: 0.245472\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 359 [0/1612 (0%)] Loss: 0.315549\n",
      "Train Epoch: 359 [160/1612 (10%)] Loss: 0.354073\n",
      "Train Epoch: 359 [320/1612 (20%)] Loss: 0.262101\n",
      "Train Epoch: 359 [480/1612 (30%)] Loss: 0.263541\n",
      "Train Epoch: 359 [640/1612 (40%)] Loss: 0.144471\n",
      "Train Epoch: 359 [800/1612 (50%)] Loss: 0.278782\n",
      "Train Epoch: 359 [960/1612 (59%)] Loss: 0.255844\n",
      "Train Epoch: 359 [1120/1612 (69%)] Loss: 0.286992\n",
      "Train Epoch: 359 [1280/1612 (79%)] Loss: 0.230211\n",
      "Train Epoch: 359 [1440/1612 (89%)] Loss: 0.362729\n",
      "Train Epoch: 359 [1200/1612 (99%)] Loss: 0.506824\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 360 [0/1612 (0%)] Loss: 0.168047\n",
      "Train Epoch: 360 [160/1612 (10%)] Loss: 0.473382\n",
      "Train Epoch: 360 [320/1612 (20%)] Loss: 0.450517\n",
      "Train Epoch: 360 [480/1612 (30%)] Loss: 0.212205\n",
      "Train Epoch: 360 [640/1612 (40%)] Loss: 0.184418\n",
      "Train Epoch: 360 [800/1612 (50%)] Loss: 0.261716\n",
      "Train Epoch: 360 [960/1612 (59%)] Loss: 0.297711\n",
      "Train Epoch: 360 [1120/1612 (69%)] Loss: 0.557647\n",
      "Train Epoch: 360 [1280/1612 (79%)] Loss: 0.250733\n",
      "Train Epoch: 360 [1440/1612 (89%)] Loss: 0.395382\n",
      "Train Epoch: 360 [1200/1612 (99%)] Loss: 0.392090\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 361 [0/1612 (0%)] Loss: 0.293485\n",
      "Train Epoch: 361 [160/1612 (10%)] Loss: 0.441370\n",
      "Train Epoch: 361 [320/1612 (20%)] Loss: 0.532111\n",
      "Train Epoch: 361 [480/1612 (30%)] Loss: 0.467059\n",
      "Train Epoch: 361 [640/1612 (40%)] Loss: 0.316353\n",
      "Train Epoch: 361 [800/1612 (50%)] Loss: 0.347299\n",
      "Train Epoch: 361 [960/1612 (59%)] Loss: 0.574135\n",
      "Train Epoch: 361 [1120/1612 (69%)] Loss: 0.399232\n",
      "Train Epoch: 361 [1280/1612 (79%)] Loss: 0.259716\n",
      "Train Epoch: 361 [1440/1612 (89%)] Loss: 0.229128\n",
      "Train Epoch: 361 [1200/1612 (99%)] Loss: 0.183998\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 362 [0/1612 (0%)] Loss: 0.628607\n",
      "Train Epoch: 362 [160/1612 (10%)] Loss: 0.379931\n",
      "Train Epoch: 362 [320/1612 (20%)] Loss: 0.445887\n",
      "Train Epoch: 362 [480/1612 (30%)] Loss: 0.465886\n",
      "Train Epoch: 362 [640/1612 (40%)] Loss: 0.182221\n",
      "Train Epoch: 362 [800/1612 (50%)] Loss: 0.276422\n",
      "Train Epoch: 362 [960/1612 (59%)] Loss: 0.182393\n",
      "Train Epoch: 362 [1120/1612 (69%)] Loss: 0.151240\n",
      "Train Epoch: 362 [1280/1612 (79%)] Loss: 0.371308\n",
      "Train Epoch: 362 [1440/1612 (89%)] Loss: 0.300510\n",
      "Train Epoch: 362 [1200/1612 (99%)] Loss: 0.335756\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 363 [0/1612 (0%)] Loss: 0.427022\n",
      "Train Epoch: 363 [160/1612 (10%)] Loss: 0.247297\n",
      "Train Epoch: 363 [320/1612 (20%)] Loss: 0.287591\n",
      "Train Epoch: 363 [480/1612 (30%)] Loss: 0.247265\n",
      "Train Epoch: 363 [640/1612 (40%)] Loss: 0.416228\n",
      "Train Epoch: 363 [800/1612 (50%)] Loss: 0.303119\n",
      "Train Epoch: 363 [960/1612 (59%)] Loss: 0.576231\n",
      "Train Epoch: 363 [1120/1612 (69%)] Loss: 0.278882\n",
      "Train Epoch: 363 [1280/1612 (79%)] Loss: 0.279761\n",
      "Train Epoch: 363 [1440/1612 (89%)] Loss: 0.239530\n",
      "Train Epoch: 363 [1200/1612 (99%)] Loss: 0.456629\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 364 [0/1612 (0%)] Loss: 0.225577\n",
      "Train Epoch: 364 [160/1612 (10%)] Loss: 0.295970\n",
      "Train Epoch: 364 [320/1612 (20%)] Loss: 0.285596\n",
      "Train Epoch: 364 [480/1612 (30%)] Loss: 0.143952\n",
      "Train Epoch: 364 [640/1612 (40%)] Loss: 0.132421\n",
      "Train Epoch: 364 [800/1612 (50%)] Loss: 0.355895\n",
      "Train Epoch: 364 [960/1612 (59%)] Loss: 0.394973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 364 [1120/1612 (69%)] Loss: 0.429315\n",
      "Train Epoch: 364 [1280/1612 (79%)] Loss: 0.341411\n",
      "Train Epoch: 364 [1440/1612 (89%)] Loss: 0.400081\n",
      "Train Epoch: 364 [1200/1612 (99%)] Loss: 0.355356\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 365 [0/1612 (0%)] Loss: 0.414470\n",
      "Train Epoch: 365 [160/1612 (10%)] Loss: 0.488536\n",
      "Train Epoch: 365 [320/1612 (20%)] Loss: 0.544665\n",
      "Train Epoch: 365 [480/1612 (30%)] Loss: 0.344293\n",
      "Train Epoch: 365 [640/1612 (40%)] Loss: 0.153914\n",
      "Train Epoch: 365 [800/1612 (50%)] Loss: 0.511296\n",
      "Train Epoch: 365 [960/1612 (59%)] Loss: 0.389910\n",
      "Train Epoch: 365 [1120/1612 (69%)] Loss: 0.393244\n",
      "Train Epoch: 365 [1280/1612 (79%)] Loss: 0.315930\n",
      "Train Epoch: 365 [1440/1612 (89%)] Loss: 0.219408\n",
      "Train Epoch: 365 [1200/1612 (99%)] Loss: 0.368350\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 366 [0/1612 (0%)] Loss: 0.194664\n",
      "Train Epoch: 366 [160/1612 (10%)] Loss: 0.189239\n",
      "Train Epoch: 366 [320/1612 (20%)] Loss: 0.323367\n",
      "Train Epoch: 366 [480/1612 (30%)] Loss: 0.734453\n",
      "Train Epoch: 366 [640/1612 (40%)] Loss: 0.500707\n",
      "Train Epoch: 366 [800/1612 (50%)] Loss: 0.255885\n",
      "Train Epoch: 366 [960/1612 (59%)] Loss: 0.512480\n",
      "Train Epoch: 366 [1120/1612 (69%)] Loss: 0.219335\n",
      "Train Epoch: 366 [1280/1612 (79%)] Loss: 0.565946\n",
      "Train Epoch: 366 [1440/1612 (89%)] Loss: 0.405406\n",
      "Train Epoch: 366 [1200/1612 (99%)] Loss: 0.188359\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 367 [0/1612 (0%)] Loss: 0.261856\n",
      "Train Epoch: 367 [160/1612 (10%)] Loss: 0.154435\n",
      "Train Epoch: 367 [320/1612 (20%)] Loss: 0.310002\n",
      "Train Epoch: 367 [480/1612 (30%)] Loss: 0.327984\n",
      "Train Epoch: 367 [640/1612 (40%)] Loss: 0.502261\n",
      "Train Epoch: 367 [800/1612 (50%)] Loss: 0.376991\n",
      "Train Epoch: 367 [960/1612 (59%)] Loss: 0.438283\n",
      "Train Epoch: 367 [1120/1612 (69%)] Loss: 0.295121\n",
      "Train Epoch: 367 [1280/1612 (79%)] Loss: 0.371686\n",
      "Train Epoch: 367 [1440/1612 (89%)] Loss: 0.122815\n",
      "Train Epoch: 367 [1200/1612 (99%)] Loss: 0.108487\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 368 [0/1612 (0%)] Loss: 0.355015\n",
      "Train Epoch: 368 [160/1612 (10%)] Loss: 0.145469\n",
      "Train Epoch: 368 [320/1612 (20%)] Loss: 0.186138\n",
      "Train Epoch: 368 [480/1612 (30%)] Loss: 0.388457\n",
      "Train Epoch: 368 [640/1612 (40%)] Loss: 0.492958\n",
      "Train Epoch: 368 [800/1612 (50%)] Loss: 0.184322\n",
      "Train Epoch: 368 [960/1612 (59%)] Loss: 0.525150\n",
      "Train Epoch: 368 [1120/1612 (69%)] Loss: 0.472526\n",
      "Train Epoch: 368 [1280/1612 (79%)] Loss: 0.198142\n",
      "Train Epoch: 368 [1440/1612 (89%)] Loss: 0.214702\n",
      "Train Epoch: 368 [1200/1612 (99%)] Loss: 0.738038\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 369 [0/1612 (0%)] Loss: 0.210093\n",
      "Train Epoch: 369 [160/1612 (10%)] Loss: 0.149220\n",
      "Train Epoch: 369 [320/1612 (20%)] Loss: 0.266589\n",
      "Train Epoch: 369 [480/1612 (30%)] Loss: 0.394365\n",
      "Train Epoch: 369 [640/1612 (40%)] Loss: 0.410657\n",
      "Train Epoch: 369 [800/1612 (50%)] Loss: 0.321599\n",
      "Train Epoch: 369 [960/1612 (59%)] Loss: 0.568628\n",
      "Train Epoch: 369 [1120/1612 (69%)] Loss: 0.589105\n",
      "Train Epoch: 369 [1280/1612 (79%)] Loss: 0.395209\n",
      "Train Epoch: 369 [1440/1612 (89%)] Loss: 0.399464\n",
      "Train Epoch: 369 [1200/1612 (99%)] Loss: 0.343799\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 370 [0/1612 (0%)] Loss: 0.398579\n",
      "Train Epoch: 370 [160/1612 (10%)] Loss: 0.386680\n",
      "Train Epoch: 370 [320/1612 (20%)] Loss: 0.340567\n",
      "Train Epoch: 370 [480/1612 (30%)] Loss: 0.322363\n",
      "Train Epoch: 370 [640/1612 (40%)] Loss: 0.466797\n",
      "Train Epoch: 370 [800/1612 (50%)] Loss: 0.300011\n",
      "Train Epoch: 370 [960/1612 (59%)] Loss: 0.402323\n",
      "Train Epoch: 370 [1120/1612 (69%)] Loss: 0.411154\n",
      "Train Epoch: 370 [1280/1612 (79%)] Loss: 0.502167\n",
      "Train Epoch: 370 [1440/1612 (89%)] Loss: 0.284216\n",
      "Train Epoch: 370 [1200/1612 (99%)] Loss: 0.249732\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 371 [0/1612 (0%)] Loss: 0.240247\n",
      "Train Epoch: 371 [160/1612 (10%)] Loss: 0.315665\n",
      "Train Epoch: 371 [320/1612 (20%)] Loss: 0.180253\n",
      "Train Epoch: 371 [480/1612 (30%)] Loss: 0.664056\n",
      "Train Epoch: 371 [640/1612 (40%)] Loss: 0.299702\n",
      "Train Epoch: 371 [800/1612 (50%)] Loss: 0.492576\n",
      "Train Epoch: 371 [960/1612 (59%)] Loss: 0.236912\n",
      "Train Epoch: 371 [1120/1612 (69%)] Loss: 0.176701\n",
      "Train Epoch: 371 [1280/1612 (79%)] Loss: 0.342110\n",
      "Train Epoch: 371 [1440/1612 (89%)] Loss: 0.450252\n",
      "Train Epoch: 371 [1200/1612 (99%)] Loss: 0.248519\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 372 [0/1612 (0%)] Loss: 0.566842\n",
      "Train Epoch: 372 [160/1612 (10%)] Loss: 0.370824\n",
      "Train Epoch: 372 [320/1612 (20%)] Loss: 0.413068\n",
      "Train Epoch: 372 [480/1612 (30%)] Loss: 0.372954\n",
      "Train Epoch: 372 [640/1612 (40%)] Loss: 0.327837\n",
      "Train Epoch: 372 [800/1612 (50%)] Loss: 0.315847\n",
      "Train Epoch: 372 [960/1612 (59%)] Loss: 0.417151\n",
      "Train Epoch: 372 [1120/1612 (69%)] Loss: 0.152078\n",
      "Train Epoch: 372 [1280/1612 (79%)] Loss: 0.377997\n",
      "Train Epoch: 372 [1440/1612 (89%)] Loss: 0.147845\n",
      "Train Epoch: 372 [1200/1612 (99%)] Loss: 0.371618\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 373 [0/1612 (0%)] Loss: 0.244933\n",
      "Train Epoch: 373 [160/1612 (10%)] Loss: 0.254503\n",
      "Train Epoch: 373 [320/1612 (20%)] Loss: 0.138710\n",
      "Train Epoch: 373 [480/1612 (30%)] Loss: 0.475460\n",
      "Train Epoch: 373 [640/1612 (40%)] Loss: 0.253410\n",
      "Train Epoch: 373 [800/1612 (50%)] Loss: 0.396155\n",
      "Train Epoch: 373 [960/1612 (59%)] Loss: 0.146462\n",
      "Train Epoch: 373 [1120/1612 (69%)] Loss: 0.473071\n",
      "Train Epoch: 373 [1280/1612 (79%)] Loss: 0.501393\n",
      "Train Epoch: 373 [1440/1612 (89%)] Loss: 0.306516\n",
      "Train Epoch: 373 [1200/1612 (99%)] Loss: 0.525505\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 374 [0/1612 (0%)] Loss: 0.459974\n",
      "Train Epoch: 374 [160/1612 (10%)] Loss: 0.638972\n",
      "Train Epoch: 374 [320/1612 (20%)] Loss: 0.357848\n",
      "Train Epoch: 374 [480/1612 (30%)] Loss: 0.107394\n",
      "Train Epoch: 374 [640/1612 (40%)] Loss: 0.229992\n",
      "Train Epoch: 374 [800/1612 (50%)] Loss: 0.186437\n",
      "Train Epoch: 374 [960/1612 (59%)] Loss: 0.381098\n",
      "Train Epoch: 374 [1120/1612 (69%)] Loss: 0.140531\n",
      "Train Epoch: 374 [1280/1612 (79%)] Loss: 0.223325\n",
      "Train Epoch: 374 [1440/1612 (89%)] Loss: 0.328580\n",
      "Train Epoch: 374 [1200/1612 (99%)] Loss: 0.241650\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 375 [0/1612 (0%)] Loss: 0.473398\n",
      "Train Epoch: 375 [160/1612 (10%)] Loss: 0.331678\n",
      "Train Epoch: 375 [320/1612 (20%)] Loss: 0.286722\n",
      "Train Epoch: 375 [480/1612 (30%)] Loss: 0.204220\n",
      "Train Epoch: 375 [640/1612 (40%)] Loss: 0.404186\n",
      "Train Epoch: 375 [800/1612 (50%)] Loss: 0.299251\n",
      "Train Epoch: 375 [960/1612 (59%)] Loss: 0.410923\n",
      "Train Epoch: 375 [1120/1612 (69%)] Loss: 0.575251\n",
      "Train Epoch: 375 [1280/1612 (79%)] Loss: 0.421702\n",
      "Train Epoch: 375 [1440/1612 (89%)] Loss: 0.420779\n",
      "Train Epoch: 375 [1200/1612 (99%)] Loss: 0.276738\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 376 [0/1612 (0%)] Loss: 0.213629\n",
      "Train Epoch: 376 [160/1612 (10%)] Loss: 0.123602\n",
      "Train Epoch: 376 [320/1612 (20%)] Loss: 0.275094\n",
      "Train Epoch: 376 [480/1612 (30%)] Loss: 0.260936\n",
      "Train Epoch: 376 [640/1612 (40%)] Loss: 0.332891\n",
      "Train Epoch: 376 [800/1612 (50%)] Loss: 0.437007\n",
      "Train Epoch: 376 [960/1612 (59%)] Loss: 0.280775\n",
      "Train Epoch: 376 [1120/1612 (69%)] Loss: 0.268037\n",
      "Train Epoch: 376 [1280/1612 (79%)] Loss: 0.301178\n",
      "Train Epoch: 376 [1440/1612 (89%)] Loss: 0.300727\n",
      "Train Epoch: 376 [1200/1612 (99%)] Loss: 0.308487\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 377 [0/1612 (0%)] Loss: 0.255741\n",
      "Train Epoch: 377 [160/1612 (10%)] Loss: 0.629647\n",
      "Train Epoch: 377 [320/1612 (20%)] Loss: 0.337594\n",
      "Train Epoch: 377 [480/1612 (30%)] Loss: 0.222775\n",
      "Train Epoch: 377 [640/1612 (40%)] Loss: 0.171909\n",
      "Train Epoch: 377 [800/1612 (50%)] Loss: 0.181853\n",
      "Train Epoch: 377 [960/1612 (59%)] Loss: 0.359966\n",
      "Train Epoch: 377 [1120/1612 (69%)] Loss: 0.435643\n",
      "Train Epoch: 377 [1280/1612 (79%)] Loss: 0.199215\n",
      "Train Epoch: 377 [1440/1612 (89%)] Loss: 0.225892\n",
      "Train Epoch: 377 [1200/1612 (99%)] Loss: 0.233355\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 378 [0/1612 (0%)] Loss: 0.413993\n",
      "Train Epoch: 378 [160/1612 (10%)] Loss: 0.336322\n",
      "Train Epoch: 378 [320/1612 (20%)] Loss: 0.667780\n",
      "Train Epoch: 378 [480/1612 (30%)] Loss: 0.536920\n",
      "Train Epoch: 378 [640/1612 (40%)] Loss: 0.166198\n",
      "Train Epoch: 378 [800/1612 (50%)] Loss: 0.436577\n",
      "Train Epoch: 378 [960/1612 (59%)] Loss: 0.286014\n",
      "Train Epoch: 378 [1120/1612 (69%)] Loss: 0.156258\n",
      "Train Epoch: 378 [1280/1612 (79%)] Loss: 0.413235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 378 [1440/1612 (89%)] Loss: 0.371381\n",
      "Train Epoch: 378 [1200/1612 (99%)] Loss: 0.577186\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 379 [0/1612 (0%)] Loss: 0.323873\n",
      "Train Epoch: 379 [160/1612 (10%)] Loss: 0.328718\n",
      "Train Epoch: 379 [320/1612 (20%)] Loss: 0.353329\n",
      "Train Epoch: 379 [480/1612 (30%)] Loss: 0.310622\n",
      "Train Epoch: 379 [640/1612 (40%)] Loss: 0.550109\n",
      "Train Epoch: 379 [800/1612 (50%)] Loss: 0.250669\n",
      "Train Epoch: 379 [960/1612 (59%)] Loss: 0.397899\n",
      "Train Epoch: 379 [1120/1612 (69%)] Loss: 0.367453\n",
      "Train Epoch: 379 [1280/1612 (79%)] Loss: 0.354939\n",
      "Train Epoch: 379 [1440/1612 (89%)] Loss: 0.160422\n",
      "Train Epoch: 379 [1200/1612 (99%)] Loss: 0.323834\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 380 [0/1612 (0%)] Loss: 0.552998\n",
      "Train Epoch: 380 [160/1612 (10%)] Loss: 0.365108\n",
      "Train Epoch: 380 [320/1612 (20%)] Loss: 0.316038\n",
      "Train Epoch: 380 [480/1612 (30%)] Loss: 0.440419\n",
      "Train Epoch: 380 [640/1612 (40%)] Loss: 0.416750\n",
      "Train Epoch: 380 [800/1612 (50%)] Loss: 0.253326\n",
      "Train Epoch: 380 [960/1612 (59%)] Loss: 0.351187\n",
      "Train Epoch: 380 [1120/1612 (69%)] Loss: 0.484169\n",
      "Train Epoch: 380 [1280/1612 (79%)] Loss: 0.238711\n",
      "Train Epoch: 380 [1440/1612 (89%)] Loss: 0.312970\n",
      "Train Epoch: 380 [1200/1612 (99%)] Loss: 0.304018\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 381 [0/1612 (0%)] Loss: 0.334983\n",
      "Train Epoch: 381 [160/1612 (10%)] Loss: 0.301291\n",
      "Train Epoch: 381 [320/1612 (20%)] Loss: 0.209679\n",
      "Train Epoch: 381 [480/1612 (30%)] Loss: 0.362075\n",
      "Train Epoch: 381 [640/1612 (40%)] Loss: 0.193540\n",
      "Train Epoch: 381 [800/1612 (50%)] Loss: 0.449395\n",
      "Train Epoch: 381 [960/1612 (59%)] Loss: 0.466334\n",
      "Train Epoch: 381 [1120/1612 (69%)] Loss: 0.176957\n",
      "Train Epoch: 381 [1280/1612 (79%)] Loss: 0.473677\n",
      "Train Epoch: 381 [1440/1612 (89%)] Loss: 0.381756\n",
      "Train Epoch: 381 [1200/1612 (99%)] Loss: 0.195612\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 382 [0/1612 (0%)] Loss: 0.485320\n",
      "Train Epoch: 382 [160/1612 (10%)] Loss: 0.563608\n",
      "Train Epoch: 382 [320/1612 (20%)] Loss: 0.598832\n",
      "Train Epoch: 382 [480/1612 (30%)] Loss: 0.236761\n",
      "Train Epoch: 382 [640/1612 (40%)] Loss: 0.600518\n",
      "Train Epoch: 382 [800/1612 (50%)] Loss: 0.398143\n",
      "Train Epoch: 382 [960/1612 (59%)] Loss: 0.477030\n",
      "Train Epoch: 382 [1120/1612 (69%)] Loss: 0.480749\n",
      "Train Epoch: 382 [1280/1612 (79%)] Loss: 0.424784\n",
      "Train Epoch: 382 [1440/1612 (89%)] Loss: 0.270382\n",
      "Train Epoch: 382 [1200/1612 (99%)] Loss: 0.318194\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 383 [0/1612 (0%)] Loss: 0.300517\n",
      "Train Epoch: 383 [160/1612 (10%)] Loss: 0.166869\n",
      "Train Epoch: 383 [320/1612 (20%)] Loss: 0.441874\n",
      "Train Epoch: 383 [480/1612 (30%)] Loss: 0.512376\n",
      "Train Epoch: 383 [640/1612 (40%)] Loss: 0.311830\n",
      "Train Epoch: 383 [800/1612 (50%)] Loss: 0.734965\n",
      "Train Epoch: 383 [960/1612 (59%)] Loss: 0.253417\n",
      "Train Epoch: 383 [1120/1612 (69%)] Loss: 0.298477\n",
      "Train Epoch: 383 [1280/1612 (79%)] Loss: 0.206122\n",
      "Train Epoch: 383 [1440/1612 (89%)] Loss: 0.226460\n",
      "Train Epoch: 383 [1200/1612 (99%)] Loss: 0.387418\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 384 [0/1612 (0%)] Loss: 0.418243\n",
      "Train Epoch: 384 [160/1612 (10%)] Loss: 0.309249\n",
      "Train Epoch: 384 [320/1612 (20%)] Loss: 0.410315\n",
      "Train Epoch: 384 [480/1612 (30%)] Loss: 0.171273\n",
      "Train Epoch: 384 [640/1612 (40%)] Loss: 0.282781\n",
      "Train Epoch: 384 [800/1612 (50%)] Loss: 0.332482\n",
      "Train Epoch: 384 [960/1612 (59%)] Loss: 0.229743\n",
      "Train Epoch: 384 [1120/1612 (69%)] Loss: 0.414347\n",
      "Train Epoch: 384 [1280/1612 (79%)] Loss: 0.396471\n",
      "Train Epoch: 384 [1440/1612 (89%)] Loss: 0.381327\n",
      "Train Epoch: 384 [1200/1612 (99%)] Loss: 0.230407\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 385 [0/1612 (0%)] Loss: 0.393147\n",
      "Train Epoch: 385 [160/1612 (10%)] Loss: 0.358429\n",
      "Train Epoch: 385 [320/1612 (20%)] Loss: 0.471672\n",
      "Train Epoch: 385 [480/1612 (30%)] Loss: 0.273264\n",
      "Train Epoch: 385 [640/1612 (40%)] Loss: 0.254394\n",
      "Train Epoch: 385 [800/1612 (50%)] Loss: 0.427335\n",
      "Train Epoch: 385 [960/1612 (59%)] Loss: 0.429752\n",
      "Train Epoch: 385 [1120/1612 (69%)] Loss: 0.302216\n",
      "Train Epoch: 385 [1280/1612 (79%)] Loss: 0.179083\n",
      "Train Epoch: 385 [1440/1612 (89%)] Loss: 0.340338\n",
      "Train Epoch: 385 [1200/1612 (99%)] Loss: 0.211753\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 386 [0/1612 (0%)] Loss: 0.310440\n",
      "Train Epoch: 386 [160/1612 (10%)] Loss: 0.236735\n",
      "Train Epoch: 386 [320/1612 (20%)] Loss: 0.490838\n",
      "Train Epoch: 386 [480/1612 (30%)] Loss: 0.257628\n",
      "Train Epoch: 386 [640/1612 (40%)] Loss: 0.440794\n",
      "Train Epoch: 386 [800/1612 (50%)] Loss: 0.193108\n",
      "Train Epoch: 386 [960/1612 (59%)] Loss: 0.322041\n",
      "Train Epoch: 386 [1120/1612 (69%)] Loss: 0.667933\n",
      "Train Epoch: 386 [1280/1612 (79%)] Loss: 0.331917\n",
      "Train Epoch: 386 [1440/1612 (89%)] Loss: 0.451306\n",
      "Train Epoch: 386 [1200/1612 (99%)] Loss: 0.431487\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 387 [0/1612 (0%)] Loss: 0.202776\n",
      "Train Epoch: 387 [160/1612 (10%)] Loss: 0.317867\n",
      "Train Epoch: 387 [320/1612 (20%)] Loss: 0.208662\n",
      "Train Epoch: 387 [480/1612 (30%)] Loss: 0.223968\n",
      "Train Epoch: 387 [640/1612 (40%)] Loss: 0.197144\n",
      "Train Epoch: 387 [800/1612 (50%)] Loss: 0.443261\n",
      "Train Epoch: 387 [960/1612 (59%)] Loss: 0.414138\n",
      "Train Epoch: 387 [1120/1612 (69%)] Loss: 0.401174\n",
      "Train Epoch: 387 [1280/1612 (79%)] Loss: 0.204790\n",
      "Train Epoch: 387 [1440/1612 (89%)] Loss: 0.240470\n",
      "Train Epoch: 387 [1200/1612 (99%)] Loss: 0.226352\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 388 [0/1612 (0%)] Loss: 0.614905\n",
      "Train Epoch: 388 [160/1612 (10%)] Loss: 0.558931\n",
      "Train Epoch: 388 [320/1612 (20%)] Loss: 0.330812\n",
      "Train Epoch: 388 [480/1612 (30%)] Loss: 0.276497\n",
      "Train Epoch: 388 [640/1612 (40%)] Loss: 0.353321\n",
      "Train Epoch: 388 [800/1612 (50%)] Loss: 0.401836\n",
      "Train Epoch: 388 [960/1612 (59%)] Loss: 0.488936\n",
      "Train Epoch: 388 [1120/1612 (69%)] Loss: 0.242307\n",
      "Train Epoch: 388 [1280/1612 (79%)] Loss: 0.238813\n",
      "Train Epoch: 388 [1440/1612 (89%)] Loss: 0.279402\n",
      "Train Epoch: 388 [1200/1612 (99%)] Loss: 0.307567\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 389 [0/1612 (0%)] Loss: 0.200463\n",
      "Train Epoch: 389 [160/1612 (10%)] Loss: 0.497134\n",
      "Train Epoch: 389 [320/1612 (20%)] Loss: 0.224848\n",
      "Train Epoch: 389 [480/1612 (30%)] Loss: 0.108980\n",
      "Train Epoch: 389 [640/1612 (40%)] Loss: 0.255950\n",
      "Train Epoch: 389 [800/1612 (50%)] Loss: 0.256986\n",
      "Train Epoch: 389 [960/1612 (59%)] Loss: 0.140784\n",
      "Train Epoch: 389 [1120/1612 (69%)] Loss: 0.217870\n",
      "Train Epoch: 389 [1280/1612 (79%)] Loss: 0.220837\n",
      "Train Epoch: 389 [1440/1612 (89%)] Loss: 0.234420\n",
      "Train Epoch: 389 [1200/1612 (99%)] Loss: 0.499498\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 390 [0/1612 (0%)] Loss: 0.184165\n",
      "Train Epoch: 390 [160/1612 (10%)] Loss: 0.189901\n",
      "Train Epoch: 390 [320/1612 (20%)] Loss: 0.286353\n",
      "Train Epoch: 390 [480/1612 (30%)] Loss: 0.384697\n",
      "Train Epoch: 390 [640/1612 (40%)] Loss: 0.315901\n",
      "Train Epoch: 390 [800/1612 (50%)] Loss: 0.245169\n",
      "Train Epoch: 390 [960/1612 (59%)] Loss: 0.239186\n",
      "Train Epoch: 390 [1120/1612 (69%)] Loss: 0.456596\n",
      "Train Epoch: 390 [1280/1612 (79%)] Loss: 0.188432\n",
      "Train Epoch: 390 [1440/1612 (89%)] Loss: 0.325292\n",
      "Train Epoch: 390 [1200/1612 (99%)] Loss: 0.487372\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 391 [0/1612 (0%)] Loss: 0.219071\n",
      "Train Epoch: 391 [160/1612 (10%)] Loss: 0.337719\n",
      "Train Epoch: 391 [320/1612 (20%)] Loss: 0.430350\n",
      "Train Epoch: 391 [480/1612 (30%)] Loss: 0.262295\n",
      "Train Epoch: 391 [640/1612 (40%)] Loss: 0.456684\n",
      "Train Epoch: 391 [800/1612 (50%)] Loss: 0.109501\n",
      "Train Epoch: 391 [960/1612 (59%)] Loss: 0.183058\n",
      "Train Epoch: 391 [1120/1612 (69%)] Loss: 0.199951\n",
      "Train Epoch: 391 [1280/1612 (79%)] Loss: 0.329461\n",
      "Train Epoch: 391 [1440/1612 (89%)] Loss: 0.364114\n",
      "Train Epoch: 391 [1200/1612 (99%)] Loss: 0.332146\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 392 [0/1612 (0%)] Loss: 0.320469\n",
      "Train Epoch: 392 [160/1612 (10%)] Loss: 0.447407\n",
      "Train Epoch: 392 [320/1612 (20%)] Loss: 0.443070\n",
      "Train Epoch: 392 [480/1612 (30%)] Loss: 0.293715\n",
      "Train Epoch: 392 [640/1612 (40%)] Loss: 0.224901\n",
      "Train Epoch: 392 [800/1612 (50%)] Loss: 0.209114\n",
      "Train Epoch: 392 [960/1612 (59%)] Loss: 0.288233\n",
      "Train Epoch: 392 [1120/1612 (69%)] Loss: 0.395227\n",
      "Train Epoch: 392 [1280/1612 (79%)] Loss: 0.497267\n",
      "Train Epoch: 392 [1440/1612 (89%)] Loss: 0.462793\n",
      "Train Epoch: 392 [1200/1612 (99%)] Loss: 0.270313\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 393 [0/1612 (0%)] Loss: 0.304406\n",
      "Train Epoch: 393 [160/1612 (10%)] Loss: 0.234327\n",
      "Train Epoch: 393 [320/1612 (20%)] Loss: 0.242727\n",
      "Train Epoch: 393 [480/1612 (30%)] Loss: 0.581156\n",
      "Train Epoch: 393 [640/1612 (40%)] Loss: 0.573881\n",
      "Train Epoch: 393 [800/1612 (50%)] Loss: 0.466936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 393 [960/1612 (59%)] Loss: 0.216201\n",
      "Train Epoch: 393 [1120/1612 (69%)] Loss: 0.343216\n",
      "Train Epoch: 393 [1280/1612 (79%)] Loss: 0.330236\n",
      "Train Epoch: 393 [1440/1612 (89%)] Loss: 0.342305\n",
      "Train Epoch: 393 [1200/1612 (99%)] Loss: 0.494000\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 394 [0/1612 (0%)] Loss: 0.527860\n",
      "Train Epoch: 394 [160/1612 (10%)] Loss: 0.254730\n",
      "Train Epoch: 394 [320/1612 (20%)] Loss: 0.357590\n",
      "Train Epoch: 394 [480/1612 (30%)] Loss: 0.265873\n",
      "Train Epoch: 394 [640/1612 (40%)] Loss: 0.244216\n",
      "Train Epoch: 394 [800/1612 (50%)] Loss: 0.173524\n",
      "Train Epoch: 394 [960/1612 (59%)] Loss: 0.330186\n",
      "Train Epoch: 394 [1120/1612 (69%)] Loss: 0.466684\n",
      "Train Epoch: 394 [1280/1612 (79%)] Loss: 0.370557\n",
      "Train Epoch: 394 [1440/1612 (89%)] Loss: 0.316266\n",
      "Train Epoch: 394 [1200/1612 (99%)] Loss: 0.190974\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 395 [0/1612 (0%)] Loss: 0.423979\n",
      "Train Epoch: 395 [160/1612 (10%)] Loss: 0.478053\n",
      "Train Epoch: 395 [320/1612 (20%)] Loss: 0.368575\n",
      "Train Epoch: 395 [480/1612 (30%)] Loss: 0.382099\n",
      "Train Epoch: 395 [640/1612 (40%)] Loss: 0.080749\n",
      "Train Epoch: 395 [800/1612 (50%)] Loss: 0.477819\n",
      "Train Epoch: 395 [960/1612 (59%)] Loss: 0.232446\n",
      "Train Epoch: 395 [1120/1612 (69%)] Loss: 0.213972\n",
      "Train Epoch: 395 [1280/1612 (79%)] Loss: 0.174704\n",
      "Train Epoch: 395 [1440/1612 (89%)] Loss: 0.309734\n",
      "Train Epoch: 395 [1200/1612 (99%)] Loss: 0.559931\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 396 [0/1612 (0%)] Loss: 0.651987\n",
      "Train Epoch: 396 [160/1612 (10%)] Loss: 0.249308\n",
      "Train Epoch: 396 [320/1612 (20%)] Loss: 0.336195\n",
      "Train Epoch: 396 [480/1612 (30%)] Loss: 0.324729\n",
      "Train Epoch: 396 [640/1612 (40%)] Loss: 0.164695\n",
      "Train Epoch: 396 [800/1612 (50%)] Loss: 0.376007\n",
      "Train Epoch: 396 [960/1612 (59%)] Loss: 0.202939\n",
      "Train Epoch: 396 [1120/1612 (69%)] Loss: 0.453859\n",
      "Train Epoch: 396 [1280/1612 (79%)] Loss: 0.248627\n",
      "Train Epoch: 396 [1440/1612 (89%)] Loss: 0.596122\n",
      "Train Epoch: 396 [1200/1612 (99%)] Loss: 0.289490\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 397 [0/1612 (0%)] Loss: 0.269587\n",
      "Train Epoch: 397 [160/1612 (10%)] Loss: 0.124393\n",
      "Train Epoch: 397 [320/1612 (20%)] Loss: 0.197674\n",
      "Train Epoch: 397 [480/1612 (30%)] Loss: 0.337733\n",
      "Train Epoch: 397 [640/1612 (40%)] Loss: 0.262790\n",
      "Train Epoch: 397 [800/1612 (50%)] Loss: 0.219367\n",
      "Train Epoch: 397 [960/1612 (59%)] Loss: 0.239448\n",
      "Train Epoch: 397 [1120/1612 (69%)] Loss: 0.226878\n",
      "Train Epoch: 397 [1280/1612 (79%)] Loss: 0.648490\n",
      "Train Epoch: 397 [1440/1612 (89%)] Loss: 0.707841\n",
      "Train Epoch: 397 [1200/1612 (99%)] Loss: 0.324830\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 398 [0/1612 (0%)] Loss: 0.798716\n",
      "Train Epoch: 398 [160/1612 (10%)] Loss: 0.118226\n",
      "Train Epoch: 398 [320/1612 (20%)] Loss: 0.421421\n",
      "Train Epoch: 398 [480/1612 (30%)] Loss: 0.231471\n",
      "Train Epoch: 398 [640/1612 (40%)] Loss: 0.251415\n",
      "Train Epoch: 398 [800/1612 (50%)] Loss: 0.203415\n",
      "Train Epoch: 398 [960/1612 (59%)] Loss: 0.446128\n",
      "Train Epoch: 398 [1120/1612 (69%)] Loss: 0.369157\n",
      "Train Epoch: 398 [1280/1612 (79%)] Loss: 0.404652\n",
      "Train Epoch: 398 [1440/1612 (89%)] Loss: 0.217248\n",
      "Train Epoch: 398 [1200/1612 (99%)] Loss: 0.313915\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 399 [0/1612 (0%)] Loss: 0.336811\n",
      "Train Epoch: 399 [160/1612 (10%)] Loss: 0.386688\n",
      "Train Epoch: 399 [320/1612 (20%)] Loss: 0.356485\n",
      "Train Epoch: 399 [480/1612 (30%)] Loss: 0.290806\n",
      "Train Epoch: 399 [640/1612 (40%)] Loss: 0.515499\n",
      "Train Epoch: 399 [800/1612 (50%)] Loss: 0.467854\n",
      "Train Epoch: 399 [960/1612 (59%)] Loss: 0.371139\n",
      "Train Epoch: 399 [1120/1612 (69%)] Loss: 0.398509\n",
      "Train Epoch: 399 [1280/1612 (79%)] Loss: 0.225487\n",
      "Train Epoch: 399 [1440/1612 (89%)] Loss: 0.395575\n",
      "Train Epoch: 399 [1200/1612 (99%)] Loss: 0.407812\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 400 [0/1612 (0%)] Loss: 0.244675\n",
      "Train Epoch: 400 [160/1612 (10%)] Loss: 0.202858\n",
      "Train Epoch: 400 [320/1612 (20%)] Loss: 0.296132\n",
      "Train Epoch: 400 [480/1612 (30%)] Loss: 0.328317\n",
      "Train Epoch: 400 [640/1612 (40%)] Loss: 0.466067\n",
      "Train Epoch: 400 [800/1612 (50%)] Loss: 0.367395\n",
      "Train Epoch: 400 [960/1612 (59%)] Loss: 0.187025\n",
      "Train Epoch: 400 [1120/1612 (69%)] Loss: 0.372704\n",
      "Train Epoch: 400 [1280/1612 (79%)] Loss: 0.124176\n",
      "Train Epoch: 400 [1440/1612 (89%)] Loss: 0.316427\n",
      "Train Epoch: 400 [1200/1612 (99%)] Loss: 0.189215\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 401 [0/1612 (0%)] Loss: 0.370475\n",
      "Train Epoch: 401 [160/1612 (10%)] Loss: 0.637624\n",
      "Train Epoch: 401 [320/1612 (20%)] Loss: 0.294167\n",
      "Train Epoch: 401 [480/1612 (30%)] Loss: 0.277364\n",
      "Train Epoch: 401 [640/1612 (40%)] Loss: 0.289811\n",
      "Train Epoch: 401 [800/1612 (50%)] Loss: 0.133426\n",
      "Train Epoch: 401 [960/1612 (59%)] Loss: 0.415104\n",
      "Train Epoch: 401 [1120/1612 (69%)] Loss: 0.162086\n",
      "Train Epoch: 401 [1280/1612 (79%)] Loss: 0.265733\n",
      "Train Epoch: 401 [1440/1612 (89%)] Loss: 0.320652\n",
      "Train Epoch: 401 [1200/1612 (99%)] Loss: 0.649130\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 402 [0/1612 (0%)] Loss: 0.223552\n",
      "Train Epoch: 402 [160/1612 (10%)] Loss: 0.409548\n",
      "Train Epoch: 402 [320/1612 (20%)] Loss: 0.682007\n",
      "Train Epoch: 402 [480/1612 (30%)] Loss: 0.415996\n",
      "Train Epoch: 402 [640/1612 (40%)] Loss: 0.393791\n",
      "Train Epoch: 402 [800/1612 (50%)] Loss: 0.118725\n",
      "Train Epoch: 402 [960/1612 (59%)] Loss: 0.644703\n",
      "Train Epoch: 402 [1120/1612 (69%)] Loss: 0.220340\n",
      "Train Epoch: 402 [1280/1612 (79%)] Loss: 0.206574\n",
      "Train Epoch: 402 [1440/1612 (89%)] Loss: 0.220364\n",
      "Train Epoch: 402 [1200/1612 (99%)] Loss: 0.912953\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 403 [0/1612 (0%)] Loss: 0.283207\n",
      "Train Epoch: 403 [160/1612 (10%)] Loss: 0.315632\n",
      "Train Epoch: 403 [320/1612 (20%)] Loss: 0.298223\n",
      "Train Epoch: 403 [480/1612 (30%)] Loss: 0.302228\n",
      "Train Epoch: 403 [640/1612 (40%)] Loss: 0.390043\n",
      "Train Epoch: 403 [800/1612 (50%)] Loss: 0.748376\n",
      "Train Epoch: 403 [960/1612 (59%)] Loss: 0.460832\n",
      "Train Epoch: 403 [1120/1612 (69%)] Loss: 0.447020\n",
      "Train Epoch: 403 [1280/1612 (79%)] Loss: 0.271326\n",
      "Train Epoch: 403 [1440/1612 (89%)] Loss: 0.325961\n",
      "Train Epoch: 403 [1200/1612 (99%)] Loss: 0.264373\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 404 [0/1612 (0%)] Loss: 0.160602\n",
      "Train Epoch: 404 [160/1612 (10%)] Loss: 0.211579\n",
      "Train Epoch: 404 [320/1612 (20%)] Loss: 0.397465\n",
      "Train Epoch: 404 [480/1612 (30%)] Loss: 0.347058\n",
      "Train Epoch: 404 [640/1612 (40%)] Loss: 0.579887\n",
      "Train Epoch: 404 [800/1612 (50%)] Loss: 0.184333\n",
      "Train Epoch: 404 [960/1612 (59%)] Loss: 0.191101\n",
      "Train Epoch: 404 [1120/1612 (69%)] Loss: 0.162396\n",
      "Train Epoch: 404 [1280/1612 (79%)] Loss: 0.333828\n",
      "Train Epoch: 404 [1440/1612 (89%)] Loss: 0.553244\n",
      "Train Epoch: 404 [1200/1612 (99%)] Loss: 0.263742\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 405 [0/1612 (0%)] Loss: 0.308511\n",
      "Train Epoch: 405 [160/1612 (10%)] Loss: 0.506495\n",
      "Train Epoch: 405 [320/1612 (20%)] Loss: 0.258646\n",
      "Train Epoch: 405 [480/1612 (30%)] Loss: 0.293747\n",
      "Train Epoch: 405 [640/1612 (40%)] Loss: 0.332162\n",
      "Train Epoch: 405 [800/1612 (50%)] Loss: 0.416882\n",
      "Train Epoch: 405 [960/1612 (59%)] Loss: 0.312625\n",
      "Train Epoch: 405 [1120/1612 (69%)] Loss: 0.276950\n",
      "Train Epoch: 405 [1280/1612 (79%)] Loss: 0.133735\n",
      "Train Epoch: 405 [1440/1612 (89%)] Loss: 0.469101\n",
      "Train Epoch: 405 [1200/1612 (99%)] Loss: 0.152376\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 406 [0/1612 (0%)] Loss: 0.550340\n",
      "Train Epoch: 406 [160/1612 (10%)] Loss: 0.192446\n",
      "Train Epoch: 406 [320/1612 (20%)] Loss: 0.305077\n",
      "Train Epoch: 406 [480/1612 (30%)] Loss: 0.293433\n",
      "Train Epoch: 406 [640/1612 (40%)] Loss: 0.313682\n",
      "Train Epoch: 406 [800/1612 (50%)] Loss: 0.172056\n",
      "Train Epoch: 406 [960/1612 (59%)] Loss: 0.480974\n",
      "Train Epoch: 406 [1120/1612 (69%)] Loss: 0.827388\n",
      "Train Epoch: 406 [1280/1612 (79%)] Loss: 0.310191\n",
      "Train Epoch: 406 [1440/1612 (89%)] Loss: 0.302307\n",
      "Train Epoch: 406 [1200/1612 (99%)] Loss: 0.195021\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 407 [0/1612 (0%)] Loss: 0.429782\n",
      "Train Epoch: 407 [160/1612 (10%)] Loss: 0.269843\n",
      "Train Epoch: 407 [320/1612 (20%)] Loss: 0.065838\n",
      "Train Epoch: 407 [480/1612 (30%)] Loss: 0.382560\n",
      "Train Epoch: 407 [640/1612 (40%)] Loss: 0.191747\n",
      "Train Epoch: 407 [800/1612 (50%)] Loss: 0.786132\n",
      "Train Epoch: 407 [960/1612 (59%)] Loss: 0.237841\n",
      "Train Epoch: 407 [1120/1612 (69%)] Loss: 0.170828\n",
      "Train Epoch: 407 [1280/1612 (79%)] Loss: 0.333894\n",
      "Train Epoch: 407 [1440/1612 (89%)] Loss: 0.599280\n",
      "Train Epoch: 407 [1200/1612 (99%)] Loss: 0.394190\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 408 [0/1612 (0%)] Loss: 0.302474\n",
      "Train Epoch: 408 [160/1612 (10%)] Loss: 0.645172\n",
      "Train Epoch: 408 [320/1612 (20%)] Loss: 0.327604\n",
      "Train Epoch: 408 [480/1612 (30%)] Loss: 0.344678\n",
      "Train Epoch: 408 [640/1612 (40%)] Loss: 0.222695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 408 [800/1612 (50%)] Loss: 0.308950\n",
      "Train Epoch: 408 [960/1612 (59%)] Loss: 0.461838\n",
      "Train Epoch: 408 [1120/1612 (69%)] Loss: 0.235756\n",
      "Train Epoch: 408 [1280/1612 (79%)] Loss: 0.340088\n",
      "Train Epoch: 408 [1440/1612 (89%)] Loss: 0.609574\n",
      "Train Epoch: 408 [1200/1612 (99%)] Loss: 0.439778\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 409 [0/1612 (0%)] Loss: 0.216925\n",
      "Train Epoch: 409 [160/1612 (10%)] Loss: 0.130692\n",
      "Train Epoch: 409 [320/1612 (20%)] Loss: 0.383347\n",
      "Train Epoch: 409 [480/1612 (30%)] Loss: 0.457760\n",
      "Train Epoch: 409 [640/1612 (40%)] Loss: 0.171425\n",
      "Train Epoch: 409 [800/1612 (50%)] Loss: 0.228545\n",
      "Train Epoch: 409 [960/1612 (59%)] Loss: 0.293339\n",
      "Train Epoch: 409 [1120/1612 (69%)] Loss: 0.390479\n",
      "Train Epoch: 409 [1280/1612 (79%)] Loss: 0.275374\n",
      "Train Epoch: 409 [1440/1612 (89%)] Loss: 0.166640\n",
      "Train Epoch: 409 [1200/1612 (99%)] Loss: 0.559075\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 410 [0/1612 (0%)] Loss: 0.169182\n",
      "Train Epoch: 410 [160/1612 (10%)] Loss: 0.184382\n",
      "Train Epoch: 410 [320/1612 (20%)] Loss: 0.322860\n",
      "Train Epoch: 410 [480/1612 (30%)] Loss: 0.310869\n",
      "Train Epoch: 410 [640/1612 (40%)] Loss: 0.356936\n",
      "Train Epoch: 410 [800/1612 (50%)] Loss: 0.211955\n",
      "Train Epoch: 410 [960/1612 (59%)] Loss: 0.511419\n",
      "Train Epoch: 410 [1120/1612 (69%)] Loss: 0.285782\n",
      "Train Epoch: 410 [1280/1612 (79%)] Loss: 0.450268\n",
      "Train Epoch: 410 [1440/1612 (89%)] Loss: 0.351020\n",
      "Train Epoch: 410 [1200/1612 (99%)] Loss: 0.324432\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 411 [0/1612 (0%)] Loss: 0.238317\n",
      "Train Epoch: 411 [160/1612 (10%)] Loss: 0.315666\n",
      "Train Epoch: 411 [320/1612 (20%)] Loss: 0.237692\n",
      "Train Epoch: 411 [480/1612 (30%)] Loss: 0.290909\n",
      "Train Epoch: 411 [640/1612 (40%)] Loss: 0.240730\n",
      "Train Epoch: 411 [800/1612 (50%)] Loss: 0.202491\n",
      "Train Epoch: 411 [960/1612 (59%)] Loss: 0.456199\n",
      "Train Epoch: 411 [1120/1612 (69%)] Loss: 0.317799\n",
      "Train Epoch: 411 [1280/1612 (79%)] Loss: 0.383433\n",
      "Train Epoch: 411 [1440/1612 (89%)] Loss: 0.325373\n",
      "Train Epoch: 411 [1200/1612 (99%)] Loss: 0.555366\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 412 [0/1612 (0%)] Loss: 0.138395\n",
      "Train Epoch: 412 [160/1612 (10%)] Loss: 0.201818\n",
      "Train Epoch: 412 [320/1612 (20%)] Loss: 0.402085\n",
      "Train Epoch: 412 [480/1612 (30%)] Loss: 0.408708\n",
      "Train Epoch: 412 [640/1612 (40%)] Loss: 0.155809\n",
      "Train Epoch: 412 [800/1612 (50%)] Loss: 0.247604\n",
      "Train Epoch: 412 [960/1612 (59%)] Loss: 0.278771\n",
      "Train Epoch: 412 [1120/1612 (69%)] Loss: 0.351186\n",
      "Train Epoch: 412 [1280/1612 (79%)] Loss: 0.473907\n",
      "Train Epoch: 412 [1440/1612 (89%)] Loss: 0.274115\n",
      "Train Epoch: 412 [1200/1612 (99%)] Loss: 0.659739\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 413 [0/1612 (0%)] Loss: 0.133110\n",
      "Train Epoch: 413 [160/1612 (10%)] Loss: 0.446839\n",
      "Train Epoch: 413 [320/1612 (20%)] Loss: 0.524360\n",
      "Train Epoch: 413 [480/1612 (30%)] Loss: 0.236467\n",
      "Train Epoch: 413 [640/1612 (40%)] Loss: 0.514130\n",
      "Train Epoch: 413 [800/1612 (50%)] Loss: 0.200689\n",
      "Train Epoch: 413 [960/1612 (59%)] Loss: 0.135806\n",
      "Train Epoch: 413 [1120/1612 (69%)] Loss: 0.224502\n",
      "Train Epoch: 413 [1280/1612 (79%)] Loss: 0.248621\n",
      "Train Epoch: 413 [1440/1612 (89%)] Loss: 0.306336\n",
      "Train Epoch: 413 [1200/1612 (99%)] Loss: 0.503193\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 414 [0/1612 (0%)] Loss: 0.263930\n",
      "Train Epoch: 414 [160/1612 (10%)] Loss: 0.417373\n",
      "Train Epoch: 414 [320/1612 (20%)] Loss: 0.641766\n",
      "Train Epoch: 414 [480/1612 (30%)] Loss: 0.209805\n",
      "Train Epoch: 414 [640/1612 (40%)] Loss: 0.235528\n",
      "Train Epoch: 414 [800/1612 (50%)] Loss: 0.395185\n",
      "Train Epoch: 414 [960/1612 (59%)] Loss: 0.676004\n",
      "Train Epoch: 414 [1120/1612 (69%)] Loss: 0.413894\n",
      "Train Epoch: 414 [1280/1612 (79%)] Loss: 0.258403\n",
      "Train Epoch: 414 [1440/1612 (89%)] Loss: 0.384589\n",
      "Train Epoch: 414 [1200/1612 (99%)] Loss: 0.350309\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 415 [0/1612 (0%)] Loss: 0.300295\n",
      "Train Epoch: 415 [160/1612 (10%)] Loss: 0.351575\n",
      "Train Epoch: 415 [320/1612 (20%)] Loss: 0.284248\n",
      "Train Epoch: 415 [480/1612 (30%)] Loss: 0.428160\n",
      "Train Epoch: 415 [640/1612 (40%)] Loss: 0.284935\n",
      "Train Epoch: 415 [800/1612 (50%)] Loss: 0.278138\n",
      "Train Epoch: 415 [960/1612 (59%)] Loss: 0.443647\n",
      "Train Epoch: 415 [1120/1612 (69%)] Loss: 0.322644\n",
      "Train Epoch: 415 [1280/1612 (79%)] Loss: 0.311558\n",
      "Train Epoch: 415 [1440/1612 (89%)] Loss: 0.222612\n",
      "Train Epoch: 415 [1200/1612 (99%)] Loss: 0.423397\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 416 [0/1612 (0%)] Loss: 0.131167\n",
      "Train Epoch: 416 [160/1612 (10%)] Loss: 0.194836\n",
      "Train Epoch: 416 [320/1612 (20%)] Loss: 0.338473\n",
      "Train Epoch: 416 [480/1612 (30%)] Loss: 0.279803\n",
      "Train Epoch: 416 [640/1612 (40%)] Loss: 0.214301\n",
      "Train Epoch: 416 [800/1612 (50%)] Loss: 0.309139\n",
      "Train Epoch: 416 [960/1612 (59%)] Loss: 0.172070\n",
      "Train Epoch: 416 [1120/1612 (69%)] Loss: 0.280674\n",
      "Train Epoch: 416 [1280/1612 (79%)] Loss: 0.272050\n",
      "Train Epoch: 416 [1440/1612 (89%)] Loss: 0.484397\n",
      "Train Epoch: 416 [1200/1612 (99%)] Loss: 0.155711\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 417 [0/1612 (0%)] Loss: 0.406376\n",
      "Train Epoch: 417 [160/1612 (10%)] Loss: 0.481575\n",
      "Train Epoch: 417 [320/1612 (20%)] Loss: 0.182489\n",
      "Train Epoch: 417 [480/1612 (30%)] Loss: 0.588583\n",
      "Train Epoch: 417 [640/1612 (40%)] Loss: 0.150648\n",
      "Train Epoch: 417 [800/1612 (50%)] Loss: 0.124086\n",
      "Train Epoch: 417 [960/1612 (59%)] Loss: 0.287373\n",
      "Train Epoch: 417 [1120/1612 (69%)] Loss: 0.401793\n",
      "Train Epoch: 417 [1280/1612 (79%)] Loss: 0.324975\n",
      "Train Epoch: 417 [1440/1612 (89%)] Loss: 0.417861\n",
      "Train Epoch: 417 [1200/1612 (99%)] Loss: 0.173666\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 418 [0/1612 (0%)] Loss: 0.194280\n",
      "Train Epoch: 418 [160/1612 (10%)] Loss: 0.374058\n",
      "Train Epoch: 418 [320/1612 (20%)] Loss: 0.248385\n",
      "Train Epoch: 418 [480/1612 (30%)] Loss: 0.301038\n",
      "Train Epoch: 418 [640/1612 (40%)] Loss: 0.257610\n",
      "Train Epoch: 418 [800/1612 (50%)] Loss: 0.293855\n",
      "Train Epoch: 418 [960/1612 (59%)] Loss: 0.569889\n",
      "Train Epoch: 418 [1120/1612 (69%)] Loss: 0.210110\n",
      "Train Epoch: 418 [1280/1612 (79%)] Loss: 0.379639\n",
      "Train Epoch: 418 [1440/1612 (89%)] Loss: 0.509636\n",
      "Train Epoch: 418 [1200/1612 (99%)] Loss: 0.249547\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 419 [0/1612 (0%)] Loss: 0.335298\n",
      "Train Epoch: 419 [160/1612 (10%)] Loss: 0.213805\n",
      "Train Epoch: 419 [320/1612 (20%)] Loss: 0.314585\n",
      "Train Epoch: 419 [480/1612 (30%)] Loss: 0.424470\n",
      "Train Epoch: 419 [640/1612 (40%)] Loss: 0.367592\n",
      "Train Epoch: 419 [800/1612 (50%)] Loss: 0.223203\n",
      "Train Epoch: 419 [960/1612 (59%)] Loss: 0.179022\n",
      "Train Epoch: 419 [1120/1612 (69%)] Loss: 0.319512\n",
      "Train Epoch: 419 [1280/1612 (79%)] Loss: 0.275117\n",
      "Train Epoch: 419 [1440/1612 (89%)] Loss: 0.410911\n",
      "Train Epoch: 419 [1200/1612 (99%)] Loss: 0.639910\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 420 [0/1612 (0%)] Loss: 0.509157\n",
      "Train Epoch: 420 [160/1612 (10%)] Loss: 0.517495\n",
      "Train Epoch: 420 [320/1612 (20%)] Loss: 0.399218\n",
      "Train Epoch: 420 [480/1612 (30%)] Loss: 0.271354\n",
      "Train Epoch: 420 [640/1612 (40%)] Loss: 0.591122\n",
      "Train Epoch: 420 [800/1612 (50%)] Loss: 0.370311\n",
      "Train Epoch: 420 [960/1612 (59%)] Loss: 0.314729\n",
      "Train Epoch: 420 [1120/1612 (69%)] Loss: 0.377822\n",
      "Train Epoch: 420 [1280/1612 (79%)] Loss: 0.330876\n",
      "Train Epoch: 420 [1440/1612 (89%)] Loss: 0.142291\n",
      "Train Epoch: 420 [1200/1612 (99%)] Loss: 0.392534\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 421 [0/1612 (0%)] Loss: 0.267489\n",
      "Train Epoch: 421 [160/1612 (10%)] Loss: 0.250920\n",
      "Train Epoch: 421 [320/1612 (20%)] Loss: 0.370889\n",
      "Train Epoch: 421 [480/1612 (30%)] Loss: 0.390591\n",
      "Train Epoch: 421 [640/1612 (40%)] Loss: 0.120211\n",
      "Train Epoch: 421 [800/1612 (50%)] Loss: 0.365016\n",
      "Train Epoch: 421 [960/1612 (59%)] Loss: 0.454598\n",
      "Train Epoch: 421 [1120/1612 (69%)] Loss: 0.406142\n",
      "Train Epoch: 421 [1280/1612 (79%)] Loss: 0.304755\n",
      "Train Epoch: 421 [1440/1612 (89%)] Loss: 0.156004\n",
      "Train Epoch: 421 [1200/1612 (99%)] Loss: 0.717736\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 422 [0/1612 (0%)] Loss: 0.303581\n",
      "Train Epoch: 422 [160/1612 (10%)] Loss: 0.179209\n",
      "Train Epoch: 422 [320/1612 (20%)] Loss: 0.200536\n",
      "Train Epoch: 422 [480/1612 (30%)] Loss: 0.263621\n",
      "Train Epoch: 422 [640/1612 (40%)] Loss: 0.130479\n",
      "Train Epoch: 422 [800/1612 (50%)] Loss: 0.288089\n",
      "Train Epoch: 422 [960/1612 (59%)] Loss: 0.334259\n",
      "Train Epoch: 422 [1120/1612 (69%)] Loss: 0.372059\n",
      "Train Epoch: 422 [1280/1612 (79%)] Loss: 0.436967\n",
      "Train Epoch: 422 [1440/1612 (89%)] Loss: 0.587375\n",
      "Train Epoch: 422 [1200/1612 (99%)] Loss: 0.208028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 423 [0/1612 (0%)] Loss: 0.556400\n",
      "Train Epoch: 423 [160/1612 (10%)] Loss: 0.288735\n",
      "Train Epoch: 423 [320/1612 (20%)] Loss: 0.458388\n",
      "Train Epoch: 423 [480/1612 (30%)] Loss: 0.488744\n",
      "Train Epoch: 423 [640/1612 (40%)] Loss: 0.335490\n",
      "Train Epoch: 423 [800/1612 (50%)] Loss: 0.262478\n",
      "Train Epoch: 423 [960/1612 (59%)] Loss: 0.378424\n",
      "Train Epoch: 423 [1120/1612 (69%)] Loss: 0.453096\n",
      "Train Epoch: 423 [1280/1612 (79%)] Loss: 0.246924\n",
      "Train Epoch: 423 [1440/1612 (89%)] Loss: 0.284023\n",
      "Train Epoch: 423 [1200/1612 (99%)] Loss: 0.126382\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 424 [0/1612 (0%)] Loss: 0.143732\n",
      "Train Epoch: 424 [160/1612 (10%)] Loss: 0.247439\n",
      "Train Epoch: 424 [320/1612 (20%)] Loss: 0.456347\n",
      "Train Epoch: 424 [480/1612 (30%)] Loss: 0.256682\n",
      "Train Epoch: 424 [640/1612 (40%)] Loss: 0.384434\n",
      "Train Epoch: 424 [800/1612 (50%)] Loss: 0.262056\n",
      "Train Epoch: 424 [960/1612 (59%)] Loss: 0.294238\n",
      "Train Epoch: 424 [1120/1612 (69%)] Loss: 0.345309\n",
      "Train Epoch: 424 [1280/1612 (79%)] Loss: 0.255406\n",
      "Train Epoch: 424 [1440/1612 (89%)] Loss: 0.142211\n",
      "Train Epoch: 424 [1200/1612 (99%)] Loss: 0.334360\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 425 [0/1612 (0%)] Loss: 0.542101\n",
      "Train Epoch: 425 [160/1612 (10%)] Loss: 0.211497\n",
      "Train Epoch: 425 [320/1612 (20%)] Loss: 0.290441\n",
      "Train Epoch: 425 [480/1612 (30%)] Loss: 0.235482\n",
      "Train Epoch: 425 [640/1612 (40%)] Loss: 0.262879\n",
      "Train Epoch: 425 [800/1612 (50%)] Loss: 0.381263\n",
      "Train Epoch: 425 [960/1612 (59%)] Loss: 0.316272\n",
      "Train Epoch: 425 [1120/1612 (69%)] Loss: 0.158661\n",
      "Train Epoch: 425 [1280/1612 (79%)] Loss: 0.236676\n",
      "Train Epoch: 425 [1440/1612 (89%)] Loss: 0.204824\n",
      "Train Epoch: 425 [1200/1612 (99%)] Loss: 0.568042\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 426 [0/1612 (0%)] Loss: 0.288390\n",
      "Train Epoch: 426 [160/1612 (10%)] Loss: 0.304534\n",
      "Train Epoch: 426 [320/1612 (20%)] Loss: 0.429844\n",
      "Train Epoch: 426 [480/1612 (30%)] Loss: 0.326731\n",
      "Train Epoch: 426 [640/1612 (40%)] Loss: 0.529948\n",
      "Train Epoch: 426 [800/1612 (50%)] Loss: 0.421411\n",
      "Train Epoch: 426 [960/1612 (59%)] Loss: 0.515801\n",
      "Train Epoch: 426 [1120/1612 (69%)] Loss: 0.526544\n",
      "Train Epoch: 426 [1280/1612 (79%)] Loss: 0.313281\n",
      "Train Epoch: 426 [1440/1612 (89%)] Loss: 0.415087\n",
      "Train Epoch: 426 [1200/1612 (99%)] Loss: 0.233072\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 427 [0/1612 (0%)] Loss: 0.184669\n",
      "Train Epoch: 427 [160/1612 (10%)] Loss: 0.199169\n",
      "Train Epoch: 427 [320/1612 (20%)] Loss: 0.235108\n",
      "Train Epoch: 427 [480/1612 (30%)] Loss: 0.432062\n",
      "Train Epoch: 427 [640/1612 (40%)] Loss: 0.379981\n",
      "Train Epoch: 427 [800/1612 (50%)] Loss: 0.373737\n",
      "Train Epoch: 427 [960/1612 (59%)] Loss: 0.445014\n",
      "Train Epoch: 427 [1120/1612 (69%)] Loss: 0.234765\n",
      "Train Epoch: 427 [1280/1612 (79%)] Loss: 0.146847\n",
      "Train Epoch: 427 [1440/1612 (89%)] Loss: 0.247976\n",
      "Train Epoch: 427 [1200/1612 (99%)] Loss: 0.173005\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 428 [0/1612 (0%)] Loss: 0.327980\n",
      "Train Epoch: 428 [160/1612 (10%)] Loss: 0.362035\n",
      "Train Epoch: 428 [320/1612 (20%)] Loss: 0.208140\n",
      "Train Epoch: 428 [480/1612 (30%)] Loss: 0.297371\n",
      "Train Epoch: 428 [640/1612 (40%)] Loss: 0.423815\n",
      "Train Epoch: 428 [800/1612 (50%)] Loss: 0.454732\n",
      "Train Epoch: 428 [960/1612 (59%)] Loss: 0.335368\n",
      "Train Epoch: 428 [1120/1612 (69%)] Loss: 0.332977\n",
      "Train Epoch: 428 [1280/1612 (79%)] Loss: 0.193712\n",
      "Train Epoch: 428 [1440/1612 (89%)] Loss: 0.286740\n",
      "Train Epoch: 428 [1200/1612 (99%)] Loss: 0.388636\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 429 [0/1612 (0%)] Loss: 0.393696\n",
      "Train Epoch: 429 [160/1612 (10%)] Loss: 0.247863\n",
      "Train Epoch: 429 [320/1612 (20%)] Loss: 0.673830\n",
      "Train Epoch: 429 [480/1612 (30%)] Loss: 0.168872\n",
      "Train Epoch: 429 [640/1612 (40%)] Loss: 0.632479\n",
      "Train Epoch: 429 [800/1612 (50%)] Loss: 0.500590\n",
      "Train Epoch: 429 [960/1612 (59%)] Loss: 0.381127\n",
      "Train Epoch: 429 [1120/1612 (69%)] Loss: 0.165075\n",
      "Train Epoch: 429 [1280/1612 (79%)] Loss: 0.415213\n",
      "Train Epoch: 429 [1440/1612 (89%)] Loss: 0.246056\n",
      "Train Epoch: 429 [1200/1612 (99%)] Loss: 0.224018\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 430 [0/1612 (0%)] Loss: 0.385427\n",
      "Train Epoch: 430 [160/1612 (10%)] Loss: 0.572153\n",
      "Train Epoch: 430 [320/1612 (20%)] Loss: 0.251720\n",
      "Train Epoch: 430 [480/1612 (30%)] Loss: 0.333468\n",
      "Train Epoch: 430 [640/1612 (40%)] Loss: 0.469116\n",
      "Train Epoch: 430 [800/1612 (50%)] Loss: 0.114302\n",
      "Train Epoch: 430 [960/1612 (59%)] Loss: 0.229190\n",
      "Train Epoch: 430 [1120/1612 (69%)] Loss: 0.509103\n",
      "Train Epoch: 430 [1280/1612 (79%)] Loss: 0.336604\n",
      "Train Epoch: 430 [1440/1612 (89%)] Loss: 0.426404\n",
      "Train Epoch: 430 [1200/1612 (99%)] Loss: 0.338498\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 431 [0/1612 (0%)] Loss: 0.231393\n",
      "Train Epoch: 431 [160/1612 (10%)] Loss: 0.288812\n",
      "Train Epoch: 431 [320/1612 (20%)] Loss: 0.464067\n",
      "Train Epoch: 431 [480/1612 (30%)] Loss: 0.196391\n",
      "Train Epoch: 431 [640/1612 (40%)] Loss: 0.346989\n",
      "Train Epoch: 431 [800/1612 (50%)] Loss: 0.314658\n",
      "Train Epoch: 431 [960/1612 (59%)] Loss: 0.332687\n",
      "Train Epoch: 431 [1120/1612 (69%)] Loss: 0.310436\n",
      "Train Epoch: 431 [1280/1612 (79%)] Loss: 0.246380\n",
      "Train Epoch: 431 [1440/1612 (89%)] Loss: 0.412325\n",
      "Train Epoch: 431 [1200/1612 (99%)] Loss: 0.453956\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 432 [0/1612 (0%)] Loss: 0.251478\n",
      "Train Epoch: 432 [160/1612 (10%)] Loss: 0.323932\n",
      "Train Epoch: 432 [320/1612 (20%)] Loss: 0.480149\n",
      "Train Epoch: 432 [480/1612 (30%)] Loss: 0.204311\n",
      "Train Epoch: 432 [640/1612 (40%)] Loss: 0.661753\n",
      "Train Epoch: 432 [800/1612 (50%)] Loss: 0.236012\n",
      "Train Epoch: 432 [960/1612 (59%)] Loss: 0.628997\n",
      "Train Epoch: 432 [1120/1612 (69%)] Loss: 0.282457\n",
      "Train Epoch: 432 [1280/1612 (79%)] Loss: 0.480542\n",
      "Train Epoch: 432 [1440/1612 (89%)] Loss: 0.243702\n",
      "Train Epoch: 432 [1200/1612 (99%)] Loss: 0.615664\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 433 [0/1612 (0%)] Loss: 0.302771\n",
      "Train Epoch: 433 [160/1612 (10%)] Loss: 0.330950\n",
      "Train Epoch: 433 [320/1612 (20%)] Loss: 0.494268\n",
      "Train Epoch: 433 [480/1612 (30%)] Loss: 0.458464\n",
      "Train Epoch: 433 [640/1612 (40%)] Loss: 0.560994\n",
      "Train Epoch: 433 [800/1612 (50%)] Loss: 0.296094\n",
      "Train Epoch: 433 [960/1612 (59%)] Loss: 0.470191\n",
      "Train Epoch: 433 [1120/1612 (69%)] Loss: 0.366066\n",
      "Train Epoch: 433 [1280/1612 (79%)] Loss: 0.561530\n",
      "Train Epoch: 433 [1440/1612 (89%)] Loss: 0.235431\n",
      "Train Epoch: 433 [1200/1612 (99%)] Loss: 0.292867\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 434 [0/1612 (0%)] Loss: 0.357556\n",
      "Train Epoch: 434 [160/1612 (10%)] Loss: 0.295450\n",
      "Train Epoch: 434 [320/1612 (20%)] Loss: 0.336259\n",
      "Train Epoch: 434 [480/1612 (30%)] Loss: 0.301773\n",
      "Train Epoch: 434 [640/1612 (40%)] Loss: 0.226856\n",
      "Train Epoch: 434 [800/1612 (50%)] Loss: 0.251850\n",
      "Train Epoch: 434 [960/1612 (59%)] Loss: 0.405034\n",
      "Train Epoch: 434 [1120/1612 (69%)] Loss: 0.513130\n",
      "Train Epoch: 434 [1280/1612 (79%)] Loss: 0.289138\n",
      "Train Epoch: 434 [1440/1612 (89%)] Loss: 0.223273\n",
      "Train Epoch: 434 [1200/1612 (99%)] Loss: 0.381397\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 435 [0/1612 (0%)] Loss: 0.203017\n",
      "Train Epoch: 435 [160/1612 (10%)] Loss: 0.284033\n",
      "Train Epoch: 435 [320/1612 (20%)] Loss: 0.311516\n",
      "Train Epoch: 435 [480/1612 (30%)] Loss: 0.318512\n",
      "Train Epoch: 435 [640/1612 (40%)] Loss: 0.380474\n",
      "Train Epoch: 435 [800/1612 (50%)] Loss: 0.345893\n",
      "Train Epoch: 435 [960/1612 (59%)] Loss: 0.393832\n",
      "Train Epoch: 435 [1120/1612 (69%)] Loss: 0.177195\n",
      "Train Epoch: 435 [1280/1612 (79%)] Loss: 0.302575\n",
      "Train Epoch: 435 [1440/1612 (89%)] Loss: 0.221493\n",
      "Train Epoch: 435 [1200/1612 (99%)] Loss: 0.440792\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 436 [0/1612 (0%)] Loss: 0.293144\n",
      "Train Epoch: 436 [160/1612 (10%)] Loss: 0.420579\n",
      "Train Epoch: 436 [320/1612 (20%)] Loss: 0.220019\n",
      "Train Epoch: 436 [480/1612 (30%)] Loss: 0.345898\n",
      "Train Epoch: 436 [640/1612 (40%)] Loss: 0.343576\n",
      "Train Epoch: 436 [800/1612 (50%)] Loss: 0.092391\n",
      "Train Epoch: 436 [960/1612 (59%)] Loss: 0.310800\n",
      "Train Epoch: 436 [1120/1612 (69%)] Loss: 0.215857\n",
      "Train Epoch: 436 [1280/1612 (79%)] Loss: 0.442384\n",
      "Train Epoch: 436 [1440/1612 (89%)] Loss: 0.424499\n",
      "Train Epoch: 436 [1200/1612 (99%)] Loss: 0.190162\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 437 [0/1612 (0%)] Loss: 0.197911\n",
      "Train Epoch: 437 [160/1612 (10%)] Loss: 0.286079\n",
      "Train Epoch: 437 [320/1612 (20%)] Loss: 0.214621\n",
      "Train Epoch: 437 [480/1612 (30%)] Loss: 0.374695\n",
      "Train Epoch: 437 [640/1612 (40%)] Loss: 0.202131\n",
      "Train Epoch: 437 [800/1612 (50%)] Loss: 0.196398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 437 [960/1612 (59%)] Loss: 0.218580\n",
      "Train Epoch: 437 [1120/1612 (69%)] Loss: 0.388000\n",
      "Train Epoch: 437 [1280/1612 (79%)] Loss: 0.158481\n",
      "Train Epoch: 437 [1440/1612 (89%)] Loss: 0.303374\n",
      "Train Epoch: 437 [1200/1612 (99%)] Loss: 0.342003\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 438 [0/1612 (0%)] Loss: 0.309517\n",
      "Train Epoch: 438 [160/1612 (10%)] Loss: 0.174593\n",
      "Train Epoch: 438 [320/1612 (20%)] Loss: 0.541332\n",
      "Train Epoch: 438 [480/1612 (30%)] Loss: 0.261052\n",
      "Train Epoch: 438 [640/1612 (40%)] Loss: 0.365473\n",
      "Train Epoch: 438 [800/1612 (50%)] Loss: 0.458259\n",
      "Train Epoch: 438 [960/1612 (59%)] Loss: 0.384006\n",
      "Train Epoch: 438 [1120/1612 (69%)] Loss: 0.177744\n",
      "Train Epoch: 438 [1280/1612 (79%)] Loss: 0.547491\n",
      "Train Epoch: 438 [1440/1612 (89%)] Loss: 0.401252\n",
      "Train Epoch: 438 [1200/1612 (99%)] Loss: 0.116271\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 439 [0/1612 (0%)] Loss: 0.498180\n",
      "Train Epoch: 439 [160/1612 (10%)] Loss: 0.193152\n",
      "Train Epoch: 439 [320/1612 (20%)] Loss: 0.284796\n",
      "Train Epoch: 439 [480/1612 (30%)] Loss: 0.319687\n",
      "Train Epoch: 439 [640/1612 (40%)] Loss: 0.282904\n",
      "Train Epoch: 439 [800/1612 (50%)] Loss: 0.404707\n",
      "Train Epoch: 439 [960/1612 (59%)] Loss: 0.176434\n",
      "Train Epoch: 439 [1120/1612 (69%)] Loss: 0.407176\n",
      "Train Epoch: 439 [1280/1612 (79%)] Loss: 0.158322\n",
      "Train Epoch: 439 [1440/1612 (89%)] Loss: 0.368376\n",
      "Train Epoch: 439 [1200/1612 (99%)] Loss: 0.331356\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 440 [0/1612 (0%)] Loss: 0.371492\n",
      "Train Epoch: 440 [160/1612 (10%)] Loss: 0.146373\n",
      "Train Epoch: 440 [320/1612 (20%)] Loss: 0.314018\n",
      "Train Epoch: 440 [480/1612 (30%)] Loss: 0.174141\n",
      "Train Epoch: 440 [640/1612 (40%)] Loss: 0.659079\n",
      "Train Epoch: 440 [800/1612 (50%)] Loss: 0.235218\n",
      "Train Epoch: 440 [960/1612 (59%)] Loss: 0.297448\n",
      "Train Epoch: 440 [1120/1612 (69%)] Loss: 0.353153\n",
      "Train Epoch: 440 [1280/1612 (79%)] Loss: 0.682914\n",
      "Train Epoch: 440 [1440/1612 (89%)] Loss: 0.298682\n",
      "Train Epoch: 440 [1200/1612 (99%)] Loss: 0.291327\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 441 [0/1612 (0%)] Loss: 0.079737\n",
      "Train Epoch: 441 [160/1612 (10%)] Loss: 0.524492\n",
      "Train Epoch: 441 [320/1612 (20%)] Loss: 0.540061\n",
      "Train Epoch: 441 [480/1612 (30%)] Loss: 0.338721\n",
      "Train Epoch: 441 [640/1612 (40%)] Loss: 0.457337\n",
      "Train Epoch: 441 [800/1612 (50%)] Loss: 0.380653\n",
      "Train Epoch: 441 [960/1612 (59%)] Loss: 0.287048\n",
      "Train Epoch: 441 [1120/1612 (69%)] Loss: 0.401064\n",
      "Train Epoch: 441 [1280/1612 (79%)] Loss: 0.427743\n",
      "Train Epoch: 441 [1440/1612 (89%)] Loss: 0.251372\n",
      "Train Epoch: 441 [1200/1612 (99%)] Loss: 0.279912\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 442 [0/1612 (0%)] Loss: 0.194482\n",
      "Train Epoch: 442 [160/1612 (10%)] Loss: 0.136749\n",
      "Train Epoch: 442 [320/1612 (20%)] Loss: 0.290077\n",
      "Train Epoch: 442 [480/1612 (30%)] Loss: 0.547358\n",
      "Train Epoch: 442 [640/1612 (40%)] Loss: 0.289584\n",
      "Train Epoch: 442 [800/1612 (50%)] Loss: 0.238229\n",
      "Train Epoch: 442 [960/1612 (59%)] Loss: 0.326985\n",
      "Train Epoch: 442 [1120/1612 (69%)] Loss: 0.327862\n",
      "Train Epoch: 442 [1280/1612 (79%)] Loss: 0.330156\n",
      "Train Epoch: 442 [1440/1612 (89%)] Loss: 0.172236\n",
      "Train Epoch: 442 [1200/1612 (99%)] Loss: 0.592264\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 443 [0/1612 (0%)] Loss: 0.332906\n",
      "Train Epoch: 443 [160/1612 (10%)] Loss: 0.375502\n",
      "Train Epoch: 443 [320/1612 (20%)] Loss: 0.240334\n",
      "Train Epoch: 443 [480/1612 (30%)] Loss: 0.141480\n",
      "Train Epoch: 443 [640/1612 (40%)] Loss: 0.418363\n",
      "Train Epoch: 443 [800/1612 (50%)] Loss: 0.320601\n",
      "Train Epoch: 443 [960/1612 (59%)] Loss: 0.376611\n",
      "Train Epoch: 443 [1120/1612 (69%)] Loss: 0.426791\n",
      "Train Epoch: 443 [1280/1612 (79%)] Loss: 0.401973\n",
      "Train Epoch: 443 [1440/1612 (89%)] Loss: 0.292580\n",
      "Train Epoch: 443 [1200/1612 (99%)] Loss: 0.448694\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 444 [0/1612 (0%)] Loss: 0.234170\n",
      "Train Epoch: 444 [160/1612 (10%)] Loss: 0.584914\n",
      "Train Epoch: 444 [320/1612 (20%)] Loss: 0.203200\n",
      "Train Epoch: 444 [480/1612 (30%)] Loss: 0.270531\n",
      "Train Epoch: 444 [640/1612 (40%)] Loss: 0.368672\n",
      "Train Epoch: 444 [800/1612 (50%)] Loss: 0.220323\n",
      "Train Epoch: 444 [960/1612 (59%)] Loss: 0.526786\n",
      "Train Epoch: 444 [1120/1612 (69%)] Loss: 0.185420\n",
      "Train Epoch: 444 [1280/1612 (79%)] Loss: 0.282959\n",
      "Train Epoch: 444 [1440/1612 (89%)] Loss: 0.348742\n",
      "Train Epoch: 444 [1200/1612 (99%)] Loss: 0.246552\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 445 [0/1612 (0%)] Loss: 0.137293\n",
      "Train Epoch: 445 [160/1612 (10%)] Loss: 0.571031\n",
      "Train Epoch: 445 [320/1612 (20%)] Loss: 0.293063\n",
      "Train Epoch: 445 [480/1612 (30%)] Loss: 0.244216\n",
      "Train Epoch: 445 [640/1612 (40%)] Loss: 0.451294\n",
      "Train Epoch: 445 [800/1612 (50%)] Loss: 0.440597\n",
      "Train Epoch: 445 [960/1612 (59%)] Loss: 0.282316\n",
      "Train Epoch: 445 [1120/1612 (69%)] Loss: 0.595484\n",
      "Train Epoch: 445 [1280/1612 (79%)] Loss: 0.468602\n",
      "Train Epoch: 445 [1440/1612 (89%)] Loss: 0.238420\n",
      "Train Epoch: 445 [1200/1612 (99%)] Loss: 0.570307\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 446 [0/1612 (0%)] Loss: 0.444045\n",
      "Train Epoch: 446 [160/1612 (10%)] Loss: 0.343886\n",
      "Train Epoch: 446 [320/1612 (20%)] Loss: 0.245521\n",
      "Train Epoch: 446 [480/1612 (30%)] Loss: 0.311671\n",
      "Train Epoch: 446 [640/1612 (40%)] Loss: 0.344582\n",
      "Train Epoch: 446 [800/1612 (50%)] Loss: 0.185915\n",
      "Train Epoch: 446 [960/1612 (59%)] Loss: 0.323834\n",
      "Train Epoch: 446 [1120/1612 (69%)] Loss: 0.246111\n",
      "Train Epoch: 446 [1280/1612 (79%)] Loss: 0.318693\n",
      "Train Epoch: 446 [1440/1612 (89%)] Loss: 0.279962\n",
      "Train Epoch: 446 [1200/1612 (99%)] Loss: 0.330362\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 447 [0/1612 (0%)] Loss: 0.275841\n",
      "Train Epoch: 447 [160/1612 (10%)] Loss: 0.195541\n",
      "Train Epoch: 447 [320/1612 (20%)] Loss: 0.499134\n",
      "Train Epoch: 447 [480/1612 (30%)] Loss: 0.154212\n",
      "Train Epoch: 447 [640/1612 (40%)] Loss: 0.080808\n",
      "Train Epoch: 447 [800/1612 (50%)] Loss: 0.149222\n",
      "Train Epoch: 447 [960/1612 (59%)] Loss: 0.325793\n",
      "Train Epoch: 447 [1120/1612 (69%)] Loss: 0.185310\n",
      "Train Epoch: 447 [1280/1612 (79%)] Loss: 0.286804\n",
      "Train Epoch: 447 [1440/1612 (89%)] Loss: 0.260630\n",
      "Train Epoch: 447 [1200/1612 (99%)] Loss: 0.306665\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 448 [0/1612 (0%)] Loss: 0.191714\n",
      "Train Epoch: 448 [160/1612 (10%)] Loss: 0.071531\n",
      "Train Epoch: 448 [320/1612 (20%)] Loss: 0.296332\n",
      "Train Epoch: 448 [480/1612 (30%)] Loss: 0.453167\n",
      "Train Epoch: 448 [640/1612 (40%)] Loss: 0.429036\n",
      "Train Epoch: 448 [800/1612 (50%)] Loss: 0.478831\n",
      "Train Epoch: 448 [960/1612 (59%)] Loss: 0.207090\n",
      "Train Epoch: 448 [1120/1612 (69%)] Loss: 0.243978\n",
      "Train Epoch: 448 [1280/1612 (79%)] Loss: 0.313064\n",
      "Train Epoch: 448 [1440/1612 (89%)] Loss: 0.351299\n",
      "Train Epoch: 448 [1200/1612 (99%)] Loss: 0.247567\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 449 [0/1612 (0%)] Loss: 0.539736\n",
      "Train Epoch: 449 [160/1612 (10%)] Loss: 0.266036\n",
      "Train Epoch: 449 [320/1612 (20%)] Loss: 0.594150\n",
      "Train Epoch: 449 [480/1612 (30%)] Loss: 0.227945\n",
      "Train Epoch: 449 [640/1612 (40%)] Loss: 0.196939\n",
      "Train Epoch: 449 [800/1612 (50%)] Loss: 0.572406\n",
      "Train Epoch: 449 [960/1612 (59%)] Loss: 0.305012\n",
      "Train Epoch: 449 [1120/1612 (69%)] Loss: 0.568008\n",
      "Train Epoch: 449 [1280/1612 (79%)] Loss: 0.221171\n",
      "Train Epoch: 449 [1440/1612 (89%)] Loss: 0.408196\n",
      "Train Epoch: 449 [1200/1612 (99%)] Loss: 0.286469\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 450 [0/1612 (0%)] Loss: 0.501041\n",
      "Train Epoch: 450 [160/1612 (10%)] Loss: 0.307344\n",
      "Train Epoch: 450 [320/1612 (20%)] Loss: 0.193396\n",
      "Train Epoch: 450 [480/1612 (30%)] Loss: 0.198463\n",
      "Train Epoch: 450 [640/1612 (40%)] Loss: 0.225868\n",
      "Train Epoch: 450 [800/1612 (50%)] Loss: 0.164255\n",
      "Train Epoch: 450 [960/1612 (59%)] Loss: 0.367938\n",
      "Train Epoch: 450 [1120/1612 (69%)] Loss: 0.623701\n",
      "Train Epoch: 450 [1280/1612 (79%)] Loss: 0.318031\n",
      "Train Epoch: 450 [1440/1612 (89%)] Loss: 0.250782\n",
      "Train Epoch: 450 [1200/1612 (99%)] Loss: 0.360366\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 451 [0/1612 (0%)] Loss: 0.205754\n",
      "Train Epoch: 451 [160/1612 (10%)] Loss: 0.220069\n",
      "Train Epoch: 451 [320/1612 (20%)] Loss: 0.300480\n",
      "Train Epoch: 451 [480/1612 (30%)] Loss: 0.286844\n",
      "Train Epoch: 451 [640/1612 (40%)] Loss: 0.374241\n",
      "Train Epoch: 451 [800/1612 (50%)] Loss: 0.378895\n",
      "Train Epoch: 451 [960/1612 (59%)] Loss: 0.183678\n",
      "Train Epoch: 451 [1120/1612 (69%)] Loss: 0.533742\n",
      "Train Epoch: 451 [1280/1612 (79%)] Loss: 0.181146\n",
      "Train Epoch: 451 [1440/1612 (89%)] Loss: 0.325350\n",
      "Train Epoch: 451 [1200/1612 (99%)] Loss: 0.122561\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 452 [0/1612 (0%)] Loss: 0.452064\n",
      "Train Epoch: 452 [160/1612 (10%)] Loss: 0.291692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 452 [320/1612 (20%)] Loss: 0.235642\n",
      "Train Epoch: 452 [480/1612 (30%)] Loss: 0.402098\n",
      "Train Epoch: 452 [640/1612 (40%)] Loss: 0.207454\n",
      "Train Epoch: 452 [800/1612 (50%)] Loss: 0.259129\n",
      "Train Epoch: 452 [960/1612 (59%)] Loss: 0.271717\n",
      "Train Epoch: 452 [1120/1612 (69%)] Loss: 0.329025\n",
      "Train Epoch: 452 [1280/1612 (79%)] Loss: 0.242249\n",
      "Train Epoch: 452 [1440/1612 (89%)] Loss: 0.082836\n",
      "Train Epoch: 452 [1200/1612 (99%)] Loss: 0.150681\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 453 [0/1612 (0%)] Loss: 0.184817\n",
      "Train Epoch: 453 [160/1612 (10%)] Loss: 0.315454\n",
      "Train Epoch: 453 [320/1612 (20%)] Loss: 0.731381\n",
      "Train Epoch: 453 [480/1612 (30%)] Loss: 0.231885\n",
      "Train Epoch: 453 [640/1612 (40%)] Loss: 0.304373\n",
      "Train Epoch: 453 [800/1612 (50%)] Loss: 0.340977\n",
      "Train Epoch: 453 [960/1612 (59%)] Loss: 0.222408\n",
      "Train Epoch: 453 [1120/1612 (69%)] Loss: 0.296062\n",
      "Train Epoch: 453 [1280/1612 (79%)] Loss: 0.215140\n",
      "Train Epoch: 453 [1440/1612 (89%)] Loss: 0.362905\n",
      "Train Epoch: 453 [1200/1612 (99%)] Loss: 0.684675\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 454 [0/1612 (0%)] Loss: 0.411526\n",
      "Train Epoch: 454 [160/1612 (10%)] Loss: 0.226097\n",
      "Train Epoch: 454 [320/1612 (20%)] Loss: 0.515255\n",
      "Train Epoch: 454 [480/1612 (30%)] Loss: 0.325198\n",
      "Train Epoch: 454 [640/1612 (40%)] Loss: 0.136703\n",
      "Train Epoch: 454 [800/1612 (50%)] Loss: 0.308136\n",
      "Train Epoch: 454 [960/1612 (59%)] Loss: 0.145856\n",
      "Train Epoch: 454 [1120/1612 (69%)] Loss: 0.301829\n",
      "Train Epoch: 454 [1280/1612 (79%)] Loss: 0.254713\n",
      "Train Epoch: 454 [1440/1612 (89%)] Loss: 0.429260\n",
      "Train Epoch: 454 [1200/1612 (99%)] Loss: 0.112370\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 455 [0/1612 (0%)] Loss: 0.154205\n",
      "Train Epoch: 455 [160/1612 (10%)] Loss: 0.284291\n",
      "Train Epoch: 455 [320/1612 (20%)] Loss: 0.296044\n",
      "Train Epoch: 455 [480/1612 (30%)] Loss: 0.259649\n",
      "Train Epoch: 455 [640/1612 (40%)] Loss: 0.321839\n",
      "Train Epoch: 455 [800/1612 (50%)] Loss: 0.271948\n",
      "Train Epoch: 455 [960/1612 (59%)] Loss: 0.430992\n",
      "Train Epoch: 455 [1120/1612 (69%)] Loss: 0.314395\n",
      "Train Epoch: 455 [1280/1612 (79%)] Loss: 0.339983\n",
      "Train Epoch: 455 [1440/1612 (89%)] Loss: 0.241523\n",
      "Train Epoch: 455 [1200/1612 (99%)] Loss: 0.378264\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 456 [0/1612 (0%)] Loss: 0.316222\n",
      "Train Epoch: 456 [160/1612 (10%)] Loss: 0.273775\n",
      "Train Epoch: 456 [320/1612 (20%)] Loss: 0.417893\n",
      "Train Epoch: 456 [480/1612 (30%)] Loss: 0.298682\n",
      "Train Epoch: 456 [640/1612 (40%)] Loss: 0.279960\n",
      "Train Epoch: 456 [800/1612 (50%)] Loss: 0.369639\n",
      "Train Epoch: 456 [960/1612 (59%)] Loss: 0.223223\n",
      "Train Epoch: 456 [1120/1612 (69%)] Loss: 0.512572\n",
      "Train Epoch: 456 [1280/1612 (79%)] Loss: 0.196714\n",
      "Train Epoch: 456 [1440/1612 (89%)] Loss: 0.505673\n",
      "Train Epoch: 456 [1200/1612 (99%)] Loss: 0.438895\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 457 [0/1612 (0%)] Loss: 0.210055\n",
      "Train Epoch: 457 [160/1612 (10%)] Loss: 0.555197\n",
      "Train Epoch: 457 [320/1612 (20%)] Loss: 0.207647\n",
      "Train Epoch: 457 [480/1612 (30%)] Loss: 0.575610\n",
      "Train Epoch: 457 [640/1612 (40%)] Loss: 0.104896\n",
      "Train Epoch: 457 [800/1612 (50%)] Loss: 0.346740\n",
      "Train Epoch: 457 [960/1612 (59%)] Loss: 0.535079\n",
      "Train Epoch: 457 [1120/1612 (69%)] Loss: 0.284412\n",
      "Train Epoch: 457 [1280/1612 (79%)] Loss: 0.546345\n",
      "Train Epoch: 457 [1440/1612 (89%)] Loss: 0.379987\n",
      "Train Epoch: 457 [1200/1612 (99%)] Loss: 0.208400\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 458 [0/1612 (0%)] Loss: 0.335264\n",
      "Train Epoch: 458 [160/1612 (10%)] Loss: 0.414685\n",
      "Train Epoch: 458 [320/1612 (20%)] Loss: 0.245912\n",
      "Train Epoch: 458 [480/1612 (30%)] Loss: 0.241704\n",
      "Train Epoch: 458 [640/1612 (40%)] Loss: 0.211003\n",
      "Train Epoch: 458 [800/1612 (50%)] Loss: 0.387049\n",
      "Train Epoch: 458 [960/1612 (59%)] Loss: 0.362859\n",
      "Train Epoch: 458 [1120/1612 (69%)] Loss: 0.487854\n",
      "Train Epoch: 458 [1280/1612 (79%)] Loss: 0.662667\n",
      "Train Epoch: 458 [1440/1612 (89%)] Loss: 0.252430\n",
      "Train Epoch: 458 [1200/1612 (99%)] Loss: 0.290641\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 459 [0/1612 (0%)] Loss: 0.524579\n",
      "Train Epoch: 459 [160/1612 (10%)] Loss: 0.067537\n",
      "Train Epoch: 459 [320/1612 (20%)] Loss: 0.359431\n",
      "Train Epoch: 459 [480/1612 (30%)] Loss: 0.271517\n",
      "Train Epoch: 459 [640/1612 (40%)] Loss: 0.574684\n",
      "Train Epoch: 459 [800/1612 (50%)] Loss: 0.176845\n",
      "Train Epoch: 459 [960/1612 (59%)] Loss: 0.361581\n",
      "Train Epoch: 459 [1120/1612 (69%)] Loss: 0.468560\n",
      "Train Epoch: 459 [1280/1612 (79%)] Loss: 0.261082\n",
      "Train Epoch: 459 [1440/1612 (89%)] Loss: 0.264434\n",
      "Train Epoch: 459 [1200/1612 (99%)] Loss: 0.180769\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 460 [0/1612 (0%)] Loss: 0.478986\n",
      "Train Epoch: 460 [160/1612 (10%)] Loss: 0.317033\n",
      "Train Epoch: 460 [320/1612 (20%)] Loss: 0.306516\n",
      "Train Epoch: 460 [480/1612 (30%)] Loss: 0.237662\n",
      "Train Epoch: 460 [640/1612 (40%)] Loss: 0.508125\n",
      "Train Epoch: 460 [800/1612 (50%)] Loss: 0.318123\n",
      "Train Epoch: 460 [960/1612 (59%)] Loss: 0.277057\n",
      "Train Epoch: 460 [1120/1612 (69%)] Loss: 0.499680\n",
      "Train Epoch: 460 [1280/1612 (79%)] Loss: 0.164368\n",
      "Train Epoch: 460 [1440/1612 (89%)] Loss: 0.595540\n",
      "Train Epoch: 460 [1200/1612 (99%)] Loss: 0.117468\n",
      "\n",
      "Test set: Average loss: 0.0241, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 461 [0/1612 (0%)] Loss: 0.384256\n",
      "Train Epoch: 461 [160/1612 (10%)] Loss: 0.454502\n",
      "Train Epoch: 461 [320/1612 (20%)] Loss: 0.403277\n",
      "Train Epoch: 461 [480/1612 (30%)] Loss: 0.437077\n",
      "Train Epoch: 461 [640/1612 (40%)] Loss: 0.293011\n",
      "Train Epoch: 461 [800/1612 (50%)] Loss: 0.330819\n",
      "Train Epoch: 461 [960/1612 (59%)] Loss: 0.265858\n",
      "Train Epoch: 461 [1120/1612 (69%)] Loss: 0.354912\n",
      "Train Epoch: 461 [1280/1612 (79%)] Loss: 0.276716\n",
      "Train Epoch: 461 [1440/1612 (89%)] Loss: 0.212924\n",
      "Train Epoch: 461 [1200/1612 (99%)] Loss: 0.126609\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 462 [0/1612 (0%)] Loss: 0.294286\n",
      "Train Epoch: 462 [160/1612 (10%)] Loss: 0.318536\n",
      "Train Epoch: 462 [320/1612 (20%)] Loss: 0.359321\n",
      "Train Epoch: 462 [480/1612 (30%)] Loss: 0.464904\n",
      "Train Epoch: 462 [640/1612 (40%)] Loss: 0.593818\n",
      "Train Epoch: 462 [800/1612 (50%)] Loss: 0.221473\n",
      "Train Epoch: 462 [960/1612 (59%)] Loss: 0.426752\n",
      "Train Epoch: 462 [1120/1612 (69%)] Loss: 0.177564\n",
      "Train Epoch: 462 [1280/1612 (79%)] Loss: 0.386154\n",
      "Train Epoch: 462 [1440/1612 (89%)] Loss: 0.521956\n",
      "Train Epoch: 462 [1200/1612 (99%)] Loss: 0.286308\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 463 [0/1612 (0%)] Loss: 0.144529\n",
      "Train Epoch: 463 [160/1612 (10%)] Loss: 0.231056\n",
      "Train Epoch: 463 [320/1612 (20%)] Loss: 0.364409\n",
      "Train Epoch: 463 [480/1612 (30%)] Loss: 0.341988\n",
      "Train Epoch: 463 [640/1612 (40%)] Loss: 0.224461\n",
      "Train Epoch: 463 [800/1612 (50%)] Loss: 0.153200\n",
      "Train Epoch: 463 [960/1612 (59%)] Loss: 0.287810\n",
      "Train Epoch: 463 [1120/1612 (69%)] Loss: 0.284692\n",
      "Train Epoch: 463 [1280/1612 (79%)] Loss: 0.429860\n",
      "Train Epoch: 463 [1440/1612 (89%)] Loss: 0.583322\n",
      "Train Epoch: 463 [1200/1612 (99%)] Loss: 0.150558\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 464 [0/1612 (0%)] Loss: 0.281592\n",
      "Train Epoch: 464 [160/1612 (10%)] Loss: 0.301681\n",
      "Train Epoch: 464 [320/1612 (20%)] Loss: 0.293073\n",
      "Train Epoch: 464 [480/1612 (30%)] Loss: 0.372895\n",
      "Train Epoch: 464 [640/1612 (40%)] Loss: 0.406947\n",
      "Train Epoch: 464 [800/1612 (50%)] Loss: 0.178434\n",
      "Train Epoch: 464 [960/1612 (59%)] Loss: 0.351182\n",
      "Train Epoch: 464 [1120/1612 (69%)] Loss: 0.213932\n",
      "Train Epoch: 464 [1280/1612 (79%)] Loss: 0.636202\n",
      "Train Epoch: 464 [1440/1612 (89%)] Loss: 0.351600\n",
      "Train Epoch: 464 [1200/1612 (99%)] Loss: 0.287204\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 465 [0/1612 (0%)] Loss: 0.308268\n",
      "Train Epoch: 465 [160/1612 (10%)] Loss: 0.364482\n",
      "Train Epoch: 465 [320/1612 (20%)] Loss: 0.144093\n",
      "Train Epoch: 465 [480/1612 (30%)] Loss: 0.281096\n",
      "Train Epoch: 465 [640/1612 (40%)] Loss: 0.126293\n",
      "Train Epoch: 465 [800/1612 (50%)] Loss: 0.206849\n",
      "Train Epoch: 465 [960/1612 (59%)] Loss: 0.287029\n",
      "Train Epoch: 465 [1120/1612 (69%)] Loss: 0.433503\n",
      "Train Epoch: 465 [1280/1612 (79%)] Loss: 0.388135\n",
      "Train Epoch: 465 [1440/1612 (89%)] Loss: 0.609734\n",
      "Train Epoch: 465 [1200/1612 (99%)] Loss: 0.479998\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 466 [0/1612 (0%)] Loss: 0.305396\n",
      "Train Epoch: 466 [160/1612 (10%)] Loss: 0.396472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 466 [320/1612 (20%)] Loss: 0.351681\n",
      "Train Epoch: 466 [480/1612 (30%)] Loss: 0.426554\n",
      "Train Epoch: 466 [640/1612 (40%)] Loss: 0.475358\n",
      "Train Epoch: 466 [800/1612 (50%)] Loss: 0.292094\n",
      "Train Epoch: 466 [960/1612 (59%)] Loss: 0.302468\n",
      "Train Epoch: 466 [1120/1612 (69%)] Loss: 0.350045\n",
      "Train Epoch: 466 [1280/1612 (79%)] Loss: 0.410387\n",
      "Train Epoch: 466 [1440/1612 (89%)] Loss: 0.226066\n",
      "Train Epoch: 466 [1200/1612 (99%)] Loss: 0.133728\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 467 [0/1612 (0%)] Loss: 0.425379\n",
      "Train Epoch: 467 [160/1612 (10%)] Loss: 0.321806\n",
      "Train Epoch: 467 [320/1612 (20%)] Loss: 0.195945\n",
      "Train Epoch: 467 [480/1612 (30%)] Loss: 0.217079\n",
      "Train Epoch: 467 [640/1612 (40%)] Loss: 0.388836\n",
      "Train Epoch: 467 [800/1612 (50%)] Loss: 0.184403\n",
      "Train Epoch: 467 [960/1612 (59%)] Loss: 0.629394\n",
      "Train Epoch: 467 [1120/1612 (69%)] Loss: 0.493383\n",
      "Train Epoch: 467 [1280/1612 (79%)] Loss: 0.329197\n",
      "Train Epoch: 467 [1440/1612 (89%)] Loss: 0.204492\n",
      "Train Epoch: 467 [1200/1612 (99%)] Loss: 0.402308\n",
      "\n",
      "Test set: Average loss: 0.0242, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 468 [0/1612 (0%)] Loss: 0.179387\n",
      "Train Epoch: 468 [160/1612 (10%)] Loss: 0.350641\n",
      "Train Epoch: 468 [320/1612 (20%)] Loss: 0.245903\n",
      "Train Epoch: 468 [480/1612 (30%)] Loss: 0.362216\n",
      "Train Epoch: 468 [640/1612 (40%)] Loss: 0.219110\n",
      "Train Epoch: 468 [800/1612 (50%)] Loss: 0.323841\n",
      "Train Epoch: 468 [960/1612 (59%)] Loss: 0.305864\n",
      "Train Epoch: 468 [1120/1612 (69%)] Loss: 0.215321\n",
      "Train Epoch: 468 [1280/1612 (79%)] Loss: 0.441009\n",
      "Train Epoch: 468 [1440/1612 (89%)] Loss: 0.535548\n",
      "Train Epoch: 468 [1200/1612 (99%)] Loss: 0.245701\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 469 [0/1612 (0%)] Loss: 0.283302\n",
      "Train Epoch: 469 [160/1612 (10%)] Loss: 0.222076\n",
      "Train Epoch: 469 [320/1612 (20%)] Loss: 0.519686\n",
      "Train Epoch: 469 [480/1612 (30%)] Loss: 0.368181\n",
      "Train Epoch: 469 [640/1612 (40%)] Loss: 0.405022\n",
      "Train Epoch: 469 [800/1612 (50%)] Loss: 0.154251\n",
      "Train Epoch: 469 [960/1612 (59%)] Loss: 0.726941\n",
      "Train Epoch: 469 [1120/1612 (69%)] Loss: 0.220133\n",
      "Train Epoch: 469 [1280/1612 (79%)] Loss: 0.440122\n",
      "Train Epoch: 469 [1440/1612 (89%)] Loss: 0.299883\n",
      "Train Epoch: 469 [1200/1612 (99%)] Loss: 0.341414\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 470 [0/1612 (0%)] Loss: 0.267469\n",
      "Train Epoch: 470 [160/1612 (10%)] Loss: 0.442322\n",
      "Train Epoch: 470 [320/1612 (20%)] Loss: 0.293357\n",
      "Train Epoch: 470 [480/1612 (30%)] Loss: 0.214876\n",
      "Train Epoch: 470 [640/1612 (40%)] Loss: 0.431725\n",
      "Train Epoch: 470 [800/1612 (50%)] Loss: 0.315801\n",
      "Train Epoch: 470 [960/1612 (59%)] Loss: 0.367011\n",
      "Train Epoch: 470 [1120/1612 (69%)] Loss: 0.330247\n",
      "Train Epoch: 470 [1280/1612 (79%)] Loss: 0.297951\n",
      "Train Epoch: 470 [1440/1612 (89%)] Loss: 0.313501\n",
      "Train Epoch: 470 [1200/1612 (99%)] Loss: 0.309963\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 471 [0/1612 (0%)] Loss: 0.411558\n",
      "Train Epoch: 471 [160/1612 (10%)] Loss: 0.225192\n",
      "Train Epoch: 471 [320/1612 (20%)] Loss: 0.178423\n",
      "Train Epoch: 471 [480/1612 (30%)] Loss: 0.302185\n",
      "Train Epoch: 471 [640/1612 (40%)] Loss: 0.183495\n",
      "Train Epoch: 471 [800/1612 (50%)] Loss: 0.174438\n",
      "Train Epoch: 471 [960/1612 (59%)] Loss: 0.117184\n",
      "Train Epoch: 471 [1120/1612 (69%)] Loss: 0.344608\n",
      "Train Epoch: 471 [1280/1612 (79%)] Loss: 0.511377\n",
      "Train Epoch: 471 [1440/1612 (89%)] Loss: 0.237830\n",
      "Train Epoch: 471 [1200/1612 (99%)] Loss: 0.320716\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 472 [0/1612 (0%)] Loss: 0.164912\n",
      "Train Epoch: 472 [160/1612 (10%)] Loss: 0.401107\n",
      "Train Epoch: 472 [320/1612 (20%)] Loss: 0.271589\n",
      "Train Epoch: 472 [480/1612 (30%)] Loss: 0.275898\n",
      "Train Epoch: 472 [640/1612 (40%)] Loss: 0.257495\n",
      "Train Epoch: 472 [800/1612 (50%)] Loss: 0.285272\n",
      "Train Epoch: 472 [960/1612 (59%)] Loss: 0.661326\n",
      "Train Epoch: 472 [1120/1612 (69%)] Loss: 0.181526\n",
      "Train Epoch: 472 [1280/1612 (79%)] Loss: 0.118132\n",
      "Train Epoch: 472 [1440/1612 (89%)] Loss: 0.302462\n",
      "Train Epoch: 472 [1200/1612 (99%)] Loss: 0.389278\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 473 [0/1612 (0%)] Loss: 0.268615\n",
      "Train Epoch: 473 [160/1612 (10%)] Loss: 0.214859\n",
      "Train Epoch: 473 [320/1612 (20%)] Loss: 0.345518\n",
      "Train Epoch: 473 [480/1612 (30%)] Loss: 0.373195\n",
      "Train Epoch: 473 [640/1612 (40%)] Loss: 0.262740\n",
      "Train Epoch: 473 [800/1612 (50%)] Loss: 0.300336\n",
      "Train Epoch: 473 [960/1612 (59%)] Loss: 0.261045\n",
      "Train Epoch: 473 [1120/1612 (69%)] Loss: 0.242730\n",
      "Train Epoch: 473 [1280/1612 (79%)] Loss: 0.372549\n",
      "Train Epoch: 473 [1440/1612 (89%)] Loss: 0.466484\n",
      "Train Epoch: 473 [1200/1612 (99%)] Loss: 0.118620\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 474 [0/1612 (0%)] Loss: 0.212503\n",
      "Train Epoch: 474 [160/1612 (10%)] Loss: 0.540622\n",
      "Train Epoch: 474 [320/1612 (20%)] Loss: 0.220136\n",
      "Train Epoch: 474 [480/1612 (30%)] Loss: 0.297377\n",
      "Train Epoch: 474 [640/1612 (40%)] Loss: 0.213455\n",
      "Train Epoch: 474 [800/1612 (50%)] Loss: 0.247170\n",
      "Train Epoch: 474 [960/1612 (59%)] Loss: 0.198427\n",
      "Train Epoch: 474 [1120/1612 (69%)] Loss: 0.455807\n",
      "Train Epoch: 474 [1280/1612 (79%)] Loss: 0.252162\n",
      "Train Epoch: 474 [1440/1612 (89%)] Loss: 0.141049\n",
      "Train Epoch: 474 [1200/1612 (99%)] Loss: 0.196894\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 475 [0/1612 (0%)] Loss: 0.339230\n",
      "Train Epoch: 475 [160/1612 (10%)] Loss: 0.288670\n",
      "Train Epoch: 475 [320/1612 (20%)] Loss: 0.504287\n",
      "Train Epoch: 475 [480/1612 (30%)] Loss: 0.152425\n",
      "Train Epoch: 475 [640/1612 (40%)] Loss: 0.457363\n",
      "Train Epoch: 475 [800/1612 (50%)] Loss: 0.158615\n",
      "Train Epoch: 475 [960/1612 (59%)] Loss: 0.803671\n",
      "Train Epoch: 475 [1120/1612 (69%)] Loss: 0.151956\n",
      "Train Epoch: 475 [1280/1612 (79%)] Loss: 0.365223\n",
      "Train Epoch: 475 [1440/1612 (89%)] Loss: 0.451599\n",
      "Train Epoch: 475 [1200/1612 (99%)] Loss: 0.332348\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 476 [0/1612 (0%)] Loss: 0.367493\n",
      "Train Epoch: 476 [160/1612 (10%)] Loss: 0.534299\n",
      "Train Epoch: 476 [320/1612 (20%)] Loss: 0.295934\n",
      "Train Epoch: 476 [480/1612 (30%)] Loss: 0.228279\n",
      "Train Epoch: 476 [640/1612 (40%)] Loss: 0.427429\n",
      "Train Epoch: 476 [800/1612 (50%)] Loss: 0.448794\n",
      "Train Epoch: 476 [960/1612 (59%)] Loss: 0.230645\n",
      "Train Epoch: 476 [1120/1612 (69%)] Loss: 0.162078\n",
      "Train Epoch: 476 [1280/1612 (79%)] Loss: 0.436264\n",
      "Train Epoch: 476 [1440/1612 (89%)] Loss: 0.410962\n",
      "Train Epoch: 476 [1200/1612 (99%)] Loss: 0.543583\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 477 [0/1612 (0%)] Loss: 0.625602\n",
      "Train Epoch: 477 [160/1612 (10%)] Loss: 0.361961\n",
      "Train Epoch: 477 [320/1612 (20%)] Loss: 0.453719\n",
      "Train Epoch: 477 [480/1612 (30%)] Loss: 0.380025\n",
      "Train Epoch: 477 [640/1612 (40%)] Loss: 0.156996\n",
      "Train Epoch: 477 [800/1612 (50%)] Loss: 0.179594\n",
      "Train Epoch: 477 [960/1612 (59%)] Loss: 0.623837\n",
      "Train Epoch: 477 [1120/1612 (69%)] Loss: 0.135942\n",
      "Train Epoch: 477 [1280/1612 (79%)] Loss: 0.251754\n",
      "Train Epoch: 477 [1440/1612 (89%)] Loss: 0.401240\n",
      "Train Epoch: 477 [1200/1612 (99%)] Loss: 0.270662\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 478 [0/1612 (0%)] Loss: 0.177071\n",
      "Train Epoch: 478 [160/1612 (10%)] Loss: 0.260406\n",
      "Train Epoch: 478 [320/1612 (20%)] Loss: 0.316620\n",
      "Train Epoch: 478 [480/1612 (30%)] Loss: 0.424087\n",
      "Train Epoch: 478 [640/1612 (40%)] Loss: 0.219138\n",
      "Train Epoch: 478 [800/1612 (50%)] Loss: 0.427018\n",
      "Train Epoch: 478 [960/1612 (59%)] Loss: 0.236517\n",
      "Train Epoch: 478 [1120/1612 (69%)] Loss: 0.321070\n",
      "Train Epoch: 478 [1280/1612 (79%)] Loss: 0.197419\n",
      "Train Epoch: 478 [1440/1612 (89%)] Loss: 0.344649\n",
      "Train Epoch: 478 [1200/1612 (99%)] Loss: 0.176495\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 479 [0/1612 (0%)] Loss: 0.491790\n",
      "Train Epoch: 479 [160/1612 (10%)] Loss: 0.294868\n",
      "Train Epoch: 479 [320/1612 (20%)] Loss: 0.320422\n",
      "Train Epoch: 479 [480/1612 (30%)] Loss: 0.385571\n",
      "Train Epoch: 479 [640/1612 (40%)] Loss: 0.599391\n",
      "Train Epoch: 479 [800/1612 (50%)] Loss: 0.553475\n",
      "Train Epoch: 479 [960/1612 (59%)] Loss: 0.353176\n",
      "Train Epoch: 479 [1120/1612 (69%)] Loss: 0.238910\n",
      "Train Epoch: 479 [1280/1612 (79%)] Loss: 0.331291\n",
      "Train Epoch: 479 [1440/1612 (89%)] Loss: 0.602251\n",
      "Train Epoch: 479 [1200/1612 (99%)] Loss: 0.180508\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 480 [0/1612 (0%)] Loss: 0.228395\n",
      "Train Epoch: 480 [160/1612 (10%)] Loss: 0.408968\n",
      "Train Epoch: 480 [320/1612 (20%)] Loss: 0.491800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 480 [480/1612 (30%)] Loss: 0.405122\n",
      "Train Epoch: 480 [640/1612 (40%)] Loss: 0.371067\n",
      "Train Epoch: 480 [800/1612 (50%)] Loss: 0.306078\n",
      "Train Epoch: 480 [960/1612 (59%)] Loss: 0.151098\n",
      "Train Epoch: 480 [1120/1612 (69%)] Loss: 0.593469\n",
      "Train Epoch: 480 [1280/1612 (79%)] Loss: 0.367330\n",
      "Train Epoch: 480 [1440/1612 (89%)] Loss: 0.229089\n",
      "Train Epoch: 480 [1200/1612 (99%)] Loss: 0.291088\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 481 [0/1612 (0%)] Loss: 0.291373\n",
      "Train Epoch: 481 [160/1612 (10%)] Loss: 0.185649\n",
      "Train Epoch: 481 [320/1612 (20%)] Loss: 0.165719\n",
      "Train Epoch: 481 [480/1612 (30%)] Loss: 0.335530\n",
      "Train Epoch: 481 [640/1612 (40%)] Loss: 0.641791\n",
      "Train Epoch: 481 [800/1612 (50%)] Loss: 0.453261\n",
      "Train Epoch: 481 [960/1612 (59%)] Loss: 0.150353\n",
      "Train Epoch: 481 [1120/1612 (69%)] Loss: 0.403695\n",
      "Train Epoch: 481 [1280/1612 (79%)] Loss: 0.256916\n",
      "Train Epoch: 481 [1440/1612 (89%)] Loss: 0.404277\n",
      "Train Epoch: 481 [1200/1612 (99%)] Loss: 0.171960\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 482 [0/1612 (0%)] Loss: 0.262935\n",
      "Train Epoch: 482 [160/1612 (10%)] Loss: 0.172512\n",
      "Train Epoch: 482 [320/1612 (20%)] Loss: 0.164399\n",
      "Train Epoch: 482 [480/1612 (30%)] Loss: 0.098630\n",
      "Train Epoch: 482 [640/1612 (40%)] Loss: 0.108373\n",
      "Train Epoch: 482 [800/1612 (50%)] Loss: 0.550511\n",
      "Train Epoch: 482 [960/1612 (59%)] Loss: 0.259629\n",
      "Train Epoch: 482 [1120/1612 (69%)] Loss: 0.233362\n",
      "Train Epoch: 482 [1280/1612 (79%)] Loss: 0.286834\n",
      "Train Epoch: 482 [1440/1612 (89%)] Loss: 0.303605\n",
      "Train Epoch: 482 [1200/1612 (99%)] Loss: 0.215887\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 483 [0/1612 (0%)] Loss: 0.336209\n",
      "Train Epoch: 483 [160/1612 (10%)] Loss: 0.236078\n",
      "Train Epoch: 483 [320/1612 (20%)] Loss: 0.125742\n",
      "Train Epoch: 483 [480/1612 (30%)] Loss: 0.173543\n",
      "Train Epoch: 483 [640/1612 (40%)] Loss: 0.330112\n",
      "Train Epoch: 483 [800/1612 (50%)] Loss: 0.202872\n",
      "Train Epoch: 483 [960/1612 (59%)] Loss: 0.440454\n",
      "Train Epoch: 483 [1120/1612 (69%)] Loss: 0.163501\n",
      "Train Epoch: 483 [1280/1612 (79%)] Loss: 0.257849\n",
      "Train Epoch: 483 [1440/1612 (89%)] Loss: 0.138205\n",
      "Train Epoch: 483 [1200/1612 (99%)] Loss: 0.357968\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 484 [0/1612 (0%)] Loss: 0.378477\n",
      "Train Epoch: 484 [160/1612 (10%)] Loss: 0.352155\n",
      "Train Epoch: 484 [320/1612 (20%)] Loss: 0.419038\n",
      "Train Epoch: 484 [480/1612 (30%)] Loss: 0.337883\n",
      "Train Epoch: 484 [640/1612 (40%)] Loss: 0.124775\n",
      "Train Epoch: 484 [800/1612 (50%)] Loss: 0.392806\n",
      "Train Epoch: 484 [960/1612 (59%)] Loss: 0.428925\n",
      "Train Epoch: 484 [1120/1612 (69%)] Loss: 0.453529\n",
      "Train Epoch: 484 [1280/1612 (79%)] Loss: 0.316920\n",
      "Train Epoch: 484 [1440/1612 (89%)] Loss: 0.537926\n",
      "Train Epoch: 484 [1200/1612 (99%)] Loss: 0.367059\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 485 [0/1612 (0%)] Loss: 0.370663\n",
      "Train Epoch: 485 [160/1612 (10%)] Loss: 0.346491\n",
      "Train Epoch: 485 [320/1612 (20%)] Loss: 0.375404\n",
      "Train Epoch: 485 [480/1612 (30%)] Loss: 0.446903\n",
      "Train Epoch: 485 [640/1612 (40%)] Loss: 0.336990\n",
      "Train Epoch: 485 [800/1612 (50%)] Loss: 0.257390\n",
      "Train Epoch: 485 [960/1612 (59%)] Loss: 0.228378\n",
      "Train Epoch: 485 [1120/1612 (69%)] Loss: 0.332356\n",
      "Train Epoch: 485 [1280/1612 (79%)] Loss: 0.273505\n",
      "Train Epoch: 485 [1440/1612 (89%)] Loss: 0.310087\n",
      "Train Epoch: 485 [1200/1612 (99%)] Loss: 0.525958\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 486 [0/1612 (0%)] Loss: 0.224700\n",
      "Train Epoch: 486 [160/1612 (10%)] Loss: 0.511800\n",
      "Train Epoch: 486 [320/1612 (20%)] Loss: 0.255915\n",
      "Train Epoch: 486 [480/1612 (30%)] Loss: 0.306906\n",
      "Train Epoch: 486 [640/1612 (40%)] Loss: 0.285634\n",
      "Train Epoch: 486 [800/1612 (50%)] Loss: 0.223787\n",
      "Train Epoch: 486 [960/1612 (59%)] Loss: 0.448630\n",
      "Train Epoch: 486 [1120/1612 (69%)] Loss: 0.162996\n",
      "Train Epoch: 486 [1280/1612 (79%)] Loss: 0.119555\n",
      "Train Epoch: 486 [1440/1612 (89%)] Loss: 0.469676\n",
      "Train Epoch: 486 [1200/1612 (99%)] Loss: 0.054857\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 487 [0/1612 (0%)] Loss: 0.515765\n",
      "Train Epoch: 487 [160/1612 (10%)] Loss: 0.245716\n",
      "Train Epoch: 487 [320/1612 (20%)] Loss: 0.165114\n",
      "Train Epoch: 487 [480/1612 (30%)] Loss: 0.236037\n",
      "Train Epoch: 487 [640/1612 (40%)] Loss: 0.233890\n",
      "Train Epoch: 487 [800/1612 (50%)] Loss: 0.442767\n",
      "Train Epoch: 487 [960/1612 (59%)] Loss: 0.345723\n",
      "Train Epoch: 487 [1120/1612 (69%)] Loss: 0.526963\n",
      "Train Epoch: 487 [1280/1612 (79%)] Loss: 0.173023\n",
      "Train Epoch: 487 [1440/1612 (89%)] Loss: 0.232173\n",
      "Train Epoch: 487 [1200/1612 (99%)] Loss: 0.128655\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 488 [0/1612 (0%)] Loss: 0.427378\n",
      "Train Epoch: 488 [160/1612 (10%)] Loss: 0.436220\n",
      "Train Epoch: 488 [320/1612 (20%)] Loss: 0.403057\n",
      "Train Epoch: 488 [480/1612 (30%)] Loss: 0.318447\n",
      "Train Epoch: 488 [640/1612 (40%)] Loss: 0.320909\n",
      "Train Epoch: 488 [800/1612 (50%)] Loss: 0.250726\n",
      "Train Epoch: 488 [960/1612 (59%)] Loss: 0.163055\n",
      "Train Epoch: 488 [1120/1612 (69%)] Loss: 0.276882\n",
      "Train Epoch: 488 [1280/1612 (79%)] Loss: 0.070634\n",
      "Train Epoch: 488 [1440/1612 (89%)] Loss: 0.194410\n",
      "Train Epoch: 488 [1200/1612 (99%)] Loss: 0.561561\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 489 [0/1612 (0%)] Loss: 0.218712\n",
      "Train Epoch: 489 [160/1612 (10%)] Loss: 0.234900\n",
      "Train Epoch: 489 [320/1612 (20%)] Loss: 0.459624\n",
      "Train Epoch: 489 [480/1612 (30%)] Loss: 0.229735\n",
      "Train Epoch: 489 [640/1612 (40%)] Loss: 0.209831\n",
      "Train Epoch: 489 [800/1612 (50%)] Loss: 0.237965\n",
      "Train Epoch: 489 [960/1612 (59%)] Loss: 0.281738\n",
      "Train Epoch: 489 [1120/1612 (69%)] Loss: 0.271302\n",
      "Train Epoch: 489 [1280/1612 (79%)] Loss: 0.279808\n",
      "Train Epoch: 489 [1440/1612 (89%)] Loss: 0.297318\n",
      "Train Epoch: 489 [1200/1612 (99%)] Loss: 0.125694\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 490 [0/1612 (0%)] Loss: 0.254592\n",
      "Train Epoch: 490 [160/1612 (10%)] Loss: 0.162343\n",
      "Train Epoch: 490 [320/1612 (20%)] Loss: 0.379610\n",
      "Train Epoch: 490 [480/1612 (30%)] Loss: 0.350223\n",
      "Train Epoch: 490 [640/1612 (40%)] Loss: 0.370368\n",
      "Train Epoch: 490 [800/1612 (50%)] Loss: 0.540939\n",
      "Train Epoch: 490 [960/1612 (59%)] Loss: 0.250708\n",
      "Train Epoch: 490 [1120/1612 (69%)] Loss: 0.286231\n",
      "Train Epoch: 490 [1280/1612 (79%)] Loss: 0.311483\n",
      "Train Epoch: 490 [1440/1612 (89%)] Loss: 0.491938\n",
      "Train Epoch: 490 [1200/1612 (99%)] Loss: 0.336803\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 491 [0/1612 (0%)] Loss: 0.254958\n",
      "Train Epoch: 491 [160/1612 (10%)] Loss: 0.212459\n",
      "Train Epoch: 491 [320/1612 (20%)] Loss: 0.410994\n",
      "Train Epoch: 491 [480/1612 (30%)] Loss: 0.527461\n",
      "Train Epoch: 491 [640/1612 (40%)] Loss: 0.404930\n",
      "Train Epoch: 491 [800/1612 (50%)] Loss: 0.463998\n",
      "Train Epoch: 491 [960/1612 (59%)] Loss: 0.399849\n",
      "Train Epoch: 491 [1120/1612 (69%)] Loss: 0.381072\n",
      "Train Epoch: 491 [1280/1612 (79%)] Loss: 0.328542\n",
      "Train Epoch: 491 [1440/1612 (89%)] Loss: 0.302804\n",
      "Train Epoch: 491 [1200/1612 (99%)] Loss: 0.465374\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 492 [0/1612 (0%)] Loss: 0.700446\n",
      "Train Epoch: 492 [160/1612 (10%)] Loss: 0.289566\n",
      "Train Epoch: 492 [320/1612 (20%)] Loss: 0.358228\n",
      "Train Epoch: 492 [480/1612 (30%)] Loss: 0.297857\n",
      "Train Epoch: 492 [640/1612 (40%)] Loss: 0.320551\n",
      "Train Epoch: 492 [800/1612 (50%)] Loss: 0.163835\n",
      "Train Epoch: 492 [960/1612 (59%)] Loss: 0.252144\n",
      "Train Epoch: 492 [1120/1612 (69%)] Loss: 0.350406\n",
      "Train Epoch: 492 [1280/1612 (79%)] Loss: 0.210758\n",
      "Train Epoch: 492 [1440/1612 (89%)] Loss: 0.172771\n",
      "Train Epoch: 492 [1200/1612 (99%)] Loss: 0.415898\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 493 [0/1612 (0%)] Loss: 0.137020\n",
      "Train Epoch: 493 [160/1612 (10%)] Loss: 0.231951\n",
      "Train Epoch: 493 [320/1612 (20%)] Loss: 0.284728\n",
      "Train Epoch: 493 [480/1612 (30%)] Loss: 0.706092\n",
      "Train Epoch: 493 [640/1612 (40%)] Loss: 0.289209\n",
      "Train Epoch: 493 [800/1612 (50%)] Loss: 0.322823\n",
      "Train Epoch: 493 [960/1612 (59%)] Loss: 0.600272\n",
      "Train Epoch: 493 [1120/1612 (69%)] Loss: 0.135182\n",
      "Train Epoch: 493 [1280/1612 (79%)] Loss: 0.333906\n",
      "Train Epoch: 493 [1440/1612 (89%)] Loss: 0.353055\n",
      "Train Epoch: 493 [1200/1612 (99%)] Loss: 0.208173\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 494 [0/1612 (0%)] Loss: 0.498299\n",
      "Train Epoch: 494 [160/1612 (10%)] Loss: 0.200799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 494 [320/1612 (20%)] Loss: 0.379062\n",
      "Train Epoch: 494 [480/1612 (30%)] Loss: 0.150271\n",
      "Train Epoch: 494 [640/1612 (40%)] Loss: 0.196331\n",
      "Train Epoch: 494 [800/1612 (50%)] Loss: 0.355333\n",
      "Train Epoch: 494 [960/1612 (59%)] Loss: 0.667498\n",
      "Train Epoch: 494 [1120/1612 (69%)] Loss: 0.438021\n",
      "Train Epoch: 494 [1280/1612 (79%)] Loss: 0.294175\n",
      "Train Epoch: 494 [1440/1612 (89%)] Loss: 0.203499\n",
      "Train Epoch: 494 [1200/1612 (99%)] Loss: 0.525657\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 495 [0/1612 (0%)] Loss: 0.256004\n",
      "Train Epoch: 495 [160/1612 (10%)] Loss: 0.172816\n",
      "Train Epoch: 495 [320/1612 (20%)] Loss: 0.252098\n",
      "Train Epoch: 495 [480/1612 (30%)] Loss: 0.227466\n",
      "Train Epoch: 495 [640/1612 (40%)] Loss: 0.137381\n",
      "Train Epoch: 495 [800/1612 (50%)] Loss: 0.228593\n",
      "Train Epoch: 495 [960/1612 (59%)] Loss: 0.263451\n",
      "Train Epoch: 495 [1120/1612 (69%)] Loss: 0.515221\n",
      "Train Epoch: 495 [1280/1612 (79%)] Loss: 0.272376\n",
      "Train Epoch: 495 [1440/1612 (89%)] Loss: 0.603641\n",
      "Train Epoch: 495 [1200/1612 (99%)] Loss: 0.167388\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 496 [0/1612 (0%)] Loss: 0.535912\n",
      "Train Epoch: 496 [160/1612 (10%)] Loss: 0.627226\n",
      "Train Epoch: 496 [320/1612 (20%)] Loss: 0.141412\n",
      "Train Epoch: 496 [480/1612 (30%)] Loss: 0.347409\n",
      "Train Epoch: 496 [640/1612 (40%)] Loss: 0.295210\n",
      "Train Epoch: 496 [800/1612 (50%)] Loss: 0.192534\n",
      "Train Epoch: 496 [960/1612 (59%)] Loss: 0.373610\n",
      "Train Epoch: 496 [1120/1612 (69%)] Loss: 0.272800\n",
      "Train Epoch: 496 [1280/1612 (79%)] Loss: 0.519945\n",
      "Train Epoch: 496 [1440/1612 (89%)] Loss: 0.155155\n",
      "Train Epoch: 496 [1200/1612 (99%)] Loss: 0.585477\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 497 [0/1612 (0%)] Loss: 0.373257\n",
      "Train Epoch: 497 [160/1612 (10%)] Loss: 0.197855\n",
      "Train Epoch: 497 [320/1612 (20%)] Loss: 0.089642\n",
      "Train Epoch: 497 [480/1612 (30%)] Loss: 0.210860\n",
      "Train Epoch: 497 [640/1612 (40%)] Loss: 0.528735\n",
      "Train Epoch: 497 [800/1612 (50%)] Loss: 0.399432\n",
      "Train Epoch: 497 [960/1612 (59%)] Loss: 0.390418\n",
      "Train Epoch: 497 [1120/1612 (69%)] Loss: 0.313070\n",
      "Train Epoch: 497 [1280/1612 (79%)] Loss: 0.438482\n",
      "Train Epoch: 497 [1440/1612 (89%)] Loss: 0.431493\n",
      "Train Epoch: 497 [1200/1612 (99%)] Loss: 0.624876\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 498 [0/1612 (0%)] Loss: 0.319548\n",
      "Train Epoch: 498 [160/1612 (10%)] Loss: 0.237225\n",
      "Train Epoch: 498 [320/1612 (20%)] Loss: 0.323031\n",
      "Train Epoch: 498 [480/1612 (30%)] Loss: 0.437212\n",
      "Train Epoch: 498 [640/1612 (40%)] Loss: 0.291389\n",
      "Train Epoch: 498 [800/1612 (50%)] Loss: 0.274037\n",
      "Train Epoch: 498 [960/1612 (59%)] Loss: 0.230338\n",
      "Train Epoch: 498 [1120/1612 (69%)] Loss: 0.262260\n",
      "Train Epoch: 498 [1280/1612 (79%)] Loss: 0.375277\n",
      "Train Epoch: 498 [1440/1612 (89%)] Loss: 0.282316\n",
      "Train Epoch: 498 [1200/1612 (99%)] Loss: 0.153960\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 499 [0/1612 (0%)] Loss: 0.189314\n",
      "Train Epoch: 499 [160/1612 (10%)] Loss: 0.299506\n",
      "Train Epoch: 499 [320/1612 (20%)] Loss: 0.221777\n",
      "Train Epoch: 499 [480/1612 (30%)] Loss: 0.588224\n",
      "Train Epoch: 499 [640/1612 (40%)] Loss: 0.317233\n",
      "Train Epoch: 499 [800/1612 (50%)] Loss: 0.200032\n",
      "Train Epoch: 499 [960/1612 (59%)] Loss: 0.133181\n",
      "Train Epoch: 499 [1120/1612 (69%)] Loss: 0.347314\n",
      "Train Epoch: 499 [1280/1612 (79%)] Loss: 0.246466\n",
      "Train Epoch: 499 [1440/1612 (89%)] Loss: 0.306015\n",
      "Train Epoch: 499 [1200/1612 (99%)] Loss: 0.495604\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 500 [0/1612 (0%)] Loss: 0.338295\n",
      "Train Epoch: 500 [160/1612 (10%)] Loss: 0.246248\n",
      "Train Epoch: 500 [320/1612 (20%)] Loss: 0.667890\n",
      "Train Epoch: 500 [480/1612 (30%)] Loss: 0.207387\n",
      "Train Epoch: 500 [640/1612 (40%)] Loss: 0.180776\n",
      "Train Epoch: 500 [800/1612 (50%)] Loss: 0.567877\n",
      "Train Epoch: 500 [960/1612 (59%)] Loss: 0.400268\n",
      "Train Epoch: 500 [1120/1612 (69%)] Loss: 0.315161\n",
      "Train Epoch: 500 [1280/1612 (79%)] Loss: 0.273772\n",
      "Train Epoch: 500 [1440/1612 (89%)] Loss: 0.360710\n",
      "Train Epoch: 500 [1200/1612 (99%)] Loss: 0.165815\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 501 [0/1612 (0%)] Loss: 0.309740\n",
      "Train Epoch: 501 [160/1612 (10%)] Loss: 0.486440\n",
      "Train Epoch: 501 [320/1612 (20%)] Loss: 0.193295\n",
      "Train Epoch: 501 [480/1612 (30%)] Loss: 0.246482\n",
      "Train Epoch: 501 [640/1612 (40%)] Loss: 0.199436\n",
      "Train Epoch: 501 [800/1612 (50%)] Loss: 0.303947\n",
      "Train Epoch: 501 [960/1612 (59%)] Loss: 0.551130\n",
      "Train Epoch: 501 [1120/1612 (69%)] Loss: 0.157726\n",
      "Train Epoch: 501 [1280/1612 (79%)] Loss: 0.332816\n",
      "Train Epoch: 501 [1440/1612 (89%)] Loss: 0.257356\n",
      "Train Epoch: 501 [1200/1612 (99%)] Loss: 0.498351\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 502 [0/1612 (0%)] Loss: 0.118095\n",
      "Train Epoch: 502 [160/1612 (10%)] Loss: 0.255015\n",
      "Train Epoch: 502 [320/1612 (20%)] Loss: 0.258180\n",
      "Train Epoch: 502 [480/1612 (30%)] Loss: 0.220684\n",
      "Train Epoch: 502 [640/1612 (40%)] Loss: 0.295811\n",
      "Train Epoch: 502 [800/1612 (50%)] Loss: 0.507309\n",
      "Train Epoch: 502 [960/1612 (59%)] Loss: 0.276642\n",
      "Train Epoch: 502 [1120/1612 (69%)] Loss: 0.610543\n",
      "Train Epoch: 502 [1280/1612 (79%)] Loss: 0.325851\n",
      "Train Epoch: 502 [1440/1612 (89%)] Loss: 0.445054\n",
      "Train Epoch: 502 [1200/1612 (99%)] Loss: 0.491323\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 503 [0/1612 (0%)] Loss: 0.093200\n",
      "Train Epoch: 503 [160/1612 (10%)] Loss: 0.200689\n",
      "Train Epoch: 503 [320/1612 (20%)] Loss: 0.458360\n",
      "Train Epoch: 503 [480/1612 (30%)] Loss: 0.326433\n",
      "Train Epoch: 503 [640/1612 (40%)] Loss: 0.152815\n",
      "Train Epoch: 503 [800/1612 (50%)] Loss: 0.319337\n",
      "Train Epoch: 503 [960/1612 (59%)] Loss: 0.172915\n",
      "Train Epoch: 503 [1120/1612 (69%)] Loss: 0.353741\n",
      "Train Epoch: 503 [1280/1612 (79%)] Loss: 0.378585\n",
      "Train Epoch: 503 [1440/1612 (89%)] Loss: 0.680087\n",
      "Train Epoch: 503 [1200/1612 (99%)] Loss: 0.154830\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 504 [0/1612 (0%)] Loss: 0.190620\n",
      "Train Epoch: 504 [160/1612 (10%)] Loss: 0.144042\n",
      "Train Epoch: 504 [320/1612 (20%)] Loss: 0.328868\n",
      "Train Epoch: 504 [480/1612 (30%)] Loss: 0.512502\n",
      "Train Epoch: 504 [640/1612 (40%)] Loss: 0.171793\n",
      "Train Epoch: 504 [800/1612 (50%)] Loss: 0.371763\n",
      "Train Epoch: 504 [960/1612 (59%)] Loss: 0.210767\n",
      "Train Epoch: 504 [1120/1612 (69%)] Loss: 0.193495\n",
      "Train Epoch: 504 [1280/1612 (79%)] Loss: 0.274265\n",
      "Train Epoch: 504 [1440/1612 (89%)] Loss: 0.357460\n",
      "Train Epoch: 504 [1200/1612 (99%)] Loss: 0.192863\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 505 [0/1612 (0%)] Loss: 0.159906\n",
      "Train Epoch: 505 [160/1612 (10%)] Loss: 0.222139\n",
      "Train Epoch: 505 [320/1612 (20%)] Loss: 0.261801\n",
      "Train Epoch: 505 [480/1612 (30%)] Loss: 0.480082\n",
      "Train Epoch: 505 [640/1612 (40%)] Loss: 0.384660\n",
      "Train Epoch: 505 [800/1612 (50%)] Loss: 0.233271\n",
      "Train Epoch: 505 [960/1612 (59%)] Loss: 0.105214\n",
      "Train Epoch: 505 [1120/1612 (69%)] Loss: 0.247055\n",
      "Train Epoch: 505 [1280/1612 (79%)] Loss: 0.349926\n",
      "Train Epoch: 505 [1440/1612 (89%)] Loss: 0.427184\n",
      "Train Epoch: 505 [1200/1612 (99%)] Loss: 0.239798\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 506 [0/1612 (0%)] Loss: 0.298950\n",
      "Train Epoch: 506 [160/1612 (10%)] Loss: 0.467550\n",
      "Train Epoch: 506 [320/1612 (20%)] Loss: 0.558482\n",
      "Train Epoch: 506 [480/1612 (30%)] Loss: 0.300582\n",
      "Train Epoch: 506 [640/1612 (40%)] Loss: 0.251901\n",
      "Train Epoch: 506 [800/1612 (50%)] Loss: 0.152948\n",
      "Train Epoch: 506 [960/1612 (59%)] Loss: 0.258427\n",
      "Train Epoch: 506 [1120/1612 (69%)] Loss: 0.167538\n",
      "Train Epoch: 506 [1280/1612 (79%)] Loss: 0.622458\n",
      "Train Epoch: 506 [1440/1612 (89%)] Loss: 0.103771\n",
      "Train Epoch: 506 [1200/1612 (99%)] Loss: 0.164395\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 507 [0/1612 (0%)] Loss: 0.288484\n",
      "Train Epoch: 507 [160/1612 (10%)] Loss: 0.566980\n",
      "Train Epoch: 507 [320/1612 (20%)] Loss: 0.210070\n",
      "Train Epoch: 507 [480/1612 (30%)] Loss: 0.382341\n",
      "Train Epoch: 507 [640/1612 (40%)] Loss: 0.438848\n",
      "Train Epoch: 507 [800/1612 (50%)] Loss: 0.211462\n",
      "Train Epoch: 507 [960/1612 (59%)] Loss: 0.246033\n",
      "Train Epoch: 507 [1120/1612 (69%)] Loss: 0.120819\n",
      "Train Epoch: 507 [1280/1612 (79%)] Loss: 0.595425\n",
      "Train Epoch: 507 [1440/1612 (89%)] Loss: 0.199149\n",
      "Train Epoch: 507 [1200/1612 (99%)] Loss: 0.177424\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 508 [0/1612 (0%)] Loss: 0.494668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 508 [160/1612 (10%)] Loss: 0.243134\n",
      "Train Epoch: 508 [320/1612 (20%)] Loss: 0.190670\n",
      "Train Epoch: 508 [480/1612 (30%)] Loss: 0.172104\n",
      "Train Epoch: 508 [640/1612 (40%)] Loss: 0.207904\n",
      "Train Epoch: 508 [800/1612 (50%)] Loss: 0.484010\n",
      "Train Epoch: 508 [960/1612 (59%)] Loss: 0.345948\n",
      "Train Epoch: 508 [1120/1612 (69%)] Loss: 0.354242\n",
      "Train Epoch: 508 [1280/1612 (79%)] Loss: 0.464561\n",
      "Train Epoch: 508 [1440/1612 (89%)] Loss: 0.546521\n",
      "Train Epoch: 508 [1200/1612 (99%)] Loss: 0.436128\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 509 [0/1612 (0%)] Loss: 0.314400\n",
      "Train Epoch: 509 [160/1612 (10%)] Loss: 0.418923\n",
      "Train Epoch: 509 [320/1612 (20%)] Loss: 0.335310\n",
      "Train Epoch: 509 [480/1612 (30%)] Loss: 0.259030\n",
      "Train Epoch: 509 [640/1612 (40%)] Loss: 0.141362\n",
      "Train Epoch: 509 [800/1612 (50%)] Loss: 0.369891\n",
      "Train Epoch: 509 [960/1612 (59%)] Loss: 0.293090\n",
      "Train Epoch: 509 [1120/1612 (69%)] Loss: 0.484835\n",
      "Train Epoch: 509 [1280/1612 (79%)] Loss: 0.294169\n",
      "Train Epoch: 509 [1440/1612 (89%)] Loss: 0.267088\n",
      "Train Epoch: 509 [1200/1612 (99%)] Loss: 0.196180\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 510 [0/1612 (0%)] Loss: 0.325636\n",
      "Train Epoch: 510 [160/1612 (10%)] Loss: 0.167163\n",
      "Train Epoch: 510 [320/1612 (20%)] Loss: 0.233581\n",
      "Train Epoch: 510 [480/1612 (30%)] Loss: 0.413164\n",
      "Train Epoch: 510 [640/1612 (40%)] Loss: 0.273799\n",
      "Train Epoch: 510 [800/1612 (50%)] Loss: 0.365019\n",
      "Train Epoch: 510 [960/1612 (59%)] Loss: 0.453516\n",
      "Train Epoch: 510 [1120/1612 (69%)] Loss: 0.474870\n",
      "Train Epoch: 510 [1280/1612 (79%)] Loss: 0.418546\n",
      "Train Epoch: 510 [1440/1612 (89%)] Loss: 0.185790\n",
      "Train Epoch: 510 [1200/1612 (99%)] Loss: 0.382804\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 511 [0/1612 (0%)] Loss: 0.334962\n",
      "Train Epoch: 511 [160/1612 (10%)] Loss: 0.508692\n",
      "Train Epoch: 511 [320/1612 (20%)] Loss: 0.409836\n",
      "Train Epoch: 511 [480/1612 (30%)] Loss: 0.226531\n",
      "Train Epoch: 511 [640/1612 (40%)] Loss: 0.332128\n",
      "Train Epoch: 511 [800/1612 (50%)] Loss: 0.520868\n",
      "Train Epoch: 511 [960/1612 (59%)] Loss: 0.178066\n",
      "Train Epoch: 511 [1120/1612 (69%)] Loss: 0.617191\n",
      "Train Epoch: 511 [1280/1612 (79%)] Loss: 0.317534\n",
      "Train Epoch: 511 [1440/1612 (89%)] Loss: 0.575665\n",
      "Train Epoch: 511 [1200/1612 (99%)] Loss: 0.244815\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 512 [0/1612 (0%)] Loss: 0.327733\n",
      "Train Epoch: 512 [160/1612 (10%)] Loss: 0.283813\n",
      "Train Epoch: 512 [320/1612 (20%)] Loss: 0.241359\n",
      "Train Epoch: 512 [480/1612 (30%)] Loss: 0.348986\n",
      "Train Epoch: 512 [640/1612 (40%)] Loss: 0.135832\n",
      "Train Epoch: 512 [800/1612 (50%)] Loss: 0.686992\n",
      "Train Epoch: 512 [960/1612 (59%)] Loss: 0.345087\n",
      "Train Epoch: 512 [1120/1612 (69%)] Loss: 0.312167\n",
      "Train Epoch: 512 [1280/1612 (79%)] Loss: 0.118379\n",
      "Train Epoch: 512 [1440/1612 (89%)] Loss: 0.416923\n",
      "Train Epoch: 512 [1200/1612 (99%)] Loss: 0.165023\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 513 [0/1612 (0%)] Loss: 0.415860\n",
      "Train Epoch: 513 [160/1612 (10%)] Loss: 0.315640\n",
      "Train Epoch: 513 [320/1612 (20%)] Loss: 0.214280\n",
      "Train Epoch: 513 [480/1612 (30%)] Loss: 0.219228\n",
      "Train Epoch: 513 [640/1612 (40%)] Loss: 0.609956\n",
      "Train Epoch: 513 [800/1612 (50%)] Loss: 0.261660\n",
      "Train Epoch: 513 [960/1612 (59%)] Loss: 0.337555\n",
      "Train Epoch: 513 [1120/1612 (69%)] Loss: 0.155213\n",
      "Train Epoch: 513 [1280/1612 (79%)] Loss: 0.262418\n",
      "Train Epoch: 513 [1440/1612 (89%)] Loss: 0.252249\n",
      "Train Epoch: 513 [1200/1612 (99%)] Loss: 0.233105\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 514 [0/1612 (0%)] Loss: 0.239572\n",
      "Train Epoch: 514 [160/1612 (10%)] Loss: 0.430082\n",
      "Train Epoch: 514 [320/1612 (20%)] Loss: 0.243881\n",
      "Train Epoch: 514 [480/1612 (30%)] Loss: 0.274778\n",
      "Train Epoch: 514 [640/1612 (40%)] Loss: 0.483083\n",
      "Train Epoch: 514 [800/1612 (50%)] Loss: 0.358520\n",
      "Train Epoch: 514 [960/1612 (59%)] Loss: 0.339195\n",
      "Train Epoch: 514 [1120/1612 (69%)] Loss: 0.256592\n",
      "Train Epoch: 514 [1280/1612 (79%)] Loss: 0.195786\n",
      "Train Epoch: 514 [1440/1612 (89%)] Loss: 0.389690\n",
      "Train Epoch: 514 [1200/1612 (99%)] Loss: 0.520916\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 515 [0/1612 (0%)] Loss: 0.420600\n",
      "Train Epoch: 515 [160/1612 (10%)] Loss: 0.432294\n",
      "Train Epoch: 515 [320/1612 (20%)] Loss: 0.121668\n",
      "Train Epoch: 515 [480/1612 (30%)] Loss: 0.440009\n",
      "Train Epoch: 515 [640/1612 (40%)] Loss: 0.468545\n",
      "Train Epoch: 515 [800/1612 (50%)] Loss: 0.306685\n",
      "Train Epoch: 515 [960/1612 (59%)] Loss: 0.290008\n",
      "Train Epoch: 515 [1120/1612 (69%)] Loss: 0.365015\n",
      "Train Epoch: 515 [1280/1612 (79%)] Loss: 0.364243\n",
      "Train Epoch: 515 [1440/1612 (89%)] Loss: 0.413566\n",
      "Train Epoch: 515 [1200/1612 (99%)] Loss: 0.271460\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 516 [0/1612 (0%)] Loss: 0.246697\n",
      "Train Epoch: 516 [160/1612 (10%)] Loss: 0.299436\n",
      "Train Epoch: 516 [320/1612 (20%)] Loss: 0.300529\n",
      "Train Epoch: 516 [480/1612 (30%)] Loss: 0.226084\n",
      "Train Epoch: 516 [640/1612 (40%)] Loss: 0.326069\n",
      "Train Epoch: 516 [800/1612 (50%)] Loss: 0.236897\n",
      "Train Epoch: 516 [960/1612 (59%)] Loss: 0.423549\n",
      "Train Epoch: 516 [1120/1612 (69%)] Loss: 0.213682\n",
      "Train Epoch: 516 [1280/1612 (79%)] Loss: 0.296030\n",
      "Train Epoch: 516 [1440/1612 (89%)] Loss: 0.350287\n",
      "Train Epoch: 516 [1200/1612 (99%)] Loss: 0.554414\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 517 [0/1612 (0%)] Loss: 0.187144\n",
      "Train Epoch: 517 [160/1612 (10%)] Loss: 0.449163\n",
      "Train Epoch: 517 [320/1612 (20%)] Loss: 0.165812\n",
      "Train Epoch: 517 [480/1612 (30%)] Loss: 0.321280\n",
      "Train Epoch: 517 [640/1612 (40%)] Loss: 0.385690\n",
      "Train Epoch: 517 [800/1612 (50%)] Loss: 0.379153\n",
      "Train Epoch: 517 [960/1612 (59%)] Loss: 0.251073\n",
      "Train Epoch: 517 [1120/1612 (69%)] Loss: 0.341980\n",
      "Train Epoch: 517 [1280/1612 (79%)] Loss: 0.366062\n",
      "Train Epoch: 517 [1440/1612 (89%)] Loss: 0.489865\n",
      "Train Epoch: 517 [1200/1612 (99%)] Loss: 0.175548\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 518 [0/1612 (0%)] Loss: 0.464674\n",
      "Train Epoch: 518 [160/1612 (10%)] Loss: 0.270819\n",
      "Train Epoch: 518 [320/1612 (20%)] Loss: 0.246780\n",
      "Train Epoch: 518 [480/1612 (30%)] Loss: 0.526363\n",
      "Train Epoch: 518 [640/1612 (40%)] Loss: 0.178869\n",
      "Train Epoch: 518 [800/1612 (50%)] Loss: 0.626877\n",
      "Train Epoch: 518 [960/1612 (59%)] Loss: 0.431336\n",
      "Train Epoch: 518 [1120/1612 (69%)] Loss: 0.294243\n",
      "Train Epoch: 518 [1280/1612 (79%)] Loss: 0.262976\n",
      "Train Epoch: 518 [1440/1612 (89%)] Loss: 0.164540\n",
      "Train Epoch: 518 [1200/1612 (99%)] Loss: 0.304051\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 519 [0/1612 (0%)] Loss: 0.291455\n",
      "Train Epoch: 519 [160/1612 (10%)] Loss: 0.289483\n",
      "Train Epoch: 519 [320/1612 (20%)] Loss: 0.280171\n",
      "Train Epoch: 519 [480/1612 (30%)] Loss: 0.311328\n",
      "Train Epoch: 519 [640/1612 (40%)] Loss: 0.341468\n",
      "Train Epoch: 519 [800/1612 (50%)] Loss: 0.622828\n",
      "Train Epoch: 519 [960/1612 (59%)] Loss: 0.492693\n",
      "Train Epoch: 519 [1120/1612 (69%)] Loss: 0.175202\n",
      "Train Epoch: 519 [1280/1612 (79%)] Loss: 0.223916\n",
      "Train Epoch: 519 [1440/1612 (89%)] Loss: 0.195476\n",
      "Train Epoch: 519 [1200/1612 (99%)] Loss: 0.363698\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 520 [0/1612 (0%)] Loss: 0.512360\n",
      "Train Epoch: 520 [160/1612 (10%)] Loss: 0.366297\n",
      "Train Epoch: 520 [320/1612 (20%)] Loss: 0.259462\n",
      "Train Epoch: 520 [480/1612 (30%)] Loss: 0.382488\n",
      "Train Epoch: 520 [640/1612 (40%)] Loss: 0.320985\n",
      "Train Epoch: 520 [800/1612 (50%)] Loss: 0.509043\n",
      "Train Epoch: 520 [960/1612 (59%)] Loss: 0.254225\n",
      "Train Epoch: 520 [1120/1612 (69%)] Loss: 0.187412\n",
      "Train Epoch: 520 [1280/1612 (79%)] Loss: 0.384274\n",
      "Train Epoch: 520 [1440/1612 (89%)] Loss: 0.299944\n",
      "Train Epoch: 520 [1200/1612 (99%)] Loss: 0.283658\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 521 [0/1612 (0%)] Loss: 0.277932\n",
      "Train Epoch: 521 [160/1612 (10%)] Loss: 0.604176\n",
      "Train Epoch: 521 [320/1612 (20%)] Loss: 0.385952\n",
      "Train Epoch: 521 [480/1612 (30%)] Loss: 0.280465\n",
      "Train Epoch: 521 [640/1612 (40%)] Loss: 0.392753\n",
      "Train Epoch: 521 [800/1612 (50%)] Loss: 0.251115\n",
      "Train Epoch: 521 [960/1612 (59%)] Loss: 0.282775\n",
      "Train Epoch: 521 [1120/1612 (69%)] Loss: 0.234086\n",
      "Train Epoch: 521 [1280/1612 (79%)] Loss: 0.154260\n",
      "Train Epoch: 521 [1440/1612 (89%)] Loss: 0.126575\n",
      "Train Epoch: 521 [1200/1612 (99%)] Loss: 0.229005\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 522 [0/1612 (0%)] Loss: 0.266385\n",
      "Train Epoch: 522 [160/1612 (10%)] Loss: 0.504563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 522 [320/1612 (20%)] Loss: 0.336733\n",
      "Train Epoch: 522 [480/1612 (30%)] Loss: 0.305044\n",
      "Train Epoch: 522 [640/1612 (40%)] Loss: 0.429130\n",
      "Train Epoch: 522 [800/1612 (50%)] Loss: 0.388003\n",
      "Train Epoch: 522 [960/1612 (59%)] Loss: 0.215754\n",
      "Train Epoch: 522 [1120/1612 (69%)] Loss: 0.235636\n",
      "Train Epoch: 522 [1280/1612 (79%)] Loss: 0.535743\n",
      "Train Epoch: 522 [1440/1612 (89%)] Loss: 0.505240\n",
      "Train Epoch: 522 [1200/1612 (99%)] Loss: 0.480909\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 523 [0/1612 (0%)] Loss: 0.068284\n",
      "Train Epoch: 523 [160/1612 (10%)] Loss: 0.414363\n",
      "Train Epoch: 523 [320/1612 (20%)] Loss: 0.427862\n",
      "Train Epoch: 523 [480/1612 (30%)] Loss: 0.192153\n",
      "Train Epoch: 523 [640/1612 (40%)] Loss: 0.371677\n",
      "Train Epoch: 523 [800/1612 (50%)] Loss: 0.489844\n",
      "Train Epoch: 523 [960/1612 (59%)] Loss: 0.563196\n",
      "Train Epoch: 523 [1120/1612 (69%)] Loss: 0.120192\n",
      "Train Epoch: 523 [1280/1612 (79%)] Loss: 0.259793\n",
      "Train Epoch: 523 [1440/1612 (89%)] Loss: 0.233753\n",
      "Train Epoch: 523 [1200/1612 (99%)] Loss: 0.322999\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 524 [0/1612 (0%)] Loss: 0.478621\n",
      "Train Epoch: 524 [160/1612 (10%)] Loss: 0.283121\n",
      "Train Epoch: 524 [320/1612 (20%)] Loss: 0.344551\n",
      "Train Epoch: 524 [480/1612 (30%)] Loss: 0.332940\n",
      "Train Epoch: 524 [640/1612 (40%)] Loss: 0.159784\n",
      "Train Epoch: 524 [800/1612 (50%)] Loss: 0.377375\n",
      "Train Epoch: 524 [960/1612 (59%)] Loss: 0.480666\n",
      "Train Epoch: 524 [1120/1612 (69%)] Loss: 0.236864\n",
      "Train Epoch: 524 [1280/1612 (79%)] Loss: 0.347195\n",
      "Train Epoch: 524 [1440/1612 (89%)] Loss: 0.257625\n",
      "Train Epoch: 524 [1200/1612 (99%)] Loss: 0.707345\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 525 [0/1612 (0%)] Loss: 0.160602\n",
      "Train Epoch: 525 [160/1612 (10%)] Loss: 0.140719\n",
      "Train Epoch: 525 [320/1612 (20%)] Loss: 0.488779\n",
      "Train Epoch: 525 [480/1612 (30%)] Loss: 0.341067\n",
      "Train Epoch: 525 [640/1612 (40%)] Loss: 0.316054\n",
      "Train Epoch: 525 [800/1612 (50%)] Loss: 0.254121\n",
      "Train Epoch: 525 [960/1612 (59%)] Loss: 0.198134\n",
      "Train Epoch: 525 [1120/1612 (69%)] Loss: 0.164553\n",
      "Train Epoch: 525 [1280/1612 (79%)] Loss: 0.317908\n",
      "Train Epoch: 525 [1440/1612 (89%)] Loss: 0.700197\n",
      "Train Epoch: 525 [1200/1612 (99%)] Loss: 0.386236\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 526 [0/1612 (0%)] Loss: 0.258578\n",
      "Train Epoch: 526 [160/1612 (10%)] Loss: 0.285921\n",
      "Train Epoch: 526 [320/1612 (20%)] Loss: 0.401550\n",
      "Train Epoch: 526 [480/1612 (30%)] Loss: 0.503639\n",
      "Train Epoch: 526 [640/1612 (40%)] Loss: 0.283727\n",
      "Train Epoch: 526 [800/1612 (50%)] Loss: 0.379914\n",
      "Train Epoch: 526 [960/1612 (59%)] Loss: 0.312159\n",
      "Train Epoch: 526 [1120/1612 (69%)] Loss: 0.365863\n",
      "Train Epoch: 526 [1280/1612 (79%)] Loss: 0.363933\n",
      "Train Epoch: 526 [1440/1612 (89%)] Loss: 0.434296\n",
      "Train Epoch: 526 [1200/1612 (99%)] Loss: 0.537731\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 527 [0/1612 (0%)] Loss: 0.170582\n",
      "Train Epoch: 527 [160/1612 (10%)] Loss: 0.365539\n",
      "Train Epoch: 527 [320/1612 (20%)] Loss: 0.569558\n",
      "Train Epoch: 527 [480/1612 (30%)] Loss: 0.283165\n",
      "Train Epoch: 527 [640/1612 (40%)] Loss: 0.094956\n",
      "Train Epoch: 527 [800/1612 (50%)] Loss: 0.457402\n",
      "Train Epoch: 527 [960/1612 (59%)] Loss: 0.163273\n",
      "Train Epoch: 527 [1120/1612 (69%)] Loss: 0.355528\n",
      "Train Epoch: 527 [1280/1612 (79%)] Loss: 0.332685\n",
      "Train Epoch: 527 [1440/1612 (89%)] Loss: 0.307953\n",
      "Train Epoch: 527 [1200/1612 (99%)] Loss: 0.195460\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 528 [0/1612 (0%)] Loss: 0.271264\n",
      "Train Epoch: 528 [160/1612 (10%)] Loss: 0.289963\n",
      "Train Epoch: 528 [320/1612 (20%)] Loss: 0.158905\n",
      "Train Epoch: 528 [480/1612 (30%)] Loss: 0.432561\n",
      "Train Epoch: 528 [640/1612 (40%)] Loss: 0.120237\n",
      "Train Epoch: 528 [800/1612 (50%)] Loss: 0.428974\n",
      "Train Epoch: 528 [960/1612 (59%)] Loss: 0.157895\n",
      "Train Epoch: 528 [1120/1612 (69%)] Loss: 0.306281\n",
      "Train Epoch: 528 [1280/1612 (79%)] Loss: 0.318653\n",
      "Train Epoch: 528 [1440/1612 (89%)] Loss: 0.498840\n",
      "Train Epoch: 528 [1200/1612 (99%)] Loss: 0.258943\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 529 [0/1612 (0%)] Loss: 0.481032\n",
      "Train Epoch: 529 [160/1612 (10%)] Loss: 0.427099\n",
      "Train Epoch: 529 [320/1612 (20%)] Loss: 0.421735\n",
      "Train Epoch: 529 [480/1612 (30%)] Loss: 0.265898\n",
      "Train Epoch: 529 [640/1612 (40%)] Loss: 0.357324\n",
      "Train Epoch: 529 [800/1612 (50%)] Loss: 0.149551\n",
      "Train Epoch: 529 [960/1612 (59%)] Loss: 0.138173\n",
      "Train Epoch: 529 [1120/1612 (69%)] Loss: 0.135067\n",
      "Train Epoch: 529 [1280/1612 (79%)] Loss: 0.066178\n",
      "Train Epoch: 529 [1440/1612 (89%)] Loss: 0.306179\n",
      "Train Epoch: 529 [1200/1612 (99%)] Loss: 0.247664\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 530 [0/1612 (0%)] Loss: 0.150129\n",
      "Train Epoch: 530 [160/1612 (10%)] Loss: 0.377086\n",
      "Train Epoch: 530 [320/1612 (20%)] Loss: 0.317418\n",
      "Train Epoch: 530 [480/1612 (30%)] Loss: 0.343673\n",
      "Train Epoch: 530 [640/1612 (40%)] Loss: 0.813049\n",
      "Train Epoch: 530 [800/1612 (50%)] Loss: 0.432847\n",
      "Train Epoch: 530 [960/1612 (59%)] Loss: 0.206405\n",
      "Train Epoch: 530 [1120/1612 (69%)] Loss: 0.381102\n",
      "Train Epoch: 530 [1280/1612 (79%)] Loss: 0.137660\n",
      "Train Epoch: 530 [1440/1612 (89%)] Loss: 0.387669\n",
      "Train Epoch: 530 [1200/1612 (99%)] Loss: 0.274174\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 531 [0/1612 (0%)] Loss: 0.545873\n",
      "Train Epoch: 531 [160/1612 (10%)] Loss: 0.454435\n",
      "Train Epoch: 531 [320/1612 (20%)] Loss: 0.294373\n",
      "Train Epoch: 531 [480/1612 (30%)] Loss: 0.162889\n",
      "Train Epoch: 531 [640/1612 (40%)] Loss: 0.527207\n",
      "Train Epoch: 531 [800/1612 (50%)] Loss: 0.250088\n",
      "Train Epoch: 531 [960/1612 (59%)] Loss: 0.380263\n",
      "Train Epoch: 531 [1120/1612 (69%)] Loss: 0.169398\n",
      "Train Epoch: 531 [1280/1612 (79%)] Loss: 0.364301\n",
      "Train Epoch: 531 [1440/1612 (89%)] Loss: 0.272525\n",
      "Train Epoch: 531 [1200/1612 (99%)] Loss: 0.512191\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 532 [0/1612 (0%)] Loss: 0.346349\n",
      "Train Epoch: 532 [160/1612 (10%)] Loss: 0.344682\n",
      "Train Epoch: 532 [320/1612 (20%)] Loss: 0.415098\n",
      "Train Epoch: 532 [480/1612 (30%)] Loss: 0.274613\n",
      "Train Epoch: 532 [640/1612 (40%)] Loss: 0.361649\n",
      "Train Epoch: 532 [800/1612 (50%)] Loss: 0.243913\n",
      "Train Epoch: 532 [960/1612 (59%)] Loss: 0.564326\n",
      "Train Epoch: 532 [1120/1612 (69%)] Loss: 0.341396\n",
      "Train Epoch: 532 [1280/1612 (79%)] Loss: 0.486463\n",
      "Train Epoch: 532 [1440/1612 (89%)] Loss: 0.530427\n",
      "Train Epoch: 532 [1200/1612 (99%)] Loss: 0.235012\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 533 [0/1612 (0%)] Loss: 0.271873\n",
      "Train Epoch: 533 [160/1612 (10%)] Loss: 0.408066\n",
      "Train Epoch: 533 [320/1612 (20%)] Loss: 0.298956\n",
      "Train Epoch: 533 [480/1612 (30%)] Loss: 0.237785\n",
      "Train Epoch: 533 [640/1612 (40%)] Loss: 0.185975\n",
      "Train Epoch: 533 [800/1612 (50%)] Loss: 0.288364\n",
      "Train Epoch: 533 [960/1612 (59%)] Loss: 0.231919\n",
      "Train Epoch: 533 [1120/1612 (69%)] Loss: 0.287223\n",
      "Train Epoch: 533 [1280/1612 (79%)] Loss: 0.426362\n",
      "Train Epoch: 533 [1440/1612 (89%)] Loss: 0.353196\n",
      "Train Epoch: 533 [1200/1612 (99%)] Loss: 0.214641\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 534 [0/1612 (0%)] Loss: 0.459060\n",
      "Train Epoch: 534 [160/1612 (10%)] Loss: 0.388359\n",
      "Train Epoch: 534 [320/1612 (20%)] Loss: 0.328709\n",
      "Train Epoch: 534 [480/1612 (30%)] Loss: 0.275998\n",
      "Train Epoch: 534 [640/1612 (40%)] Loss: 0.756602\n",
      "Train Epoch: 534 [800/1612 (50%)] Loss: 0.514314\n",
      "Train Epoch: 534 [960/1612 (59%)] Loss: 0.378091\n",
      "Train Epoch: 534 [1120/1612 (69%)] Loss: 0.250277\n",
      "Train Epoch: 534 [1280/1612 (79%)] Loss: 0.319377\n",
      "Train Epoch: 534 [1440/1612 (89%)] Loss: 0.274280\n",
      "Train Epoch: 534 [1200/1612 (99%)] Loss: 0.440943\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 535 [0/1612 (0%)] Loss: 0.398220\n",
      "Train Epoch: 535 [160/1612 (10%)] Loss: 0.106637\n",
      "Train Epoch: 535 [320/1612 (20%)] Loss: 0.232474\n",
      "Train Epoch: 535 [480/1612 (30%)] Loss: 0.409990\n",
      "Train Epoch: 535 [640/1612 (40%)] Loss: 0.306234\n",
      "Train Epoch: 535 [800/1612 (50%)] Loss: 0.404060\n",
      "Train Epoch: 535 [960/1612 (59%)] Loss: 0.260887\n",
      "Train Epoch: 535 [1120/1612 (69%)] Loss: 0.605559\n",
      "Train Epoch: 535 [1280/1612 (79%)] Loss: 0.314808\n",
      "Train Epoch: 535 [1440/1612 (89%)] Loss: 0.256412\n",
      "Train Epoch: 535 [1200/1612 (99%)] Loss: 0.084791\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 536 [0/1612 (0%)] Loss: 0.267803\n",
      "Train Epoch: 536 [160/1612 (10%)] Loss: 0.397566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 536 [320/1612 (20%)] Loss: 0.246744\n",
      "Train Epoch: 536 [480/1612 (30%)] Loss: 0.310012\n",
      "Train Epoch: 536 [640/1612 (40%)] Loss: 0.498679\n",
      "Train Epoch: 536 [800/1612 (50%)] Loss: 0.233923\n",
      "Train Epoch: 536 [960/1612 (59%)] Loss: 0.272513\n",
      "Train Epoch: 536 [1120/1612 (69%)] Loss: 0.717994\n",
      "Train Epoch: 536 [1280/1612 (79%)] Loss: 0.268674\n",
      "Train Epoch: 536 [1440/1612 (89%)] Loss: 0.405128\n",
      "Train Epoch: 536 [1200/1612 (99%)] Loss: 0.308687\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 537 [0/1612 (0%)] Loss: 0.375888\n",
      "Train Epoch: 537 [160/1612 (10%)] Loss: 0.274670\n",
      "Train Epoch: 537 [320/1612 (20%)] Loss: 0.341127\n",
      "Train Epoch: 537 [480/1612 (30%)] Loss: 0.348450\n",
      "Train Epoch: 537 [640/1612 (40%)] Loss: 0.268724\n",
      "Train Epoch: 537 [800/1612 (50%)] Loss: 0.315292\n",
      "Train Epoch: 537 [960/1612 (59%)] Loss: 0.258695\n",
      "Train Epoch: 537 [1120/1612 (69%)] Loss: 0.537670\n",
      "Train Epoch: 537 [1280/1612 (79%)] Loss: 0.110115\n",
      "Train Epoch: 537 [1440/1612 (89%)] Loss: 0.456478\n",
      "Train Epoch: 537 [1200/1612 (99%)] Loss: 0.379039\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 538 [0/1612 (0%)] Loss: 0.231695\n",
      "Train Epoch: 538 [160/1612 (10%)] Loss: 0.293225\n",
      "Train Epoch: 538 [320/1612 (20%)] Loss: 0.384413\n",
      "Train Epoch: 538 [480/1612 (30%)] Loss: 0.193974\n",
      "Train Epoch: 538 [640/1612 (40%)] Loss: 0.286747\n",
      "Train Epoch: 538 [800/1612 (50%)] Loss: 0.070279\n",
      "Train Epoch: 538 [960/1612 (59%)] Loss: 0.322600\n",
      "Train Epoch: 538 [1120/1612 (69%)] Loss: 0.264991\n",
      "Train Epoch: 538 [1280/1612 (79%)] Loss: 0.318989\n",
      "Train Epoch: 538 [1440/1612 (89%)] Loss: 0.147799\n",
      "Train Epoch: 538 [1200/1612 (99%)] Loss: 0.436864\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 539 [0/1612 (0%)] Loss: 0.317074\n",
      "Train Epoch: 539 [160/1612 (10%)] Loss: 0.193479\n",
      "Train Epoch: 539 [320/1612 (20%)] Loss: 0.203231\n",
      "Train Epoch: 539 [480/1612 (30%)] Loss: 0.220552\n",
      "Train Epoch: 539 [640/1612 (40%)] Loss: 0.280382\n",
      "Train Epoch: 539 [800/1612 (50%)] Loss: 0.395893\n",
      "Train Epoch: 539 [960/1612 (59%)] Loss: 0.282616\n",
      "Train Epoch: 539 [1120/1612 (69%)] Loss: 0.301632\n",
      "Train Epoch: 539 [1280/1612 (79%)] Loss: 0.373411\n",
      "Train Epoch: 539 [1440/1612 (89%)] Loss: 0.222747\n",
      "Train Epoch: 539 [1200/1612 (99%)] Loss: 0.362961\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 540 [0/1612 (0%)] Loss: 0.566489\n",
      "Train Epoch: 540 [160/1612 (10%)] Loss: 0.420357\n",
      "Train Epoch: 540 [320/1612 (20%)] Loss: 0.495398\n",
      "Train Epoch: 540 [480/1612 (30%)] Loss: 0.444076\n",
      "Train Epoch: 540 [640/1612 (40%)] Loss: 0.204798\n",
      "Train Epoch: 540 [800/1612 (50%)] Loss: 0.474165\n",
      "Train Epoch: 540 [960/1612 (59%)] Loss: 0.273907\n",
      "Train Epoch: 540 [1120/1612 (69%)] Loss: 0.554973\n",
      "Train Epoch: 540 [1280/1612 (79%)] Loss: 0.094105\n",
      "Train Epoch: 540 [1440/1612 (89%)] Loss: 0.220061\n",
      "Train Epoch: 540 [1200/1612 (99%)] Loss: 0.397630\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 541 [0/1612 (0%)] Loss: 0.518574\n",
      "Train Epoch: 541 [160/1612 (10%)] Loss: 0.104621\n",
      "Train Epoch: 541 [320/1612 (20%)] Loss: 0.463853\n",
      "Train Epoch: 541 [480/1612 (30%)] Loss: 0.387824\n",
      "Train Epoch: 541 [640/1612 (40%)] Loss: 0.329951\n",
      "Train Epoch: 541 [800/1612 (50%)] Loss: 0.227383\n",
      "Train Epoch: 541 [960/1612 (59%)] Loss: 0.470694\n",
      "Train Epoch: 541 [1120/1612 (69%)] Loss: 0.319629\n",
      "Train Epoch: 541 [1280/1612 (79%)] Loss: 0.575387\n",
      "Train Epoch: 541 [1440/1612 (89%)] Loss: 0.479512\n",
      "Train Epoch: 541 [1200/1612 (99%)] Loss: 0.524450\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 542 [0/1612 (0%)] Loss: 0.322210\n",
      "Train Epoch: 542 [160/1612 (10%)] Loss: 0.282454\n",
      "Train Epoch: 542 [320/1612 (20%)] Loss: 0.108670\n",
      "Train Epoch: 542 [480/1612 (30%)] Loss: 0.304763\n",
      "Train Epoch: 542 [640/1612 (40%)] Loss: 0.296099\n",
      "Train Epoch: 542 [800/1612 (50%)] Loss: 0.197474\n",
      "Train Epoch: 542 [960/1612 (59%)] Loss: 0.272810\n",
      "Train Epoch: 542 [1120/1612 (69%)] Loss: 0.276096\n",
      "Train Epoch: 542 [1280/1612 (79%)] Loss: 0.081623\n",
      "Train Epoch: 542 [1440/1612 (89%)] Loss: 0.251661\n",
      "Train Epoch: 542 [1200/1612 (99%)] Loss: 0.179547\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 543 [0/1612 (0%)] Loss: 0.311647\n",
      "Train Epoch: 543 [160/1612 (10%)] Loss: 0.203936\n",
      "Train Epoch: 543 [320/1612 (20%)] Loss: 0.490536\n",
      "Train Epoch: 543 [480/1612 (30%)] Loss: 0.406033\n",
      "Train Epoch: 543 [640/1612 (40%)] Loss: 0.370168\n",
      "Train Epoch: 543 [800/1612 (50%)] Loss: 0.271621\n",
      "Train Epoch: 543 [960/1612 (59%)] Loss: 0.272622\n",
      "Train Epoch: 543 [1120/1612 (69%)] Loss: 0.305889\n",
      "Train Epoch: 543 [1280/1612 (79%)] Loss: 0.409904\n",
      "Train Epoch: 543 [1440/1612 (89%)] Loss: 0.575992\n",
      "Train Epoch: 543 [1200/1612 (99%)] Loss: 0.448073\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 544 [0/1612 (0%)] Loss: 0.573794\n",
      "Train Epoch: 544 [160/1612 (10%)] Loss: 0.219229\n",
      "Train Epoch: 544 [320/1612 (20%)] Loss: 0.469892\n",
      "Train Epoch: 544 [480/1612 (30%)] Loss: 0.202575\n",
      "Train Epoch: 544 [640/1612 (40%)] Loss: 0.463272\n",
      "Train Epoch: 544 [800/1612 (50%)] Loss: 0.248552\n",
      "Train Epoch: 544 [960/1612 (59%)] Loss: 0.234538\n",
      "Train Epoch: 544 [1120/1612 (69%)] Loss: 0.248038\n",
      "Train Epoch: 544 [1280/1612 (79%)] Loss: 0.642466\n",
      "Train Epoch: 544 [1440/1612 (89%)] Loss: 0.156699\n",
      "Train Epoch: 544 [1200/1612 (99%)] Loss: 0.154728\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 545 [0/1612 (0%)] Loss: 0.379180\n",
      "Train Epoch: 545 [160/1612 (10%)] Loss: 0.140222\n",
      "Train Epoch: 545 [320/1612 (20%)] Loss: 0.245297\n",
      "Train Epoch: 545 [480/1612 (30%)] Loss: 0.262980\n",
      "Train Epoch: 545 [640/1612 (40%)] Loss: 0.323612\n",
      "Train Epoch: 545 [800/1612 (50%)] Loss: 0.276741\n",
      "Train Epoch: 545 [960/1612 (59%)] Loss: 0.079980\n",
      "Train Epoch: 545 [1120/1612 (69%)] Loss: 0.351239\n",
      "Train Epoch: 545 [1280/1612 (79%)] Loss: 0.700910\n",
      "Train Epoch: 545 [1440/1612 (89%)] Loss: 0.320016\n",
      "Train Epoch: 545 [1200/1612 (99%)] Loss: 0.329745\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 546 [0/1612 (0%)] Loss: 0.307342\n",
      "Train Epoch: 546 [160/1612 (10%)] Loss: 0.367383\n",
      "Train Epoch: 546 [320/1612 (20%)] Loss: 0.392012\n",
      "Train Epoch: 546 [480/1612 (30%)] Loss: 0.300189\n",
      "Train Epoch: 546 [640/1612 (40%)] Loss: 0.358574\n",
      "Train Epoch: 546 [800/1612 (50%)] Loss: 0.449473\n",
      "Train Epoch: 546 [960/1612 (59%)] Loss: 0.170863\n",
      "Train Epoch: 546 [1120/1612 (69%)] Loss: 0.264293\n",
      "Train Epoch: 546 [1280/1612 (79%)] Loss: 0.354031\n",
      "Train Epoch: 546 [1440/1612 (89%)] Loss: 0.267847\n",
      "Train Epoch: 546 [1200/1612 (99%)] Loss: 0.878487\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 547 [0/1612 (0%)] Loss: 0.125603\n",
      "Train Epoch: 547 [160/1612 (10%)] Loss: 0.447385\n",
      "Train Epoch: 547 [320/1612 (20%)] Loss: 0.096177\n",
      "Train Epoch: 547 [480/1612 (30%)] Loss: 0.253355\n",
      "Train Epoch: 547 [640/1612 (40%)] Loss: 0.414838\n",
      "Train Epoch: 547 [800/1612 (50%)] Loss: 0.386440\n",
      "Train Epoch: 547 [960/1612 (59%)] Loss: 0.368659\n",
      "Train Epoch: 547 [1120/1612 (69%)] Loss: 0.185363\n",
      "Train Epoch: 547 [1280/1612 (79%)] Loss: 0.386118\n",
      "Train Epoch: 547 [1440/1612 (89%)] Loss: 0.410178\n",
      "Train Epoch: 547 [1200/1612 (99%)] Loss: 0.137676\n",
      "\n",
      "Test set: Average loss: 0.0242, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 548 [0/1612 (0%)] Loss: 0.147648\n",
      "Train Epoch: 548 [160/1612 (10%)] Loss: 0.471984\n",
      "Train Epoch: 548 [320/1612 (20%)] Loss: 0.104593\n",
      "Train Epoch: 548 [480/1612 (30%)] Loss: 0.206458\n",
      "Train Epoch: 548 [640/1612 (40%)] Loss: 0.163669\n",
      "Train Epoch: 548 [800/1612 (50%)] Loss: 0.244191\n",
      "Train Epoch: 548 [960/1612 (59%)] Loss: 0.259920\n",
      "Train Epoch: 548 [1120/1612 (69%)] Loss: 0.390458\n",
      "Train Epoch: 548 [1280/1612 (79%)] Loss: 0.330816\n",
      "Train Epoch: 548 [1440/1612 (89%)] Loss: 0.455933\n",
      "Train Epoch: 548 [1200/1612 (99%)] Loss: 0.308367\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 549 [0/1612 (0%)] Loss: 0.321121\n",
      "Train Epoch: 549 [160/1612 (10%)] Loss: 0.281388\n",
      "Train Epoch: 549 [320/1612 (20%)] Loss: 0.471862\n",
      "Train Epoch: 549 [480/1612 (30%)] Loss: 0.153779\n",
      "Train Epoch: 549 [640/1612 (40%)] Loss: 0.180825\n",
      "Train Epoch: 549 [800/1612 (50%)] Loss: 0.277634\n",
      "Train Epoch: 549 [960/1612 (59%)] Loss: 0.196738\n",
      "Train Epoch: 549 [1120/1612 (69%)] Loss: 0.562363\n",
      "Train Epoch: 549 [1280/1612 (79%)] Loss: 0.188813\n",
      "Train Epoch: 549 [1440/1612 (89%)] Loss: 0.236332\n",
      "Train Epoch: 549 [1200/1612 (99%)] Loss: 0.286266\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 550 [0/1612 (0%)] Loss: 0.208679\n",
      "Train Epoch: 550 [160/1612 (10%)] Loss: 0.364282\n",
      "Train Epoch: 550 [320/1612 (20%)] Loss: 0.229766\n",
      "Train Epoch: 550 [480/1612 (30%)] Loss: 0.416658\n",
      "Train Epoch: 550 [640/1612 (40%)] Loss: 0.442600\n",
      "Train Epoch: 550 [800/1612 (50%)] Loss: 0.235385\n",
      "Train Epoch: 550 [960/1612 (59%)] Loss: 0.379161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 550 [1120/1612 (69%)] Loss: 0.277959\n",
      "Train Epoch: 550 [1280/1612 (79%)] Loss: 0.206020\n",
      "Train Epoch: 550 [1440/1612 (89%)] Loss: 0.304576\n",
      "Train Epoch: 550 [1200/1612 (99%)] Loss: 0.412460\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 551 [0/1612 (0%)] Loss: 0.395730\n",
      "Train Epoch: 551 [160/1612 (10%)] Loss: 0.460711\n",
      "Train Epoch: 551 [320/1612 (20%)] Loss: 0.261289\n",
      "Train Epoch: 551 [480/1612 (30%)] Loss: 0.250979\n",
      "Train Epoch: 551 [640/1612 (40%)] Loss: 0.323713\n",
      "Train Epoch: 551 [800/1612 (50%)] Loss: 0.308995\n",
      "Train Epoch: 551 [960/1612 (59%)] Loss: 0.184016\n",
      "Train Epoch: 551 [1120/1612 (69%)] Loss: 0.306411\n",
      "Train Epoch: 551 [1280/1612 (79%)] Loss: 0.288977\n",
      "Train Epoch: 551 [1440/1612 (89%)] Loss: 0.327149\n",
      "Train Epoch: 551 [1200/1612 (99%)] Loss: 0.485351\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 552 [0/1612 (0%)] Loss: 0.192054\n",
      "Train Epoch: 552 [160/1612 (10%)] Loss: 0.332488\n",
      "Train Epoch: 552 [320/1612 (20%)] Loss: 0.235114\n",
      "Train Epoch: 552 [480/1612 (30%)] Loss: 0.248498\n",
      "Train Epoch: 552 [640/1612 (40%)] Loss: 0.333645\n",
      "Train Epoch: 552 [800/1612 (50%)] Loss: 0.209439\n",
      "Train Epoch: 552 [960/1612 (59%)] Loss: 0.281105\n",
      "Train Epoch: 552 [1120/1612 (69%)] Loss: 0.489329\n",
      "Train Epoch: 552 [1280/1612 (79%)] Loss: 0.219992\n",
      "Train Epoch: 552 [1440/1612 (89%)] Loss: 0.470957\n",
      "Train Epoch: 552 [1200/1612 (99%)] Loss: 0.292108\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 553 [0/1612 (0%)] Loss: 0.340824\n",
      "Train Epoch: 553 [160/1612 (10%)] Loss: 0.405173\n",
      "Train Epoch: 553 [320/1612 (20%)] Loss: 0.393611\n",
      "Train Epoch: 553 [480/1612 (30%)] Loss: 0.251432\n",
      "Train Epoch: 553 [640/1612 (40%)] Loss: 0.361007\n",
      "Train Epoch: 553 [800/1612 (50%)] Loss: 0.277975\n",
      "Train Epoch: 553 [960/1612 (59%)] Loss: 0.246842\n",
      "Train Epoch: 553 [1120/1612 (69%)] Loss: 0.479679\n",
      "Train Epoch: 553 [1280/1612 (79%)] Loss: 0.158930\n",
      "Train Epoch: 553 [1440/1612 (89%)] Loss: 0.272452\n",
      "Train Epoch: 553 [1200/1612 (99%)] Loss: 0.545487\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 554 [0/1612 (0%)] Loss: 0.307240\n",
      "Train Epoch: 554 [160/1612 (10%)] Loss: 0.207186\n",
      "Train Epoch: 554 [320/1612 (20%)] Loss: 0.248905\n",
      "Train Epoch: 554 [480/1612 (30%)] Loss: 0.180684\n",
      "Train Epoch: 554 [640/1612 (40%)] Loss: 0.228747\n",
      "Train Epoch: 554 [800/1612 (50%)] Loss: 0.335677\n",
      "Train Epoch: 554 [960/1612 (59%)] Loss: 0.120263\n",
      "Train Epoch: 554 [1120/1612 (69%)] Loss: 0.562892\n",
      "Train Epoch: 554 [1280/1612 (79%)] Loss: 0.246487\n",
      "Train Epoch: 554 [1440/1612 (89%)] Loss: 0.507312\n",
      "Train Epoch: 554 [1200/1612 (99%)] Loss: 0.214118\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 555 [0/1612 (0%)] Loss: 0.142041\n",
      "Train Epoch: 555 [160/1612 (10%)] Loss: 0.239898\n",
      "Train Epoch: 555 [320/1612 (20%)] Loss: 0.256067\n",
      "Train Epoch: 555 [480/1612 (30%)] Loss: 0.233217\n",
      "Train Epoch: 555 [640/1612 (40%)] Loss: 0.306941\n",
      "Train Epoch: 555 [800/1612 (50%)] Loss: 0.657373\n",
      "Train Epoch: 555 [960/1612 (59%)] Loss: 0.627412\n",
      "Train Epoch: 555 [1120/1612 (69%)] Loss: 0.446604\n",
      "Train Epoch: 555 [1280/1612 (79%)] Loss: 0.404766\n",
      "Train Epoch: 555 [1440/1612 (89%)] Loss: 0.295079\n",
      "Train Epoch: 555 [1200/1612 (99%)] Loss: 0.275234\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 556 [0/1612 (0%)] Loss: 0.276437\n",
      "Train Epoch: 556 [160/1612 (10%)] Loss: 0.473232\n",
      "Train Epoch: 556 [320/1612 (20%)] Loss: 0.392737\n",
      "Train Epoch: 556 [480/1612 (30%)] Loss: 0.321555\n",
      "Train Epoch: 556 [640/1612 (40%)] Loss: 0.263571\n",
      "Train Epoch: 556 [800/1612 (50%)] Loss: 0.353727\n",
      "Train Epoch: 556 [960/1612 (59%)] Loss: 0.344621\n",
      "Train Epoch: 556 [1120/1612 (69%)] Loss: 0.382923\n",
      "Train Epoch: 556 [1280/1612 (79%)] Loss: 0.412213\n",
      "Train Epoch: 556 [1440/1612 (89%)] Loss: 0.154675\n",
      "Train Epoch: 556 [1200/1612 (99%)] Loss: 0.424291\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 557 [0/1612 (0%)] Loss: 0.172813\n",
      "Train Epoch: 557 [160/1612 (10%)] Loss: 0.657252\n",
      "Train Epoch: 557 [320/1612 (20%)] Loss: 0.225260\n",
      "Train Epoch: 557 [480/1612 (30%)] Loss: 0.355444\n",
      "Train Epoch: 557 [640/1612 (40%)] Loss: 0.396640\n",
      "Train Epoch: 557 [800/1612 (50%)] Loss: 0.496659\n",
      "Train Epoch: 557 [960/1612 (59%)] Loss: 0.260942\n",
      "Train Epoch: 557 [1120/1612 (69%)] Loss: 0.125912\n",
      "Train Epoch: 557 [1280/1612 (79%)] Loss: 0.565691\n",
      "Train Epoch: 557 [1440/1612 (89%)] Loss: 0.361763\n",
      "Train Epoch: 557 [1200/1612 (99%)] Loss: 0.196942\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 558 [0/1612 (0%)] Loss: 0.292613\n",
      "Train Epoch: 558 [160/1612 (10%)] Loss: 0.239458\n",
      "Train Epoch: 558 [320/1612 (20%)] Loss: 0.212988\n",
      "Train Epoch: 558 [480/1612 (30%)] Loss: 0.229646\n",
      "Train Epoch: 558 [640/1612 (40%)] Loss: 0.250712\n",
      "Train Epoch: 558 [800/1612 (50%)] Loss: 0.197844\n",
      "Train Epoch: 558 [960/1612 (59%)] Loss: 0.305072\n",
      "Train Epoch: 558 [1120/1612 (69%)] Loss: 0.327497\n",
      "Train Epoch: 558 [1280/1612 (79%)] Loss: 0.381482\n",
      "Train Epoch: 558 [1440/1612 (89%)] Loss: 0.395668\n",
      "Train Epoch: 558 [1200/1612 (99%)] Loss: 0.706133\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 559 [0/1612 (0%)] Loss: 0.512269\n",
      "Train Epoch: 559 [160/1612 (10%)] Loss: 0.377941\n",
      "Train Epoch: 559 [320/1612 (20%)] Loss: 0.290565\n",
      "Train Epoch: 559 [480/1612 (30%)] Loss: 0.422002\n",
      "Train Epoch: 559 [640/1612 (40%)] Loss: 0.081272\n",
      "Train Epoch: 559 [800/1612 (50%)] Loss: 0.298805\n",
      "Train Epoch: 559 [960/1612 (59%)] Loss: 0.294586\n",
      "Train Epoch: 559 [1120/1612 (69%)] Loss: 0.366272\n",
      "Train Epoch: 559 [1280/1612 (79%)] Loss: 0.390315\n",
      "Train Epoch: 559 [1440/1612 (89%)] Loss: 0.237095\n",
      "Train Epoch: 559 [1200/1612 (99%)] Loss: 0.320946\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 560 [0/1612 (0%)] Loss: 0.208145\n",
      "Train Epoch: 560 [160/1612 (10%)] Loss: 0.486966\n",
      "Train Epoch: 560 [320/1612 (20%)] Loss: 0.390320\n",
      "Train Epoch: 560 [480/1612 (30%)] Loss: 0.177164\n",
      "Train Epoch: 560 [640/1612 (40%)] Loss: 0.291632\n",
      "Train Epoch: 560 [800/1612 (50%)] Loss: 0.392746\n",
      "Train Epoch: 560 [960/1612 (59%)] Loss: 0.213812\n",
      "Train Epoch: 560 [1120/1612 (69%)] Loss: 0.385255\n",
      "Train Epoch: 560 [1280/1612 (79%)] Loss: 0.341484\n",
      "Train Epoch: 560 [1440/1612 (89%)] Loss: 0.490851\n",
      "Train Epoch: 560 [1200/1612 (99%)] Loss: 0.188140\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 561 [0/1612 (0%)] Loss: 0.539365\n",
      "Train Epoch: 561 [160/1612 (10%)] Loss: 0.316330\n",
      "Train Epoch: 561 [320/1612 (20%)] Loss: 0.312592\n",
      "Train Epoch: 561 [480/1612 (30%)] Loss: 0.174583\n",
      "Train Epoch: 561 [640/1612 (40%)] Loss: 0.141382\n",
      "Train Epoch: 561 [800/1612 (50%)] Loss: 0.173559\n",
      "Train Epoch: 561 [960/1612 (59%)] Loss: 0.289443\n",
      "Train Epoch: 561 [1120/1612 (69%)] Loss: 0.656475\n",
      "Train Epoch: 561 [1280/1612 (79%)] Loss: 0.415804\n",
      "Train Epoch: 561 [1440/1612 (89%)] Loss: 0.220644\n",
      "Train Epoch: 561 [1200/1612 (99%)] Loss: 0.174802\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 562 [0/1612 (0%)] Loss: 0.135244\n",
      "Train Epoch: 562 [160/1612 (10%)] Loss: 0.282479\n",
      "Train Epoch: 562 [320/1612 (20%)] Loss: 0.235919\n",
      "Train Epoch: 562 [480/1612 (30%)] Loss: 0.327068\n",
      "Train Epoch: 562 [640/1612 (40%)] Loss: 0.321014\n",
      "Train Epoch: 562 [800/1612 (50%)] Loss: 0.441475\n",
      "Train Epoch: 562 [960/1612 (59%)] Loss: 0.232073\n",
      "Train Epoch: 562 [1120/1612 (69%)] Loss: 0.361202\n",
      "Train Epoch: 562 [1280/1612 (79%)] Loss: 0.159837\n",
      "Train Epoch: 562 [1440/1612 (89%)] Loss: 0.307470\n",
      "Train Epoch: 562 [1200/1612 (99%)] Loss: 0.348141\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 563 [0/1612 (0%)] Loss: 0.160642\n",
      "Train Epoch: 563 [160/1612 (10%)] Loss: 0.212965\n",
      "Train Epoch: 563 [320/1612 (20%)] Loss: 0.282593\n",
      "Train Epoch: 563 [480/1612 (30%)] Loss: 0.432598\n",
      "Train Epoch: 563 [640/1612 (40%)] Loss: 0.573624\n",
      "Train Epoch: 563 [800/1612 (50%)] Loss: 0.201969\n",
      "Train Epoch: 563 [960/1612 (59%)] Loss: 0.310307\n",
      "Train Epoch: 563 [1120/1612 (69%)] Loss: 0.293838\n",
      "Train Epoch: 563 [1280/1612 (79%)] Loss: 0.359217\n",
      "Train Epoch: 563 [1440/1612 (89%)] Loss: 0.488485\n",
      "Train Epoch: 563 [1200/1612 (99%)] Loss: 0.330384\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 564 [0/1612 (0%)] Loss: 0.422849\n",
      "Train Epoch: 564 [160/1612 (10%)] Loss: 0.316305\n",
      "Train Epoch: 564 [320/1612 (20%)] Loss: 0.473265\n",
      "Train Epoch: 564 [480/1612 (30%)] Loss: 0.399590\n",
      "Train Epoch: 564 [640/1612 (40%)] Loss: 0.220235\n",
      "Train Epoch: 564 [800/1612 (50%)] Loss: 0.261096\n",
      "Train Epoch: 564 [960/1612 (59%)] Loss: 0.101174\n",
      "Train Epoch: 564 [1120/1612 (69%)] Loss: 0.322316\n",
      "Train Epoch: 564 [1280/1612 (79%)] Loss: 0.295201\n",
      "Train Epoch: 564 [1440/1612 (89%)] Loss: 0.327805\n",
      "Train Epoch: 564 [1200/1612 (99%)] Loss: 0.360323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 565 [0/1612 (0%)] Loss: 0.197119\n",
      "Train Epoch: 565 [160/1612 (10%)] Loss: 0.393567\n",
      "Train Epoch: 565 [320/1612 (20%)] Loss: 0.389194\n",
      "Train Epoch: 565 [480/1612 (30%)] Loss: 0.501755\n",
      "Train Epoch: 565 [640/1612 (40%)] Loss: 0.432211\n",
      "Train Epoch: 565 [800/1612 (50%)] Loss: 0.137933\n",
      "Train Epoch: 565 [960/1612 (59%)] Loss: 0.300585\n",
      "Train Epoch: 565 [1120/1612 (69%)] Loss: 0.370279\n",
      "Train Epoch: 565 [1280/1612 (79%)] Loss: 0.482785\n",
      "Train Epoch: 565 [1440/1612 (89%)] Loss: 0.454886\n",
      "Train Epoch: 565 [1200/1612 (99%)] Loss: 0.135782\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 566 [0/1612 (0%)] Loss: 0.180749\n",
      "Train Epoch: 566 [160/1612 (10%)] Loss: 0.475417\n",
      "Train Epoch: 566 [320/1612 (20%)] Loss: 0.601712\n",
      "Train Epoch: 566 [480/1612 (30%)] Loss: 0.345216\n",
      "Train Epoch: 566 [640/1612 (40%)] Loss: 0.376867\n",
      "Train Epoch: 566 [800/1612 (50%)] Loss: 0.252510\n",
      "Train Epoch: 566 [960/1612 (59%)] Loss: 0.531871\n",
      "Train Epoch: 566 [1120/1612 (69%)] Loss: 0.354839\n",
      "Train Epoch: 566 [1280/1612 (79%)] Loss: 0.363666\n",
      "Train Epoch: 566 [1440/1612 (89%)] Loss: 0.212347\n",
      "Train Epoch: 566 [1200/1612 (99%)] Loss: 0.515995\n",
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 567 [0/1612 (0%)] Loss: 0.246757\n",
      "Train Epoch: 567 [160/1612 (10%)] Loss: 0.533059\n",
      "Train Epoch: 567 [320/1612 (20%)] Loss: 0.175593\n",
      "Train Epoch: 567 [480/1612 (30%)] Loss: 0.188138\n",
      "Train Epoch: 567 [640/1612 (40%)] Loss: 0.214966\n",
      "Train Epoch: 567 [800/1612 (50%)] Loss: 0.295797\n",
      "Train Epoch: 567 [960/1612 (59%)] Loss: 0.174462\n",
      "Train Epoch: 567 [1120/1612 (69%)] Loss: 0.299607\n",
      "Train Epoch: 567 [1280/1612 (79%)] Loss: 0.271151\n",
      "Train Epoch: 567 [1440/1612 (89%)] Loss: 0.131274\n",
      "Train Epoch: 567 [1200/1612 (99%)] Loss: 0.201737\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 568 [0/1612 (0%)] Loss: 0.267082\n",
      "Train Epoch: 568 [160/1612 (10%)] Loss: 0.223703\n",
      "Train Epoch: 568 [320/1612 (20%)] Loss: 0.315519\n",
      "Train Epoch: 568 [480/1612 (30%)] Loss: 0.335423\n",
      "Train Epoch: 568 [640/1612 (40%)] Loss: 0.555082\n",
      "Train Epoch: 568 [800/1612 (50%)] Loss: 0.500887\n",
      "Train Epoch: 568 [960/1612 (59%)] Loss: 0.403013\n",
      "Train Epoch: 568 [1120/1612 (69%)] Loss: 0.316160\n",
      "Train Epoch: 568 [1280/1612 (79%)] Loss: 0.398060\n",
      "Train Epoch: 568 [1440/1612 (89%)] Loss: 0.239325\n",
      "Train Epoch: 568 [1200/1612 (99%)] Loss: 0.565787\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 569 [0/1612 (0%)] Loss: 0.442790\n",
      "Train Epoch: 569 [160/1612 (10%)] Loss: 0.443841\n",
      "Train Epoch: 569 [320/1612 (20%)] Loss: 0.280285\n",
      "Train Epoch: 569 [480/1612 (30%)] Loss: 0.266697\n",
      "Train Epoch: 569 [640/1612 (40%)] Loss: 0.531425\n",
      "Train Epoch: 569 [800/1612 (50%)] Loss: 0.145156\n",
      "Train Epoch: 569 [960/1612 (59%)] Loss: 0.300019\n",
      "Train Epoch: 569 [1120/1612 (69%)] Loss: 0.272775\n",
      "Train Epoch: 569 [1280/1612 (79%)] Loss: 0.084410\n",
      "Train Epoch: 569 [1440/1612 (89%)] Loss: 0.393083\n",
      "Train Epoch: 569 [1200/1612 (99%)] Loss: 0.418732\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 570 [0/1612 (0%)] Loss: 0.159659\n",
      "Train Epoch: 570 [160/1612 (10%)] Loss: 0.211511\n",
      "Train Epoch: 570 [320/1612 (20%)] Loss: 0.349874\n",
      "Train Epoch: 570 [480/1612 (30%)] Loss: 0.249433\n",
      "Train Epoch: 570 [640/1612 (40%)] Loss: 0.466350\n",
      "Train Epoch: 570 [800/1612 (50%)] Loss: 0.216364\n",
      "Train Epoch: 570 [960/1612 (59%)] Loss: 0.346921\n",
      "Train Epoch: 570 [1120/1612 (69%)] Loss: 0.427168\n",
      "Train Epoch: 570 [1280/1612 (79%)] Loss: 0.280847\n",
      "Train Epoch: 570 [1440/1612 (89%)] Loss: 0.140509\n",
      "Train Epoch: 570 [1200/1612 (99%)] Loss: 0.363912\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 571 [0/1612 (0%)] Loss: 0.378667\n",
      "Train Epoch: 571 [160/1612 (10%)] Loss: 0.200956\n",
      "Train Epoch: 571 [320/1612 (20%)] Loss: 0.369608\n",
      "Train Epoch: 571 [480/1612 (30%)] Loss: 0.350681\n",
      "Train Epoch: 571 [640/1612 (40%)] Loss: 0.292587\n",
      "Train Epoch: 571 [800/1612 (50%)] Loss: 0.271573\n",
      "Train Epoch: 571 [960/1612 (59%)] Loss: 0.355167\n",
      "Train Epoch: 571 [1120/1612 (69%)] Loss: 0.364572\n",
      "Train Epoch: 571 [1280/1612 (79%)] Loss: 0.351976\n",
      "Train Epoch: 571 [1440/1612 (89%)] Loss: 0.189790\n",
      "Train Epoch: 571 [1200/1612 (99%)] Loss: 0.405259\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 572 [0/1612 (0%)] Loss: 0.219996\n",
      "Train Epoch: 572 [160/1612 (10%)] Loss: 0.403119\n",
      "Train Epoch: 572 [320/1612 (20%)] Loss: 0.297877\n",
      "Train Epoch: 572 [480/1612 (30%)] Loss: 0.167517\n",
      "Train Epoch: 572 [640/1612 (40%)] Loss: 0.269990\n",
      "Train Epoch: 572 [800/1612 (50%)] Loss: 0.353258\n",
      "Train Epoch: 572 [960/1612 (59%)] Loss: 0.424199\n",
      "Train Epoch: 572 [1120/1612 (69%)] Loss: 0.470091\n",
      "Train Epoch: 572 [1280/1612 (79%)] Loss: 0.424042\n",
      "Train Epoch: 572 [1440/1612 (89%)] Loss: 0.312672\n",
      "Train Epoch: 572 [1200/1612 (99%)] Loss: 0.312977\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 573 [0/1612 (0%)] Loss: 0.259903\n",
      "Train Epoch: 573 [160/1612 (10%)] Loss: 0.230453\n",
      "Train Epoch: 573 [320/1612 (20%)] Loss: 0.482883\n",
      "Train Epoch: 573 [480/1612 (30%)] Loss: 0.445554\n",
      "Train Epoch: 573 [640/1612 (40%)] Loss: 0.302561\n",
      "Train Epoch: 573 [800/1612 (50%)] Loss: 0.408095\n",
      "Train Epoch: 573 [960/1612 (59%)] Loss: 0.238561\n",
      "Train Epoch: 573 [1120/1612 (69%)] Loss: 0.249555\n",
      "Train Epoch: 573 [1280/1612 (79%)] Loss: 0.280741\n",
      "Train Epoch: 573 [1440/1612 (89%)] Loss: 0.246886\n",
      "Train Epoch: 573 [1200/1612 (99%)] Loss: 0.612767\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 574 [0/1612 (0%)] Loss: 0.508678\n",
      "Train Epoch: 574 [160/1612 (10%)] Loss: 0.150469\n",
      "Train Epoch: 574 [320/1612 (20%)] Loss: 0.175663\n",
      "Train Epoch: 574 [480/1612 (30%)] Loss: 0.305800\n",
      "Train Epoch: 574 [640/1612 (40%)] Loss: 0.283405\n",
      "Train Epoch: 574 [800/1612 (50%)] Loss: 0.425509\n",
      "Train Epoch: 574 [960/1612 (59%)] Loss: 0.207688\n",
      "Train Epoch: 574 [1120/1612 (69%)] Loss: 0.202631\n",
      "Train Epoch: 574 [1280/1612 (79%)] Loss: 0.163117\n",
      "Train Epoch: 574 [1440/1612 (89%)] Loss: 0.320417\n",
      "Train Epoch: 574 [1200/1612 (99%)] Loss: 0.161687\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 575 [0/1612 (0%)] Loss: 0.787374\n",
      "Train Epoch: 575 [160/1612 (10%)] Loss: 0.312497\n",
      "Train Epoch: 575 [320/1612 (20%)] Loss: 0.342257\n",
      "Train Epoch: 575 [480/1612 (30%)] Loss: 0.175738\n",
      "Train Epoch: 575 [640/1612 (40%)] Loss: 0.243752\n",
      "Train Epoch: 575 [800/1612 (50%)] Loss: 0.089217\n",
      "Train Epoch: 575 [960/1612 (59%)] Loss: 0.268664\n",
      "Train Epoch: 575 [1120/1612 (69%)] Loss: 0.436637\n",
      "Train Epoch: 575 [1280/1612 (79%)] Loss: 0.206305\n",
      "Train Epoch: 575 [1440/1612 (89%)] Loss: 0.226666\n",
      "Train Epoch: 575 [1200/1612 (99%)] Loss: 0.318016\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 576 [0/1612 (0%)] Loss: 0.312455\n",
      "Train Epoch: 576 [160/1612 (10%)] Loss: 0.239502\n",
      "Train Epoch: 576 [320/1612 (20%)] Loss: 0.309675\n",
      "Train Epoch: 576 [480/1612 (30%)] Loss: 0.586368\n",
      "Train Epoch: 576 [640/1612 (40%)] Loss: 0.339323\n",
      "Train Epoch: 576 [800/1612 (50%)] Loss: 0.191822\n",
      "Train Epoch: 576 [960/1612 (59%)] Loss: 0.146519\n",
      "Train Epoch: 576 [1120/1612 (69%)] Loss: 0.374169\n",
      "Train Epoch: 576 [1280/1612 (79%)] Loss: 0.318024\n",
      "Train Epoch: 576 [1440/1612 (89%)] Loss: 0.316665\n",
      "Train Epoch: 576 [1200/1612 (99%)] Loss: 0.426255\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 577 [0/1612 (0%)] Loss: 0.408429\n",
      "Train Epoch: 577 [160/1612 (10%)] Loss: 0.243626\n",
      "Train Epoch: 577 [320/1612 (20%)] Loss: 0.232119\n",
      "Train Epoch: 577 [480/1612 (30%)] Loss: 0.344851\n",
      "Train Epoch: 577 [640/1612 (40%)] Loss: 0.417514\n",
      "Train Epoch: 577 [800/1612 (50%)] Loss: 0.256785\n",
      "Train Epoch: 577 [960/1612 (59%)] Loss: 0.324069\n",
      "Train Epoch: 577 [1120/1612 (69%)] Loss: 0.611088\n",
      "Train Epoch: 577 [1280/1612 (79%)] Loss: 0.319604\n",
      "Train Epoch: 577 [1440/1612 (89%)] Loss: 0.311270\n",
      "Train Epoch: 577 [1200/1612 (99%)] Loss: 0.116891\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 578 [0/1612 (0%)] Loss: 0.369699\n",
      "Train Epoch: 578 [160/1612 (10%)] Loss: 0.255604\n",
      "Train Epoch: 578 [320/1612 (20%)] Loss: 0.486556\n",
      "Train Epoch: 578 [480/1612 (30%)] Loss: 0.279134\n",
      "Train Epoch: 578 [640/1612 (40%)] Loss: 0.306332\n",
      "Train Epoch: 578 [800/1612 (50%)] Loss: 0.185057\n",
      "Train Epoch: 578 [960/1612 (59%)] Loss: 0.171146\n",
      "Train Epoch: 578 [1120/1612 (69%)] Loss: 0.221876\n",
      "Train Epoch: 578 [1280/1612 (79%)] Loss: 0.396217\n",
      "Train Epoch: 578 [1440/1612 (89%)] Loss: 0.362197\n",
      "Train Epoch: 578 [1200/1612 (99%)] Loss: 0.191550\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 579 [0/1612 (0%)] Loss: 0.187908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 579 [160/1612 (10%)] Loss: 0.460442\n",
      "Train Epoch: 579 [320/1612 (20%)] Loss: 0.263693\n",
      "Train Epoch: 579 [480/1612 (30%)] Loss: 0.131551\n",
      "Train Epoch: 579 [640/1612 (40%)] Loss: 0.498615\n",
      "Train Epoch: 579 [800/1612 (50%)] Loss: 0.196025\n",
      "Train Epoch: 579 [960/1612 (59%)] Loss: 0.528316\n",
      "Train Epoch: 579 [1120/1612 (69%)] Loss: 0.448627\n",
      "Train Epoch: 579 [1280/1612 (79%)] Loss: 0.301236\n",
      "Train Epoch: 579 [1440/1612 (89%)] Loss: 0.310891\n",
      "Train Epoch: 579 [1200/1612 (99%)] Loss: 0.158828\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 580 [0/1612 (0%)] Loss: 0.297785\n",
      "Train Epoch: 580 [160/1612 (10%)] Loss: 0.090279\n",
      "Train Epoch: 580 [320/1612 (20%)] Loss: 0.440065\n",
      "Train Epoch: 580 [480/1612 (30%)] Loss: 0.225167\n",
      "Train Epoch: 580 [640/1612 (40%)] Loss: 0.137219\n",
      "Train Epoch: 580 [800/1612 (50%)] Loss: 0.339693\n",
      "Train Epoch: 580 [960/1612 (59%)] Loss: 0.101649\n",
      "Train Epoch: 580 [1120/1612 (69%)] Loss: 0.417086\n",
      "Train Epoch: 580 [1280/1612 (79%)] Loss: 0.220790\n",
      "Train Epoch: 580 [1440/1612 (89%)] Loss: 0.263508\n",
      "Train Epoch: 580 [1200/1612 (99%)] Loss: 0.225463\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 581 [0/1612 (0%)] Loss: 0.253904\n",
      "Train Epoch: 581 [160/1612 (10%)] Loss: 0.248784\n",
      "Train Epoch: 581 [320/1612 (20%)] Loss: 0.198389\n",
      "Train Epoch: 581 [480/1612 (30%)] Loss: 0.301027\n",
      "Train Epoch: 581 [640/1612 (40%)] Loss: 0.325416\n",
      "Train Epoch: 581 [800/1612 (50%)] Loss: 0.612172\n",
      "Train Epoch: 581 [960/1612 (59%)] Loss: 0.463293\n",
      "Train Epoch: 581 [1120/1612 (69%)] Loss: 0.111475\n",
      "Train Epoch: 581 [1280/1612 (79%)] Loss: 0.384530\n",
      "Train Epoch: 581 [1440/1612 (89%)] Loss: 0.283008\n",
      "Train Epoch: 581 [1200/1612 (99%)] Loss: 0.220033\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 582 [0/1612 (0%)] Loss: 0.178996\n",
      "Train Epoch: 582 [160/1612 (10%)] Loss: 0.166037\n",
      "Train Epoch: 582 [320/1612 (20%)] Loss: 0.161896\n",
      "Train Epoch: 582 [480/1612 (30%)] Loss: 0.177426\n",
      "Train Epoch: 582 [640/1612 (40%)] Loss: 0.275610\n",
      "Train Epoch: 582 [800/1612 (50%)] Loss: 0.491174\n",
      "Train Epoch: 582 [960/1612 (59%)] Loss: 0.494100\n",
      "Train Epoch: 582 [1120/1612 (69%)] Loss: 0.296374\n",
      "Train Epoch: 582 [1280/1612 (79%)] Loss: 0.218395\n",
      "Train Epoch: 582 [1440/1612 (89%)] Loss: 0.318599\n",
      "Train Epoch: 582 [1200/1612 (99%)] Loss: 0.262095\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 583 [0/1612 (0%)] Loss: 0.197421\n",
      "Train Epoch: 583 [160/1612 (10%)] Loss: 0.174906\n",
      "Train Epoch: 583 [320/1612 (20%)] Loss: 0.239772\n",
      "Train Epoch: 583 [480/1612 (30%)] Loss: 0.342216\n",
      "Train Epoch: 583 [640/1612 (40%)] Loss: 0.185001\n",
      "Train Epoch: 583 [800/1612 (50%)] Loss: 0.403329\n",
      "Train Epoch: 583 [960/1612 (59%)] Loss: 0.344738\n",
      "Train Epoch: 583 [1120/1612 (69%)] Loss: 0.225171\n",
      "Train Epoch: 583 [1280/1612 (79%)] Loss: 0.475776\n",
      "Train Epoch: 583 [1440/1612 (89%)] Loss: 0.228527\n",
      "Train Epoch: 583 [1200/1612 (99%)] Loss: 0.377544\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 584 [0/1612 (0%)] Loss: 0.244368\n",
      "Train Epoch: 584 [160/1612 (10%)] Loss: 0.165434\n",
      "Train Epoch: 584 [320/1612 (20%)] Loss: 0.226850\n",
      "Train Epoch: 584 [480/1612 (30%)] Loss: 0.400761\n",
      "Train Epoch: 584 [640/1612 (40%)] Loss: 0.337763\n",
      "Train Epoch: 584 [800/1612 (50%)] Loss: 0.293442\n",
      "Train Epoch: 584 [960/1612 (59%)] Loss: 0.521696\n",
      "Train Epoch: 584 [1120/1612 (69%)] Loss: 0.532530\n",
      "Train Epoch: 584 [1280/1612 (79%)] Loss: 0.337822\n",
      "Train Epoch: 584 [1440/1612 (89%)] Loss: 0.383116\n",
      "Train Epoch: 584 [1200/1612 (99%)] Loss: 0.163005\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 585 [0/1612 (0%)] Loss: 0.447581\n",
      "Train Epoch: 585 [160/1612 (10%)] Loss: 0.362924\n",
      "Train Epoch: 585 [320/1612 (20%)] Loss: 0.209002\n",
      "Train Epoch: 585 [480/1612 (30%)] Loss: 0.328732\n",
      "Train Epoch: 585 [640/1612 (40%)] Loss: 0.269140\n",
      "Train Epoch: 585 [800/1612 (50%)] Loss: 0.175481\n",
      "Train Epoch: 585 [960/1612 (59%)] Loss: 0.300126\n",
      "Train Epoch: 585 [1120/1612 (69%)] Loss: 0.196446\n",
      "Train Epoch: 585 [1280/1612 (79%)] Loss: 0.610975\n",
      "Train Epoch: 585 [1440/1612 (89%)] Loss: 0.263913\n",
      "Train Epoch: 585 [1200/1612 (99%)] Loss: 0.282830\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 586 [0/1612 (0%)] Loss: 0.388941\n",
      "Train Epoch: 586 [160/1612 (10%)] Loss: 0.265867\n",
      "Train Epoch: 586 [320/1612 (20%)] Loss: 0.301961\n",
      "Train Epoch: 586 [480/1612 (30%)] Loss: 0.211927\n",
      "Train Epoch: 586 [640/1612 (40%)] Loss: 0.545415\n",
      "Train Epoch: 586 [800/1612 (50%)] Loss: 0.478473\n",
      "Train Epoch: 586 [960/1612 (59%)] Loss: 0.195299\n",
      "Train Epoch: 586 [1120/1612 (69%)] Loss: 0.235693\n",
      "Train Epoch: 586 [1280/1612 (79%)] Loss: 0.222096\n",
      "Train Epoch: 586 [1440/1612 (89%)] Loss: 0.368925\n",
      "Train Epoch: 586 [1200/1612 (99%)] Loss: 0.280495\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 587 [0/1612 (0%)] Loss: 0.353984\n",
      "Train Epoch: 587 [160/1612 (10%)] Loss: 0.262118\n",
      "Train Epoch: 587 [320/1612 (20%)] Loss: 0.240072\n",
      "Train Epoch: 587 [480/1612 (30%)] Loss: 0.320781\n",
      "Train Epoch: 587 [640/1612 (40%)] Loss: 0.530771\n",
      "Train Epoch: 587 [800/1612 (50%)] Loss: 0.177266\n",
      "Train Epoch: 587 [960/1612 (59%)] Loss: 0.366755\n",
      "Train Epoch: 587 [1120/1612 (69%)] Loss: 0.611568\n",
      "Train Epoch: 587 [1280/1612 (79%)] Loss: 0.233665\n",
      "Train Epoch: 587 [1440/1612 (89%)] Loss: 0.559662\n",
      "Train Epoch: 587 [1200/1612 (99%)] Loss: 0.282428\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 588 [0/1612 (0%)] Loss: 0.444253\n",
      "Train Epoch: 588 [160/1612 (10%)] Loss: 0.317963\n",
      "Train Epoch: 588 [320/1612 (20%)] Loss: 0.179969\n",
      "Train Epoch: 588 [480/1612 (30%)] Loss: 0.178625\n",
      "Train Epoch: 588 [640/1612 (40%)] Loss: 0.473086\n",
      "Train Epoch: 588 [800/1612 (50%)] Loss: 0.198671\n",
      "Train Epoch: 588 [960/1612 (59%)] Loss: 0.270115\n",
      "Train Epoch: 588 [1120/1612 (69%)] Loss: 0.372529\n",
      "Train Epoch: 588 [1280/1612 (79%)] Loss: 0.418057\n",
      "Train Epoch: 588 [1440/1612 (89%)] Loss: 0.459691\n",
      "Train Epoch: 588 [1200/1612 (99%)] Loss: 0.245211\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 589 [0/1612 (0%)] Loss: 0.371013\n",
      "Train Epoch: 589 [160/1612 (10%)] Loss: 0.313081\n",
      "Train Epoch: 589 [320/1612 (20%)] Loss: 0.269745\n",
      "Train Epoch: 589 [480/1612 (30%)] Loss: 0.470543\n",
      "Train Epoch: 589 [640/1612 (40%)] Loss: 0.279710\n",
      "Train Epoch: 589 [800/1612 (50%)] Loss: 0.507977\n",
      "Train Epoch: 589 [960/1612 (59%)] Loss: 0.284866\n",
      "Train Epoch: 589 [1120/1612 (69%)] Loss: 0.544263\n",
      "Train Epoch: 589 [1280/1612 (79%)] Loss: 0.404512\n",
      "Train Epoch: 589 [1440/1612 (89%)] Loss: 0.156223\n",
      "Train Epoch: 589 [1200/1612 (99%)] Loss: 0.264232\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 590 [0/1612 (0%)] Loss: 0.185990\n",
      "Train Epoch: 590 [160/1612 (10%)] Loss: 0.278468\n",
      "Train Epoch: 590 [320/1612 (20%)] Loss: 0.392721\n",
      "Train Epoch: 590 [480/1612 (30%)] Loss: 0.223511\n",
      "Train Epoch: 590 [640/1612 (40%)] Loss: 0.379194\n",
      "Train Epoch: 590 [800/1612 (50%)] Loss: 0.167832\n",
      "Train Epoch: 590 [960/1612 (59%)] Loss: 0.360574\n",
      "Train Epoch: 590 [1120/1612 (69%)] Loss: 0.124731\n",
      "Train Epoch: 590 [1280/1612 (79%)] Loss: 0.267839\n",
      "Train Epoch: 590 [1440/1612 (89%)] Loss: 0.154286\n",
      "Train Epoch: 590 [1200/1612 (99%)] Loss: 0.248178\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 591 [0/1612 (0%)] Loss: 0.264223\n",
      "Train Epoch: 591 [160/1612 (10%)] Loss: 0.232031\n",
      "Train Epoch: 591 [320/1612 (20%)] Loss: 0.455747\n",
      "Train Epoch: 591 [480/1612 (30%)] Loss: 0.311752\n",
      "Train Epoch: 591 [640/1612 (40%)] Loss: 0.234030\n",
      "Train Epoch: 591 [800/1612 (50%)] Loss: 0.173725\n",
      "Train Epoch: 591 [960/1612 (59%)] Loss: 0.350386\n",
      "Train Epoch: 591 [1120/1612 (69%)] Loss: 0.504405\n",
      "Train Epoch: 591 [1280/1612 (79%)] Loss: 0.253795\n",
      "Train Epoch: 591 [1440/1612 (89%)] Loss: 0.181406\n",
      "Train Epoch: 591 [1200/1612 (99%)] Loss: 0.393153\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 592 [0/1612 (0%)] Loss: 0.441486\n",
      "Train Epoch: 592 [160/1612 (10%)] Loss: 0.419788\n",
      "Train Epoch: 592 [320/1612 (20%)] Loss: 0.235216\n",
      "Train Epoch: 592 [480/1612 (30%)] Loss: 0.348320\n",
      "Train Epoch: 592 [640/1612 (40%)] Loss: 0.192728\n",
      "Train Epoch: 592 [800/1612 (50%)] Loss: 0.300253\n",
      "Train Epoch: 592 [960/1612 (59%)] Loss: 0.323847\n",
      "Train Epoch: 592 [1120/1612 (69%)] Loss: 0.385949\n",
      "Train Epoch: 592 [1280/1612 (79%)] Loss: 0.274722\n",
      "Train Epoch: 592 [1440/1612 (89%)] Loss: 0.230704\n",
      "Train Epoch: 592 [1200/1612 (99%)] Loss: 0.176403\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 593 [0/1612 (0%)] Loss: 0.184227\n",
      "Train Epoch: 593 [160/1612 (10%)] Loss: 0.493084\n",
      "Train Epoch: 593 [320/1612 (20%)] Loss: 0.413288\n",
      "Train Epoch: 593 [480/1612 (30%)] Loss: 0.335687\n",
      "Train Epoch: 593 [640/1612 (40%)] Loss: 0.278943\n",
      "Train Epoch: 593 [800/1612 (50%)] Loss: 0.247538\n",
      "Train Epoch: 593 [960/1612 (59%)] Loss: 0.486913\n",
      "Train Epoch: 593 [1120/1612 (69%)] Loss: 0.400811\n",
      "Train Epoch: 593 [1280/1612 (79%)] Loss: 0.602997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 593 [1440/1612 (89%)] Loss: 0.433483\n",
      "Train Epoch: 593 [1200/1612 (99%)] Loss: 0.383350\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 594 [0/1612 (0%)] Loss: 0.380195\n",
      "Train Epoch: 594 [160/1612 (10%)] Loss: 0.222302\n",
      "Train Epoch: 594 [320/1612 (20%)] Loss: 0.194229\n",
      "Train Epoch: 594 [480/1612 (30%)] Loss: 0.281690\n",
      "Train Epoch: 594 [640/1612 (40%)] Loss: 0.363703\n",
      "Train Epoch: 594 [800/1612 (50%)] Loss: 0.367212\n",
      "Train Epoch: 594 [960/1612 (59%)] Loss: 0.171710\n",
      "Train Epoch: 594 [1120/1612 (69%)] Loss: 0.225667\n",
      "Train Epoch: 594 [1280/1612 (79%)] Loss: 0.362040\n",
      "Train Epoch: 594 [1440/1612 (89%)] Loss: 0.205641\n",
      "Train Epoch: 594 [1200/1612 (99%)] Loss: 0.276933\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 595 [0/1612 (0%)] Loss: 0.276384\n",
      "Train Epoch: 595 [160/1612 (10%)] Loss: 0.255278\n",
      "Train Epoch: 595 [320/1612 (20%)] Loss: 0.160148\n",
      "Train Epoch: 595 [480/1612 (30%)] Loss: 0.353234\n",
      "Train Epoch: 595 [640/1612 (40%)] Loss: 0.095014\n",
      "Train Epoch: 595 [800/1612 (50%)] Loss: 0.234958\n",
      "Train Epoch: 595 [960/1612 (59%)] Loss: 0.342975\n",
      "Train Epoch: 595 [1120/1612 (69%)] Loss: 0.386460\n",
      "Train Epoch: 595 [1280/1612 (79%)] Loss: 0.593043\n",
      "Train Epoch: 595 [1440/1612 (89%)] Loss: 0.293356\n",
      "Train Epoch: 595 [1200/1612 (99%)] Loss: 0.238875\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 596 [0/1612 (0%)] Loss: 0.218712\n",
      "Train Epoch: 596 [160/1612 (10%)] Loss: 0.412219\n",
      "Train Epoch: 596 [320/1612 (20%)] Loss: 0.137837\n",
      "Train Epoch: 596 [480/1612 (30%)] Loss: 0.312563\n",
      "Train Epoch: 596 [640/1612 (40%)] Loss: 0.344076\n",
      "Train Epoch: 596 [800/1612 (50%)] Loss: 0.449551\n",
      "Train Epoch: 596 [960/1612 (59%)] Loss: 0.310854\n",
      "Train Epoch: 596 [1120/1612 (69%)] Loss: 0.177731\n",
      "Train Epoch: 596 [1280/1612 (79%)] Loss: 0.412880\n",
      "Train Epoch: 596 [1440/1612 (89%)] Loss: 0.353833\n",
      "Train Epoch: 596 [1200/1612 (99%)] Loss: 0.506207\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 597 [0/1612 (0%)] Loss: 0.364928\n",
      "Train Epoch: 597 [160/1612 (10%)] Loss: 0.127332\n",
      "Train Epoch: 597 [320/1612 (20%)] Loss: 0.391047\n",
      "Train Epoch: 597 [480/1612 (30%)] Loss: 0.189294\n",
      "Train Epoch: 597 [640/1612 (40%)] Loss: 0.298471\n",
      "Train Epoch: 597 [800/1612 (50%)] Loss: 0.263220\n",
      "Train Epoch: 597 [960/1612 (59%)] Loss: 0.226948\n",
      "Train Epoch: 597 [1120/1612 (69%)] Loss: 0.432531\n",
      "Train Epoch: 597 [1280/1612 (79%)] Loss: 0.517473\n",
      "Train Epoch: 597 [1440/1612 (89%)] Loss: 0.196607\n",
      "Train Epoch: 597 [1200/1612 (99%)] Loss: 0.131620\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 598 [0/1612 (0%)] Loss: 0.184551\n",
      "Train Epoch: 598 [160/1612 (10%)] Loss: 0.290212\n",
      "Train Epoch: 598 [320/1612 (20%)] Loss: 0.255423\n",
      "Train Epoch: 598 [480/1612 (30%)] Loss: 0.388113\n",
      "Train Epoch: 598 [640/1612 (40%)] Loss: 0.378152\n",
      "Train Epoch: 598 [800/1612 (50%)] Loss: 0.508251\n",
      "Train Epoch: 598 [960/1612 (59%)] Loss: 0.233058\n",
      "Train Epoch: 598 [1120/1612 (69%)] Loss: 0.290272\n",
      "Train Epoch: 598 [1280/1612 (79%)] Loss: 0.394801\n",
      "Train Epoch: 598 [1440/1612 (89%)] Loss: 0.250845\n",
      "Train Epoch: 598 [1200/1612 (99%)] Loss: 0.220339\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 599 [0/1612 (0%)] Loss: 0.279275\n",
      "Train Epoch: 599 [160/1612 (10%)] Loss: 0.281265\n",
      "Train Epoch: 599 [320/1612 (20%)] Loss: 0.318057\n",
      "Train Epoch: 599 [480/1612 (30%)] Loss: 0.342874\n",
      "Train Epoch: 599 [640/1612 (40%)] Loss: 0.326560\n",
      "Train Epoch: 599 [800/1612 (50%)] Loss: 0.233950\n",
      "Train Epoch: 599 [960/1612 (59%)] Loss: 0.181925\n",
      "Train Epoch: 599 [1120/1612 (69%)] Loss: 0.204839\n",
      "Train Epoch: 599 [1280/1612 (79%)] Loss: 0.407899\n",
      "Train Epoch: 599 [1440/1612 (89%)] Loss: 0.396439\n",
      "Train Epoch: 599 [1200/1612 (99%)] Loss: 0.330529\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 600 [0/1612 (0%)] Loss: 0.365812\n",
      "Train Epoch: 600 [160/1612 (10%)] Loss: 0.345417\n",
      "Train Epoch: 600 [320/1612 (20%)] Loss: 0.307154\n",
      "Train Epoch: 600 [480/1612 (30%)] Loss: 0.124368\n",
      "Train Epoch: 600 [640/1612 (40%)] Loss: 0.453278\n",
      "Train Epoch: 600 [800/1612 (50%)] Loss: 0.287375\n",
      "Train Epoch: 600 [960/1612 (59%)] Loss: 0.368994\n",
      "Train Epoch: 600 [1120/1612 (69%)] Loss: 0.458622\n",
      "Train Epoch: 600 [1280/1612 (79%)] Loss: 0.378850\n",
      "Train Epoch: 600 [1440/1612 (89%)] Loss: 0.432954\n",
      "Train Epoch: 600 [1200/1612 (99%)] Loss: 0.095501\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 601 [0/1612 (0%)] Loss: 0.356718\n",
      "Train Epoch: 601 [160/1612 (10%)] Loss: 0.308407\n",
      "Train Epoch: 601 [320/1612 (20%)] Loss: 0.367344\n",
      "Train Epoch: 601 [480/1612 (30%)] Loss: 0.369735\n",
      "Train Epoch: 601 [640/1612 (40%)] Loss: 0.222005\n",
      "Train Epoch: 601 [800/1612 (50%)] Loss: 0.468157\n",
      "Train Epoch: 601 [960/1612 (59%)] Loss: 0.342908\n",
      "Train Epoch: 601 [1120/1612 (69%)] Loss: 0.312018\n",
      "Train Epoch: 601 [1280/1612 (79%)] Loss: 0.086419\n",
      "Train Epoch: 601 [1440/1612 (89%)] Loss: 0.231291\n",
      "Train Epoch: 601 [1200/1612 (99%)] Loss: 0.177920\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 602 [0/1612 (0%)] Loss: 0.237018\n",
      "Train Epoch: 602 [160/1612 (10%)] Loss: 0.294598\n",
      "Train Epoch: 602 [320/1612 (20%)] Loss: 0.408320\n",
      "Train Epoch: 602 [480/1612 (30%)] Loss: 0.268762\n",
      "Train Epoch: 602 [640/1612 (40%)] Loss: 0.367406\n",
      "Train Epoch: 602 [800/1612 (50%)] Loss: 0.404162\n",
      "Train Epoch: 602 [960/1612 (59%)] Loss: 0.580108\n",
      "Train Epoch: 602 [1120/1612 (69%)] Loss: 0.355003\n",
      "Train Epoch: 602 [1280/1612 (79%)] Loss: 0.334466\n",
      "Train Epoch: 602 [1440/1612 (89%)] Loss: 0.469708\n",
      "Train Epoch: 602 [1200/1612 (99%)] Loss: 0.168750\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 603 [0/1612 (0%)] Loss: 0.482411\n",
      "Train Epoch: 603 [160/1612 (10%)] Loss: 0.260250\n",
      "Train Epoch: 603 [320/1612 (20%)] Loss: 0.323953\n",
      "Train Epoch: 603 [480/1612 (30%)] Loss: 0.287000\n",
      "Train Epoch: 603 [640/1612 (40%)] Loss: 0.378075\n",
      "Train Epoch: 603 [800/1612 (50%)] Loss: 0.230691\n",
      "Train Epoch: 603 [960/1612 (59%)] Loss: 0.401507\n",
      "Train Epoch: 603 [1120/1612 (69%)] Loss: 0.265658\n",
      "Train Epoch: 603 [1280/1612 (79%)] Loss: 0.201551\n",
      "Train Epoch: 603 [1440/1612 (89%)] Loss: 0.206271\n",
      "Train Epoch: 603 [1200/1612 (99%)] Loss: 0.546367\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 604 [0/1612 (0%)] Loss: 0.242089\n",
      "Train Epoch: 604 [160/1612 (10%)] Loss: 0.255063\n",
      "Train Epoch: 604 [320/1612 (20%)] Loss: 0.337568\n",
      "Train Epoch: 604 [480/1612 (30%)] Loss: 0.554250\n",
      "Train Epoch: 604 [640/1612 (40%)] Loss: 0.214329\n",
      "Train Epoch: 604 [800/1612 (50%)] Loss: 0.322148\n",
      "Train Epoch: 604 [960/1612 (59%)] Loss: 0.301093\n",
      "Train Epoch: 604 [1120/1612 (69%)] Loss: 0.360904\n",
      "Train Epoch: 604 [1280/1612 (79%)] Loss: 0.282071\n",
      "Train Epoch: 604 [1440/1612 (89%)] Loss: 0.222633\n",
      "Train Epoch: 604 [1200/1612 (99%)] Loss: 0.244885\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 605 [0/1612 (0%)] Loss: 0.258196\n",
      "Train Epoch: 605 [160/1612 (10%)] Loss: 0.399499\n",
      "Train Epoch: 605 [320/1612 (20%)] Loss: 0.194013\n",
      "Train Epoch: 605 [480/1612 (30%)] Loss: 0.204082\n",
      "Train Epoch: 605 [640/1612 (40%)] Loss: 0.361806\n",
      "Train Epoch: 605 [800/1612 (50%)] Loss: 0.495217\n",
      "Train Epoch: 605 [960/1612 (59%)] Loss: 0.214003\n",
      "Train Epoch: 605 [1120/1612 (69%)] Loss: 0.187579\n",
      "Train Epoch: 605 [1280/1612 (79%)] Loss: 0.181986\n",
      "Train Epoch: 605 [1440/1612 (89%)] Loss: 0.355991\n",
      "Train Epoch: 605 [1200/1612 (99%)] Loss: 0.292404\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 606 [0/1612 (0%)] Loss: 0.348796\n",
      "Train Epoch: 606 [160/1612 (10%)] Loss: 0.631394\n",
      "Train Epoch: 606 [320/1612 (20%)] Loss: 0.199000\n",
      "Train Epoch: 606 [480/1612 (30%)] Loss: 0.319355\n",
      "Train Epoch: 606 [640/1612 (40%)] Loss: 0.284538\n",
      "Train Epoch: 606 [800/1612 (50%)] Loss: 0.128919\n",
      "Train Epoch: 606 [960/1612 (59%)] Loss: 0.490423\n",
      "Train Epoch: 606 [1120/1612 (69%)] Loss: 0.165344\n",
      "Train Epoch: 606 [1280/1612 (79%)] Loss: 0.187274\n",
      "Train Epoch: 606 [1440/1612 (89%)] Loss: 0.151928\n",
      "Train Epoch: 606 [1200/1612 (99%)] Loss: 0.242329\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 607 [0/1612 (0%)] Loss: 0.293972\n",
      "Train Epoch: 607 [160/1612 (10%)] Loss: 0.525536\n",
      "Train Epoch: 607 [320/1612 (20%)] Loss: 0.285465\n",
      "Train Epoch: 607 [480/1612 (30%)] Loss: 0.204568\n",
      "Train Epoch: 607 [640/1612 (40%)] Loss: 0.370448\n",
      "Train Epoch: 607 [800/1612 (50%)] Loss: 0.279629\n",
      "Train Epoch: 607 [960/1612 (59%)] Loss: 0.160392\n",
      "Train Epoch: 607 [1120/1612 (69%)] Loss: 0.404174\n",
      "Train Epoch: 607 [1280/1612 (79%)] Loss: 0.138605\n",
      "Train Epoch: 607 [1440/1612 (89%)] Loss: 0.321757\n",
      "Train Epoch: 607 [1200/1612 (99%)] Loss: 0.254917\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 608 [0/1612 (0%)] Loss: 0.240971\n",
      "Train Epoch: 608 [160/1612 (10%)] Loss: 0.349522\n",
      "Train Epoch: 608 [320/1612 (20%)] Loss: 0.271398\n",
      "Train Epoch: 608 [480/1612 (30%)] Loss: 0.264627\n",
      "Train Epoch: 608 [640/1612 (40%)] Loss: 0.154779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 608 [800/1612 (50%)] Loss: 0.407159\n",
      "Train Epoch: 608 [960/1612 (59%)] Loss: 0.503776\n",
      "Train Epoch: 608 [1120/1612 (69%)] Loss: 0.398970\n",
      "Train Epoch: 608 [1280/1612 (79%)] Loss: 0.379930\n",
      "Train Epoch: 608 [1440/1612 (89%)] Loss: 0.268920\n",
      "Train Epoch: 608 [1200/1612 (99%)] Loss: 0.198208\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 609 [0/1612 (0%)] Loss: 0.137886\n",
      "Train Epoch: 609 [160/1612 (10%)] Loss: 0.221638\n",
      "Train Epoch: 609 [320/1612 (20%)] Loss: 0.263273\n",
      "Train Epoch: 609 [480/1612 (30%)] Loss: 0.552541\n",
      "Train Epoch: 609 [640/1612 (40%)] Loss: 0.276320\n",
      "Train Epoch: 609 [800/1612 (50%)] Loss: 0.178274\n",
      "Train Epoch: 609 [960/1612 (59%)] Loss: 0.272754\n",
      "Train Epoch: 609 [1120/1612 (69%)] Loss: 0.372487\n",
      "Train Epoch: 609 [1280/1612 (79%)] Loss: 0.435911\n",
      "Train Epoch: 609 [1440/1612 (89%)] Loss: 0.439659\n",
      "Train Epoch: 609 [1200/1612 (99%)] Loss: 0.390255\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 610 [0/1612 (0%)] Loss: 0.423974\n",
      "Train Epoch: 610 [160/1612 (10%)] Loss: 0.278675\n",
      "Train Epoch: 610 [320/1612 (20%)] Loss: 0.313517\n",
      "Train Epoch: 610 [480/1612 (30%)] Loss: 0.391800\n",
      "Train Epoch: 610 [640/1612 (40%)] Loss: 0.323268\n",
      "Train Epoch: 610 [800/1612 (50%)] Loss: 0.404491\n",
      "Train Epoch: 610 [960/1612 (59%)] Loss: 0.102573\n",
      "Train Epoch: 610 [1120/1612 (69%)] Loss: 0.351017\n",
      "Train Epoch: 610 [1280/1612 (79%)] Loss: 0.450956\n",
      "Train Epoch: 610 [1440/1612 (89%)] Loss: 0.257726\n",
      "Train Epoch: 610 [1200/1612 (99%)] Loss: 0.187162\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 611 [0/1612 (0%)] Loss: 0.184381\n",
      "Train Epoch: 611 [160/1612 (10%)] Loss: 0.181899\n",
      "Train Epoch: 611 [320/1612 (20%)] Loss: 0.137477\n",
      "Train Epoch: 611 [480/1612 (30%)] Loss: 0.333492\n",
      "Train Epoch: 611 [640/1612 (40%)] Loss: 0.302989\n",
      "Train Epoch: 611 [800/1612 (50%)] Loss: 0.260769\n",
      "Train Epoch: 611 [960/1612 (59%)] Loss: 0.326911\n",
      "Train Epoch: 611 [1120/1612 (69%)] Loss: 0.314692\n",
      "Train Epoch: 611 [1280/1612 (79%)] Loss: 0.113126\n",
      "Train Epoch: 611 [1440/1612 (89%)] Loss: 0.272898\n",
      "Train Epoch: 611 [1200/1612 (99%)] Loss: 0.139386\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 612 [0/1612 (0%)] Loss: 0.274022\n",
      "Train Epoch: 612 [160/1612 (10%)] Loss: 0.151460\n",
      "Train Epoch: 612 [320/1612 (20%)] Loss: 0.375511\n",
      "Train Epoch: 612 [480/1612 (30%)] Loss: 0.330860\n",
      "Train Epoch: 612 [640/1612 (40%)] Loss: 0.202487\n",
      "Train Epoch: 612 [800/1612 (50%)] Loss: 0.447888\n",
      "Train Epoch: 612 [960/1612 (59%)] Loss: 0.264893\n",
      "Train Epoch: 612 [1120/1612 (69%)] Loss: 0.181609\n",
      "Train Epoch: 612 [1280/1612 (79%)] Loss: 0.196296\n",
      "Train Epoch: 612 [1440/1612 (89%)] Loss: 0.284916\n",
      "Train Epoch: 612 [1200/1612 (99%)] Loss: 0.416567\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 613 [0/1612 (0%)] Loss: 0.298101\n",
      "Train Epoch: 613 [160/1612 (10%)] Loss: 0.559426\n",
      "Train Epoch: 613 [320/1612 (20%)] Loss: 0.412575\n",
      "Train Epoch: 613 [480/1612 (30%)] Loss: 0.322008\n",
      "Train Epoch: 613 [640/1612 (40%)] Loss: 0.143609\n",
      "Train Epoch: 613 [800/1612 (50%)] Loss: 0.264020\n",
      "Train Epoch: 613 [960/1612 (59%)] Loss: 0.231285\n",
      "Train Epoch: 613 [1120/1612 (69%)] Loss: 0.347323\n",
      "Train Epoch: 613 [1280/1612 (79%)] Loss: 0.222994\n",
      "Train Epoch: 613 [1440/1612 (89%)] Loss: 0.422617\n",
      "Train Epoch: 613 [1200/1612 (99%)] Loss: 0.229059\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 614 [0/1612 (0%)] Loss: 0.351022\n",
      "Train Epoch: 614 [160/1612 (10%)] Loss: 0.418341\n",
      "Train Epoch: 614 [320/1612 (20%)] Loss: 0.141350\n",
      "Train Epoch: 614 [480/1612 (30%)] Loss: 0.351072\n",
      "Train Epoch: 614 [640/1612 (40%)] Loss: 0.224153\n",
      "Train Epoch: 614 [800/1612 (50%)] Loss: 0.301128\n",
      "Train Epoch: 614 [960/1612 (59%)] Loss: 0.345065\n",
      "Train Epoch: 614 [1120/1612 (69%)] Loss: 0.519889\n",
      "Train Epoch: 614 [1280/1612 (79%)] Loss: 0.529119\n",
      "Train Epoch: 614 [1440/1612 (89%)] Loss: 0.294632\n",
      "Train Epoch: 614 [1200/1612 (99%)] Loss: 0.470328\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 615 [0/1612 (0%)] Loss: 0.234941\n",
      "Train Epoch: 615 [160/1612 (10%)] Loss: 0.332024\n",
      "Train Epoch: 615 [320/1612 (20%)] Loss: 0.228211\n",
      "Train Epoch: 615 [480/1612 (30%)] Loss: 0.259268\n",
      "Train Epoch: 615 [640/1612 (40%)] Loss: 0.691857\n",
      "Train Epoch: 615 [800/1612 (50%)] Loss: 0.245607\n",
      "Train Epoch: 615 [960/1612 (59%)] Loss: 0.346050\n",
      "Train Epoch: 615 [1120/1612 (69%)] Loss: 0.404779\n",
      "Train Epoch: 615 [1280/1612 (79%)] Loss: 0.329743\n",
      "Train Epoch: 615 [1440/1612 (89%)] Loss: 0.310602\n",
      "Train Epoch: 615 [1200/1612 (99%)] Loss: 0.166722\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 616 [0/1612 (0%)] Loss: 0.613916\n",
      "Train Epoch: 616 [160/1612 (10%)] Loss: 0.422211\n",
      "Train Epoch: 616 [320/1612 (20%)] Loss: 0.156375\n",
      "Train Epoch: 616 [480/1612 (30%)] Loss: 0.191989\n",
      "Train Epoch: 616 [640/1612 (40%)] Loss: 0.208582\n",
      "Train Epoch: 616 [800/1612 (50%)] Loss: 0.273584\n",
      "Train Epoch: 616 [960/1612 (59%)] Loss: 0.104640\n",
      "Train Epoch: 616 [1120/1612 (69%)] Loss: 0.409951\n",
      "Train Epoch: 616 [1280/1612 (79%)] Loss: 0.524678\n",
      "Train Epoch: 616 [1440/1612 (89%)] Loss: 0.450727\n",
      "Train Epoch: 616 [1200/1612 (99%)] Loss: 0.521463\n",
      "\n",
      "Test set: Average loss: 0.0242, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 617 [0/1612 (0%)] Loss: 0.204540\n",
      "Train Epoch: 617 [160/1612 (10%)] Loss: 0.208393\n",
      "Train Epoch: 617 [320/1612 (20%)] Loss: 0.368853\n",
      "Train Epoch: 617 [480/1612 (30%)] Loss: 0.333942\n",
      "Train Epoch: 617 [640/1612 (40%)] Loss: 0.392356\n",
      "Train Epoch: 617 [800/1612 (50%)] Loss: 0.322804\n",
      "Train Epoch: 617 [960/1612 (59%)] Loss: 0.366250\n",
      "Train Epoch: 617 [1120/1612 (69%)] Loss: 0.350565\n",
      "Train Epoch: 617 [1280/1612 (79%)] Loss: 0.250858\n",
      "Train Epoch: 617 [1440/1612 (89%)] Loss: 0.608895\n",
      "Train Epoch: 617 [1200/1612 (99%)] Loss: 0.212050\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 618 [0/1612 (0%)] Loss: 0.267711\n",
      "Train Epoch: 618 [160/1612 (10%)] Loss: 0.144098\n",
      "Train Epoch: 618 [320/1612 (20%)] Loss: 0.533917\n",
      "Train Epoch: 618 [480/1612 (30%)] Loss: 0.366135\n",
      "Train Epoch: 618 [640/1612 (40%)] Loss: 0.217383\n",
      "Train Epoch: 618 [800/1612 (50%)] Loss: 0.165591\n",
      "Train Epoch: 618 [960/1612 (59%)] Loss: 0.356698\n",
      "Train Epoch: 618 [1120/1612 (69%)] Loss: 0.297018\n",
      "Train Epoch: 618 [1280/1612 (79%)] Loss: 0.494194\n",
      "Train Epoch: 618 [1440/1612 (89%)] Loss: 0.133521\n",
      "Train Epoch: 618 [1200/1612 (99%)] Loss: 0.323028\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 619 [0/1612 (0%)] Loss: 0.343679\n",
      "Train Epoch: 619 [160/1612 (10%)] Loss: 0.243777\n",
      "Train Epoch: 619 [320/1612 (20%)] Loss: 0.270634\n",
      "Train Epoch: 619 [480/1612 (30%)] Loss: 0.472960\n",
      "Train Epoch: 619 [640/1612 (40%)] Loss: 0.378355\n",
      "Train Epoch: 619 [800/1612 (50%)] Loss: 0.434676\n",
      "Train Epoch: 619 [960/1612 (59%)] Loss: 0.387167\n",
      "Train Epoch: 619 [1120/1612 (69%)] Loss: 0.228525\n",
      "Train Epoch: 619 [1280/1612 (79%)] Loss: 0.287719\n",
      "Train Epoch: 619 [1440/1612 (89%)] Loss: 0.314241\n",
      "Train Epoch: 619 [1200/1612 (99%)] Loss: 0.205675\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 620 [0/1612 (0%)] Loss: 0.253742\n",
      "Train Epoch: 620 [160/1612 (10%)] Loss: 0.389153\n",
      "Train Epoch: 620 [320/1612 (20%)] Loss: 0.125997\n",
      "Train Epoch: 620 [480/1612 (30%)] Loss: 0.328834\n",
      "Train Epoch: 620 [640/1612 (40%)] Loss: 0.295380\n",
      "Train Epoch: 620 [800/1612 (50%)] Loss: 0.176504\n",
      "Train Epoch: 620 [960/1612 (59%)] Loss: 0.478647\n",
      "Train Epoch: 620 [1120/1612 (69%)] Loss: 0.235704\n",
      "Train Epoch: 620 [1280/1612 (79%)] Loss: 0.307627\n",
      "Train Epoch: 620 [1440/1612 (89%)] Loss: 0.448449\n",
      "Train Epoch: 620 [1200/1612 (99%)] Loss: 0.208887\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 621 [0/1612 (0%)] Loss: 0.470384\n",
      "Train Epoch: 621 [160/1612 (10%)] Loss: 0.356779\n",
      "Train Epoch: 621 [320/1612 (20%)] Loss: 0.539779\n",
      "Train Epoch: 621 [480/1612 (30%)] Loss: 0.320917\n",
      "Train Epoch: 621 [640/1612 (40%)] Loss: 0.264406\n",
      "Train Epoch: 621 [800/1612 (50%)] Loss: 0.220812\n",
      "Train Epoch: 621 [960/1612 (59%)] Loss: 0.298855\n",
      "Train Epoch: 621 [1120/1612 (69%)] Loss: 0.281499\n",
      "Train Epoch: 621 [1280/1612 (79%)] Loss: 0.358261\n",
      "Train Epoch: 621 [1440/1612 (89%)] Loss: 0.447347\n",
      "Train Epoch: 621 [1200/1612 (99%)] Loss: 0.573277\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 622 [0/1612 (0%)] Loss: 0.112568\n",
      "Train Epoch: 622 [160/1612 (10%)] Loss: 0.299813\n",
      "Train Epoch: 622 [320/1612 (20%)] Loss: 0.224094\n",
      "Train Epoch: 622 [480/1612 (30%)] Loss: 0.223533\n",
      "Train Epoch: 622 [640/1612 (40%)] Loss: 0.363941\n",
      "Train Epoch: 622 [800/1612 (50%)] Loss: 0.211302\n",
      "Train Epoch: 622 [960/1612 (59%)] Loss: 0.126815\n",
      "Train Epoch: 622 [1120/1612 (69%)] Loss: 0.312410\n",
      "Train Epoch: 622 [1280/1612 (79%)] Loss: 0.333201\n",
      "Train Epoch: 622 [1440/1612 (89%)] Loss: 0.200933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 622 [1200/1612 (99%)] Loss: 0.690125\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 623 [0/1612 (0%)] Loss: 0.389517\n",
      "Train Epoch: 623 [160/1612 (10%)] Loss: 0.286577\n",
      "Train Epoch: 623 [320/1612 (20%)] Loss: 0.417974\n",
      "Train Epoch: 623 [480/1612 (30%)] Loss: 0.637859\n",
      "Train Epoch: 623 [640/1612 (40%)] Loss: 0.233202\n",
      "Train Epoch: 623 [800/1612 (50%)] Loss: 0.293809\n",
      "Train Epoch: 623 [960/1612 (59%)] Loss: 0.456774\n",
      "Train Epoch: 623 [1120/1612 (69%)] Loss: 0.393960\n",
      "Train Epoch: 623 [1280/1612 (79%)] Loss: 0.312614\n",
      "Train Epoch: 623 [1440/1612 (89%)] Loss: 0.630297\n",
      "Train Epoch: 623 [1200/1612 (99%)] Loss: 0.291849\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 624 [0/1612 (0%)] Loss: 0.535530\n",
      "Train Epoch: 624 [160/1612 (10%)] Loss: 0.267328\n",
      "Train Epoch: 624 [320/1612 (20%)] Loss: 0.341846\n",
      "Train Epoch: 624 [480/1612 (30%)] Loss: 0.278646\n",
      "Train Epoch: 624 [640/1612 (40%)] Loss: 0.135279\n",
      "Train Epoch: 624 [800/1612 (50%)] Loss: 0.412039\n",
      "Train Epoch: 624 [960/1612 (59%)] Loss: 0.380708\n",
      "Train Epoch: 624 [1120/1612 (69%)] Loss: 0.173615\n",
      "Train Epoch: 624 [1280/1612 (79%)] Loss: 0.259940\n",
      "Train Epoch: 624 [1440/1612 (89%)] Loss: 0.384291\n",
      "Train Epoch: 624 [1200/1612 (99%)] Loss: 0.266574\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 625 [0/1612 (0%)] Loss: 0.181268\n",
      "Train Epoch: 625 [160/1612 (10%)] Loss: 0.210539\n",
      "Train Epoch: 625 [320/1612 (20%)] Loss: 0.407639\n",
      "Train Epoch: 625 [480/1612 (30%)] Loss: 0.250285\n",
      "Train Epoch: 625 [640/1612 (40%)] Loss: 0.225071\n",
      "Train Epoch: 625 [800/1612 (50%)] Loss: 0.389854\n",
      "Train Epoch: 625 [960/1612 (59%)] Loss: 0.350656\n",
      "Train Epoch: 625 [1120/1612 (69%)] Loss: 0.389522\n",
      "Train Epoch: 625 [1280/1612 (79%)] Loss: 0.334187\n",
      "Train Epoch: 625 [1440/1612 (89%)] Loss: 0.223297\n",
      "Train Epoch: 625 [1200/1612 (99%)] Loss: 0.242028\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 626 [0/1612 (0%)] Loss: 0.366465\n",
      "Train Epoch: 626 [160/1612 (10%)] Loss: 0.446045\n",
      "Train Epoch: 626 [320/1612 (20%)] Loss: 0.305344\n",
      "Train Epoch: 626 [480/1612 (30%)] Loss: 0.324900\n",
      "Train Epoch: 626 [640/1612 (40%)] Loss: 0.361962\n",
      "Train Epoch: 626 [800/1612 (50%)] Loss: 0.379923\n",
      "Train Epoch: 626 [960/1612 (59%)] Loss: 0.258951\n",
      "Train Epoch: 626 [1120/1612 (69%)] Loss: 0.431901\n",
      "Train Epoch: 626 [1280/1612 (79%)] Loss: 0.326400\n",
      "Train Epoch: 626 [1440/1612 (89%)] Loss: 0.183331\n",
      "Train Epoch: 626 [1200/1612 (99%)] Loss: 0.146211\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 627 [0/1612 (0%)] Loss: 0.196926\n",
      "Train Epoch: 627 [160/1612 (10%)] Loss: 0.232122\n",
      "Train Epoch: 627 [320/1612 (20%)] Loss: 0.280269\n",
      "Train Epoch: 627 [480/1612 (30%)] Loss: 0.432379\n",
      "Train Epoch: 627 [640/1612 (40%)] Loss: 0.521257\n",
      "Train Epoch: 627 [800/1612 (50%)] Loss: 0.118864\n",
      "Train Epoch: 627 [960/1612 (59%)] Loss: 0.207260\n",
      "Train Epoch: 627 [1120/1612 (69%)] Loss: 0.377769\n",
      "Train Epoch: 627 [1280/1612 (79%)] Loss: 0.351127\n",
      "Train Epoch: 627 [1440/1612 (89%)] Loss: 0.359879\n",
      "Train Epoch: 627 [1200/1612 (99%)] Loss: 0.511284\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 628 [0/1612 (0%)] Loss: 0.392191\n",
      "Train Epoch: 628 [160/1612 (10%)] Loss: 0.370652\n",
      "Train Epoch: 628 [320/1612 (20%)] Loss: 0.334987\n",
      "Train Epoch: 628 [480/1612 (30%)] Loss: 0.266087\n",
      "Train Epoch: 628 [640/1612 (40%)] Loss: 0.212961\n",
      "Train Epoch: 628 [800/1612 (50%)] Loss: 0.470088\n",
      "Train Epoch: 628 [960/1612 (59%)] Loss: 0.301937\n",
      "Train Epoch: 628 [1120/1612 (69%)] Loss: 0.572358\n",
      "Train Epoch: 628 [1280/1612 (79%)] Loss: 0.185285\n",
      "Train Epoch: 628 [1440/1612 (89%)] Loss: 0.325030\n",
      "Train Epoch: 628 [1200/1612 (99%)] Loss: 0.151491\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 629 [0/1612 (0%)] Loss: 0.417854\n",
      "Train Epoch: 629 [160/1612 (10%)] Loss: 0.355471\n",
      "Train Epoch: 629 [320/1612 (20%)] Loss: 0.208049\n",
      "Train Epoch: 629 [480/1612 (30%)] Loss: 0.266570\n",
      "Train Epoch: 629 [640/1612 (40%)] Loss: 0.513638\n",
      "Train Epoch: 629 [800/1612 (50%)] Loss: 0.270389\n",
      "Train Epoch: 629 [960/1612 (59%)] Loss: 0.195482\n",
      "Train Epoch: 629 [1120/1612 (69%)] Loss: 0.501070\n",
      "Train Epoch: 629 [1280/1612 (79%)] Loss: 0.196867\n",
      "Train Epoch: 629 [1440/1612 (89%)] Loss: 0.221960\n",
      "Train Epoch: 629 [1200/1612 (99%)] Loss: 0.192127\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 630 [0/1612 (0%)] Loss: 0.262226\n",
      "Train Epoch: 630 [160/1612 (10%)] Loss: 0.301900\n",
      "Train Epoch: 630 [320/1612 (20%)] Loss: 0.211422\n",
      "Train Epoch: 630 [480/1612 (30%)] Loss: 0.250921\n",
      "Train Epoch: 630 [640/1612 (40%)] Loss: 0.217950\n",
      "Train Epoch: 630 [800/1612 (50%)] Loss: 0.226932\n",
      "Train Epoch: 630 [960/1612 (59%)] Loss: 0.333052\n",
      "Train Epoch: 630 [1120/1612 (69%)] Loss: 0.550916\n",
      "Train Epoch: 630 [1280/1612 (79%)] Loss: 0.119771\n",
      "Train Epoch: 630 [1440/1612 (89%)] Loss: 0.363367\n",
      "Train Epoch: 630 [1200/1612 (99%)] Loss: 0.375437\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 631 [0/1612 (0%)] Loss: 0.329240\n",
      "Train Epoch: 631 [160/1612 (10%)] Loss: 0.220110\n",
      "Train Epoch: 631 [320/1612 (20%)] Loss: 0.486743\n",
      "Train Epoch: 631 [480/1612 (30%)] Loss: 0.364545\n",
      "Train Epoch: 631 [640/1612 (40%)] Loss: 0.256591\n",
      "Train Epoch: 631 [800/1612 (50%)] Loss: 0.403850\n",
      "Train Epoch: 631 [960/1612 (59%)] Loss: 0.245106\n",
      "Train Epoch: 631 [1120/1612 (69%)] Loss: 0.395225\n",
      "Train Epoch: 631 [1280/1612 (79%)] Loss: 0.459286\n",
      "Train Epoch: 631 [1440/1612 (89%)] Loss: 0.312882\n",
      "Train Epoch: 631 [1200/1612 (99%)] Loss: 0.402422\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 632 [0/1612 (0%)] Loss: 0.544995\n",
      "Train Epoch: 632 [160/1612 (10%)] Loss: 0.181574\n",
      "Train Epoch: 632 [320/1612 (20%)] Loss: 0.427268\n",
      "Train Epoch: 632 [480/1612 (30%)] Loss: 0.328693\n",
      "Train Epoch: 632 [640/1612 (40%)] Loss: 0.319175\n",
      "Train Epoch: 632 [800/1612 (50%)] Loss: 0.438233\n",
      "Train Epoch: 632 [960/1612 (59%)] Loss: 0.581553\n",
      "Train Epoch: 632 [1120/1612 (69%)] Loss: 0.199955\n",
      "Train Epoch: 632 [1280/1612 (79%)] Loss: 0.463365\n",
      "Train Epoch: 632 [1440/1612 (89%)] Loss: 0.533180\n",
      "Train Epoch: 632 [1200/1612 (99%)] Loss: 0.362742\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 633 [0/1612 (0%)] Loss: 0.118356\n",
      "Train Epoch: 633 [160/1612 (10%)] Loss: 0.252938\n",
      "Train Epoch: 633 [320/1612 (20%)] Loss: 0.467387\n",
      "Train Epoch: 633 [480/1612 (30%)] Loss: 0.412399\n",
      "Train Epoch: 633 [640/1612 (40%)] Loss: 0.608088\n",
      "Train Epoch: 633 [800/1612 (50%)] Loss: 0.138709\n",
      "Train Epoch: 633 [960/1612 (59%)] Loss: 0.290966\n",
      "Train Epoch: 633 [1120/1612 (69%)] Loss: 0.229214\n",
      "Train Epoch: 633 [1280/1612 (79%)] Loss: 0.316259\n",
      "Train Epoch: 633 [1440/1612 (89%)] Loss: 0.553456\n",
      "Train Epoch: 633 [1200/1612 (99%)] Loss: 0.583298\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 634 [0/1612 (0%)] Loss: 0.428958\n",
      "Train Epoch: 634 [160/1612 (10%)] Loss: 0.381104\n",
      "Train Epoch: 634 [320/1612 (20%)] Loss: 0.266010\n",
      "Train Epoch: 634 [480/1612 (30%)] Loss: 0.215710\n",
      "Train Epoch: 634 [640/1612 (40%)] Loss: 0.226726\n",
      "Train Epoch: 634 [800/1612 (50%)] Loss: 0.207329\n",
      "Train Epoch: 634 [960/1612 (59%)] Loss: 0.156280\n",
      "Train Epoch: 634 [1120/1612 (69%)] Loss: 0.179220\n",
      "Train Epoch: 634 [1280/1612 (79%)] Loss: 0.287330\n",
      "Train Epoch: 634 [1440/1612 (89%)] Loss: 0.236274\n",
      "Train Epoch: 634 [1200/1612 (99%)] Loss: 0.241328\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 635 [0/1612 (0%)] Loss: 0.334058\n",
      "Train Epoch: 635 [160/1612 (10%)] Loss: 0.083115\n",
      "Train Epoch: 635 [320/1612 (20%)] Loss: 0.377926\n",
      "Train Epoch: 635 [480/1612 (30%)] Loss: 0.145352\n",
      "Train Epoch: 635 [640/1612 (40%)] Loss: 0.316433\n",
      "Train Epoch: 635 [800/1612 (50%)] Loss: 0.383239\n",
      "Train Epoch: 635 [960/1612 (59%)] Loss: 0.527443\n",
      "Train Epoch: 635 [1120/1612 (69%)] Loss: 0.248478\n",
      "Train Epoch: 635 [1280/1612 (79%)] Loss: 0.324764\n",
      "Train Epoch: 635 [1440/1612 (89%)] Loss: 0.270967\n",
      "Train Epoch: 635 [1200/1612 (99%)] Loss: 0.157615\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 636 [0/1612 (0%)] Loss: 0.274806\n",
      "Train Epoch: 636 [160/1612 (10%)] Loss: 0.502427\n",
      "Train Epoch: 636 [320/1612 (20%)] Loss: 0.355319\n",
      "Train Epoch: 636 [480/1612 (30%)] Loss: 0.272082\n",
      "Train Epoch: 636 [640/1612 (40%)] Loss: 0.200416\n",
      "Train Epoch: 636 [800/1612 (50%)] Loss: 0.165786\n",
      "Train Epoch: 636 [960/1612 (59%)] Loss: 0.405000\n",
      "Train Epoch: 636 [1120/1612 (69%)] Loss: 0.243805\n",
      "Train Epoch: 636 [1280/1612 (79%)] Loss: 0.257618\n",
      "Train Epoch: 636 [1440/1612 (89%)] Loss: 0.421997\n",
      "Train Epoch: 636 [1200/1612 (99%)] Loss: 0.242709\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 637 [0/1612 (0%)] Loss: 0.346622\n",
      "Train Epoch: 637 [160/1612 (10%)] Loss: 0.306238\n",
      "Train Epoch: 637 [320/1612 (20%)] Loss: 0.289743\n",
      "Train Epoch: 637 [480/1612 (30%)] Loss: 0.419600\n",
      "Train Epoch: 637 [640/1612 (40%)] Loss: 0.312780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 637 [800/1612 (50%)] Loss: 0.613470\n",
      "Train Epoch: 637 [960/1612 (59%)] Loss: 0.168178\n",
      "Train Epoch: 637 [1120/1612 (69%)] Loss: 0.261836\n",
      "Train Epoch: 637 [1280/1612 (79%)] Loss: 0.216679\n",
      "Train Epoch: 637 [1440/1612 (89%)] Loss: 0.608444\n",
      "Train Epoch: 637 [1200/1612 (99%)] Loss: 0.138819\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 638 [0/1612 (0%)] Loss: 0.235473\n",
      "Train Epoch: 638 [160/1612 (10%)] Loss: 0.448679\n",
      "Train Epoch: 638 [320/1612 (20%)] Loss: 0.192596\n",
      "Train Epoch: 638 [480/1612 (30%)] Loss: 0.353628\n",
      "Train Epoch: 638 [640/1612 (40%)] Loss: 0.291970\n",
      "Train Epoch: 638 [800/1612 (50%)] Loss: 0.602065\n",
      "Train Epoch: 638 [960/1612 (59%)] Loss: 0.268208\n",
      "Train Epoch: 638 [1120/1612 (69%)] Loss: 0.422911\n",
      "Train Epoch: 638 [1280/1612 (79%)] Loss: 0.370804\n",
      "Train Epoch: 638 [1440/1612 (89%)] Loss: 0.139237\n",
      "Train Epoch: 638 [1200/1612 (99%)] Loss: 0.195628\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 639 [0/1612 (0%)] Loss: 0.095943\n",
      "Train Epoch: 639 [160/1612 (10%)] Loss: 0.230431\n",
      "Train Epoch: 639 [320/1612 (20%)] Loss: 0.509445\n",
      "Train Epoch: 639 [480/1612 (30%)] Loss: 0.123600\n",
      "Train Epoch: 639 [640/1612 (40%)] Loss: 0.404997\n",
      "Train Epoch: 639 [800/1612 (50%)] Loss: 0.229993\n",
      "Train Epoch: 639 [960/1612 (59%)] Loss: 0.271134\n",
      "Train Epoch: 639 [1120/1612 (69%)] Loss: 0.479329\n",
      "Train Epoch: 639 [1280/1612 (79%)] Loss: 0.267473\n",
      "Train Epoch: 639 [1440/1612 (89%)] Loss: 0.493257\n",
      "Train Epoch: 639 [1200/1612 (99%)] Loss: 0.402573\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 640 [0/1612 (0%)] Loss: 0.419903\n",
      "Train Epoch: 640 [160/1612 (10%)] Loss: 0.458777\n",
      "Train Epoch: 640 [320/1612 (20%)] Loss: 0.422510\n",
      "Train Epoch: 640 [480/1612 (30%)] Loss: 0.296913\n",
      "Train Epoch: 640 [640/1612 (40%)] Loss: 0.212786\n",
      "Train Epoch: 640 [800/1612 (50%)] Loss: 0.308040\n",
      "Train Epoch: 640 [960/1612 (59%)] Loss: 0.548627\n",
      "Train Epoch: 640 [1120/1612 (69%)] Loss: 0.214364\n",
      "Train Epoch: 640 [1280/1612 (79%)] Loss: 0.415285\n",
      "Train Epoch: 640 [1440/1612 (89%)] Loss: 0.164091\n",
      "Train Epoch: 640 [1200/1612 (99%)] Loss: 0.613196\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 641 [0/1612 (0%)] Loss: 0.238756\n",
      "Train Epoch: 641 [160/1612 (10%)] Loss: 0.228944\n",
      "Train Epoch: 641 [320/1612 (20%)] Loss: 0.333055\n",
      "Train Epoch: 641 [480/1612 (30%)] Loss: 0.328764\n",
      "Train Epoch: 641 [640/1612 (40%)] Loss: 0.270721\n",
      "Train Epoch: 641 [800/1612 (50%)] Loss: 0.345724\n",
      "Train Epoch: 641 [960/1612 (59%)] Loss: 0.149445\n",
      "Train Epoch: 641 [1120/1612 (69%)] Loss: 0.132035\n",
      "Train Epoch: 641 [1280/1612 (79%)] Loss: 0.331246\n",
      "Train Epoch: 641 [1440/1612 (89%)] Loss: 0.301488\n",
      "Train Epoch: 641 [1200/1612 (99%)] Loss: 0.144764\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 642 [0/1612 (0%)] Loss: 0.622476\n",
      "Train Epoch: 642 [160/1612 (10%)] Loss: 0.453340\n",
      "Train Epoch: 642 [320/1612 (20%)] Loss: 0.261375\n",
      "Train Epoch: 642 [480/1612 (30%)] Loss: 0.401555\n",
      "Train Epoch: 642 [640/1612 (40%)] Loss: 0.288713\n",
      "Train Epoch: 642 [800/1612 (50%)] Loss: 0.103127\n",
      "Train Epoch: 642 [960/1612 (59%)] Loss: 0.199147\n",
      "Train Epoch: 642 [1120/1612 (69%)] Loss: 0.332232\n",
      "Train Epoch: 642 [1280/1612 (79%)] Loss: 0.213389\n",
      "Train Epoch: 642 [1440/1612 (89%)] Loss: 0.386239\n",
      "Train Epoch: 642 [1200/1612 (99%)] Loss: 0.213082\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 643 [0/1612 (0%)] Loss: 0.146046\n",
      "Train Epoch: 643 [160/1612 (10%)] Loss: 0.124475\n",
      "Train Epoch: 643 [320/1612 (20%)] Loss: 0.179918\n",
      "Train Epoch: 643 [480/1612 (30%)] Loss: 0.508112\n",
      "Train Epoch: 643 [640/1612 (40%)] Loss: 0.185382\n",
      "Train Epoch: 643 [800/1612 (50%)] Loss: 0.394522\n",
      "Train Epoch: 643 [960/1612 (59%)] Loss: 0.250926\n",
      "Train Epoch: 643 [1120/1612 (69%)] Loss: 0.247529\n",
      "Train Epoch: 643 [1280/1612 (79%)] Loss: 0.466520\n",
      "Train Epoch: 643 [1440/1612 (89%)] Loss: 0.392389\n",
      "Train Epoch: 643 [1200/1612 (99%)] Loss: 0.339099\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 644 [0/1612 (0%)] Loss: 0.249428\n",
      "Train Epoch: 644 [160/1612 (10%)] Loss: 0.106478\n",
      "Train Epoch: 644 [320/1612 (20%)] Loss: 0.165897\n",
      "Train Epoch: 644 [480/1612 (30%)] Loss: 0.162048\n",
      "Train Epoch: 644 [640/1612 (40%)] Loss: 0.223498\n",
      "Train Epoch: 644 [800/1612 (50%)] Loss: 0.242139\n",
      "Train Epoch: 644 [960/1612 (59%)] Loss: 0.405632\n",
      "Train Epoch: 644 [1120/1612 (69%)] Loss: 0.226860\n",
      "Train Epoch: 644 [1280/1612 (79%)] Loss: 0.190690\n",
      "Train Epoch: 644 [1440/1612 (89%)] Loss: 0.351803\n",
      "Train Epoch: 644 [1200/1612 (99%)] Loss: 0.493334\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 645 [0/1612 (0%)] Loss: 0.223075\n",
      "Train Epoch: 645 [160/1612 (10%)] Loss: 0.195881\n",
      "Train Epoch: 645 [320/1612 (20%)] Loss: 0.500360\n",
      "Train Epoch: 645 [480/1612 (30%)] Loss: 0.233231\n",
      "Train Epoch: 645 [640/1612 (40%)] Loss: 0.154190\n",
      "Train Epoch: 645 [800/1612 (50%)] Loss: 0.580131\n",
      "Train Epoch: 645 [960/1612 (59%)] Loss: 0.675586\n",
      "Train Epoch: 645 [1120/1612 (69%)] Loss: 0.541988\n",
      "Train Epoch: 645 [1280/1612 (79%)] Loss: 0.412979\n",
      "Train Epoch: 645 [1440/1612 (89%)] Loss: 0.272960\n",
      "Train Epoch: 645 [1200/1612 (99%)] Loss: 0.488285\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 646 [0/1612 (0%)] Loss: 0.395002\n",
      "Train Epoch: 646 [160/1612 (10%)] Loss: 0.377718\n",
      "Train Epoch: 646 [320/1612 (20%)] Loss: 0.214693\n",
      "Train Epoch: 646 [480/1612 (30%)] Loss: 0.211586\n",
      "Train Epoch: 646 [640/1612 (40%)] Loss: 0.189867\n",
      "Train Epoch: 646 [800/1612 (50%)] Loss: 0.487621\n",
      "Train Epoch: 646 [960/1612 (59%)] Loss: 0.350250\n",
      "Train Epoch: 646 [1120/1612 (69%)] Loss: 0.398750\n",
      "Train Epoch: 646 [1280/1612 (79%)] Loss: 0.279980\n",
      "Train Epoch: 646 [1440/1612 (89%)] Loss: 0.314304\n",
      "Train Epoch: 646 [1200/1612 (99%)] Loss: 0.402546\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 647 [0/1612 (0%)] Loss: 0.162052\n",
      "Train Epoch: 647 [160/1612 (10%)] Loss: 0.236081\n",
      "Train Epoch: 647 [320/1612 (20%)] Loss: 0.296888\n",
      "Train Epoch: 647 [480/1612 (30%)] Loss: 0.282857\n",
      "Train Epoch: 647 [640/1612 (40%)] Loss: 0.401324\n",
      "Train Epoch: 647 [800/1612 (50%)] Loss: 0.198934\n",
      "Train Epoch: 647 [960/1612 (59%)] Loss: 0.191216\n",
      "Train Epoch: 647 [1120/1612 (69%)] Loss: 0.251756\n",
      "Train Epoch: 647 [1280/1612 (79%)] Loss: 0.335605\n",
      "Train Epoch: 647 [1440/1612 (89%)] Loss: 0.588467\n",
      "Train Epoch: 647 [1200/1612 (99%)] Loss: 0.279894\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 648 [0/1612 (0%)] Loss: 0.331360\n",
      "Train Epoch: 648 [160/1612 (10%)] Loss: 0.162675\n",
      "Train Epoch: 648 [320/1612 (20%)] Loss: 0.274820\n",
      "Train Epoch: 648 [480/1612 (30%)] Loss: 0.230478\n",
      "Train Epoch: 648 [640/1612 (40%)] Loss: 0.316133\n",
      "Train Epoch: 648 [800/1612 (50%)] Loss: 0.234224\n",
      "Train Epoch: 648 [960/1612 (59%)] Loss: 0.263641\n",
      "Train Epoch: 648 [1120/1612 (69%)] Loss: 0.215981\n",
      "Train Epoch: 648 [1280/1612 (79%)] Loss: 0.374904\n",
      "Train Epoch: 648 [1440/1612 (89%)] Loss: 0.508254\n",
      "Train Epoch: 648 [1200/1612 (99%)] Loss: 0.577577\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 649 [0/1612 (0%)] Loss: 0.416541\n",
      "Train Epoch: 649 [160/1612 (10%)] Loss: 0.247706\n",
      "Train Epoch: 649 [320/1612 (20%)] Loss: 0.477325\n",
      "Train Epoch: 649 [480/1612 (30%)] Loss: 0.247823\n",
      "Train Epoch: 649 [640/1612 (40%)] Loss: 0.440727\n",
      "Train Epoch: 649 [800/1612 (50%)] Loss: 0.218489\n",
      "Train Epoch: 649 [960/1612 (59%)] Loss: 0.292650\n",
      "Train Epoch: 649 [1120/1612 (69%)] Loss: 0.291471\n",
      "Train Epoch: 649 [1280/1612 (79%)] Loss: 0.044810\n",
      "Train Epoch: 649 [1440/1612 (89%)] Loss: 0.380428\n",
      "Train Epoch: 649 [1200/1612 (99%)] Loss: 0.249461\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 650 [0/1612 (0%)] Loss: 0.093108\n",
      "Train Epoch: 650 [160/1612 (10%)] Loss: 0.298417\n",
      "Train Epoch: 650 [320/1612 (20%)] Loss: 0.360019\n",
      "Train Epoch: 650 [480/1612 (30%)] Loss: 0.187256\n",
      "Train Epoch: 650 [640/1612 (40%)] Loss: 0.621327\n",
      "Train Epoch: 650 [800/1612 (50%)] Loss: 0.319107\n",
      "Train Epoch: 650 [960/1612 (59%)] Loss: 0.326701\n",
      "Train Epoch: 650 [1120/1612 (69%)] Loss: 0.428713\n",
      "Train Epoch: 650 [1280/1612 (79%)] Loss: 0.206772\n",
      "Train Epoch: 650 [1440/1612 (89%)] Loss: 0.365792\n",
      "Train Epoch: 650 [1200/1612 (99%)] Loss: 0.216908\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 651 [0/1612 (0%)] Loss: 0.331696\n",
      "Train Epoch: 651 [160/1612 (10%)] Loss: 0.375577\n",
      "Train Epoch: 651 [320/1612 (20%)] Loss: 0.166660\n",
      "Train Epoch: 651 [480/1612 (30%)] Loss: 0.342439\n",
      "Train Epoch: 651 [640/1612 (40%)] Loss: 0.203403\n",
      "Train Epoch: 651 [800/1612 (50%)] Loss: 0.472058\n",
      "Train Epoch: 651 [960/1612 (59%)] Loss: 0.363526\n",
      "Train Epoch: 651 [1120/1612 (69%)] Loss: 0.234089\n",
      "Train Epoch: 651 [1280/1612 (79%)] Loss: 0.256553\n",
      "Train Epoch: 651 [1440/1612 (89%)] Loss: 0.338693\n",
      "Train Epoch: 651 [1200/1612 (99%)] Loss: 0.566528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 652 [0/1612 (0%)] Loss: 0.323805\n",
      "Train Epoch: 652 [160/1612 (10%)] Loss: 0.304931\n",
      "Train Epoch: 652 [320/1612 (20%)] Loss: 0.389890\n",
      "Train Epoch: 652 [480/1612 (30%)] Loss: 0.210775\n",
      "Train Epoch: 652 [640/1612 (40%)] Loss: 0.260182\n",
      "Train Epoch: 652 [800/1612 (50%)] Loss: 0.187254\n",
      "Train Epoch: 652 [960/1612 (59%)] Loss: 0.338549\n",
      "Train Epoch: 652 [1120/1612 (69%)] Loss: 0.242053\n",
      "Train Epoch: 652 [1280/1612 (79%)] Loss: 0.213638\n",
      "Train Epoch: 652 [1440/1612 (89%)] Loss: 0.430298\n",
      "Train Epoch: 652 [1200/1612 (99%)] Loss: 0.300404\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 653 [0/1612 (0%)] Loss: 0.504660\n",
      "Train Epoch: 653 [160/1612 (10%)] Loss: 0.381435\n",
      "Train Epoch: 653 [320/1612 (20%)] Loss: 0.228713\n",
      "Train Epoch: 653 [480/1612 (30%)] Loss: 0.356542\n",
      "Train Epoch: 653 [640/1612 (40%)] Loss: 0.281567\n",
      "Train Epoch: 653 [800/1612 (50%)] Loss: 0.452988\n",
      "Train Epoch: 653 [960/1612 (59%)] Loss: 0.377513\n",
      "Train Epoch: 653 [1120/1612 (69%)] Loss: 0.270886\n",
      "Train Epoch: 653 [1280/1612 (79%)] Loss: 0.354841\n",
      "Train Epoch: 653 [1440/1612 (89%)] Loss: 0.317437\n",
      "Train Epoch: 653 [1200/1612 (99%)] Loss: 0.618415\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 654 [0/1612 (0%)] Loss: 0.233520\n",
      "Train Epoch: 654 [160/1612 (10%)] Loss: 0.419813\n",
      "Train Epoch: 654 [320/1612 (20%)] Loss: 0.437362\n",
      "Train Epoch: 654 [480/1612 (30%)] Loss: 0.419025\n",
      "Train Epoch: 654 [640/1612 (40%)] Loss: 0.358679\n",
      "Train Epoch: 654 [800/1612 (50%)] Loss: 0.358301\n",
      "Train Epoch: 654 [960/1612 (59%)] Loss: 0.193698\n",
      "Train Epoch: 654 [1120/1612 (69%)] Loss: 0.193880\n",
      "Train Epoch: 654 [1280/1612 (79%)] Loss: 0.365325\n",
      "Train Epoch: 654 [1440/1612 (89%)] Loss: 0.362088\n",
      "Train Epoch: 654 [1200/1612 (99%)] Loss: 0.497228\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 655 [0/1612 (0%)] Loss: 0.174200\n",
      "Train Epoch: 655 [160/1612 (10%)] Loss: 0.365641\n",
      "Train Epoch: 655 [320/1612 (20%)] Loss: 0.383677\n",
      "Train Epoch: 655 [480/1612 (30%)] Loss: 0.401961\n",
      "Train Epoch: 655 [640/1612 (40%)] Loss: 0.300142\n",
      "Train Epoch: 655 [800/1612 (50%)] Loss: 0.179858\n",
      "Train Epoch: 655 [960/1612 (59%)] Loss: 0.232061\n",
      "Train Epoch: 655 [1120/1612 (69%)] Loss: 0.209844\n",
      "Train Epoch: 655 [1280/1612 (79%)] Loss: 0.455255\n",
      "Train Epoch: 655 [1440/1612 (89%)] Loss: 0.314040\n",
      "Train Epoch: 655 [1200/1612 (99%)] Loss: 0.324723\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 656 [0/1612 (0%)] Loss: 0.377906\n",
      "Train Epoch: 656 [160/1612 (10%)] Loss: 0.568313\n",
      "Train Epoch: 656 [320/1612 (20%)] Loss: 0.225507\n",
      "Train Epoch: 656 [480/1612 (30%)] Loss: 0.407565\n",
      "Train Epoch: 656 [640/1612 (40%)] Loss: 0.224984\n",
      "Train Epoch: 656 [800/1612 (50%)] Loss: 0.410321\n",
      "Train Epoch: 656 [960/1612 (59%)] Loss: 0.452106\n",
      "Train Epoch: 656 [1120/1612 (69%)] Loss: 0.606299\n",
      "Train Epoch: 656 [1280/1612 (79%)] Loss: 0.377436\n",
      "Train Epoch: 656 [1440/1612 (89%)] Loss: 0.267421\n",
      "Train Epoch: 656 [1200/1612 (99%)] Loss: 0.221361\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 657 [0/1612 (0%)] Loss: 0.306849\n",
      "Train Epoch: 657 [160/1612 (10%)] Loss: 0.340794\n",
      "Train Epoch: 657 [320/1612 (20%)] Loss: 0.270106\n",
      "Train Epoch: 657 [480/1612 (30%)] Loss: 0.402296\n",
      "Train Epoch: 657 [640/1612 (40%)] Loss: 0.301181\n",
      "Train Epoch: 657 [800/1612 (50%)] Loss: 0.339501\n",
      "Train Epoch: 657 [960/1612 (59%)] Loss: 0.172740\n",
      "Train Epoch: 657 [1120/1612 (69%)] Loss: 0.276107\n",
      "Train Epoch: 657 [1280/1612 (79%)] Loss: 0.305528\n",
      "Train Epoch: 657 [1440/1612 (89%)] Loss: 0.169234\n",
      "Train Epoch: 657 [1200/1612 (99%)] Loss: 0.588541\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 658 [0/1612 (0%)] Loss: 0.285717\n",
      "Train Epoch: 658 [160/1612 (10%)] Loss: 0.600745\n",
      "Train Epoch: 658 [320/1612 (20%)] Loss: 0.183590\n",
      "Train Epoch: 658 [480/1612 (30%)] Loss: 0.212717\n",
      "Train Epoch: 658 [640/1612 (40%)] Loss: 0.145949\n",
      "Train Epoch: 658 [800/1612 (50%)] Loss: 0.297034\n",
      "Train Epoch: 658 [960/1612 (59%)] Loss: 0.204933\n",
      "Train Epoch: 658 [1120/1612 (69%)] Loss: 0.150967\n",
      "Train Epoch: 658 [1280/1612 (79%)] Loss: 0.309774\n",
      "Train Epoch: 658 [1440/1612 (89%)] Loss: 0.186163\n",
      "Train Epoch: 658 [1200/1612 (99%)] Loss: 0.370287\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 659 [0/1612 (0%)] Loss: 0.169135\n",
      "Train Epoch: 659 [160/1612 (10%)] Loss: 0.228658\n",
      "Train Epoch: 659 [320/1612 (20%)] Loss: 0.214380\n",
      "Train Epoch: 659 [480/1612 (30%)] Loss: 0.305675\n",
      "Train Epoch: 659 [640/1612 (40%)] Loss: 0.239371\n",
      "Train Epoch: 659 [800/1612 (50%)] Loss: 0.353557\n",
      "Train Epoch: 659 [960/1612 (59%)] Loss: 0.103222\n",
      "Train Epoch: 659 [1120/1612 (69%)] Loss: 0.666576\n",
      "Train Epoch: 659 [1280/1612 (79%)] Loss: 0.361462\n",
      "Train Epoch: 659 [1440/1612 (89%)] Loss: 0.265022\n",
      "Train Epoch: 659 [1200/1612 (99%)] Loss: 0.403678\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 660 [0/1612 (0%)] Loss: 0.416143\n",
      "Train Epoch: 660 [160/1612 (10%)] Loss: 0.293558\n",
      "Train Epoch: 660 [320/1612 (20%)] Loss: 0.292291\n",
      "Train Epoch: 660 [480/1612 (30%)] Loss: 0.472602\n",
      "Train Epoch: 660 [640/1612 (40%)] Loss: 0.272315\n",
      "Train Epoch: 660 [800/1612 (50%)] Loss: 0.222796\n",
      "Train Epoch: 660 [960/1612 (59%)] Loss: 0.252484\n",
      "Train Epoch: 660 [1120/1612 (69%)] Loss: 0.129656\n",
      "Train Epoch: 660 [1280/1612 (79%)] Loss: 0.202320\n",
      "Train Epoch: 660 [1440/1612 (89%)] Loss: 0.619618\n",
      "Train Epoch: 660 [1200/1612 (99%)] Loss: 0.190434\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 661 [0/1612 (0%)] Loss: 0.104576\n",
      "Train Epoch: 661 [160/1612 (10%)] Loss: 0.314643\n",
      "Train Epoch: 661 [320/1612 (20%)] Loss: 0.109578\n",
      "Train Epoch: 661 [480/1612 (30%)] Loss: 0.272074\n",
      "Train Epoch: 661 [640/1612 (40%)] Loss: 0.358949\n",
      "Train Epoch: 661 [800/1612 (50%)] Loss: 0.255970\n",
      "Train Epoch: 661 [960/1612 (59%)] Loss: 0.247441\n",
      "Train Epoch: 661 [1120/1612 (69%)] Loss: 0.188431\n",
      "Train Epoch: 661 [1280/1612 (79%)] Loss: 0.393619\n",
      "Train Epoch: 661 [1440/1612 (89%)] Loss: 0.158314\n",
      "Train Epoch: 661 [1200/1612 (99%)] Loss: 0.263957\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 662 [0/1612 (0%)] Loss: 0.140206\n",
      "Train Epoch: 662 [160/1612 (10%)] Loss: 0.392810\n",
      "Train Epoch: 662 [320/1612 (20%)] Loss: 0.345307\n",
      "Train Epoch: 662 [480/1612 (30%)] Loss: 0.213070\n",
      "Train Epoch: 662 [640/1612 (40%)] Loss: 0.294691\n",
      "Train Epoch: 662 [800/1612 (50%)] Loss: 0.460597\n",
      "Train Epoch: 662 [960/1612 (59%)] Loss: 0.241062\n",
      "Train Epoch: 662 [1120/1612 (69%)] Loss: 0.482921\n",
      "Train Epoch: 662 [1280/1612 (79%)] Loss: 0.145713\n",
      "Train Epoch: 662 [1440/1612 (89%)] Loss: 0.214669\n",
      "Train Epoch: 662 [1200/1612 (99%)] Loss: 0.272416\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 663 [0/1612 (0%)] Loss: 0.156401\n",
      "Train Epoch: 663 [160/1612 (10%)] Loss: 0.293894\n",
      "Train Epoch: 663 [320/1612 (20%)] Loss: 0.228533\n",
      "Train Epoch: 663 [480/1612 (30%)] Loss: 0.165139\n",
      "Train Epoch: 663 [640/1612 (40%)] Loss: 0.431775\n",
      "Train Epoch: 663 [800/1612 (50%)] Loss: 0.180121\n",
      "Train Epoch: 663 [960/1612 (59%)] Loss: 0.230377\n",
      "Train Epoch: 663 [1120/1612 (69%)] Loss: 0.292108\n",
      "Train Epoch: 663 [1280/1612 (79%)] Loss: 0.250388\n",
      "Train Epoch: 663 [1440/1612 (89%)] Loss: 0.321279\n",
      "Train Epoch: 663 [1200/1612 (99%)] Loss: 0.085021\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 664 [0/1612 (0%)] Loss: 0.275658\n",
      "Train Epoch: 664 [160/1612 (10%)] Loss: 0.266959\n",
      "Train Epoch: 664 [320/1612 (20%)] Loss: 0.306978\n",
      "Train Epoch: 664 [480/1612 (30%)] Loss: 0.635434\n",
      "Train Epoch: 664 [640/1612 (40%)] Loss: 0.162408\n",
      "Train Epoch: 664 [800/1612 (50%)] Loss: 0.182841\n",
      "Train Epoch: 664 [960/1612 (59%)] Loss: 0.433870\n",
      "Train Epoch: 664 [1120/1612 (69%)] Loss: 0.382998\n",
      "Train Epoch: 664 [1280/1612 (79%)] Loss: 0.416576\n",
      "Train Epoch: 664 [1440/1612 (89%)] Loss: 0.299390\n",
      "Train Epoch: 664 [1200/1612 (99%)] Loss: 0.445227\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 665 [0/1612 (0%)] Loss: 0.378079\n",
      "Train Epoch: 665 [160/1612 (10%)] Loss: 0.498131\n",
      "Train Epoch: 665 [320/1612 (20%)] Loss: 0.307605\n",
      "Train Epoch: 665 [480/1612 (30%)] Loss: 0.720533\n",
      "Train Epoch: 665 [640/1612 (40%)] Loss: 0.380159\n",
      "Train Epoch: 665 [800/1612 (50%)] Loss: 0.259042\n",
      "Train Epoch: 665 [960/1612 (59%)] Loss: 0.284744\n",
      "Train Epoch: 665 [1120/1612 (69%)] Loss: 0.271175\n",
      "Train Epoch: 665 [1280/1612 (79%)] Loss: 0.111294\n",
      "Train Epoch: 665 [1440/1612 (89%)] Loss: 0.538491\n",
      "Train Epoch: 665 [1200/1612 (99%)] Loss: 0.181415\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 666 [0/1612 (0%)] Loss: 0.213354\n",
      "Train Epoch: 666 [160/1612 (10%)] Loss: 0.110115\n",
      "Train Epoch: 666 [320/1612 (20%)] Loss: 0.349160\n",
      "Train Epoch: 666 [480/1612 (30%)] Loss: 0.223643\n",
      "Train Epoch: 666 [640/1612 (40%)] Loss: 0.253428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 666 [800/1612 (50%)] Loss: 0.142915\n",
      "Train Epoch: 666 [960/1612 (59%)] Loss: 0.385191\n",
      "Train Epoch: 666 [1120/1612 (69%)] Loss: 0.180530\n",
      "Train Epoch: 666 [1280/1612 (79%)] Loss: 0.216699\n",
      "Train Epoch: 666 [1440/1612 (89%)] Loss: 0.513499\n",
      "Train Epoch: 666 [1200/1612 (99%)] Loss: 0.334598\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 667 [0/1612 (0%)] Loss: 0.203898\n",
      "Train Epoch: 667 [160/1612 (10%)] Loss: 0.592977\n",
      "Train Epoch: 667 [320/1612 (20%)] Loss: 0.260196\n",
      "Train Epoch: 667 [480/1612 (30%)] Loss: 0.347441\n",
      "Train Epoch: 667 [640/1612 (40%)] Loss: 0.402382\n",
      "Train Epoch: 667 [800/1612 (50%)] Loss: 0.261290\n",
      "Train Epoch: 667 [960/1612 (59%)] Loss: 0.361177\n",
      "Train Epoch: 667 [1120/1612 (69%)] Loss: 0.251005\n",
      "Train Epoch: 667 [1280/1612 (79%)] Loss: 0.377707\n",
      "Train Epoch: 667 [1440/1612 (89%)] Loss: 0.063486\n",
      "Train Epoch: 667 [1200/1612 (99%)] Loss: 0.142645\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 668 [0/1612 (0%)] Loss: 0.292213\n",
      "Train Epoch: 668 [160/1612 (10%)] Loss: 0.425282\n",
      "Train Epoch: 668 [320/1612 (20%)] Loss: 0.405598\n",
      "Train Epoch: 668 [480/1612 (30%)] Loss: 0.346419\n",
      "Train Epoch: 668 [640/1612 (40%)] Loss: 0.756288\n",
      "Train Epoch: 668 [800/1612 (50%)] Loss: 0.303485\n",
      "Train Epoch: 668 [960/1612 (59%)] Loss: 0.277747\n",
      "Train Epoch: 668 [1120/1612 (69%)] Loss: 0.254972\n",
      "Train Epoch: 668 [1280/1612 (79%)] Loss: 0.406069\n",
      "Train Epoch: 668 [1440/1612 (89%)] Loss: 0.323454\n",
      "Train Epoch: 668 [1200/1612 (99%)] Loss: 0.477223\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 669 [0/1612 (0%)] Loss: 0.129319\n",
      "Train Epoch: 669 [160/1612 (10%)] Loss: 0.193623\n",
      "Train Epoch: 669 [320/1612 (20%)] Loss: 0.190295\n",
      "Train Epoch: 669 [480/1612 (30%)] Loss: 0.185926\n",
      "Train Epoch: 669 [640/1612 (40%)] Loss: 0.328093\n",
      "Train Epoch: 669 [800/1612 (50%)] Loss: 0.522484\n",
      "Train Epoch: 669 [960/1612 (59%)] Loss: 0.217161\n",
      "Train Epoch: 669 [1120/1612 (69%)] Loss: 0.365635\n",
      "Train Epoch: 669 [1280/1612 (79%)] Loss: 0.274140\n",
      "Train Epoch: 669 [1440/1612 (89%)] Loss: 0.387143\n",
      "Train Epoch: 669 [1200/1612 (99%)] Loss: 0.078396\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 670 [0/1612 (0%)] Loss: 0.536191\n",
      "Train Epoch: 670 [160/1612 (10%)] Loss: 0.327371\n",
      "Train Epoch: 670 [320/1612 (20%)] Loss: 0.370651\n",
      "Train Epoch: 670 [480/1612 (30%)] Loss: 0.205062\n",
      "Train Epoch: 670 [640/1612 (40%)] Loss: 0.236991\n",
      "Train Epoch: 670 [800/1612 (50%)] Loss: 0.295969\n",
      "Train Epoch: 670 [960/1612 (59%)] Loss: 0.361615\n",
      "Train Epoch: 670 [1120/1612 (69%)] Loss: 0.204723\n",
      "Train Epoch: 670 [1280/1612 (79%)] Loss: 0.224399\n",
      "Train Epoch: 670 [1440/1612 (89%)] Loss: 0.134705\n",
      "Train Epoch: 670 [1200/1612 (99%)] Loss: 0.160314\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 671 [0/1612 (0%)] Loss: 0.421722\n",
      "Train Epoch: 671 [160/1612 (10%)] Loss: 0.493928\n",
      "Train Epoch: 671 [320/1612 (20%)] Loss: 0.396804\n",
      "Train Epoch: 671 [480/1612 (30%)] Loss: 0.376388\n",
      "Train Epoch: 671 [640/1612 (40%)] Loss: 0.354655\n",
      "Train Epoch: 671 [800/1612 (50%)] Loss: 0.504310\n",
      "Train Epoch: 671 [960/1612 (59%)] Loss: 0.347874\n",
      "Train Epoch: 671 [1120/1612 (69%)] Loss: 0.327917\n",
      "Train Epoch: 671 [1280/1612 (79%)] Loss: 0.311980\n",
      "Train Epoch: 671 [1440/1612 (89%)] Loss: 0.515053\n",
      "Train Epoch: 671 [1200/1612 (99%)] Loss: 0.066389\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 672 [0/1612 (0%)] Loss: 0.072091\n",
      "Train Epoch: 672 [160/1612 (10%)] Loss: 0.176070\n",
      "Train Epoch: 672 [320/1612 (20%)] Loss: 0.279260\n",
      "Train Epoch: 672 [480/1612 (30%)] Loss: 0.221138\n",
      "Train Epoch: 672 [640/1612 (40%)] Loss: 0.260188\n",
      "Train Epoch: 672 [800/1612 (50%)] Loss: 0.421475\n",
      "Train Epoch: 672 [960/1612 (59%)] Loss: 0.341438\n",
      "Train Epoch: 672 [1120/1612 (69%)] Loss: 0.295094\n",
      "Train Epoch: 672 [1280/1612 (79%)] Loss: 0.245647\n",
      "Train Epoch: 672 [1440/1612 (89%)] Loss: 0.331084\n",
      "Train Epoch: 672 [1200/1612 (99%)] Loss: 0.234809\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 673 [0/1612 (0%)] Loss: 0.196895\n",
      "Train Epoch: 673 [160/1612 (10%)] Loss: 0.267784\n",
      "Train Epoch: 673 [320/1612 (20%)] Loss: 0.259800\n",
      "Train Epoch: 673 [480/1612 (30%)] Loss: 0.489838\n",
      "Train Epoch: 673 [640/1612 (40%)] Loss: 0.393291\n",
      "Train Epoch: 673 [800/1612 (50%)] Loss: 0.285081\n",
      "Train Epoch: 673 [960/1612 (59%)] Loss: 0.238096\n",
      "Train Epoch: 673 [1120/1612 (69%)] Loss: 0.234677\n",
      "Train Epoch: 673 [1280/1612 (79%)] Loss: 0.356873\n",
      "Train Epoch: 673 [1440/1612 (89%)] Loss: 0.119813\n",
      "Train Epoch: 673 [1200/1612 (99%)] Loss: 0.515217\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 674 [0/1612 (0%)] Loss: 0.251687\n",
      "Train Epoch: 674 [160/1612 (10%)] Loss: 0.298022\n",
      "Train Epoch: 674 [320/1612 (20%)] Loss: 0.390186\n",
      "Train Epoch: 674 [480/1612 (30%)] Loss: 0.221837\n",
      "Train Epoch: 674 [640/1612 (40%)] Loss: 0.344218\n",
      "Train Epoch: 674 [800/1612 (50%)] Loss: 0.133444\n",
      "Train Epoch: 674 [960/1612 (59%)] Loss: 0.260496\n",
      "Train Epoch: 674 [1120/1612 (69%)] Loss: 0.406768\n",
      "Train Epoch: 674 [1280/1612 (79%)] Loss: 0.292600\n",
      "Train Epoch: 674 [1440/1612 (89%)] Loss: 0.122799\n",
      "Train Epoch: 674 [1200/1612 (99%)] Loss: 0.279500\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 675 [0/1612 (0%)] Loss: 0.397394\n",
      "Train Epoch: 675 [160/1612 (10%)] Loss: 0.319901\n",
      "Train Epoch: 675 [320/1612 (20%)] Loss: 0.317286\n",
      "Train Epoch: 675 [480/1612 (30%)] Loss: 0.170619\n",
      "Train Epoch: 675 [640/1612 (40%)] Loss: 0.258554\n",
      "Train Epoch: 675 [800/1612 (50%)] Loss: 0.204017\n",
      "Train Epoch: 675 [960/1612 (59%)] Loss: 0.517748\n",
      "Train Epoch: 675 [1120/1612 (69%)] Loss: 0.194744\n",
      "Train Epoch: 675 [1280/1612 (79%)] Loss: 0.268363\n",
      "Train Epoch: 675 [1440/1612 (89%)] Loss: 0.224728\n",
      "Train Epoch: 675 [1200/1612 (99%)] Loss: 0.300342\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 676 [0/1612 (0%)] Loss: 0.381674\n",
      "Train Epoch: 676 [160/1612 (10%)] Loss: 0.469200\n",
      "Train Epoch: 676 [320/1612 (20%)] Loss: 0.172163\n",
      "Train Epoch: 676 [480/1612 (30%)] Loss: 0.263141\n",
      "Train Epoch: 676 [640/1612 (40%)] Loss: 0.470058\n",
      "Train Epoch: 676 [800/1612 (50%)] Loss: 0.251990\n",
      "Train Epoch: 676 [960/1612 (59%)] Loss: 0.387055\n",
      "Train Epoch: 676 [1120/1612 (69%)] Loss: 0.321812\n",
      "Train Epoch: 676 [1280/1612 (79%)] Loss: 0.379235\n",
      "Train Epoch: 676 [1440/1612 (89%)] Loss: 0.375399\n",
      "Train Epoch: 676 [1200/1612 (99%)] Loss: 0.098641\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 677 [0/1612 (0%)] Loss: 0.394897\n",
      "Train Epoch: 677 [160/1612 (10%)] Loss: 0.590332\n",
      "Train Epoch: 677 [320/1612 (20%)] Loss: 0.337239\n",
      "Train Epoch: 677 [480/1612 (30%)] Loss: 0.222288\n",
      "Train Epoch: 677 [640/1612 (40%)] Loss: 0.290951\n",
      "Train Epoch: 677 [800/1612 (50%)] Loss: 0.450152\n",
      "Train Epoch: 677 [960/1612 (59%)] Loss: 0.201979\n",
      "Train Epoch: 677 [1120/1612 (69%)] Loss: 0.308712\n",
      "Train Epoch: 677 [1280/1612 (79%)] Loss: 0.195460\n",
      "Train Epoch: 677 [1440/1612 (89%)] Loss: 0.371075\n",
      "Train Epoch: 677 [1200/1612 (99%)] Loss: 0.309738\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 678 [0/1612 (0%)] Loss: 0.244034\n",
      "Train Epoch: 678 [160/1612 (10%)] Loss: 0.416611\n",
      "Train Epoch: 678 [320/1612 (20%)] Loss: 0.113858\n",
      "Train Epoch: 678 [480/1612 (30%)] Loss: 0.368439\n",
      "Train Epoch: 678 [640/1612 (40%)] Loss: 0.366669\n",
      "Train Epoch: 678 [800/1612 (50%)] Loss: 0.297631\n",
      "Train Epoch: 678 [960/1612 (59%)] Loss: 0.140300\n",
      "Train Epoch: 678 [1120/1612 (69%)] Loss: 0.173668\n",
      "Train Epoch: 678 [1280/1612 (79%)] Loss: 0.392209\n",
      "Train Epoch: 678 [1440/1612 (89%)] Loss: 0.511862\n",
      "Train Epoch: 678 [1200/1612 (99%)] Loss: 0.218782\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 679 [0/1612 (0%)] Loss: 0.628893\n",
      "Train Epoch: 679 [160/1612 (10%)] Loss: 0.124922\n",
      "Train Epoch: 679 [320/1612 (20%)] Loss: 0.159000\n",
      "Train Epoch: 679 [480/1612 (30%)] Loss: 0.232299\n",
      "Train Epoch: 679 [640/1612 (40%)] Loss: 0.165393\n",
      "Train Epoch: 679 [800/1612 (50%)] Loss: 0.339177\n",
      "Train Epoch: 679 [960/1612 (59%)] Loss: 0.463483\n",
      "Train Epoch: 679 [1120/1612 (69%)] Loss: 0.299239\n",
      "Train Epoch: 679 [1280/1612 (79%)] Loss: 0.114934\n",
      "Train Epoch: 679 [1440/1612 (89%)] Loss: 0.434596\n",
      "Train Epoch: 679 [1200/1612 (99%)] Loss: 0.350711\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 680 [0/1612 (0%)] Loss: 0.238989\n",
      "Train Epoch: 680 [160/1612 (10%)] Loss: 0.188946\n",
      "Train Epoch: 680 [320/1612 (20%)] Loss: 0.139303\n",
      "Train Epoch: 680 [480/1612 (30%)] Loss: 0.162660\n",
      "Train Epoch: 680 [640/1612 (40%)] Loss: 0.496102\n",
      "Train Epoch: 680 [800/1612 (50%)] Loss: 0.183901\n",
      "Train Epoch: 680 [960/1612 (59%)] Loss: 0.378334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 680 [1120/1612 (69%)] Loss: 0.212059\n",
      "Train Epoch: 680 [1280/1612 (79%)] Loss: 0.146322\n",
      "Train Epoch: 680 [1440/1612 (89%)] Loss: 0.464217\n",
      "Train Epoch: 680 [1200/1612 (99%)] Loss: 0.220022\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 681 [0/1612 (0%)] Loss: 0.146301\n",
      "Train Epoch: 681 [160/1612 (10%)] Loss: 0.580850\n",
      "Train Epoch: 681 [320/1612 (20%)] Loss: 0.452915\n",
      "Train Epoch: 681 [480/1612 (30%)] Loss: 0.355400\n",
      "Train Epoch: 681 [640/1612 (40%)] Loss: 0.469469\n",
      "Train Epoch: 681 [800/1612 (50%)] Loss: 0.254952\n",
      "Train Epoch: 681 [960/1612 (59%)] Loss: 0.125244\n",
      "Train Epoch: 681 [1120/1612 (69%)] Loss: 0.306640\n",
      "Train Epoch: 681 [1280/1612 (79%)] Loss: 0.222246\n",
      "Train Epoch: 681 [1440/1612 (89%)] Loss: 0.446551\n",
      "Train Epoch: 681 [1200/1612 (99%)] Loss: 0.204243\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 682 [0/1612 (0%)] Loss: 0.164949\n",
      "Train Epoch: 682 [160/1612 (10%)] Loss: 0.696043\n",
      "Train Epoch: 682 [320/1612 (20%)] Loss: 0.343108\n",
      "Train Epoch: 682 [480/1612 (30%)] Loss: 0.245009\n",
      "Train Epoch: 682 [640/1612 (40%)] Loss: 0.233575\n",
      "Train Epoch: 682 [800/1612 (50%)] Loss: 0.388259\n",
      "Train Epoch: 682 [960/1612 (59%)] Loss: 0.567312\n",
      "Train Epoch: 682 [1120/1612 (69%)] Loss: 0.302942\n",
      "Train Epoch: 682 [1280/1612 (79%)] Loss: 0.272597\n",
      "Train Epoch: 682 [1440/1612 (89%)] Loss: 0.398396\n",
      "Train Epoch: 682 [1200/1612 (99%)] Loss: 0.457610\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 683 [0/1612 (0%)] Loss: 0.262461\n",
      "Train Epoch: 683 [160/1612 (10%)] Loss: 0.286224\n",
      "Train Epoch: 683 [320/1612 (20%)] Loss: 0.669632\n",
      "Train Epoch: 683 [480/1612 (30%)] Loss: 0.399897\n",
      "Train Epoch: 683 [640/1612 (40%)] Loss: 0.320395\n",
      "Train Epoch: 683 [800/1612 (50%)] Loss: 0.186127\n",
      "Train Epoch: 683 [960/1612 (59%)] Loss: 0.380206\n",
      "Train Epoch: 683 [1120/1612 (69%)] Loss: 0.180408\n",
      "Train Epoch: 683 [1280/1612 (79%)] Loss: 0.306368\n",
      "Train Epoch: 683 [1440/1612 (89%)] Loss: 0.201195\n",
      "Train Epoch: 683 [1200/1612 (99%)] Loss: 0.145866\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 684 [0/1612 (0%)] Loss: 0.492117\n",
      "Train Epoch: 684 [160/1612 (10%)] Loss: 0.085325\n",
      "Train Epoch: 684 [320/1612 (20%)] Loss: 0.296323\n",
      "Train Epoch: 684 [480/1612 (30%)] Loss: 0.327186\n",
      "Train Epoch: 684 [640/1612 (40%)] Loss: 0.495782\n",
      "Train Epoch: 684 [800/1612 (50%)] Loss: 0.204001\n",
      "Train Epoch: 684 [960/1612 (59%)] Loss: 0.452831\n",
      "Train Epoch: 684 [1120/1612 (69%)] Loss: 0.455477\n",
      "Train Epoch: 684 [1280/1612 (79%)] Loss: 0.414047\n",
      "Train Epoch: 684 [1440/1612 (89%)] Loss: 0.138740\n",
      "Train Epoch: 684 [1200/1612 (99%)] Loss: 0.340157\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 685 [0/1612 (0%)] Loss: 0.335653\n",
      "Train Epoch: 685 [160/1612 (10%)] Loss: 0.444399\n",
      "Train Epoch: 685 [320/1612 (20%)] Loss: 0.315720\n",
      "Train Epoch: 685 [480/1612 (30%)] Loss: 0.335957\n",
      "Train Epoch: 685 [640/1612 (40%)] Loss: 0.267803\n",
      "Train Epoch: 685 [800/1612 (50%)] Loss: 0.121796\n",
      "Train Epoch: 685 [960/1612 (59%)] Loss: 0.208961\n",
      "Train Epoch: 685 [1120/1612 (69%)] Loss: 0.505005\n",
      "Train Epoch: 685 [1280/1612 (79%)] Loss: 0.366018\n",
      "Train Epoch: 685 [1440/1612 (89%)] Loss: 0.183253\n",
      "Train Epoch: 685 [1200/1612 (99%)] Loss: 0.607932\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 686 [0/1612 (0%)] Loss: 0.091173\n",
      "Train Epoch: 686 [160/1612 (10%)] Loss: 0.233335\n",
      "Train Epoch: 686 [320/1612 (20%)] Loss: 0.192270\n",
      "Train Epoch: 686 [480/1612 (30%)] Loss: 0.342690\n",
      "Train Epoch: 686 [640/1612 (40%)] Loss: 0.266102\n",
      "Train Epoch: 686 [800/1612 (50%)] Loss: 0.474175\n",
      "Train Epoch: 686 [960/1612 (59%)] Loss: 0.571463\n",
      "Train Epoch: 686 [1120/1612 (69%)] Loss: 0.378420\n",
      "Train Epoch: 686 [1280/1612 (79%)] Loss: 0.339212\n",
      "Train Epoch: 686 [1440/1612 (89%)] Loss: 0.290110\n",
      "Train Epoch: 686 [1200/1612 (99%)] Loss: 0.147554\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 687 [0/1612 (0%)] Loss: 0.487631\n",
      "Train Epoch: 687 [160/1612 (10%)] Loss: 0.358125\n",
      "Train Epoch: 687 [320/1612 (20%)] Loss: 0.555701\n",
      "Train Epoch: 687 [480/1612 (30%)] Loss: 0.276242\n",
      "Train Epoch: 687 [640/1612 (40%)] Loss: 0.252185\n",
      "Train Epoch: 687 [800/1612 (50%)] Loss: 0.317147\n",
      "Train Epoch: 687 [960/1612 (59%)] Loss: 0.313275\n",
      "Train Epoch: 687 [1120/1612 (69%)] Loss: 0.325056\n",
      "Train Epoch: 687 [1280/1612 (79%)] Loss: 0.392976\n",
      "Train Epoch: 687 [1440/1612 (89%)] Loss: 0.523981\n",
      "Train Epoch: 687 [1200/1612 (99%)] Loss: 0.198320\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 688 [0/1612 (0%)] Loss: 0.331821\n",
      "Train Epoch: 688 [160/1612 (10%)] Loss: 0.250504\n",
      "Train Epoch: 688 [320/1612 (20%)] Loss: 0.277110\n",
      "Train Epoch: 688 [480/1612 (30%)] Loss: 0.290234\n",
      "Train Epoch: 688 [640/1612 (40%)] Loss: 0.206331\n",
      "Train Epoch: 688 [800/1612 (50%)] Loss: 0.395363\n",
      "Train Epoch: 688 [960/1612 (59%)] Loss: 0.337279\n",
      "Train Epoch: 688 [1120/1612 (69%)] Loss: 0.671524\n",
      "Train Epoch: 688 [1280/1612 (79%)] Loss: 0.158351\n",
      "Train Epoch: 688 [1440/1612 (89%)] Loss: 0.287354\n",
      "Train Epoch: 688 [1200/1612 (99%)] Loss: 0.291156\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 689 [0/1612 (0%)] Loss: 0.262300\n",
      "Train Epoch: 689 [160/1612 (10%)] Loss: 0.418716\n",
      "Train Epoch: 689 [320/1612 (20%)] Loss: 0.164355\n",
      "Train Epoch: 689 [480/1612 (30%)] Loss: 0.476823\n",
      "Train Epoch: 689 [640/1612 (40%)] Loss: 0.139700\n",
      "Train Epoch: 689 [800/1612 (50%)] Loss: 0.230059\n",
      "Train Epoch: 689 [960/1612 (59%)] Loss: 0.468531\n",
      "Train Epoch: 689 [1120/1612 (69%)] Loss: 0.258754\n",
      "Train Epoch: 689 [1280/1612 (79%)] Loss: 0.357050\n",
      "Train Epoch: 689 [1440/1612 (89%)] Loss: 0.259584\n",
      "Train Epoch: 689 [1200/1612 (99%)] Loss: 0.300730\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 690 [0/1612 (0%)] Loss: 0.392641\n",
      "Train Epoch: 690 [160/1612 (10%)] Loss: 0.335565\n",
      "Train Epoch: 690 [320/1612 (20%)] Loss: 0.338276\n",
      "Train Epoch: 690 [480/1612 (30%)] Loss: 0.449909\n",
      "Train Epoch: 690 [640/1612 (40%)] Loss: 0.314860\n",
      "Train Epoch: 690 [800/1612 (50%)] Loss: 0.224038\n",
      "Train Epoch: 690 [960/1612 (59%)] Loss: 0.266493\n",
      "Train Epoch: 690 [1120/1612 (69%)] Loss: 0.559563\n",
      "Train Epoch: 690 [1280/1612 (79%)] Loss: 0.384462\n",
      "Train Epoch: 690 [1440/1612 (89%)] Loss: 0.239665\n",
      "Train Epoch: 690 [1200/1612 (99%)] Loss: 0.295627\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 691 [0/1612 (0%)] Loss: 0.188362\n",
      "Train Epoch: 691 [160/1612 (10%)] Loss: 0.484331\n",
      "Train Epoch: 691 [320/1612 (20%)] Loss: 0.304987\n",
      "Train Epoch: 691 [480/1612 (30%)] Loss: 0.236800\n",
      "Train Epoch: 691 [640/1612 (40%)] Loss: 0.354238\n",
      "Train Epoch: 691 [800/1612 (50%)] Loss: 0.390725\n",
      "Train Epoch: 691 [960/1612 (59%)] Loss: 0.158327\n",
      "Train Epoch: 691 [1120/1612 (69%)] Loss: 0.107108\n",
      "Train Epoch: 691 [1280/1612 (79%)] Loss: 0.622453\n",
      "Train Epoch: 691 [1440/1612 (89%)] Loss: 0.181688\n",
      "Train Epoch: 691 [1200/1612 (99%)] Loss: 0.109766\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 692 [0/1612 (0%)] Loss: 0.228043\n",
      "Train Epoch: 692 [160/1612 (10%)] Loss: 0.597030\n",
      "Train Epoch: 692 [320/1612 (20%)] Loss: 0.210769\n",
      "Train Epoch: 692 [480/1612 (30%)] Loss: 0.556370\n",
      "Train Epoch: 692 [640/1612 (40%)] Loss: 0.190241\n",
      "Train Epoch: 692 [800/1612 (50%)] Loss: 0.449509\n",
      "Train Epoch: 692 [960/1612 (59%)] Loss: 0.379968\n",
      "Train Epoch: 692 [1120/1612 (69%)] Loss: 0.477948\n",
      "Train Epoch: 692 [1280/1612 (79%)] Loss: 0.330907\n",
      "Train Epoch: 692 [1440/1612 (89%)] Loss: 0.326796\n",
      "Train Epoch: 692 [1200/1612 (99%)] Loss: 0.316372\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 693 [0/1612 (0%)] Loss: 0.347165\n",
      "Train Epoch: 693 [160/1612 (10%)] Loss: 0.500736\n",
      "Train Epoch: 693 [320/1612 (20%)] Loss: 0.229903\n",
      "Train Epoch: 693 [480/1612 (30%)] Loss: 0.389128\n",
      "Train Epoch: 693 [640/1612 (40%)] Loss: 0.360920\n",
      "Train Epoch: 693 [800/1612 (50%)] Loss: 0.336141\n",
      "Train Epoch: 693 [960/1612 (59%)] Loss: 0.205227\n",
      "Train Epoch: 693 [1120/1612 (69%)] Loss: 0.285943\n",
      "Train Epoch: 693 [1280/1612 (79%)] Loss: 0.297060\n",
      "Train Epoch: 693 [1440/1612 (89%)] Loss: 0.149961\n",
      "Train Epoch: 693 [1200/1612 (99%)] Loss: 0.200011\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 694 [0/1612 (0%)] Loss: 0.380930\n",
      "Train Epoch: 694 [160/1612 (10%)] Loss: 0.183446\n",
      "Train Epoch: 694 [320/1612 (20%)] Loss: 0.298054\n",
      "Train Epoch: 694 [480/1612 (30%)] Loss: 0.194367\n",
      "Train Epoch: 694 [640/1612 (40%)] Loss: 0.151790\n",
      "Train Epoch: 694 [800/1612 (50%)] Loss: 0.338924\n",
      "Train Epoch: 694 [960/1612 (59%)] Loss: 0.177360\n",
      "Train Epoch: 694 [1120/1612 (69%)] Loss: 0.354932\n",
      "Train Epoch: 694 [1280/1612 (79%)] Loss: 0.250013\n",
      "Train Epoch: 694 [1440/1612 (89%)] Loss: 0.561469\n",
      "Train Epoch: 694 [1200/1612 (99%)] Loss: 0.314051\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 695 [0/1612 (0%)] Loss: 0.385765\n",
      "Train Epoch: 695 [160/1612 (10%)] Loss: 0.349196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 695 [320/1612 (20%)] Loss: 0.334918\n",
      "Train Epoch: 695 [480/1612 (30%)] Loss: 0.324266\n",
      "Train Epoch: 695 [640/1612 (40%)] Loss: 0.356832\n",
      "Train Epoch: 695 [800/1612 (50%)] Loss: 0.469388\n",
      "Train Epoch: 695 [960/1612 (59%)] Loss: 0.278377\n",
      "Train Epoch: 695 [1120/1612 (69%)] Loss: 0.314568\n",
      "Train Epoch: 695 [1280/1612 (79%)] Loss: 0.132694\n",
      "Train Epoch: 695 [1440/1612 (89%)] Loss: 0.228993\n",
      "Train Epoch: 695 [1200/1612 (99%)] Loss: 0.184126\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 696 [0/1612 (0%)] Loss: 0.309346\n",
      "Train Epoch: 696 [160/1612 (10%)] Loss: 0.393245\n",
      "Train Epoch: 696 [320/1612 (20%)] Loss: 0.319921\n",
      "Train Epoch: 696 [480/1612 (30%)] Loss: 0.219959\n",
      "Train Epoch: 696 [640/1612 (40%)] Loss: 0.342002\n",
      "Train Epoch: 696 [800/1612 (50%)] Loss: 0.162407\n",
      "Train Epoch: 696 [960/1612 (59%)] Loss: 0.364054\n",
      "Train Epoch: 696 [1120/1612 (69%)] Loss: 0.505859\n",
      "Train Epoch: 696 [1280/1612 (79%)] Loss: 0.570895\n",
      "Train Epoch: 696 [1440/1612 (89%)] Loss: 0.258143\n",
      "Train Epoch: 696 [1200/1612 (99%)] Loss: 0.220080\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 697 [0/1612 (0%)] Loss: 0.280204\n",
      "Train Epoch: 697 [160/1612 (10%)] Loss: 0.125605\n",
      "Train Epoch: 697 [320/1612 (20%)] Loss: 0.505714\n",
      "Train Epoch: 697 [480/1612 (30%)] Loss: 0.234017\n",
      "Train Epoch: 697 [640/1612 (40%)] Loss: 0.379443\n",
      "Train Epoch: 697 [800/1612 (50%)] Loss: 0.127873\n",
      "Train Epoch: 697 [960/1612 (59%)] Loss: 0.213232\n",
      "Train Epoch: 697 [1120/1612 (69%)] Loss: 0.283255\n",
      "Train Epoch: 697 [1280/1612 (79%)] Loss: 0.468650\n",
      "Train Epoch: 697 [1440/1612 (89%)] Loss: 0.286395\n",
      "Train Epoch: 697 [1200/1612 (99%)] Loss: 0.292388\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 698 [0/1612 (0%)] Loss: 0.357182\n",
      "Train Epoch: 698 [160/1612 (10%)] Loss: 0.316618\n",
      "Train Epoch: 698 [320/1612 (20%)] Loss: 0.160370\n",
      "Train Epoch: 698 [480/1612 (30%)] Loss: 0.281056\n",
      "Train Epoch: 698 [640/1612 (40%)] Loss: 0.428596\n",
      "Train Epoch: 698 [800/1612 (50%)] Loss: 0.086963\n",
      "Train Epoch: 698 [960/1612 (59%)] Loss: 0.165752\n",
      "Train Epoch: 698 [1120/1612 (69%)] Loss: 0.466136\n",
      "Train Epoch: 698 [1280/1612 (79%)] Loss: 0.388253\n",
      "Train Epoch: 698 [1440/1612 (89%)] Loss: 0.333973\n",
      "Train Epoch: 698 [1200/1612 (99%)] Loss: 0.212362\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 699 [0/1612 (0%)] Loss: 0.336672\n",
      "Train Epoch: 699 [160/1612 (10%)] Loss: 0.192557\n",
      "Train Epoch: 699 [320/1612 (20%)] Loss: 0.241463\n",
      "Train Epoch: 699 [480/1612 (30%)] Loss: 0.223957\n",
      "Train Epoch: 699 [640/1612 (40%)] Loss: 0.348254\n",
      "Train Epoch: 699 [800/1612 (50%)] Loss: 0.170938\n",
      "Train Epoch: 699 [960/1612 (59%)] Loss: 0.233994\n",
      "Train Epoch: 699 [1120/1612 (69%)] Loss: 0.309693\n",
      "Train Epoch: 699 [1280/1612 (79%)] Loss: 0.340296\n",
      "Train Epoch: 699 [1440/1612 (89%)] Loss: 0.353540\n",
      "Train Epoch: 699 [1200/1612 (99%)] Loss: 0.104459\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 700 [0/1612 (0%)] Loss: 0.440976\n",
      "Train Epoch: 700 [160/1612 (10%)] Loss: 0.308171\n",
      "Train Epoch: 700 [320/1612 (20%)] Loss: 0.247321\n",
      "Train Epoch: 700 [480/1612 (30%)] Loss: 0.148058\n",
      "Train Epoch: 700 [640/1612 (40%)] Loss: 0.239877\n",
      "Train Epoch: 700 [800/1612 (50%)] Loss: 0.360009\n",
      "Train Epoch: 700 [960/1612 (59%)] Loss: 0.419570\n",
      "Train Epoch: 700 [1120/1612 (69%)] Loss: 0.369086\n",
      "Train Epoch: 700 [1280/1612 (79%)] Loss: 0.572970\n",
      "Train Epoch: 700 [1440/1612 (89%)] Loss: 0.305086\n",
      "Train Epoch: 700 [1200/1612 (99%)] Loss: 0.267958\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 701 [0/1612 (0%)] Loss: 0.350316\n",
      "Train Epoch: 701 [160/1612 (10%)] Loss: 0.395240\n",
      "Train Epoch: 701 [320/1612 (20%)] Loss: 0.298283\n",
      "Train Epoch: 701 [480/1612 (30%)] Loss: 0.345575\n",
      "Train Epoch: 701 [640/1612 (40%)] Loss: 0.521599\n",
      "Train Epoch: 701 [800/1612 (50%)] Loss: 0.281214\n",
      "Train Epoch: 701 [960/1612 (59%)] Loss: 0.231722\n",
      "Train Epoch: 701 [1120/1612 (69%)] Loss: 0.368216\n",
      "Train Epoch: 701 [1280/1612 (79%)] Loss: 0.380592\n",
      "Train Epoch: 701 [1440/1612 (89%)] Loss: 0.438549\n",
      "Train Epoch: 701 [1200/1612 (99%)] Loss: 0.245057\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 702 [0/1612 (0%)] Loss: 0.218508\n",
      "Train Epoch: 702 [160/1612 (10%)] Loss: 0.262173\n",
      "Train Epoch: 702 [320/1612 (20%)] Loss: 0.242730\n",
      "Train Epoch: 702 [480/1612 (30%)] Loss: 0.458082\n",
      "Train Epoch: 702 [640/1612 (40%)] Loss: 0.273461\n",
      "Train Epoch: 702 [800/1612 (50%)] Loss: 0.406754\n",
      "Train Epoch: 702 [960/1612 (59%)] Loss: 0.392777\n",
      "Train Epoch: 702 [1120/1612 (69%)] Loss: 0.511993\n",
      "Train Epoch: 702 [1280/1612 (79%)] Loss: 0.434516\n",
      "Train Epoch: 702 [1440/1612 (89%)] Loss: 0.276042\n",
      "Train Epoch: 702 [1200/1612 (99%)] Loss: 0.281560\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 703 [0/1612 (0%)] Loss: 0.256314\n",
      "Train Epoch: 703 [160/1612 (10%)] Loss: 0.125883\n",
      "Train Epoch: 703 [320/1612 (20%)] Loss: 0.328424\n",
      "Train Epoch: 703 [480/1612 (30%)] Loss: 0.681104\n",
      "Train Epoch: 703 [640/1612 (40%)] Loss: 0.210611\n",
      "Train Epoch: 703 [800/1612 (50%)] Loss: 0.228732\n",
      "Train Epoch: 703 [960/1612 (59%)] Loss: 0.555399\n",
      "Train Epoch: 703 [1120/1612 (69%)] Loss: 0.199293\n",
      "Train Epoch: 703 [1280/1612 (79%)] Loss: 0.431905\n",
      "Train Epoch: 703 [1440/1612 (89%)] Loss: 0.387820\n",
      "Train Epoch: 703 [1200/1612 (99%)] Loss: 0.269430\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 704 [0/1612 (0%)] Loss: 0.505469\n",
      "Train Epoch: 704 [160/1612 (10%)] Loss: 0.282469\n",
      "Train Epoch: 704 [320/1612 (20%)] Loss: 0.307315\n",
      "Train Epoch: 704 [480/1612 (30%)] Loss: 0.630562\n",
      "Train Epoch: 704 [640/1612 (40%)] Loss: 0.263016\n",
      "Train Epoch: 704 [800/1612 (50%)] Loss: 0.342129\n",
      "Train Epoch: 704 [960/1612 (59%)] Loss: 0.180279\n",
      "Train Epoch: 704 [1120/1612 (69%)] Loss: 0.204040\n",
      "Train Epoch: 704 [1280/1612 (79%)] Loss: 0.203352\n",
      "Train Epoch: 704 [1440/1612 (89%)] Loss: 0.271595\n",
      "Train Epoch: 704 [1200/1612 (99%)] Loss: 0.292823\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 705 [0/1612 (0%)] Loss: 0.427885\n",
      "Train Epoch: 705 [160/1612 (10%)] Loss: 0.186105\n",
      "Train Epoch: 705 [320/1612 (20%)] Loss: 0.225716\n",
      "Train Epoch: 705 [480/1612 (30%)] Loss: 0.440625\n",
      "Train Epoch: 705 [640/1612 (40%)] Loss: 0.384514\n",
      "Train Epoch: 705 [800/1612 (50%)] Loss: 0.270542\n",
      "Train Epoch: 705 [960/1612 (59%)] Loss: 0.303697\n",
      "Train Epoch: 705 [1120/1612 (69%)] Loss: 0.233674\n",
      "Train Epoch: 705 [1280/1612 (79%)] Loss: 0.509332\n",
      "Train Epoch: 705 [1440/1612 (89%)] Loss: 0.179033\n",
      "Train Epoch: 705 [1200/1612 (99%)] Loss: 0.193716\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 706 [0/1612 (0%)] Loss: 0.643179\n",
      "Train Epoch: 706 [160/1612 (10%)] Loss: 0.288088\n",
      "Train Epoch: 706 [320/1612 (20%)] Loss: 0.218552\n",
      "Train Epoch: 706 [480/1612 (30%)] Loss: 0.350100\n",
      "Train Epoch: 706 [640/1612 (40%)] Loss: 0.174183\n",
      "Train Epoch: 706 [800/1612 (50%)] Loss: 0.384007\n",
      "Train Epoch: 706 [960/1612 (59%)] Loss: 0.380826\n",
      "Train Epoch: 706 [1120/1612 (69%)] Loss: 0.384626\n",
      "Train Epoch: 706 [1280/1612 (79%)] Loss: 0.324796\n",
      "Train Epoch: 706 [1440/1612 (89%)] Loss: 0.142381\n",
      "Train Epoch: 706 [1200/1612 (99%)] Loss: 0.348359\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 707 [0/1612 (0%)] Loss: 0.312061\n",
      "Train Epoch: 707 [160/1612 (10%)] Loss: 0.209824\n",
      "Train Epoch: 707 [320/1612 (20%)] Loss: 0.489039\n",
      "Train Epoch: 707 [480/1612 (30%)] Loss: 0.215107\n",
      "Train Epoch: 707 [640/1612 (40%)] Loss: 0.221314\n",
      "Train Epoch: 707 [800/1612 (50%)] Loss: 0.146947\n",
      "Train Epoch: 707 [960/1612 (59%)] Loss: 0.302641\n",
      "Train Epoch: 707 [1120/1612 (69%)] Loss: 0.321073\n",
      "Train Epoch: 707 [1280/1612 (79%)] Loss: 0.166528\n",
      "Train Epoch: 707 [1440/1612 (89%)] Loss: 0.390143\n",
      "Train Epoch: 707 [1200/1612 (99%)] Loss: 0.168810\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 708 [0/1612 (0%)] Loss: 0.211792\n",
      "Train Epoch: 708 [160/1612 (10%)] Loss: 0.300777\n",
      "Train Epoch: 708 [320/1612 (20%)] Loss: 0.409915\n",
      "Train Epoch: 708 [480/1612 (30%)] Loss: 0.269035\n",
      "Train Epoch: 708 [640/1612 (40%)] Loss: 0.423625\n",
      "Train Epoch: 708 [800/1612 (50%)] Loss: 0.096722\n",
      "Train Epoch: 708 [960/1612 (59%)] Loss: 0.432777\n",
      "Train Epoch: 708 [1120/1612 (69%)] Loss: 0.427274\n",
      "Train Epoch: 708 [1280/1612 (79%)] Loss: 0.362738\n",
      "Train Epoch: 708 [1440/1612 (89%)] Loss: 0.377141\n",
      "Train Epoch: 708 [1200/1612 (99%)] Loss: 0.198974\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 709 [0/1612 (0%)] Loss: 0.225841\n",
      "Train Epoch: 709 [160/1612 (10%)] Loss: 0.191641\n",
      "Train Epoch: 709 [320/1612 (20%)] Loss: 0.546833\n",
      "Train Epoch: 709 [480/1612 (30%)] Loss: 0.422850\n",
      "Train Epoch: 709 [640/1612 (40%)] Loss: 0.337362\n",
      "Train Epoch: 709 [800/1612 (50%)] Loss: 0.301407\n",
      "Train Epoch: 709 [960/1612 (59%)] Loss: 0.529247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 709 [1120/1612 (69%)] Loss: 0.316813\n",
      "Train Epoch: 709 [1280/1612 (79%)] Loss: 0.292953\n",
      "Train Epoch: 709 [1440/1612 (89%)] Loss: 0.101912\n",
      "Train Epoch: 709 [1200/1612 (99%)] Loss: 0.384532\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 710 [0/1612 (0%)] Loss: 0.233872\n",
      "Train Epoch: 710 [160/1612 (10%)] Loss: 0.435359\n",
      "Train Epoch: 710 [320/1612 (20%)] Loss: 0.303385\n",
      "Train Epoch: 710 [480/1612 (30%)] Loss: 0.292085\n",
      "Train Epoch: 710 [640/1612 (40%)] Loss: 0.144895\n",
      "Train Epoch: 710 [800/1612 (50%)] Loss: 0.332768\n",
      "Train Epoch: 710 [960/1612 (59%)] Loss: 0.121404\n",
      "Train Epoch: 710 [1120/1612 (69%)] Loss: 0.312067\n",
      "Train Epoch: 710 [1280/1612 (79%)] Loss: 0.127990\n",
      "Train Epoch: 710 [1440/1612 (89%)] Loss: 0.091334\n",
      "Train Epoch: 710 [1200/1612 (99%)] Loss: 0.354343\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 711 [0/1612 (0%)] Loss: 0.267078\n",
      "Train Epoch: 711 [160/1612 (10%)] Loss: 0.304295\n",
      "Train Epoch: 711 [320/1612 (20%)] Loss: 0.177791\n",
      "Train Epoch: 711 [480/1612 (30%)] Loss: 0.259923\n",
      "Train Epoch: 711 [640/1612 (40%)] Loss: 0.285993\n",
      "Train Epoch: 711 [800/1612 (50%)] Loss: 0.254168\n",
      "Train Epoch: 711 [960/1612 (59%)] Loss: 0.465400\n",
      "Train Epoch: 711 [1120/1612 (69%)] Loss: 0.308078\n",
      "Train Epoch: 711 [1280/1612 (79%)] Loss: 0.324135\n",
      "Train Epoch: 711 [1440/1612 (89%)] Loss: 0.482769\n",
      "Train Epoch: 711 [1200/1612 (99%)] Loss: 0.348258\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 712 [0/1612 (0%)] Loss: 0.351572\n",
      "Train Epoch: 712 [160/1612 (10%)] Loss: 0.313693\n",
      "Train Epoch: 712 [320/1612 (20%)] Loss: 0.305372\n",
      "Train Epoch: 712 [480/1612 (30%)] Loss: 0.230946\n",
      "Train Epoch: 712 [640/1612 (40%)] Loss: 0.411080\n",
      "Train Epoch: 712 [800/1612 (50%)] Loss: 0.200055\n",
      "Train Epoch: 712 [960/1612 (59%)] Loss: 0.326651\n",
      "Train Epoch: 712 [1120/1612 (69%)] Loss: 0.209479\n",
      "Train Epoch: 712 [1280/1612 (79%)] Loss: 0.352349\n",
      "Train Epoch: 712 [1440/1612 (89%)] Loss: 0.117615\n",
      "Train Epoch: 712 [1200/1612 (99%)] Loss: 0.201872\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 713 [0/1612 (0%)] Loss: 0.621865\n",
      "Train Epoch: 713 [160/1612 (10%)] Loss: 0.458774\n",
      "Train Epoch: 713 [320/1612 (20%)] Loss: 0.689774\n",
      "Train Epoch: 713 [480/1612 (30%)] Loss: 0.072778\n",
      "Train Epoch: 713 [640/1612 (40%)] Loss: 0.182913\n",
      "Train Epoch: 713 [800/1612 (50%)] Loss: 0.460349\n",
      "Train Epoch: 713 [960/1612 (59%)] Loss: 0.195655\n",
      "Train Epoch: 713 [1120/1612 (69%)] Loss: 0.443977\n",
      "Train Epoch: 713 [1280/1612 (79%)] Loss: 0.190966\n",
      "Train Epoch: 713 [1440/1612 (89%)] Loss: 0.209704\n",
      "Train Epoch: 713 [1200/1612 (99%)] Loss: 0.225129\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 714 [0/1612 (0%)] Loss: 0.316491\n",
      "Train Epoch: 714 [160/1612 (10%)] Loss: 0.247418\n",
      "Train Epoch: 714 [320/1612 (20%)] Loss: 0.243838\n",
      "Train Epoch: 714 [480/1612 (30%)] Loss: 0.262925\n",
      "Train Epoch: 714 [640/1612 (40%)] Loss: 0.223730\n",
      "Train Epoch: 714 [800/1612 (50%)] Loss: 0.399411\n",
      "Train Epoch: 714 [960/1612 (59%)] Loss: 0.259467\n",
      "Train Epoch: 714 [1120/1612 (69%)] Loss: 0.463671\n",
      "Train Epoch: 714 [1280/1612 (79%)] Loss: 0.236014\n",
      "Train Epoch: 714 [1440/1612 (89%)] Loss: 0.264978\n",
      "Train Epoch: 714 [1200/1612 (99%)] Loss: 0.447335\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 715 [0/1612 (0%)] Loss: 0.467195\n",
      "Train Epoch: 715 [160/1612 (10%)] Loss: 0.137911\n",
      "Train Epoch: 715 [320/1612 (20%)] Loss: 0.429871\n",
      "Train Epoch: 715 [480/1612 (30%)] Loss: 0.429557\n",
      "Train Epoch: 715 [640/1612 (40%)] Loss: 0.387395\n",
      "Train Epoch: 715 [800/1612 (50%)] Loss: 0.185904\n",
      "Train Epoch: 715 [960/1612 (59%)] Loss: 0.448808\n",
      "Train Epoch: 715 [1120/1612 (69%)] Loss: 0.239286\n",
      "Train Epoch: 715 [1280/1612 (79%)] Loss: 0.272979\n",
      "Train Epoch: 715 [1440/1612 (89%)] Loss: 0.406213\n",
      "Train Epoch: 715 [1200/1612 (99%)] Loss: 0.697939\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 716 [0/1612 (0%)] Loss: 0.122160\n",
      "Train Epoch: 716 [160/1612 (10%)] Loss: 0.271509\n",
      "Train Epoch: 716 [320/1612 (20%)] Loss: 0.267897\n",
      "Train Epoch: 716 [480/1612 (30%)] Loss: 0.202785\n",
      "Train Epoch: 716 [640/1612 (40%)] Loss: 0.262682\n",
      "Train Epoch: 716 [800/1612 (50%)] Loss: 0.109411\n",
      "Train Epoch: 716 [960/1612 (59%)] Loss: 0.364186\n",
      "Train Epoch: 716 [1120/1612 (69%)] Loss: 0.521715\n",
      "Train Epoch: 716 [1280/1612 (79%)] Loss: 0.295211\n",
      "Train Epoch: 716 [1440/1612 (89%)] Loss: 0.353151\n",
      "Train Epoch: 716 [1200/1612 (99%)] Loss: 0.241606\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 717 [0/1612 (0%)] Loss: 0.206333\n",
      "Train Epoch: 717 [160/1612 (10%)] Loss: 0.378629\n",
      "Train Epoch: 717 [320/1612 (20%)] Loss: 0.286681\n",
      "Train Epoch: 717 [480/1612 (30%)] Loss: 0.370280\n",
      "Train Epoch: 717 [640/1612 (40%)] Loss: 0.296575\n",
      "Train Epoch: 717 [800/1612 (50%)] Loss: 0.350029\n",
      "Train Epoch: 717 [960/1612 (59%)] Loss: 0.267470\n",
      "Train Epoch: 717 [1120/1612 (69%)] Loss: 0.347247\n",
      "Train Epoch: 717 [1280/1612 (79%)] Loss: 0.245632\n",
      "Train Epoch: 717 [1440/1612 (89%)] Loss: 0.224254\n",
      "Train Epoch: 717 [1200/1612 (99%)] Loss: 0.306524\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 718 [0/1612 (0%)] Loss: 0.440714\n",
      "Train Epoch: 718 [160/1612 (10%)] Loss: 0.427360\n",
      "Train Epoch: 718 [320/1612 (20%)] Loss: 0.329421\n",
      "Train Epoch: 718 [480/1612 (30%)] Loss: 0.243922\n",
      "Train Epoch: 718 [640/1612 (40%)] Loss: 0.444858\n",
      "Train Epoch: 718 [800/1612 (50%)] Loss: 0.471140\n",
      "Train Epoch: 718 [960/1612 (59%)] Loss: 0.350903\n",
      "Train Epoch: 718 [1120/1612 (69%)] Loss: 0.548957\n",
      "Train Epoch: 718 [1280/1612 (79%)] Loss: 0.327267\n",
      "Train Epoch: 718 [1440/1612 (89%)] Loss: 0.275889\n",
      "Train Epoch: 718 [1200/1612 (99%)] Loss: 0.434724\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 719 [0/1612 (0%)] Loss: 0.108561\n",
      "Train Epoch: 719 [160/1612 (10%)] Loss: 0.335716\n",
      "Train Epoch: 719 [320/1612 (20%)] Loss: 0.283228\n",
      "Train Epoch: 719 [480/1612 (30%)] Loss: 0.245385\n",
      "Train Epoch: 719 [640/1612 (40%)] Loss: 0.284365\n",
      "Train Epoch: 719 [800/1612 (50%)] Loss: 0.259598\n",
      "Train Epoch: 719 [960/1612 (59%)] Loss: 0.437257\n",
      "Train Epoch: 719 [1120/1612 (69%)] Loss: 0.474035\n",
      "Train Epoch: 719 [1280/1612 (79%)] Loss: 0.308501\n",
      "Train Epoch: 719 [1440/1612 (89%)] Loss: 0.243630\n",
      "Train Epoch: 719 [1200/1612 (99%)] Loss: 0.385166\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 720 [0/1612 (0%)] Loss: 0.510991\n",
      "Train Epoch: 720 [160/1612 (10%)] Loss: 0.245367\n",
      "Train Epoch: 720 [320/1612 (20%)] Loss: 0.314202\n",
      "Train Epoch: 720 [480/1612 (30%)] Loss: 0.309073\n",
      "Train Epoch: 720 [640/1612 (40%)] Loss: 0.501313\n",
      "Train Epoch: 720 [800/1612 (50%)] Loss: 0.382083\n",
      "Train Epoch: 720 [960/1612 (59%)] Loss: 0.523800\n",
      "Train Epoch: 720 [1120/1612 (69%)] Loss: 0.289517\n",
      "Train Epoch: 720 [1280/1612 (79%)] Loss: 0.279812\n",
      "Train Epoch: 720 [1440/1612 (89%)] Loss: 0.245445\n",
      "Train Epoch: 720 [1200/1612 (99%)] Loss: 0.428716\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 721 [0/1612 (0%)] Loss: 0.143226\n",
      "Train Epoch: 721 [160/1612 (10%)] Loss: 0.365883\n",
      "Train Epoch: 721 [320/1612 (20%)] Loss: 0.295367\n",
      "Train Epoch: 721 [480/1612 (30%)] Loss: 0.386913\n",
      "Train Epoch: 721 [640/1612 (40%)] Loss: 0.406886\n",
      "Train Epoch: 721 [800/1612 (50%)] Loss: 0.440013\n",
      "Train Epoch: 721 [960/1612 (59%)] Loss: 0.319959\n",
      "Train Epoch: 721 [1120/1612 (69%)] Loss: 0.202919\n",
      "Train Epoch: 721 [1280/1612 (79%)] Loss: 0.315834\n",
      "Train Epoch: 721 [1440/1612 (89%)] Loss: 0.188078\n",
      "Train Epoch: 721 [1200/1612 (99%)] Loss: 0.219973\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 722 [0/1612 (0%)] Loss: 0.372794\n",
      "Train Epoch: 722 [160/1612 (10%)] Loss: 0.258818\n",
      "Train Epoch: 722 [320/1612 (20%)] Loss: 0.269073\n",
      "Train Epoch: 722 [480/1612 (30%)] Loss: 0.186870\n",
      "Train Epoch: 722 [640/1612 (40%)] Loss: 0.429927\n",
      "Train Epoch: 722 [800/1612 (50%)] Loss: 0.295532\n",
      "Train Epoch: 722 [960/1612 (59%)] Loss: 0.205130\n",
      "Train Epoch: 722 [1120/1612 (69%)] Loss: 0.107401\n",
      "Train Epoch: 722 [1280/1612 (79%)] Loss: 0.175318\n",
      "Train Epoch: 722 [1440/1612 (89%)] Loss: 0.361816\n",
      "Train Epoch: 722 [1200/1612 (99%)] Loss: 0.116780\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 723 [0/1612 (0%)] Loss: 0.487361\n",
      "Train Epoch: 723 [160/1612 (10%)] Loss: 0.259769\n",
      "Train Epoch: 723 [320/1612 (20%)] Loss: 0.149836\n",
      "Train Epoch: 723 [480/1612 (30%)] Loss: 0.178452\n",
      "Train Epoch: 723 [640/1612 (40%)] Loss: 0.528349\n",
      "Train Epoch: 723 [800/1612 (50%)] Loss: 0.620718\n",
      "Train Epoch: 723 [960/1612 (59%)] Loss: 0.143479\n",
      "Train Epoch: 723 [1120/1612 (69%)] Loss: 0.286125\n",
      "Train Epoch: 723 [1280/1612 (79%)] Loss: 0.217857\n",
      "Train Epoch: 723 [1440/1612 (89%)] Loss: 0.157966\n",
      "Train Epoch: 723 [1200/1612 (99%)] Loss: 0.274931\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 724 [0/1612 (0%)] Loss: 0.472964\n",
      "Train Epoch: 724 [160/1612 (10%)] Loss: 0.419881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 724 [320/1612 (20%)] Loss: 0.322918\n",
      "Train Epoch: 724 [480/1612 (30%)] Loss: 0.298610\n",
      "Train Epoch: 724 [640/1612 (40%)] Loss: 0.272144\n",
      "Train Epoch: 724 [800/1612 (50%)] Loss: 0.212895\n",
      "Train Epoch: 724 [960/1612 (59%)] Loss: 0.352078\n",
      "Train Epoch: 724 [1120/1612 (69%)] Loss: 0.308817\n",
      "Train Epoch: 724 [1280/1612 (79%)] Loss: 0.276218\n",
      "Train Epoch: 724 [1440/1612 (89%)] Loss: 0.367849\n",
      "Train Epoch: 724 [1200/1612 (99%)] Loss: 0.160713\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 725 [0/1612 (0%)] Loss: 0.364623\n",
      "Train Epoch: 725 [160/1612 (10%)] Loss: 0.304115\n",
      "Train Epoch: 725 [320/1612 (20%)] Loss: 0.396531\n",
      "Train Epoch: 725 [480/1612 (30%)] Loss: 0.271910\n",
      "Train Epoch: 725 [640/1612 (40%)] Loss: 0.426874\n",
      "Train Epoch: 725 [800/1612 (50%)] Loss: 0.317952\n",
      "Train Epoch: 725 [960/1612 (59%)] Loss: 0.211624\n",
      "Train Epoch: 725 [1120/1612 (69%)] Loss: 0.404122\n",
      "Train Epoch: 725 [1280/1612 (79%)] Loss: 0.340972\n",
      "Train Epoch: 725 [1440/1612 (89%)] Loss: 0.211867\n",
      "Train Epoch: 725 [1200/1612 (99%)] Loss: 0.200477\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 726 [0/1612 (0%)] Loss: 0.343416\n",
      "Train Epoch: 726 [160/1612 (10%)] Loss: 0.409746\n",
      "Train Epoch: 726 [320/1612 (20%)] Loss: 0.395444\n",
      "Train Epoch: 726 [480/1612 (30%)] Loss: 0.510294\n",
      "Train Epoch: 726 [640/1612 (40%)] Loss: 0.146316\n",
      "Train Epoch: 726 [800/1612 (50%)] Loss: 0.471713\n",
      "Train Epoch: 726 [960/1612 (59%)] Loss: 0.300457\n",
      "Train Epoch: 726 [1120/1612 (69%)] Loss: 0.091478\n",
      "Train Epoch: 726 [1280/1612 (79%)] Loss: 0.287357\n",
      "Train Epoch: 726 [1440/1612 (89%)] Loss: 0.250361\n",
      "Train Epoch: 726 [1200/1612 (99%)] Loss: 0.380901\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 727 [0/1612 (0%)] Loss: 0.294311\n",
      "Train Epoch: 727 [160/1612 (10%)] Loss: 0.110274\n",
      "Train Epoch: 727 [320/1612 (20%)] Loss: 0.255106\n",
      "Train Epoch: 727 [480/1612 (30%)] Loss: 0.230771\n",
      "Train Epoch: 727 [640/1612 (40%)] Loss: 0.323235\n",
      "Train Epoch: 727 [800/1612 (50%)] Loss: 0.340870\n",
      "Train Epoch: 727 [960/1612 (59%)] Loss: 0.184094\n",
      "Train Epoch: 727 [1120/1612 (69%)] Loss: 0.198427\n",
      "Train Epoch: 727 [1280/1612 (79%)] Loss: 0.392908\n",
      "Train Epoch: 727 [1440/1612 (89%)] Loss: 0.259036\n",
      "Train Epoch: 727 [1200/1612 (99%)] Loss: 0.361589\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 728 [0/1612 (0%)] Loss: 0.173932\n",
      "Train Epoch: 728 [160/1612 (10%)] Loss: 0.213842\n",
      "Train Epoch: 728 [320/1612 (20%)] Loss: 0.352512\n",
      "Train Epoch: 728 [480/1612 (30%)] Loss: 0.383311\n",
      "Train Epoch: 728 [640/1612 (40%)] Loss: 0.186282\n",
      "Train Epoch: 728 [800/1612 (50%)] Loss: 0.492598\n",
      "Train Epoch: 728 [960/1612 (59%)] Loss: 0.188892\n",
      "Train Epoch: 728 [1120/1612 (69%)] Loss: 0.422345\n",
      "Train Epoch: 728 [1280/1612 (79%)] Loss: 0.168315\n",
      "Train Epoch: 728 [1440/1612 (89%)] Loss: 0.248002\n",
      "Train Epoch: 728 [1200/1612 (99%)] Loss: 0.406629\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 729 [0/1612 (0%)] Loss: 0.281816\n",
      "Train Epoch: 729 [160/1612 (10%)] Loss: 0.563457\n",
      "Train Epoch: 729 [320/1612 (20%)] Loss: 0.263280\n",
      "Train Epoch: 729 [480/1612 (30%)] Loss: 0.265153\n",
      "Train Epoch: 729 [640/1612 (40%)] Loss: 0.434882\n",
      "Train Epoch: 729 [800/1612 (50%)] Loss: 0.196161\n",
      "Train Epoch: 729 [960/1612 (59%)] Loss: 0.567971\n",
      "Train Epoch: 729 [1120/1612 (69%)] Loss: 0.484102\n",
      "Train Epoch: 729 [1280/1612 (79%)] Loss: 0.246004\n",
      "Train Epoch: 729 [1440/1612 (89%)] Loss: 0.342749\n",
      "Train Epoch: 729 [1200/1612 (99%)] Loss: 0.604241\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 730 [0/1612 (0%)] Loss: 0.358838\n",
      "Train Epoch: 730 [160/1612 (10%)] Loss: 0.373803\n",
      "Train Epoch: 730 [320/1612 (20%)] Loss: 0.432760\n",
      "Train Epoch: 730 [480/1612 (30%)] Loss: 0.230778\n",
      "Train Epoch: 730 [640/1612 (40%)] Loss: 0.161747\n",
      "Train Epoch: 730 [800/1612 (50%)] Loss: 0.205171\n",
      "Train Epoch: 730 [960/1612 (59%)] Loss: 0.111169\n",
      "Train Epoch: 730 [1120/1612 (69%)] Loss: 0.483357\n",
      "Train Epoch: 730 [1280/1612 (79%)] Loss: 0.228573\n",
      "Train Epoch: 730 [1440/1612 (89%)] Loss: 0.326935\n",
      "Train Epoch: 730 [1200/1612 (99%)] Loss: 0.283031\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 731 [0/1612 (0%)] Loss: 0.505033\n",
      "Train Epoch: 731 [160/1612 (10%)] Loss: 0.368273\n",
      "Train Epoch: 731 [320/1612 (20%)] Loss: 0.293781\n",
      "Train Epoch: 731 [480/1612 (30%)] Loss: 0.338362\n",
      "Train Epoch: 731 [640/1612 (40%)] Loss: 0.248034\n",
      "Train Epoch: 731 [800/1612 (50%)] Loss: 0.414239\n",
      "Train Epoch: 731 [960/1612 (59%)] Loss: 0.260098\n",
      "Train Epoch: 731 [1120/1612 (69%)] Loss: 0.173287\n",
      "Train Epoch: 731 [1280/1612 (79%)] Loss: 0.209311\n",
      "Train Epoch: 731 [1440/1612 (89%)] Loss: 0.321107\n",
      "Train Epoch: 731 [1200/1612 (99%)] Loss: 0.365203\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 732 [0/1612 (0%)] Loss: 0.199030\n",
      "Train Epoch: 732 [160/1612 (10%)] Loss: 0.386192\n",
      "Train Epoch: 732 [320/1612 (20%)] Loss: 0.264483\n",
      "Train Epoch: 732 [480/1612 (30%)] Loss: 0.300422\n",
      "Train Epoch: 732 [640/1612 (40%)] Loss: 0.163705\n",
      "Train Epoch: 732 [800/1612 (50%)] Loss: 0.688293\n",
      "Train Epoch: 732 [960/1612 (59%)] Loss: 0.129305\n",
      "Train Epoch: 732 [1120/1612 (69%)] Loss: 0.377565\n",
      "Train Epoch: 732 [1280/1612 (79%)] Loss: 0.231425\n",
      "Train Epoch: 732 [1440/1612 (89%)] Loss: 0.235534\n",
      "Train Epoch: 732 [1200/1612 (99%)] Loss: 0.268500\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 733 [0/1612 (0%)] Loss: 0.306576\n",
      "Train Epoch: 733 [160/1612 (10%)] Loss: 0.189395\n",
      "Train Epoch: 733 [320/1612 (20%)] Loss: 0.519261\n",
      "Train Epoch: 733 [480/1612 (30%)] Loss: 0.223798\n",
      "Train Epoch: 733 [640/1612 (40%)] Loss: 0.266634\n",
      "Train Epoch: 733 [800/1612 (50%)] Loss: 0.163440\n",
      "Train Epoch: 733 [960/1612 (59%)] Loss: 0.263702\n",
      "Train Epoch: 733 [1120/1612 (69%)] Loss: 0.275191\n",
      "Train Epoch: 733 [1280/1612 (79%)] Loss: 0.131117\n",
      "Train Epoch: 733 [1440/1612 (89%)] Loss: 0.326559\n",
      "Train Epoch: 733 [1200/1612 (99%)] Loss: 0.156874\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 734 [0/1612 (0%)] Loss: 0.190155\n",
      "Train Epoch: 734 [160/1612 (10%)] Loss: 0.322921\n",
      "Train Epoch: 734 [320/1612 (20%)] Loss: 0.531129\n",
      "Train Epoch: 734 [480/1612 (30%)] Loss: 0.494824\n",
      "Train Epoch: 734 [640/1612 (40%)] Loss: 0.397328\n",
      "Train Epoch: 734 [800/1612 (50%)] Loss: 0.498049\n",
      "Train Epoch: 734 [960/1612 (59%)] Loss: 0.334899\n",
      "Train Epoch: 734 [1120/1612 (69%)] Loss: 0.257072\n",
      "Train Epoch: 734 [1280/1612 (79%)] Loss: 0.236036\n",
      "Train Epoch: 734 [1440/1612 (89%)] Loss: 0.244040\n",
      "Train Epoch: 734 [1200/1612 (99%)] Loss: 0.126006\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 735 [0/1612 (0%)] Loss: 0.314491\n",
      "Train Epoch: 735 [160/1612 (10%)] Loss: 0.279415\n",
      "Train Epoch: 735 [320/1612 (20%)] Loss: 0.204588\n",
      "Train Epoch: 735 [480/1612 (30%)] Loss: 0.392802\n",
      "Train Epoch: 735 [640/1612 (40%)] Loss: 0.540117\n",
      "Train Epoch: 735 [800/1612 (50%)] Loss: 0.253817\n",
      "Train Epoch: 735 [960/1612 (59%)] Loss: 0.293614\n",
      "Train Epoch: 735 [1120/1612 (69%)] Loss: 0.308497\n",
      "Train Epoch: 735 [1280/1612 (79%)] Loss: 0.508581\n",
      "Train Epoch: 735 [1440/1612 (89%)] Loss: 0.155378\n",
      "Train Epoch: 735 [1200/1612 (99%)] Loss: 0.329113\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 736 [0/1612 (0%)] Loss: 0.326330\n",
      "Train Epoch: 736 [160/1612 (10%)] Loss: 0.231222\n",
      "Train Epoch: 736 [320/1612 (20%)] Loss: 0.280895\n",
      "Train Epoch: 736 [480/1612 (30%)] Loss: 0.190564\n",
      "Train Epoch: 736 [640/1612 (40%)] Loss: 0.239365\n",
      "Train Epoch: 736 [800/1612 (50%)] Loss: 0.310487\n",
      "Train Epoch: 736 [960/1612 (59%)] Loss: 0.329243\n",
      "Train Epoch: 736 [1120/1612 (69%)] Loss: 0.218488\n",
      "Train Epoch: 736 [1280/1612 (79%)] Loss: 0.482858\n",
      "Train Epoch: 736 [1440/1612 (89%)] Loss: 0.479512\n",
      "Train Epoch: 736 [1200/1612 (99%)] Loss: 0.540675\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 737 [0/1612 (0%)] Loss: 0.217579\n",
      "Train Epoch: 737 [160/1612 (10%)] Loss: 0.336906\n",
      "Train Epoch: 737 [320/1612 (20%)] Loss: 0.283014\n",
      "Train Epoch: 737 [480/1612 (30%)] Loss: 0.259569\n",
      "Train Epoch: 737 [640/1612 (40%)] Loss: 0.255938\n",
      "Train Epoch: 737 [800/1612 (50%)] Loss: 0.234568\n",
      "Train Epoch: 737 [960/1612 (59%)] Loss: 0.309869\n",
      "Train Epoch: 737 [1120/1612 (69%)] Loss: 0.181061\n",
      "Train Epoch: 737 [1280/1612 (79%)] Loss: 0.457876\n",
      "Train Epoch: 737 [1440/1612 (89%)] Loss: 0.164144\n",
      "Train Epoch: 737 [1200/1612 (99%)] Loss: 0.149620\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 738 [0/1612 (0%)] Loss: 0.327736\n",
      "Train Epoch: 738 [160/1612 (10%)] Loss: 0.425577\n",
      "Train Epoch: 738 [320/1612 (20%)] Loss: 0.420575\n",
      "Train Epoch: 738 [480/1612 (30%)] Loss: 0.524249\n",
      "Train Epoch: 738 [640/1612 (40%)] Loss: 0.248895\n",
      "Train Epoch: 738 [800/1612 (50%)] Loss: 0.110901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 738 [960/1612 (59%)] Loss: 0.216387\n",
      "Train Epoch: 738 [1120/1612 (69%)] Loss: 0.225806\n",
      "Train Epoch: 738 [1280/1612 (79%)] Loss: 0.333116\n",
      "Train Epoch: 738 [1440/1612 (89%)] Loss: 0.248042\n",
      "Train Epoch: 738 [1200/1612 (99%)] Loss: 0.123593\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 739 [0/1612 (0%)] Loss: 0.299479\n",
      "Train Epoch: 739 [160/1612 (10%)] Loss: 0.631823\n",
      "Train Epoch: 739 [320/1612 (20%)] Loss: 0.361732\n",
      "Train Epoch: 739 [480/1612 (30%)] Loss: 0.149098\n",
      "Train Epoch: 739 [640/1612 (40%)] Loss: 0.257474\n",
      "Train Epoch: 739 [800/1612 (50%)] Loss: 0.243198\n",
      "Train Epoch: 739 [960/1612 (59%)] Loss: 0.174354\n",
      "Train Epoch: 739 [1120/1612 (69%)] Loss: 0.221036\n",
      "Train Epoch: 739 [1280/1612 (79%)] Loss: 0.328080\n",
      "Train Epoch: 739 [1440/1612 (89%)] Loss: 0.445825\n",
      "Train Epoch: 739 [1200/1612 (99%)] Loss: 0.186359\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 740 [0/1612 (0%)] Loss: 0.157424\n",
      "Train Epoch: 740 [160/1612 (10%)] Loss: 0.259884\n",
      "Train Epoch: 740 [320/1612 (20%)] Loss: 0.148643\n",
      "Train Epoch: 740 [480/1612 (30%)] Loss: 0.128805\n",
      "Train Epoch: 740 [640/1612 (40%)] Loss: 0.307147\n",
      "Train Epoch: 740 [800/1612 (50%)] Loss: 0.210424\n",
      "Train Epoch: 740 [960/1612 (59%)] Loss: 0.367231\n",
      "Train Epoch: 740 [1120/1612 (69%)] Loss: 0.413588\n",
      "Train Epoch: 740 [1280/1612 (79%)] Loss: 0.253490\n",
      "Train Epoch: 740 [1440/1612 (89%)] Loss: 0.302351\n",
      "Train Epoch: 740 [1200/1612 (99%)] Loss: 0.420189\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 741 [0/1612 (0%)] Loss: 0.332909\n",
      "Train Epoch: 741 [160/1612 (10%)] Loss: 0.230334\n",
      "Train Epoch: 741 [320/1612 (20%)] Loss: 0.203853\n",
      "Train Epoch: 741 [480/1612 (30%)] Loss: 0.359714\n",
      "Train Epoch: 741 [640/1612 (40%)] Loss: 0.290257\n",
      "Train Epoch: 741 [800/1612 (50%)] Loss: 0.456816\n",
      "Train Epoch: 741 [960/1612 (59%)] Loss: 0.177292\n",
      "Train Epoch: 741 [1120/1612 (69%)] Loss: 0.146401\n",
      "Train Epoch: 741 [1280/1612 (79%)] Loss: 0.327455\n",
      "Train Epoch: 741 [1440/1612 (89%)] Loss: 0.327807\n",
      "Train Epoch: 741 [1200/1612 (99%)] Loss: 0.440664\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 742 [0/1612 (0%)] Loss: 0.137627\n",
      "Train Epoch: 742 [160/1612 (10%)] Loss: 0.333831\n",
      "Train Epoch: 742 [320/1612 (20%)] Loss: 0.278293\n",
      "Train Epoch: 742 [480/1612 (30%)] Loss: 0.242539\n",
      "Train Epoch: 742 [640/1612 (40%)] Loss: 0.403476\n",
      "Train Epoch: 742 [800/1612 (50%)] Loss: 0.266682\n",
      "Train Epoch: 742 [960/1612 (59%)] Loss: 0.507964\n",
      "Train Epoch: 742 [1120/1612 (69%)] Loss: 0.488782\n",
      "Train Epoch: 742 [1280/1612 (79%)] Loss: 0.060751\n",
      "Train Epoch: 742 [1440/1612 (89%)] Loss: 0.534258\n",
      "Train Epoch: 742 [1200/1612 (99%)] Loss: 0.510361\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 743 [0/1612 (0%)] Loss: 0.356187\n",
      "Train Epoch: 743 [160/1612 (10%)] Loss: 0.360976\n",
      "Train Epoch: 743 [320/1612 (20%)] Loss: 0.211087\n",
      "Train Epoch: 743 [480/1612 (30%)] Loss: 0.453609\n",
      "Train Epoch: 743 [640/1612 (40%)] Loss: 0.351310\n",
      "Train Epoch: 743 [800/1612 (50%)] Loss: 0.602050\n",
      "Train Epoch: 743 [960/1612 (59%)] Loss: 0.394714\n",
      "Train Epoch: 743 [1120/1612 (69%)] Loss: 0.385266\n",
      "Train Epoch: 743 [1280/1612 (79%)] Loss: 0.583815\n",
      "Train Epoch: 743 [1440/1612 (89%)] Loss: 0.309596\n",
      "Train Epoch: 743 [1200/1612 (99%)] Loss: 0.256484\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 744 [0/1612 (0%)] Loss: 0.265700\n",
      "Train Epoch: 744 [160/1612 (10%)] Loss: 0.203941\n",
      "Train Epoch: 744 [320/1612 (20%)] Loss: 0.498962\n",
      "Train Epoch: 744 [480/1612 (30%)] Loss: 0.222889\n",
      "Train Epoch: 744 [640/1612 (40%)] Loss: 0.186547\n",
      "Train Epoch: 744 [800/1612 (50%)] Loss: 0.145470\n",
      "Train Epoch: 744 [960/1612 (59%)] Loss: 0.487938\n",
      "Train Epoch: 744 [1120/1612 (69%)] Loss: 0.381182\n",
      "Train Epoch: 744 [1280/1612 (79%)] Loss: 0.150612\n",
      "Train Epoch: 744 [1440/1612 (89%)] Loss: 0.228373\n",
      "Train Epoch: 744 [1200/1612 (99%)] Loss: 0.127763\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 745 [0/1612 (0%)] Loss: 0.347439\n",
      "Train Epoch: 745 [160/1612 (10%)] Loss: 0.410246\n",
      "Train Epoch: 745 [320/1612 (20%)] Loss: 0.264862\n",
      "Train Epoch: 745 [480/1612 (30%)] Loss: 0.309060\n",
      "Train Epoch: 745 [640/1612 (40%)] Loss: 0.545369\n",
      "Train Epoch: 745 [800/1612 (50%)] Loss: 0.195188\n",
      "Train Epoch: 745 [960/1612 (59%)] Loss: 0.454843\n",
      "Train Epoch: 745 [1120/1612 (69%)] Loss: 0.426014\n",
      "Train Epoch: 745 [1280/1612 (79%)] Loss: 0.240880\n",
      "Train Epoch: 745 [1440/1612 (89%)] Loss: 0.166425\n",
      "Train Epoch: 745 [1200/1612 (99%)] Loss: 0.287879\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 746 [0/1612 (0%)] Loss: 0.333724\n",
      "Train Epoch: 746 [160/1612 (10%)] Loss: 0.345294\n",
      "Train Epoch: 746 [320/1612 (20%)] Loss: 0.448713\n",
      "Train Epoch: 746 [480/1612 (30%)] Loss: 0.397899\n",
      "Train Epoch: 746 [640/1612 (40%)] Loss: 0.127676\n",
      "Train Epoch: 746 [800/1612 (50%)] Loss: 0.394784\n",
      "Train Epoch: 746 [960/1612 (59%)] Loss: 0.255344\n",
      "Train Epoch: 746 [1120/1612 (69%)] Loss: 0.391885\n",
      "Train Epoch: 746 [1280/1612 (79%)] Loss: 0.477962\n",
      "Train Epoch: 746 [1440/1612 (89%)] Loss: 0.336586\n",
      "Train Epoch: 746 [1200/1612 (99%)] Loss: 0.299620\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 747 [0/1612 (0%)] Loss: 0.363386\n",
      "Train Epoch: 747 [160/1612 (10%)] Loss: 0.500221\n",
      "Train Epoch: 747 [320/1612 (20%)] Loss: 0.277520\n",
      "Train Epoch: 747 [480/1612 (30%)] Loss: 0.548872\n",
      "Train Epoch: 747 [640/1612 (40%)] Loss: 0.144201\n",
      "Train Epoch: 747 [800/1612 (50%)] Loss: 0.417606\n",
      "Train Epoch: 747 [960/1612 (59%)] Loss: 0.276796\n",
      "Train Epoch: 747 [1120/1612 (69%)] Loss: 0.284815\n",
      "Train Epoch: 747 [1280/1612 (79%)] Loss: 0.249195\n",
      "Train Epoch: 747 [1440/1612 (89%)] Loss: 0.186171\n",
      "Train Epoch: 747 [1200/1612 (99%)] Loss: 0.402474\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 748 [0/1612 (0%)] Loss: 0.144130\n",
      "Train Epoch: 748 [160/1612 (10%)] Loss: 0.579810\n",
      "Train Epoch: 748 [320/1612 (20%)] Loss: 0.261770\n",
      "Train Epoch: 748 [480/1612 (30%)] Loss: 0.373212\n",
      "Train Epoch: 748 [640/1612 (40%)] Loss: 0.272858\n",
      "Train Epoch: 748 [800/1612 (50%)] Loss: 0.292477\n",
      "Train Epoch: 748 [960/1612 (59%)] Loss: 0.331649\n",
      "Train Epoch: 748 [1120/1612 (69%)] Loss: 0.244556\n",
      "Train Epoch: 748 [1280/1612 (79%)] Loss: 0.199876\n",
      "Train Epoch: 748 [1440/1612 (89%)] Loss: 0.232055\n",
      "Train Epoch: 748 [1200/1612 (99%)] Loss: 0.527172\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 749 [0/1612 (0%)] Loss: 0.321882\n",
      "Train Epoch: 749 [160/1612 (10%)] Loss: 0.463739\n",
      "Train Epoch: 749 [320/1612 (20%)] Loss: 0.205691\n",
      "Train Epoch: 749 [480/1612 (30%)] Loss: 0.298281\n",
      "Train Epoch: 749 [640/1612 (40%)] Loss: 0.232080\n",
      "Train Epoch: 749 [800/1612 (50%)] Loss: 0.231236\n",
      "Train Epoch: 749 [960/1612 (59%)] Loss: 0.261787\n",
      "Train Epoch: 749 [1120/1612 (69%)] Loss: 0.204841\n",
      "Train Epoch: 749 [1280/1612 (79%)] Loss: 0.390971\n",
      "Train Epoch: 749 [1440/1612 (89%)] Loss: 0.198703\n",
      "Train Epoch: 749 [1200/1612 (99%)] Loss: 0.356547\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 750 [0/1612 (0%)] Loss: 0.419750\n",
      "Train Epoch: 750 [160/1612 (10%)] Loss: 0.284896\n",
      "Train Epoch: 750 [320/1612 (20%)] Loss: 0.238916\n",
      "Train Epoch: 750 [480/1612 (30%)] Loss: 0.533988\n",
      "Train Epoch: 750 [640/1612 (40%)] Loss: 0.355849\n",
      "Train Epoch: 750 [800/1612 (50%)] Loss: 0.412622\n",
      "Train Epoch: 750 [960/1612 (59%)] Loss: 0.331506\n",
      "Train Epoch: 750 [1120/1612 (69%)] Loss: 0.354988\n",
      "Train Epoch: 750 [1280/1612 (79%)] Loss: 0.394837\n",
      "Train Epoch: 750 [1440/1612 (89%)] Loss: 0.260644\n",
      "Train Epoch: 750 [1200/1612 (99%)] Loss: 0.280089\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 751 [0/1612 (0%)] Loss: 0.337051\n",
      "Train Epoch: 751 [160/1612 (10%)] Loss: 0.260442\n",
      "Train Epoch: 751 [320/1612 (20%)] Loss: 0.340337\n",
      "Train Epoch: 751 [480/1612 (30%)] Loss: 0.240771\n",
      "Train Epoch: 751 [640/1612 (40%)] Loss: 0.284971\n",
      "Train Epoch: 751 [800/1612 (50%)] Loss: 0.891009\n",
      "Train Epoch: 751 [960/1612 (59%)] Loss: 0.170065\n",
      "Train Epoch: 751 [1120/1612 (69%)] Loss: 0.248258\n",
      "Train Epoch: 751 [1280/1612 (79%)] Loss: 0.289960\n",
      "Train Epoch: 751 [1440/1612 (89%)] Loss: 0.325648\n",
      "Train Epoch: 751 [1200/1612 (99%)] Loss: 0.249859\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 752 [0/1612 (0%)] Loss: 0.132495\n",
      "Train Epoch: 752 [160/1612 (10%)] Loss: 0.294347\n",
      "Train Epoch: 752 [320/1612 (20%)] Loss: 0.390359\n",
      "Train Epoch: 752 [480/1612 (30%)] Loss: 0.217671\n",
      "Train Epoch: 752 [640/1612 (40%)] Loss: 0.321924\n",
      "Train Epoch: 752 [800/1612 (50%)] Loss: 0.535636\n",
      "Train Epoch: 752 [960/1612 (59%)] Loss: 0.418774\n",
      "Train Epoch: 752 [1120/1612 (69%)] Loss: 0.587754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 752 [1280/1612 (79%)] Loss: 0.199429\n",
      "Train Epoch: 752 [1440/1612 (89%)] Loss: 0.276637\n",
      "Train Epoch: 752 [1200/1612 (99%)] Loss: 0.201728\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 753 [0/1612 (0%)] Loss: 0.503645\n",
      "Train Epoch: 753 [160/1612 (10%)] Loss: 0.353459\n",
      "Train Epoch: 753 [320/1612 (20%)] Loss: 0.189416\n",
      "Train Epoch: 753 [480/1612 (30%)] Loss: 0.251803\n",
      "Train Epoch: 753 [640/1612 (40%)] Loss: 0.342607\n",
      "Train Epoch: 753 [800/1612 (50%)] Loss: 0.376310\n",
      "Train Epoch: 753 [960/1612 (59%)] Loss: 0.422390\n",
      "Train Epoch: 753 [1120/1612 (69%)] Loss: 0.134369\n",
      "Train Epoch: 753 [1280/1612 (79%)] Loss: 0.294472\n",
      "Train Epoch: 753 [1440/1612 (89%)] Loss: 0.360847\n",
      "Train Epoch: 753 [1200/1612 (99%)] Loss: 0.350144\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 754 [0/1612 (0%)] Loss: 0.366053\n",
      "Train Epoch: 754 [160/1612 (10%)] Loss: 0.277925\n",
      "Train Epoch: 754 [320/1612 (20%)] Loss: 0.188307\n",
      "Train Epoch: 754 [480/1612 (30%)] Loss: 0.421991\n",
      "Train Epoch: 754 [640/1612 (40%)] Loss: 0.352161\n",
      "Train Epoch: 754 [800/1612 (50%)] Loss: 0.222932\n",
      "Train Epoch: 754 [960/1612 (59%)] Loss: 0.386526\n",
      "Train Epoch: 754 [1120/1612 (69%)] Loss: 0.406042\n",
      "Train Epoch: 754 [1280/1612 (79%)] Loss: 0.454263\n",
      "Train Epoch: 754 [1440/1612 (89%)] Loss: 0.350287\n",
      "Train Epoch: 754 [1200/1612 (99%)] Loss: 0.489209\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 755 [0/1612 (0%)] Loss: 0.477518\n",
      "Train Epoch: 755 [160/1612 (10%)] Loss: 0.199928\n",
      "Train Epoch: 755 [320/1612 (20%)] Loss: 0.331044\n",
      "Train Epoch: 755 [480/1612 (30%)] Loss: 0.393126\n",
      "Train Epoch: 755 [640/1612 (40%)] Loss: 0.362380\n",
      "Train Epoch: 755 [800/1612 (50%)] Loss: 0.388442\n",
      "Train Epoch: 755 [960/1612 (59%)] Loss: 0.162445\n",
      "Train Epoch: 755 [1120/1612 (69%)] Loss: 0.193170\n",
      "Train Epoch: 755 [1280/1612 (79%)] Loss: 0.410400\n",
      "Train Epoch: 755 [1440/1612 (89%)] Loss: 0.449501\n",
      "Train Epoch: 755 [1200/1612 (99%)] Loss: 0.390071\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 756 [0/1612 (0%)] Loss: 0.213819\n",
      "Train Epoch: 756 [160/1612 (10%)] Loss: 0.297662\n",
      "Train Epoch: 756 [320/1612 (20%)] Loss: 0.356360\n",
      "Train Epoch: 756 [480/1612 (30%)] Loss: 0.214079\n",
      "Train Epoch: 756 [640/1612 (40%)] Loss: 0.242363\n",
      "Train Epoch: 756 [800/1612 (50%)] Loss: 0.316422\n",
      "Train Epoch: 756 [960/1612 (59%)] Loss: 0.283306\n",
      "Train Epoch: 756 [1120/1612 (69%)] Loss: 0.311615\n",
      "Train Epoch: 756 [1280/1612 (79%)] Loss: 0.339672\n",
      "Train Epoch: 756 [1440/1612 (89%)] Loss: 0.531993\n",
      "Train Epoch: 756 [1200/1612 (99%)] Loss: 0.149541\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 757 [0/1612 (0%)] Loss: 0.611272\n",
      "Train Epoch: 757 [160/1612 (10%)] Loss: 0.218134\n",
      "Train Epoch: 757 [320/1612 (20%)] Loss: 0.112164\n",
      "Train Epoch: 757 [480/1612 (30%)] Loss: 0.244947\n",
      "Train Epoch: 757 [640/1612 (40%)] Loss: 0.309856\n",
      "Train Epoch: 757 [800/1612 (50%)] Loss: 0.376799\n",
      "Train Epoch: 757 [960/1612 (59%)] Loss: 0.279707\n",
      "Train Epoch: 757 [1120/1612 (69%)] Loss: 0.441014\n",
      "Train Epoch: 757 [1280/1612 (79%)] Loss: 0.312688\n",
      "Train Epoch: 757 [1440/1612 (89%)] Loss: 0.220514\n",
      "Train Epoch: 757 [1200/1612 (99%)] Loss: 0.539776\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 758 [0/1612 (0%)] Loss: 0.238997\n",
      "Train Epoch: 758 [160/1612 (10%)] Loss: 0.255820\n",
      "Train Epoch: 758 [320/1612 (20%)] Loss: 0.263707\n",
      "Train Epoch: 758 [480/1612 (30%)] Loss: 0.279084\n",
      "Train Epoch: 758 [640/1612 (40%)] Loss: 0.321723\n",
      "Train Epoch: 758 [800/1612 (50%)] Loss: 0.373905\n",
      "Train Epoch: 758 [960/1612 (59%)] Loss: 0.173469\n",
      "Train Epoch: 758 [1120/1612 (69%)] Loss: 0.437099\n",
      "Train Epoch: 758 [1280/1612 (79%)] Loss: 0.462760\n",
      "Train Epoch: 758 [1440/1612 (89%)] Loss: 0.558533\n",
      "Train Epoch: 758 [1200/1612 (99%)] Loss: 0.304186\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 759 [0/1612 (0%)] Loss: 0.307381\n",
      "Train Epoch: 759 [160/1612 (10%)] Loss: 0.161327\n",
      "Train Epoch: 759 [320/1612 (20%)] Loss: 0.355764\n",
      "Train Epoch: 759 [480/1612 (30%)] Loss: 0.631155\n",
      "Train Epoch: 759 [640/1612 (40%)] Loss: 0.618339\n",
      "Train Epoch: 759 [800/1612 (50%)] Loss: 0.382674\n",
      "Train Epoch: 759 [960/1612 (59%)] Loss: 0.154445\n",
      "Train Epoch: 759 [1120/1612 (69%)] Loss: 0.344280\n",
      "Train Epoch: 759 [1280/1612 (79%)] Loss: 0.310207\n",
      "Train Epoch: 759 [1440/1612 (89%)] Loss: 0.186215\n",
      "Train Epoch: 759 [1200/1612 (99%)] Loss: 0.376560\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 760 [0/1612 (0%)] Loss: 0.511075\n",
      "Train Epoch: 760 [160/1612 (10%)] Loss: 0.247218\n",
      "Train Epoch: 760 [320/1612 (20%)] Loss: 0.369862\n",
      "Train Epoch: 760 [480/1612 (30%)] Loss: 0.617521\n",
      "Train Epoch: 760 [640/1612 (40%)] Loss: 0.138851\n",
      "Train Epoch: 760 [800/1612 (50%)] Loss: 0.406817\n",
      "Train Epoch: 760 [960/1612 (59%)] Loss: 0.222032\n",
      "Train Epoch: 760 [1120/1612 (69%)] Loss: 0.441857\n",
      "Train Epoch: 760 [1280/1612 (79%)] Loss: 0.214204\n",
      "Train Epoch: 760 [1440/1612 (89%)] Loss: 0.412274\n",
      "Train Epoch: 760 [1200/1612 (99%)] Loss: 0.361464\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 761 [0/1612 (0%)] Loss: 0.405843\n",
      "Train Epoch: 761 [160/1612 (10%)] Loss: 0.163709\n",
      "Train Epoch: 761 [320/1612 (20%)] Loss: 0.489465\n",
      "Train Epoch: 761 [480/1612 (30%)] Loss: 0.550144\n",
      "Train Epoch: 761 [640/1612 (40%)] Loss: 0.470598\n",
      "Train Epoch: 761 [800/1612 (50%)] Loss: 0.097821\n",
      "Train Epoch: 761 [960/1612 (59%)] Loss: 0.200026\n",
      "Train Epoch: 761 [1120/1612 (69%)] Loss: 0.359336\n",
      "Train Epoch: 761 [1280/1612 (79%)] Loss: 0.220173\n",
      "Train Epoch: 761 [1440/1612 (89%)] Loss: 0.404275\n",
      "Train Epoch: 761 [1200/1612 (99%)] Loss: 0.289349\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 762 [0/1612 (0%)] Loss: 0.450710\n",
      "Train Epoch: 762 [160/1612 (10%)] Loss: 0.188104\n",
      "Train Epoch: 762 [320/1612 (20%)] Loss: 0.115244\n",
      "Train Epoch: 762 [480/1612 (30%)] Loss: 0.274341\n",
      "Train Epoch: 762 [640/1612 (40%)] Loss: 0.273520\n",
      "Train Epoch: 762 [800/1612 (50%)] Loss: 0.292405\n",
      "Train Epoch: 762 [960/1612 (59%)] Loss: 0.157129\n",
      "Train Epoch: 762 [1120/1612 (69%)] Loss: 0.255691\n",
      "Train Epoch: 762 [1280/1612 (79%)] Loss: 0.492698\n",
      "Train Epoch: 762 [1440/1612 (89%)] Loss: 0.340597\n",
      "Train Epoch: 762 [1200/1612 (99%)] Loss: 0.312181\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 763 [0/1612 (0%)] Loss: 0.367426\n",
      "Train Epoch: 763 [160/1612 (10%)] Loss: 0.272611\n",
      "Train Epoch: 763 [320/1612 (20%)] Loss: 0.295371\n",
      "Train Epoch: 763 [480/1612 (30%)] Loss: 0.136063\n",
      "Train Epoch: 763 [640/1612 (40%)] Loss: 0.346901\n",
      "Train Epoch: 763 [800/1612 (50%)] Loss: 0.201167\n",
      "Train Epoch: 763 [960/1612 (59%)] Loss: 0.179172\n",
      "Train Epoch: 763 [1120/1612 (69%)] Loss: 0.143147\n",
      "Train Epoch: 763 [1280/1612 (79%)] Loss: 0.256575\n",
      "Train Epoch: 763 [1440/1612 (89%)] Loss: 0.186921\n",
      "Train Epoch: 763 [1200/1612 (99%)] Loss: 0.383158\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 764 [0/1612 (0%)] Loss: 0.223983\n",
      "Train Epoch: 764 [160/1612 (10%)] Loss: 0.379109\n",
      "Train Epoch: 764 [320/1612 (20%)] Loss: 0.188722\n",
      "Train Epoch: 764 [480/1612 (30%)] Loss: 0.580589\n",
      "Train Epoch: 764 [640/1612 (40%)] Loss: 0.369143\n",
      "Train Epoch: 764 [800/1612 (50%)] Loss: 0.212111\n",
      "Train Epoch: 764 [960/1612 (59%)] Loss: 0.201056\n",
      "Train Epoch: 764 [1120/1612 (69%)] Loss: 0.177999\n",
      "Train Epoch: 764 [1280/1612 (79%)] Loss: 0.466299\n",
      "Train Epoch: 764 [1440/1612 (89%)] Loss: 0.166887\n",
      "Train Epoch: 764 [1200/1612 (99%)] Loss: 0.213708\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 765 [0/1612 (0%)] Loss: 0.538957\n",
      "Train Epoch: 765 [160/1612 (10%)] Loss: 0.232022\n",
      "Train Epoch: 765 [320/1612 (20%)] Loss: 0.223615\n",
      "Train Epoch: 765 [480/1612 (30%)] Loss: 0.384212\n",
      "Train Epoch: 765 [640/1612 (40%)] Loss: 0.312089\n",
      "Train Epoch: 765 [800/1612 (50%)] Loss: 0.257112\n",
      "Train Epoch: 765 [960/1612 (59%)] Loss: 0.254286\n",
      "Train Epoch: 765 [1120/1612 (69%)] Loss: 0.350500\n",
      "Train Epoch: 765 [1280/1612 (79%)] Loss: 0.279153\n",
      "Train Epoch: 765 [1440/1612 (89%)] Loss: 0.214127\n",
      "Train Epoch: 765 [1200/1612 (99%)] Loss: 0.456699\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 766 [0/1612 (0%)] Loss: 0.271745\n",
      "Train Epoch: 766 [160/1612 (10%)] Loss: 0.322630\n",
      "Train Epoch: 766 [320/1612 (20%)] Loss: 0.243801\n",
      "Train Epoch: 766 [480/1612 (30%)] Loss: 0.349976\n",
      "Train Epoch: 766 [640/1612 (40%)] Loss: 0.258129\n",
      "Train Epoch: 766 [800/1612 (50%)] Loss: 0.215221\n",
      "Train Epoch: 766 [960/1612 (59%)] Loss: 0.433594\n",
      "Train Epoch: 766 [1120/1612 (69%)] Loss: 0.217189\n",
      "Train Epoch: 766 [1280/1612 (79%)] Loss: 0.245281\n",
      "Train Epoch: 766 [1440/1612 (89%)] Loss: 0.312033\n",
      "Train Epoch: 766 [1200/1612 (99%)] Loss: 0.319749\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 767 [0/1612 (0%)] Loss: 0.189810\n",
      "Train Epoch: 767 [160/1612 (10%)] Loss: 0.243911\n",
      "Train Epoch: 767 [320/1612 (20%)] Loss: 0.449608\n",
      "Train Epoch: 767 [480/1612 (30%)] Loss: 0.141175\n",
      "Train Epoch: 767 [640/1612 (40%)] Loss: 0.402108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 767 [800/1612 (50%)] Loss: 0.417412\n",
      "Train Epoch: 767 [960/1612 (59%)] Loss: 0.207350\n",
      "Train Epoch: 767 [1120/1612 (69%)] Loss: 0.467088\n",
      "Train Epoch: 767 [1280/1612 (79%)] Loss: 0.272697\n",
      "Train Epoch: 767 [1440/1612 (89%)] Loss: 0.251610\n",
      "Train Epoch: 767 [1200/1612 (99%)] Loss: 0.320711\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 768 [0/1612 (0%)] Loss: 0.361480\n",
      "Train Epoch: 768 [160/1612 (10%)] Loss: 0.301743\n",
      "Train Epoch: 768 [320/1612 (20%)] Loss: 0.170216\n",
      "Train Epoch: 768 [480/1612 (30%)] Loss: 0.281560\n",
      "Train Epoch: 768 [640/1612 (40%)] Loss: 0.039174\n",
      "Train Epoch: 768 [800/1612 (50%)] Loss: 0.319246\n",
      "Train Epoch: 768 [960/1612 (59%)] Loss: 0.347862\n",
      "Train Epoch: 768 [1120/1612 (69%)] Loss: 0.307071\n",
      "Train Epoch: 768 [1280/1612 (79%)] Loss: 0.208184\n",
      "Train Epoch: 768 [1440/1612 (89%)] Loss: 0.182129\n",
      "Train Epoch: 768 [1200/1612 (99%)] Loss: 0.149605\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 769 [0/1612 (0%)] Loss: 0.262478\n",
      "Train Epoch: 769 [160/1612 (10%)] Loss: 0.371518\n",
      "Train Epoch: 769 [320/1612 (20%)] Loss: 0.260535\n",
      "Train Epoch: 769 [480/1612 (30%)] Loss: 0.278975\n",
      "Train Epoch: 769 [640/1612 (40%)] Loss: 0.328624\n",
      "Train Epoch: 769 [800/1612 (50%)] Loss: 0.322713\n",
      "Train Epoch: 769 [960/1612 (59%)] Loss: 0.301865\n",
      "Train Epoch: 769 [1120/1612 (69%)] Loss: 0.335139\n",
      "Train Epoch: 769 [1280/1612 (79%)] Loss: 0.308209\n",
      "Train Epoch: 769 [1440/1612 (89%)] Loss: 0.454935\n",
      "Train Epoch: 769 [1200/1612 (99%)] Loss: 0.388467\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 770 [0/1612 (0%)] Loss: 0.191834\n",
      "Train Epoch: 770 [160/1612 (10%)] Loss: 0.513636\n",
      "Train Epoch: 770 [320/1612 (20%)] Loss: 0.320362\n",
      "Train Epoch: 770 [480/1612 (30%)] Loss: 0.160906\n",
      "Train Epoch: 770 [640/1612 (40%)] Loss: 0.229904\n",
      "Train Epoch: 770 [800/1612 (50%)] Loss: 0.362985\n",
      "Train Epoch: 770 [960/1612 (59%)] Loss: 0.279650\n",
      "Train Epoch: 770 [1120/1612 (69%)] Loss: 0.461066\n",
      "Train Epoch: 770 [1280/1612 (79%)] Loss: 0.454730\n",
      "Train Epoch: 770 [1440/1612 (89%)] Loss: 0.425511\n",
      "Train Epoch: 770 [1200/1612 (99%)] Loss: 0.165349\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 771 [0/1612 (0%)] Loss: 0.235931\n",
      "Train Epoch: 771 [160/1612 (10%)] Loss: 0.511990\n",
      "Train Epoch: 771 [320/1612 (20%)] Loss: 0.240039\n",
      "Train Epoch: 771 [480/1612 (30%)] Loss: 0.237530\n",
      "Train Epoch: 771 [640/1612 (40%)] Loss: 0.397112\n",
      "Train Epoch: 771 [800/1612 (50%)] Loss: 0.188453\n",
      "Train Epoch: 771 [960/1612 (59%)] Loss: 0.197167\n",
      "Train Epoch: 771 [1120/1612 (69%)] Loss: 0.314409\n",
      "Train Epoch: 771 [1280/1612 (79%)] Loss: 0.295364\n",
      "Train Epoch: 771 [1440/1612 (89%)] Loss: 0.339252\n",
      "Train Epoch: 771 [1200/1612 (99%)] Loss: 0.537099\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 772 [0/1612 (0%)] Loss: 0.279337\n",
      "Train Epoch: 772 [160/1612 (10%)] Loss: 0.353283\n",
      "Train Epoch: 772 [320/1612 (20%)] Loss: 0.403723\n",
      "Train Epoch: 772 [480/1612 (30%)] Loss: 0.338789\n",
      "Train Epoch: 772 [640/1612 (40%)] Loss: 0.225241\n",
      "Train Epoch: 772 [800/1612 (50%)] Loss: 0.234108\n",
      "Train Epoch: 772 [960/1612 (59%)] Loss: 0.146458\n",
      "Train Epoch: 772 [1120/1612 (69%)] Loss: 0.145297\n",
      "Train Epoch: 772 [1280/1612 (79%)] Loss: 0.138909\n",
      "Train Epoch: 772 [1440/1612 (89%)] Loss: 0.365069\n",
      "Train Epoch: 772 [1200/1612 (99%)] Loss: 0.177493\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 773 [0/1612 (0%)] Loss: 0.181700\n",
      "Train Epoch: 773 [160/1612 (10%)] Loss: 0.112958\n",
      "Train Epoch: 773 [320/1612 (20%)] Loss: 0.260785\n",
      "Train Epoch: 773 [480/1612 (30%)] Loss: 0.275974\n",
      "Train Epoch: 773 [640/1612 (40%)] Loss: 0.372326\n",
      "Train Epoch: 773 [800/1612 (50%)] Loss: 0.217650\n",
      "Train Epoch: 773 [960/1612 (59%)] Loss: 0.242708\n",
      "Train Epoch: 773 [1120/1612 (69%)] Loss: 0.292584\n",
      "Train Epoch: 773 [1280/1612 (79%)] Loss: 0.317996\n",
      "Train Epoch: 773 [1440/1612 (89%)] Loss: 0.152734\n",
      "Train Epoch: 773 [1200/1612 (99%)] Loss: 0.120719\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 774 [0/1612 (0%)] Loss: 0.585636\n",
      "Train Epoch: 774 [160/1612 (10%)] Loss: 0.215382\n",
      "Train Epoch: 774 [320/1612 (20%)] Loss: 0.151505\n",
      "Train Epoch: 774 [480/1612 (30%)] Loss: 0.170686\n",
      "Train Epoch: 774 [640/1612 (40%)] Loss: 0.216078\n",
      "Train Epoch: 774 [800/1612 (50%)] Loss: 0.279010\n",
      "Train Epoch: 774 [960/1612 (59%)] Loss: 0.346122\n",
      "Train Epoch: 774 [1120/1612 (69%)] Loss: 0.357610\n",
      "Train Epoch: 774 [1280/1612 (79%)] Loss: 0.504980\n",
      "Train Epoch: 774 [1440/1612 (89%)] Loss: 0.229244\n",
      "Train Epoch: 774 [1200/1612 (99%)] Loss: 0.285555\n",
      "\n",
      "Test set: Average loss: 0.0295, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 775 [0/1612 (0%)] Loss: 0.149218\n",
      "Train Epoch: 775 [160/1612 (10%)] Loss: 0.179937\n",
      "Train Epoch: 775 [320/1612 (20%)] Loss: 0.231742\n",
      "Train Epoch: 775 [480/1612 (30%)] Loss: 0.521138\n",
      "Train Epoch: 775 [640/1612 (40%)] Loss: 0.215134\n",
      "Train Epoch: 775 [800/1612 (50%)] Loss: 0.168995\n",
      "Train Epoch: 775 [960/1612 (59%)] Loss: 0.260304\n",
      "Train Epoch: 775 [1120/1612 (69%)] Loss: 0.296837\n",
      "Train Epoch: 775 [1280/1612 (79%)] Loss: 0.320668\n",
      "Train Epoch: 775 [1440/1612 (89%)] Loss: 0.715324\n",
      "Train Epoch: 775 [1200/1612 (99%)] Loss: 0.361164\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 776 [0/1612 (0%)] Loss: 0.577316\n",
      "Train Epoch: 776 [160/1612 (10%)] Loss: 0.354522\n",
      "Train Epoch: 776 [320/1612 (20%)] Loss: 0.330345\n",
      "Train Epoch: 776 [480/1612 (30%)] Loss: 0.275587\n",
      "Train Epoch: 776 [640/1612 (40%)] Loss: 0.198424\n",
      "Train Epoch: 776 [800/1612 (50%)] Loss: 0.182900\n",
      "Train Epoch: 776 [960/1612 (59%)] Loss: 0.642721\n",
      "Train Epoch: 776 [1120/1612 (69%)] Loss: 0.277298\n",
      "Train Epoch: 776 [1280/1612 (79%)] Loss: 0.255274\n",
      "Train Epoch: 776 [1440/1612 (89%)] Loss: 0.159259\n",
      "Train Epoch: 776 [1200/1612 (99%)] Loss: 0.290921\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 777 [0/1612 (0%)] Loss: 0.276764\n",
      "Train Epoch: 777 [160/1612 (10%)] Loss: 0.163947\n",
      "Train Epoch: 777 [320/1612 (20%)] Loss: 0.236250\n",
      "Train Epoch: 777 [480/1612 (30%)] Loss: 0.317407\n",
      "Train Epoch: 777 [640/1612 (40%)] Loss: 0.514971\n",
      "Train Epoch: 777 [800/1612 (50%)] Loss: 0.266233\n",
      "Train Epoch: 777 [960/1612 (59%)] Loss: 0.483643\n",
      "Train Epoch: 777 [1120/1612 (69%)] Loss: 0.130123\n",
      "Train Epoch: 777 [1280/1612 (79%)] Loss: 0.244752\n",
      "Train Epoch: 777 [1440/1612 (89%)] Loss: 0.183615\n",
      "Train Epoch: 777 [1200/1612 (99%)] Loss: 0.302584\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 778 [0/1612 (0%)] Loss: 0.219432\n",
      "Train Epoch: 778 [160/1612 (10%)] Loss: 0.189443\n",
      "Train Epoch: 778 [320/1612 (20%)] Loss: 0.119469\n",
      "Train Epoch: 778 [480/1612 (30%)] Loss: 0.322564\n",
      "Train Epoch: 778 [640/1612 (40%)] Loss: 0.257145\n",
      "Train Epoch: 778 [800/1612 (50%)] Loss: 0.478516\n",
      "Train Epoch: 778 [960/1612 (59%)] Loss: 0.315669\n",
      "Train Epoch: 778 [1120/1612 (69%)] Loss: 0.568975\n",
      "Train Epoch: 778 [1280/1612 (79%)] Loss: 0.172765\n",
      "Train Epoch: 778 [1440/1612 (89%)] Loss: 0.470615\n",
      "Train Epoch: 778 [1200/1612 (99%)] Loss: 0.420970\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 779 [0/1612 (0%)] Loss: 0.228881\n",
      "Train Epoch: 779 [160/1612 (10%)] Loss: 0.366965\n",
      "Train Epoch: 779 [320/1612 (20%)] Loss: 0.569036\n",
      "Train Epoch: 779 [480/1612 (30%)] Loss: 0.372363\n",
      "Train Epoch: 779 [640/1612 (40%)] Loss: 0.313359\n",
      "Train Epoch: 779 [800/1612 (50%)] Loss: 0.437823\n",
      "Train Epoch: 779 [960/1612 (59%)] Loss: 0.282563\n",
      "Train Epoch: 779 [1120/1612 (69%)] Loss: 0.534077\n",
      "Train Epoch: 779 [1280/1612 (79%)] Loss: 0.450515\n",
      "Train Epoch: 779 [1440/1612 (89%)] Loss: 0.249314\n",
      "Train Epoch: 779 [1200/1612 (99%)] Loss: 0.288586\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 780 [0/1612 (0%)] Loss: 0.210901\n",
      "Train Epoch: 780 [160/1612 (10%)] Loss: 0.257763\n",
      "Train Epoch: 780 [320/1612 (20%)] Loss: 0.331880\n",
      "Train Epoch: 780 [480/1612 (30%)] Loss: 0.244326\n",
      "Train Epoch: 780 [640/1612 (40%)] Loss: 0.192540\n",
      "Train Epoch: 780 [800/1612 (50%)] Loss: 0.154309\n",
      "Train Epoch: 780 [960/1612 (59%)] Loss: 0.239313\n",
      "Train Epoch: 780 [1120/1612 (69%)] Loss: 0.385058\n",
      "Train Epoch: 780 [1280/1612 (79%)] Loss: 0.289078\n",
      "Train Epoch: 780 [1440/1612 (89%)] Loss: 0.318173\n",
      "Train Epoch: 780 [1200/1612 (99%)] Loss: 0.224119\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 781 [0/1612 (0%)] Loss: 0.222108\n",
      "Train Epoch: 781 [160/1612 (10%)] Loss: 0.289599\n",
      "Train Epoch: 781 [320/1612 (20%)] Loss: 0.279972\n",
      "Train Epoch: 781 [480/1612 (30%)] Loss: 0.685407\n",
      "Train Epoch: 781 [640/1612 (40%)] Loss: 0.159411\n",
      "Train Epoch: 781 [800/1612 (50%)] Loss: 0.373952\n",
      "Train Epoch: 781 [960/1612 (59%)] Loss: 0.331972\n",
      "Train Epoch: 781 [1120/1612 (69%)] Loss: 0.659228\n",
      "Train Epoch: 781 [1280/1612 (79%)] Loss: 0.225067\n",
      "Train Epoch: 781 [1440/1612 (89%)] Loss: 0.264492\n",
      "Train Epoch: 781 [1200/1612 (99%)] Loss: 0.446156\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 782 [0/1612 (0%)] Loss: 0.293407\n",
      "Train Epoch: 782 [160/1612 (10%)] Loss: 0.226434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 782 [320/1612 (20%)] Loss: 0.344632\n",
      "Train Epoch: 782 [480/1612 (30%)] Loss: 0.161409\n",
      "Train Epoch: 782 [640/1612 (40%)] Loss: 0.280288\n",
      "Train Epoch: 782 [800/1612 (50%)] Loss: 0.487692\n",
      "Train Epoch: 782 [960/1612 (59%)] Loss: 0.231208\n",
      "Train Epoch: 782 [1120/1612 (69%)] Loss: 0.511023\n",
      "Train Epoch: 782 [1280/1612 (79%)] Loss: 0.389078\n",
      "Train Epoch: 782 [1440/1612 (89%)] Loss: 0.146871\n",
      "Train Epoch: 782 [1200/1612 (99%)] Loss: 0.256972\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 783 [0/1612 (0%)] Loss: 0.199978\n",
      "Train Epoch: 783 [160/1612 (10%)] Loss: 0.152182\n",
      "Train Epoch: 783 [320/1612 (20%)] Loss: 0.423950\n",
      "Train Epoch: 783 [480/1612 (30%)] Loss: 0.492985\n",
      "Train Epoch: 783 [640/1612 (40%)] Loss: 0.229249\n",
      "Train Epoch: 783 [800/1612 (50%)] Loss: 0.437561\n",
      "Train Epoch: 783 [960/1612 (59%)] Loss: 0.407745\n",
      "Train Epoch: 783 [1120/1612 (69%)] Loss: 0.241834\n",
      "Train Epoch: 783 [1280/1612 (79%)] Loss: 0.152872\n",
      "Train Epoch: 783 [1440/1612 (89%)] Loss: 0.326290\n",
      "Train Epoch: 783 [1200/1612 (99%)] Loss: 0.315848\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 784 [0/1612 (0%)] Loss: 0.098126\n",
      "Train Epoch: 784 [160/1612 (10%)] Loss: 0.379996\n",
      "Train Epoch: 784 [320/1612 (20%)] Loss: 0.354398\n",
      "Train Epoch: 784 [480/1612 (30%)] Loss: 0.340054\n",
      "Train Epoch: 784 [640/1612 (40%)] Loss: 0.154624\n",
      "Train Epoch: 784 [800/1612 (50%)] Loss: 0.355743\n",
      "Train Epoch: 784 [960/1612 (59%)] Loss: 0.376222\n",
      "Train Epoch: 784 [1120/1612 (69%)] Loss: 0.440817\n",
      "Train Epoch: 784 [1280/1612 (79%)] Loss: 0.213096\n",
      "Train Epoch: 784 [1440/1612 (89%)] Loss: 0.297351\n",
      "Train Epoch: 784 [1200/1612 (99%)] Loss: 0.597587\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 785 [0/1612 (0%)] Loss: 0.152859\n",
      "Train Epoch: 785 [160/1612 (10%)] Loss: 0.412872\n",
      "Train Epoch: 785 [320/1612 (20%)] Loss: 0.541797\n",
      "Train Epoch: 785 [480/1612 (30%)] Loss: 0.194639\n",
      "Train Epoch: 785 [640/1612 (40%)] Loss: 0.197788\n",
      "Train Epoch: 785 [800/1612 (50%)] Loss: 0.140973\n",
      "Train Epoch: 785 [960/1612 (59%)] Loss: 0.529690\n",
      "Train Epoch: 785 [1120/1612 (69%)] Loss: 0.504029\n",
      "Train Epoch: 785 [1280/1612 (79%)] Loss: 0.436626\n",
      "Train Epoch: 785 [1440/1612 (89%)] Loss: 0.386397\n",
      "Train Epoch: 785 [1200/1612 (99%)] Loss: 0.282891\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 786 [0/1612 (0%)] Loss: 0.128474\n",
      "Train Epoch: 786 [160/1612 (10%)] Loss: 0.181056\n",
      "Train Epoch: 786 [320/1612 (20%)] Loss: 0.451840\n",
      "Train Epoch: 786 [480/1612 (30%)] Loss: 0.136766\n",
      "Train Epoch: 786 [640/1612 (40%)] Loss: 0.313348\n",
      "Train Epoch: 786 [800/1612 (50%)] Loss: 0.139710\n",
      "Train Epoch: 786 [960/1612 (59%)] Loss: 0.541469\n",
      "Train Epoch: 786 [1120/1612 (69%)] Loss: 0.392277\n",
      "Train Epoch: 786 [1280/1612 (79%)] Loss: 0.450142\n",
      "Train Epoch: 786 [1440/1612 (89%)] Loss: 0.300109\n",
      "Train Epoch: 786 [1200/1612 (99%)] Loss: 0.113748\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 787 [0/1612 (0%)] Loss: 0.251156\n",
      "Train Epoch: 787 [160/1612 (10%)] Loss: 0.259236\n",
      "Train Epoch: 787 [320/1612 (20%)] Loss: 0.144152\n",
      "Train Epoch: 787 [480/1612 (30%)] Loss: 0.222770\n",
      "Train Epoch: 787 [640/1612 (40%)] Loss: 0.207511\n",
      "Train Epoch: 787 [800/1612 (50%)] Loss: 0.177136\n",
      "Train Epoch: 787 [960/1612 (59%)] Loss: 0.266201\n",
      "Train Epoch: 787 [1120/1612 (69%)] Loss: 0.504557\n",
      "Train Epoch: 787 [1280/1612 (79%)] Loss: 0.207698\n",
      "Train Epoch: 787 [1440/1612 (89%)] Loss: 0.313696\n",
      "Train Epoch: 787 [1200/1612 (99%)] Loss: 0.195390\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 788 [0/1612 (0%)] Loss: 0.295401\n",
      "Train Epoch: 788 [160/1612 (10%)] Loss: 0.231944\n",
      "Train Epoch: 788 [320/1612 (20%)] Loss: 0.212687\n",
      "Train Epoch: 788 [480/1612 (30%)] Loss: 0.253013\n",
      "Train Epoch: 788 [640/1612 (40%)] Loss: 0.382262\n",
      "Train Epoch: 788 [800/1612 (50%)] Loss: 0.428480\n",
      "Train Epoch: 788 [960/1612 (59%)] Loss: 0.328299\n",
      "Train Epoch: 788 [1120/1612 (69%)] Loss: 0.491206\n",
      "Train Epoch: 788 [1280/1612 (79%)] Loss: 0.208456\n",
      "Train Epoch: 788 [1440/1612 (89%)] Loss: 0.210506\n",
      "Train Epoch: 788 [1200/1612 (99%)] Loss: 0.342805\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 789 [0/1612 (0%)] Loss: 0.360715\n",
      "Train Epoch: 789 [160/1612 (10%)] Loss: 0.334334\n",
      "Train Epoch: 789 [320/1612 (20%)] Loss: 0.295956\n",
      "Train Epoch: 789 [480/1612 (30%)] Loss: 0.203010\n",
      "Train Epoch: 789 [640/1612 (40%)] Loss: 0.139813\n",
      "Train Epoch: 789 [800/1612 (50%)] Loss: 0.358425\n",
      "Train Epoch: 789 [960/1612 (59%)] Loss: 0.073039\n",
      "Train Epoch: 789 [1120/1612 (69%)] Loss: 0.422586\n",
      "Train Epoch: 789 [1280/1612 (79%)] Loss: 0.245429\n",
      "Train Epoch: 789 [1440/1612 (89%)] Loss: 0.352614\n",
      "Train Epoch: 789 [1200/1612 (99%)] Loss: 0.475513\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 790 [0/1612 (0%)] Loss: 0.365469\n",
      "Train Epoch: 790 [160/1612 (10%)] Loss: 0.312720\n",
      "Train Epoch: 790 [320/1612 (20%)] Loss: 0.372174\n",
      "Train Epoch: 790 [480/1612 (30%)] Loss: 0.372758\n",
      "Train Epoch: 790 [640/1612 (40%)] Loss: 0.329732\n",
      "Train Epoch: 790 [800/1612 (50%)] Loss: 0.332385\n",
      "Train Epoch: 790 [960/1612 (59%)] Loss: 0.269257\n",
      "Train Epoch: 790 [1120/1612 (69%)] Loss: 0.349031\n",
      "Train Epoch: 790 [1280/1612 (79%)] Loss: 0.354088\n",
      "Train Epoch: 790 [1440/1612 (89%)] Loss: 0.264722\n",
      "Train Epoch: 790 [1200/1612 (99%)] Loss: 0.207747\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 791 [0/1612 (0%)] Loss: 0.310943\n",
      "Train Epoch: 791 [160/1612 (10%)] Loss: 0.343321\n",
      "Train Epoch: 791 [320/1612 (20%)] Loss: 0.359148\n",
      "Train Epoch: 791 [480/1612 (30%)] Loss: 0.374752\n",
      "Train Epoch: 791 [640/1612 (40%)] Loss: 0.406944\n",
      "Train Epoch: 791 [800/1612 (50%)] Loss: 0.221808\n",
      "Train Epoch: 791 [960/1612 (59%)] Loss: 0.342563\n",
      "Train Epoch: 791 [1120/1612 (69%)] Loss: 0.284410\n",
      "Train Epoch: 791 [1280/1612 (79%)] Loss: 0.121776\n",
      "Train Epoch: 791 [1440/1612 (89%)] Loss: 0.647572\n",
      "Train Epoch: 791 [1200/1612 (99%)] Loss: 0.306884\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 792 [0/1612 (0%)] Loss: 0.229724\n",
      "Train Epoch: 792 [160/1612 (10%)] Loss: 0.141941\n",
      "Train Epoch: 792 [320/1612 (20%)] Loss: 0.171406\n",
      "Train Epoch: 792 [480/1612 (30%)] Loss: 0.177654\n",
      "Train Epoch: 792 [640/1612 (40%)] Loss: 0.508348\n",
      "Train Epoch: 792 [800/1612 (50%)] Loss: 0.679781\n",
      "Train Epoch: 792 [960/1612 (59%)] Loss: 0.222691\n",
      "Train Epoch: 792 [1120/1612 (69%)] Loss: 0.234484\n",
      "Train Epoch: 792 [1280/1612 (79%)] Loss: 0.123614\n",
      "Train Epoch: 792 [1440/1612 (89%)] Loss: 0.285402\n",
      "Train Epoch: 792 [1200/1612 (99%)] Loss: 0.141999\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 793 [0/1612 (0%)] Loss: 0.319982\n",
      "Train Epoch: 793 [160/1612 (10%)] Loss: 0.457313\n",
      "Train Epoch: 793 [320/1612 (20%)] Loss: 0.255684\n",
      "Train Epoch: 793 [480/1612 (30%)] Loss: 0.245010\n",
      "Train Epoch: 793 [640/1612 (40%)] Loss: 0.717347\n",
      "Train Epoch: 793 [800/1612 (50%)] Loss: 0.580199\n",
      "Train Epoch: 793 [960/1612 (59%)] Loss: 0.170470\n",
      "Train Epoch: 793 [1120/1612 (69%)] Loss: 0.365856\n",
      "Train Epoch: 793 [1280/1612 (79%)] Loss: 0.468919\n",
      "Train Epoch: 793 [1440/1612 (89%)] Loss: 0.207135\n",
      "Train Epoch: 793 [1200/1612 (99%)] Loss: 0.167156\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 794 [0/1612 (0%)] Loss: 0.332864\n",
      "Train Epoch: 794 [160/1612 (10%)] Loss: 0.608018\n",
      "Train Epoch: 794 [320/1612 (20%)] Loss: 0.523743\n",
      "Train Epoch: 794 [480/1612 (30%)] Loss: 0.358904\n",
      "Train Epoch: 794 [640/1612 (40%)] Loss: 0.192232\n",
      "Train Epoch: 794 [800/1612 (50%)] Loss: 0.291553\n",
      "Train Epoch: 794 [960/1612 (59%)] Loss: 0.273635\n",
      "Train Epoch: 794 [1120/1612 (69%)] Loss: 0.427741\n",
      "Train Epoch: 794 [1280/1612 (79%)] Loss: 0.384329\n",
      "Train Epoch: 794 [1440/1612 (89%)] Loss: 0.293214\n",
      "Train Epoch: 794 [1200/1612 (99%)] Loss: 0.358644\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 795 [0/1612 (0%)] Loss: 0.361441\n",
      "Train Epoch: 795 [160/1612 (10%)] Loss: 0.231575\n",
      "Train Epoch: 795 [320/1612 (20%)] Loss: 0.336641\n",
      "Train Epoch: 795 [480/1612 (30%)] Loss: 0.142588\n",
      "Train Epoch: 795 [640/1612 (40%)] Loss: 0.295648\n",
      "Train Epoch: 795 [800/1612 (50%)] Loss: 0.151168\n",
      "Train Epoch: 795 [960/1612 (59%)] Loss: 0.246919\n",
      "Train Epoch: 795 [1120/1612 (69%)] Loss: 0.402770\n",
      "Train Epoch: 795 [1280/1612 (79%)] Loss: 0.480496\n",
      "Train Epoch: 795 [1440/1612 (89%)] Loss: 0.381534\n",
      "Train Epoch: 795 [1200/1612 (99%)] Loss: 0.254490\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 796 [0/1612 (0%)] Loss: 0.301999\n",
      "Train Epoch: 796 [160/1612 (10%)] Loss: 0.232755\n",
      "Train Epoch: 796 [320/1612 (20%)] Loss: 0.137799\n",
      "Train Epoch: 796 [480/1612 (30%)] Loss: 0.239497\n",
      "Train Epoch: 796 [640/1612 (40%)] Loss: 0.317157\n",
      "Train Epoch: 796 [800/1612 (50%)] Loss: 0.562883\n",
      "Train Epoch: 796 [960/1612 (59%)] Loss: 0.334258\n",
      "Train Epoch: 796 [1120/1612 (69%)] Loss: 0.354044\n",
      "Train Epoch: 796 [1280/1612 (79%)] Loss: 0.173048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 796 [1440/1612 (89%)] Loss: 0.221356\n",
      "Train Epoch: 796 [1200/1612 (99%)] Loss: 0.206257\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 797 [0/1612 (0%)] Loss: 0.172950\n",
      "Train Epoch: 797 [160/1612 (10%)] Loss: 0.158422\n",
      "Train Epoch: 797 [320/1612 (20%)] Loss: 0.332606\n",
      "Train Epoch: 797 [480/1612 (30%)] Loss: 0.475326\n",
      "Train Epoch: 797 [640/1612 (40%)] Loss: 0.198878\n",
      "Train Epoch: 797 [800/1612 (50%)] Loss: 0.211361\n",
      "Train Epoch: 797 [960/1612 (59%)] Loss: 0.145704\n",
      "Train Epoch: 797 [1120/1612 (69%)] Loss: 0.437203\n",
      "Train Epoch: 797 [1280/1612 (79%)] Loss: 0.281940\n",
      "Train Epoch: 797 [1440/1612 (89%)] Loss: 0.283601\n",
      "Train Epoch: 797 [1200/1612 (99%)] Loss: 0.592923\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 798 [0/1612 (0%)] Loss: 0.651772\n",
      "Train Epoch: 798 [160/1612 (10%)] Loss: 0.450393\n",
      "Train Epoch: 798 [320/1612 (20%)] Loss: 0.242470\n",
      "Train Epoch: 798 [480/1612 (30%)] Loss: 0.324105\n",
      "Train Epoch: 798 [640/1612 (40%)] Loss: 0.234230\n",
      "Train Epoch: 798 [800/1612 (50%)] Loss: 0.117746\n",
      "Train Epoch: 798 [960/1612 (59%)] Loss: 0.513437\n",
      "Train Epoch: 798 [1120/1612 (69%)] Loss: 0.237826\n",
      "Train Epoch: 798 [1280/1612 (79%)] Loss: 0.289092\n",
      "Train Epoch: 798 [1440/1612 (89%)] Loss: 0.176385\n",
      "Train Epoch: 798 [1200/1612 (99%)] Loss: 0.259548\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 799 [0/1612 (0%)] Loss: 0.261950\n",
      "Train Epoch: 799 [160/1612 (10%)] Loss: 0.253141\n",
      "Train Epoch: 799 [320/1612 (20%)] Loss: 0.158678\n",
      "Train Epoch: 799 [480/1612 (30%)] Loss: 0.342545\n",
      "Train Epoch: 799 [640/1612 (40%)] Loss: 0.270515\n",
      "Train Epoch: 799 [800/1612 (50%)] Loss: 0.286180\n",
      "Train Epoch: 799 [960/1612 (59%)] Loss: 0.358733\n",
      "Train Epoch: 799 [1120/1612 (69%)] Loss: 0.430293\n",
      "Train Epoch: 799 [1280/1612 (79%)] Loss: 0.192631\n",
      "Train Epoch: 799 [1440/1612 (89%)] Loss: 0.239882\n",
      "Train Epoch: 799 [1200/1612 (99%)] Loss: 0.217910\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 800 [0/1612 (0%)] Loss: 0.520101\n",
      "Train Epoch: 800 [160/1612 (10%)] Loss: 0.205169\n",
      "Train Epoch: 800 [320/1612 (20%)] Loss: 0.158320\n",
      "Train Epoch: 800 [480/1612 (30%)] Loss: 0.243645\n",
      "Train Epoch: 800 [640/1612 (40%)] Loss: 0.414594\n",
      "Train Epoch: 800 [800/1612 (50%)] Loss: 0.203991\n",
      "Train Epoch: 800 [960/1612 (59%)] Loss: 0.223594\n",
      "Train Epoch: 800 [1120/1612 (69%)] Loss: 0.309825\n",
      "Train Epoch: 800 [1280/1612 (79%)] Loss: 0.398706\n",
      "Train Epoch: 800 [1440/1612 (89%)] Loss: 0.096714\n",
      "Train Epoch: 800 [1200/1612 (99%)] Loss: 0.253795\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 801 [0/1612 (0%)] Loss: 0.449428\n",
      "Train Epoch: 801 [160/1612 (10%)] Loss: 0.323171\n",
      "Train Epoch: 801 [320/1612 (20%)] Loss: 0.301987\n",
      "Train Epoch: 801 [480/1612 (30%)] Loss: 0.339366\n",
      "Train Epoch: 801 [640/1612 (40%)] Loss: 0.336993\n",
      "Train Epoch: 801 [800/1612 (50%)] Loss: 0.238558\n",
      "Train Epoch: 801 [960/1612 (59%)] Loss: 0.265340\n",
      "Train Epoch: 801 [1120/1612 (69%)] Loss: 0.359713\n",
      "Train Epoch: 801 [1280/1612 (79%)] Loss: 0.110757\n",
      "Train Epoch: 801 [1440/1612 (89%)] Loss: 0.456791\n",
      "Train Epoch: 801 [1200/1612 (99%)] Loss: 0.211770\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 802 [0/1612 (0%)] Loss: 0.395546\n",
      "Train Epoch: 802 [160/1612 (10%)] Loss: 0.610217\n",
      "Train Epoch: 802 [320/1612 (20%)] Loss: 0.338828\n",
      "Train Epoch: 802 [480/1612 (30%)] Loss: 0.469145\n",
      "Train Epoch: 802 [640/1612 (40%)] Loss: 0.154068\n",
      "Train Epoch: 802 [800/1612 (50%)] Loss: 0.398637\n",
      "Train Epoch: 802 [960/1612 (59%)] Loss: 0.397954\n",
      "Train Epoch: 802 [1120/1612 (69%)] Loss: 0.337543\n",
      "Train Epoch: 802 [1280/1612 (79%)] Loss: 0.309624\n",
      "Train Epoch: 802 [1440/1612 (89%)] Loss: 0.126107\n",
      "Train Epoch: 802 [1200/1612 (99%)] Loss: 0.188237\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 803 [0/1612 (0%)] Loss: 0.311555\n",
      "Train Epoch: 803 [160/1612 (10%)] Loss: 0.232655\n",
      "Train Epoch: 803 [320/1612 (20%)] Loss: 0.189071\n",
      "Train Epoch: 803 [480/1612 (30%)] Loss: 0.432599\n",
      "Train Epoch: 803 [640/1612 (40%)] Loss: 0.550594\n",
      "Train Epoch: 803 [800/1612 (50%)] Loss: 0.349128\n",
      "Train Epoch: 803 [960/1612 (59%)] Loss: 0.271310\n",
      "Train Epoch: 803 [1120/1612 (69%)] Loss: 0.431233\n",
      "Train Epoch: 803 [1280/1612 (79%)] Loss: 0.102044\n",
      "Train Epoch: 803 [1440/1612 (89%)] Loss: 0.319971\n",
      "Train Epoch: 803 [1200/1612 (99%)] Loss: 0.427469\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 804 [0/1612 (0%)] Loss: 0.234707\n",
      "Train Epoch: 804 [160/1612 (10%)] Loss: 0.216662\n",
      "Train Epoch: 804 [320/1612 (20%)] Loss: 0.215401\n",
      "Train Epoch: 804 [480/1612 (30%)] Loss: 0.381193\n",
      "Train Epoch: 804 [640/1612 (40%)] Loss: 0.174014\n",
      "Train Epoch: 804 [800/1612 (50%)] Loss: 0.437364\n",
      "Train Epoch: 804 [960/1612 (59%)] Loss: 0.324325\n",
      "Train Epoch: 804 [1120/1612 (69%)] Loss: 0.224737\n",
      "Train Epoch: 804 [1280/1612 (79%)] Loss: 0.243976\n",
      "Train Epoch: 804 [1440/1612 (89%)] Loss: 0.431623\n",
      "Train Epoch: 804 [1200/1612 (99%)] Loss: 0.450094\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 805 [0/1612 (0%)] Loss: 0.331551\n",
      "Train Epoch: 805 [160/1612 (10%)] Loss: 0.272117\n",
      "Train Epoch: 805 [320/1612 (20%)] Loss: 0.279753\n",
      "Train Epoch: 805 [480/1612 (30%)] Loss: 0.172875\n",
      "Train Epoch: 805 [640/1612 (40%)] Loss: 0.350768\n",
      "Train Epoch: 805 [800/1612 (50%)] Loss: 0.336076\n",
      "Train Epoch: 805 [960/1612 (59%)] Loss: 0.198935\n",
      "Train Epoch: 805 [1120/1612 (69%)] Loss: 0.157858\n",
      "Train Epoch: 805 [1280/1612 (79%)] Loss: 0.153313\n",
      "Train Epoch: 805 [1440/1612 (89%)] Loss: 0.304598\n",
      "Train Epoch: 805 [1200/1612 (99%)] Loss: 0.268528\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 806 [0/1612 (0%)] Loss: 0.320627\n",
      "Train Epoch: 806 [160/1612 (10%)] Loss: 0.239413\n",
      "Train Epoch: 806 [320/1612 (20%)] Loss: 0.156146\n",
      "Train Epoch: 806 [480/1612 (30%)] Loss: 0.194783\n",
      "Train Epoch: 806 [640/1612 (40%)] Loss: 0.201835\n",
      "Train Epoch: 806 [800/1612 (50%)] Loss: 0.166387\n",
      "Train Epoch: 806 [960/1612 (59%)] Loss: 0.401179\n",
      "Train Epoch: 806 [1120/1612 (69%)] Loss: 0.253525\n",
      "Train Epoch: 806 [1280/1612 (79%)] Loss: 0.241350\n",
      "Train Epoch: 806 [1440/1612 (89%)] Loss: 0.304305\n",
      "Train Epoch: 806 [1200/1612 (99%)] Loss: 0.162041\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 807 [0/1612 (0%)] Loss: 0.194719\n",
      "Train Epoch: 807 [160/1612 (10%)] Loss: 0.179724\n",
      "Train Epoch: 807 [320/1612 (20%)] Loss: 0.390459\n",
      "Train Epoch: 807 [480/1612 (30%)] Loss: 0.341748\n",
      "Train Epoch: 807 [640/1612 (40%)] Loss: 0.351468\n",
      "Train Epoch: 807 [800/1612 (50%)] Loss: 0.228673\n",
      "Train Epoch: 807 [960/1612 (59%)] Loss: 0.289959\n",
      "Train Epoch: 807 [1120/1612 (69%)] Loss: 0.164514\n",
      "Train Epoch: 807 [1280/1612 (79%)] Loss: 0.579484\n",
      "Train Epoch: 807 [1440/1612 (89%)] Loss: 0.257011\n",
      "Train Epoch: 807 [1200/1612 (99%)] Loss: 0.779222\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 808 [0/1612 (0%)] Loss: 0.340894\n",
      "Train Epoch: 808 [160/1612 (10%)] Loss: 0.245169\n",
      "Train Epoch: 808 [320/1612 (20%)] Loss: 0.505847\n",
      "Train Epoch: 808 [480/1612 (30%)] Loss: 0.216550\n",
      "Train Epoch: 808 [640/1612 (40%)] Loss: 0.398862\n",
      "Train Epoch: 808 [800/1612 (50%)] Loss: 0.257845\n",
      "Train Epoch: 808 [960/1612 (59%)] Loss: 0.303595\n",
      "Train Epoch: 808 [1120/1612 (69%)] Loss: 0.343014\n",
      "Train Epoch: 808 [1280/1612 (79%)] Loss: 0.410894\n",
      "Train Epoch: 808 [1440/1612 (89%)] Loss: 0.353353\n",
      "Train Epoch: 808 [1200/1612 (99%)] Loss: 0.417214\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 809 [0/1612 (0%)] Loss: 0.182883\n",
      "Train Epoch: 809 [160/1612 (10%)] Loss: 0.286358\n",
      "Train Epoch: 809 [320/1612 (20%)] Loss: 0.320098\n",
      "Train Epoch: 809 [480/1612 (30%)] Loss: 0.269825\n",
      "Train Epoch: 809 [640/1612 (40%)] Loss: 0.231703\n",
      "Train Epoch: 809 [800/1612 (50%)] Loss: 0.561665\n",
      "Train Epoch: 809 [960/1612 (59%)] Loss: 0.157648\n",
      "Train Epoch: 809 [1120/1612 (69%)] Loss: 0.317715\n",
      "Train Epoch: 809 [1280/1612 (79%)] Loss: 0.630410\n",
      "Train Epoch: 809 [1440/1612 (89%)] Loss: 0.492248\n",
      "Train Epoch: 809 [1200/1612 (99%)] Loss: 0.205169\n",
      "\n",
      "Test set: Average loss: 0.0308, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 810 [0/1612 (0%)] Loss: 0.428134\n",
      "Train Epoch: 810 [160/1612 (10%)] Loss: 0.237146\n",
      "Train Epoch: 810 [320/1612 (20%)] Loss: 0.314676\n",
      "Train Epoch: 810 [480/1612 (30%)] Loss: 0.359532\n",
      "Train Epoch: 810 [640/1612 (40%)] Loss: 0.371039\n",
      "Train Epoch: 810 [800/1612 (50%)] Loss: 0.185604\n",
      "Train Epoch: 810 [960/1612 (59%)] Loss: 0.209499\n",
      "Train Epoch: 810 [1120/1612 (69%)] Loss: 0.266631\n",
      "Train Epoch: 810 [1280/1612 (79%)] Loss: 0.249555\n",
      "Train Epoch: 810 [1440/1612 (89%)] Loss: 0.326880\n",
      "Train Epoch: 810 [1200/1612 (99%)] Loss: 0.036908\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 811 [0/1612 (0%)] Loss: 0.262229\n",
      "Train Epoch: 811 [160/1612 (10%)] Loss: 0.428907\n",
      "Train Epoch: 811 [320/1612 (20%)] Loss: 0.384031\n",
      "Train Epoch: 811 [480/1612 (30%)] Loss: 0.219063\n",
      "Train Epoch: 811 [640/1612 (40%)] Loss: 0.205957\n",
      "Train Epoch: 811 [800/1612 (50%)] Loss: 0.391548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 811 [960/1612 (59%)] Loss: 0.259889\n",
      "Train Epoch: 811 [1120/1612 (69%)] Loss: 0.315405\n",
      "Train Epoch: 811 [1280/1612 (79%)] Loss: 0.273925\n",
      "Train Epoch: 811 [1440/1612 (89%)] Loss: 0.411850\n",
      "Train Epoch: 811 [1200/1612 (99%)] Loss: 0.433169\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 812 [0/1612 (0%)] Loss: 0.082976\n",
      "Train Epoch: 812 [160/1612 (10%)] Loss: 0.349593\n",
      "Train Epoch: 812 [320/1612 (20%)] Loss: 0.380774\n",
      "Train Epoch: 812 [480/1612 (30%)] Loss: 0.416308\n",
      "Train Epoch: 812 [640/1612 (40%)] Loss: 0.220097\n",
      "Train Epoch: 812 [800/1612 (50%)] Loss: 0.194947\n",
      "Train Epoch: 812 [960/1612 (59%)] Loss: 0.229001\n",
      "Train Epoch: 812 [1120/1612 (69%)] Loss: 0.281274\n",
      "Train Epoch: 812 [1280/1612 (79%)] Loss: 0.465080\n",
      "Train Epoch: 812 [1440/1612 (89%)] Loss: 0.242561\n",
      "Train Epoch: 812 [1200/1612 (99%)] Loss: 0.166160\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 813 [0/1612 (0%)] Loss: 0.131703\n",
      "Train Epoch: 813 [160/1612 (10%)] Loss: 0.109138\n",
      "Train Epoch: 813 [320/1612 (20%)] Loss: 0.091838\n",
      "Train Epoch: 813 [480/1612 (30%)] Loss: 0.154080\n",
      "Train Epoch: 813 [640/1612 (40%)] Loss: 0.253215\n",
      "Train Epoch: 813 [800/1612 (50%)] Loss: 0.193779\n",
      "Train Epoch: 813 [960/1612 (59%)] Loss: 0.221521\n",
      "Train Epoch: 813 [1120/1612 (69%)] Loss: 0.479159\n",
      "Train Epoch: 813 [1280/1612 (79%)] Loss: 0.242852\n",
      "Train Epoch: 813 [1440/1612 (89%)] Loss: 0.357854\n",
      "Train Epoch: 813 [1200/1612 (99%)] Loss: 0.326866\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 814 [0/1612 (0%)] Loss: 0.144808\n",
      "Train Epoch: 814 [160/1612 (10%)] Loss: 0.273599\n",
      "Train Epoch: 814 [320/1612 (20%)] Loss: 0.643271\n",
      "Train Epoch: 814 [480/1612 (30%)] Loss: 0.407700\n",
      "Train Epoch: 814 [640/1612 (40%)] Loss: 0.317613\n",
      "Train Epoch: 814 [800/1612 (50%)] Loss: 0.091004\n",
      "Train Epoch: 814 [960/1612 (59%)] Loss: 0.396411\n",
      "Train Epoch: 814 [1120/1612 (69%)] Loss: 0.402866\n",
      "Train Epoch: 814 [1280/1612 (79%)] Loss: 0.522433\n",
      "Train Epoch: 814 [1440/1612 (89%)] Loss: 0.176221\n",
      "Train Epoch: 814 [1200/1612 (99%)] Loss: 0.229180\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 815 [0/1612 (0%)] Loss: 0.560566\n",
      "Train Epoch: 815 [160/1612 (10%)] Loss: 0.230284\n",
      "Train Epoch: 815 [320/1612 (20%)] Loss: 0.228656\n",
      "Train Epoch: 815 [480/1612 (30%)] Loss: 0.120911\n",
      "Train Epoch: 815 [640/1612 (40%)] Loss: 0.113110\n",
      "Train Epoch: 815 [800/1612 (50%)] Loss: 0.409144\n",
      "Train Epoch: 815 [960/1612 (59%)] Loss: 0.260616\n",
      "Train Epoch: 815 [1120/1612 (69%)] Loss: 0.115111\n",
      "Train Epoch: 815 [1280/1612 (79%)] Loss: 0.186797\n",
      "Train Epoch: 815 [1440/1612 (89%)] Loss: 0.561540\n",
      "Train Epoch: 815 [1200/1612 (99%)] Loss: 0.415846\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 816 [0/1612 (0%)] Loss: 0.323899\n",
      "Train Epoch: 816 [160/1612 (10%)] Loss: 0.149875\n",
      "Train Epoch: 816 [320/1612 (20%)] Loss: 0.135821\n",
      "Train Epoch: 816 [480/1612 (30%)] Loss: 0.333661\n",
      "Train Epoch: 816 [640/1612 (40%)] Loss: 0.290169\n",
      "Train Epoch: 816 [800/1612 (50%)] Loss: 0.357762\n",
      "Train Epoch: 816 [960/1612 (59%)] Loss: 0.253256\n",
      "Train Epoch: 816 [1120/1612 (69%)] Loss: 0.321736\n",
      "Train Epoch: 816 [1280/1612 (79%)] Loss: 0.168718\n",
      "Train Epoch: 816 [1440/1612 (89%)] Loss: 0.294704\n",
      "Train Epoch: 816 [1200/1612 (99%)] Loss: 0.319660\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 817 [0/1612 (0%)] Loss: 0.227646\n",
      "Train Epoch: 817 [160/1612 (10%)] Loss: 0.523127\n",
      "Train Epoch: 817 [320/1612 (20%)] Loss: 0.134646\n",
      "Train Epoch: 817 [480/1612 (30%)] Loss: 0.181826\n",
      "Train Epoch: 817 [640/1612 (40%)] Loss: 0.284849\n",
      "Train Epoch: 817 [800/1612 (50%)] Loss: 0.323443\n",
      "Train Epoch: 817 [960/1612 (59%)] Loss: 0.163765\n",
      "Train Epoch: 817 [1120/1612 (69%)] Loss: 0.288718\n",
      "Train Epoch: 817 [1280/1612 (79%)] Loss: 0.582148\n",
      "Train Epoch: 817 [1440/1612 (89%)] Loss: 0.255394\n",
      "Train Epoch: 817 [1200/1612 (99%)] Loss: 0.159740\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 818 [0/1612 (0%)] Loss: 0.075650\n",
      "Train Epoch: 818 [160/1612 (10%)] Loss: 0.250312\n",
      "Train Epoch: 818 [320/1612 (20%)] Loss: 0.154747\n",
      "Train Epoch: 818 [480/1612 (30%)] Loss: 1.045499\n",
      "Train Epoch: 818 [640/1612 (40%)] Loss: 0.327606\n",
      "Train Epoch: 818 [800/1612 (50%)] Loss: 0.312940\n",
      "Train Epoch: 818 [960/1612 (59%)] Loss: 0.177120\n",
      "Train Epoch: 818 [1120/1612 (69%)] Loss: 0.199030\n",
      "Train Epoch: 818 [1280/1612 (79%)] Loss: 0.198810\n",
      "Train Epoch: 818 [1440/1612 (89%)] Loss: 0.271290\n",
      "Train Epoch: 818 [1200/1612 (99%)] Loss: 0.204723\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 819 [0/1612 (0%)] Loss: 0.125260\n",
      "Train Epoch: 819 [160/1612 (10%)] Loss: 0.156858\n",
      "Train Epoch: 819 [320/1612 (20%)] Loss: 0.277069\n",
      "Train Epoch: 819 [480/1612 (30%)] Loss: 0.369685\n",
      "Train Epoch: 819 [640/1612 (40%)] Loss: 0.280701\n",
      "Train Epoch: 819 [800/1612 (50%)] Loss: 0.474147\n",
      "Train Epoch: 819 [960/1612 (59%)] Loss: 0.270081\n",
      "Train Epoch: 819 [1120/1612 (69%)] Loss: 0.291673\n",
      "Train Epoch: 819 [1280/1612 (79%)] Loss: 0.128247\n",
      "Train Epoch: 819 [1440/1612 (89%)] Loss: 0.438718\n",
      "Train Epoch: 819 [1200/1612 (99%)] Loss: 0.390811\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 820 [0/1612 (0%)] Loss: 0.356721\n",
      "Train Epoch: 820 [160/1612 (10%)] Loss: 0.356143\n",
      "Train Epoch: 820 [320/1612 (20%)] Loss: 0.284573\n",
      "Train Epoch: 820 [480/1612 (30%)] Loss: 0.385698\n",
      "Train Epoch: 820 [640/1612 (40%)] Loss: 0.193642\n",
      "Train Epoch: 820 [800/1612 (50%)] Loss: 0.232995\n",
      "Train Epoch: 820 [960/1612 (59%)] Loss: 0.697683\n",
      "Train Epoch: 820 [1120/1612 (69%)] Loss: 0.277730\n",
      "Train Epoch: 820 [1280/1612 (79%)] Loss: 0.129988\n",
      "Train Epoch: 820 [1440/1612 (89%)] Loss: 0.741205\n",
      "Train Epoch: 820 [1200/1612 (99%)] Loss: 0.438472\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 821 [0/1612 (0%)] Loss: 0.385475\n",
      "Train Epoch: 821 [160/1612 (10%)] Loss: 0.195011\n",
      "Train Epoch: 821 [320/1612 (20%)] Loss: 0.427142\n",
      "Train Epoch: 821 [480/1612 (30%)] Loss: 0.136705\n",
      "Train Epoch: 821 [640/1612 (40%)] Loss: 0.221583\n",
      "Train Epoch: 821 [800/1612 (50%)] Loss: 0.390327\n",
      "Train Epoch: 821 [960/1612 (59%)] Loss: 0.189275\n",
      "Train Epoch: 821 [1120/1612 (69%)] Loss: 0.393107\n",
      "Train Epoch: 821 [1280/1612 (79%)] Loss: 0.447152\n",
      "Train Epoch: 821 [1440/1612 (89%)] Loss: 0.304095\n",
      "Train Epoch: 821 [1200/1612 (99%)] Loss: 0.314859\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 822 [0/1612 (0%)] Loss: 0.301764\n",
      "Train Epoch: 822 [160/1612 (10%)] Loss: 0.369980\n",
      "Train Epoch: 822 [320/1612 (20%)] Loss: 0.394476\n",
      "Train Epoch: 822 [480/1612 (30%)] Loss: 0.193678\n",
      "Train Epoch: 822 [640/1612 (40%)] Loss: 0.241904\n",
      "Train Epoch: 822 [800/1612 (50%)] Loss: 0.211668\n",
      "Train Epoch: 822 [960/1612 (59%)] Loss: 0.343943\n",
      "Train Epoch: 822 [1120/1612 (69%)] Loss: 0.158929\n",
      "Train Epoch: 822 [1280/1612 (79%)] Loss: 0.214459\n",
      "Train Epoch: 822 [1440/1612 (89%)] Loss: 0.505428\n",
      "Train Epoch: 822 [1200/1612 (99%)] Loss: 0.212985\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 823 [0/1612 (0%)] Loss: 0.253265\n",
      "Train Epoch: 823 [160/1612 (10%)] Loss: 0.196465\n",
      "Train Epoch: 823 [320/1612 (20%)] Loss: 0.170539\n",
      "Train Epoch: 823 [480/1612 (30%)] Loss: 0.339133\n",
      "Train Epoch: 823 [640/1612 (40%)] Loss: 0.224228\n",
      "Train Epoch: 823 [800/1612 (50%)] Loss: 0.078133\n",
      "Train Epoch: 823 [960/1612 (59%)] Loss: 0.413888\n",
      "Train Epoch: 823 [1120/1612 (69%)] Loss: 0.384682\n",
      "Train Epoch: 823 [1280/1612 (79%)] Loss: 0.487918\n",
      "Train Epoch: 823 [1440/1612 (89%)] Loss: 0.158426\n",
      "Train Epoch: 823 [1200/1612 (99%)] Loss: 0.273644\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 824 [0/1612 (0%)] Loss: 0.297055\n",
      "Train Epoch: 824 [160/1612 (10%)] Loss: 0.374467\n",
      "Train Epoch: 824 [320/1612 (20%)] Loss: 0.636479\n",
      "Train Epoch: 824 [480/1612 (30%)] Loss: 0.382979\n",
      "Train Epoch: 824 [640/1612 (40%)] Loss: 0.246437\n",
      "Train Epoch: 824 [800/1612 (50%)] Loss: 0.237975\n",
      "Train Epoch: 824 [960/1612 (59%)] Loss: 0.261266\n",
      "Train Epoch: 824 [1120/1612 (69%)] Loss: 0.159008\n",
      "Train Epoch: 824 [1280/1612 (79%)] Loss: 0.409205\n",
      "Train Epoch: 824 [1440/1612 (89%)] Loss: 0.316123\n",
      "Train Epoch: 824 [1200/1612 (99%)] Loss: 0.267811\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 825 [0/1612 (0%)] Loss: 0.317340\n",
      "Train Epoch: 825 [160/1612 (10%)] Loss: 0.298476\n",
      "Train Epoch: 825 [320/1612 (20%)] Loss: 0.139461\n",
      "Train Epoch: 825 [480/1612 (30%)] Loss: 0.228223\n",
      "Train Epoch: 825 [640/1612 (40%)] Loss: 0.220611\n",
      "Train Epoch: 825 [800/1612 (50%)] Loss: 0.278940\n",
      "Train Epoch: 825 [960/1612 (59%)] Loss: 0.146465\n",
      "Train Epoch: 825 [1120/1612 (69%)] Loss: 0.222722\n",
      "Train Epoch: 825 [1280/1612 (79%)] Loss: 0.178540\n",
      "Train Epoch: 825 [1440/1612 (89%)] Loss: 0.137378\n",
      "Train Epoch: 825 [1200/1612 (99%)] Loss: 0.174148\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 826 [0/1612 (0%)] Loss: 0.238801\n",
      "Train Epoch: 826 [160/1612 (10%)] Loss: 0.335056\n",
      "Train Epoch: 826 [320/1612 (20%)] Loss: 0.328034\n",
      "Train Epoch: 826 [480/1612 (30%)] Loss: 0.256013\n",
      "Train Epoch: 826 [640/1612 (40%)] Loss: 0.318333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 826 [800/1612 (50%)] Loss: 0.119765\n",
      "Train Epoch: 826 [960/1612 (59%)] Loss: 0.579475\n",
      "Train Epoch: 826 [1120/1612 (69%)] Loss: 0.509296\n",
      "Train Epoch: 826 [1280/1612 (79%)] Loss: 0.383424\n",
      "Train Epoch: 826 [1440/1612 (89%)] Loss: 0.454728\n",
      "Train Epoch: 826 [1200/1612 (99%)] Loss: 0.518642\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 827 [0/1612 (0%)] Loss: 0.413781\n",
      "Train Epoch: 827 [160/1612 (10%)] Loss: 0.291780\n",
      "Train Epoch: 827 [320/1612 (20%)] Loss: 0.263118\n",
      "Train Epoch: 827 [480/1612 (30%)] Loss: 0.251851\n",
      "Train Epoch: 827 [640/1612 (40%)] Loss: 0.369704\n",
      "Train Epoch: 827 [800/1612 (50%)] Loss: 0.352320\n",
      "Train Epoch: 827 [960/1612 (59%)] Loss: 0.271002\n",
      "Train Epoch: 827 [1120/1612 (69%)] Loss: 0.161458\n",
      "Train Epoch: 827 [1280/1612 (79%)] Loss: 0.364572\n",
      "Train Epoch: 827 [1440/1612 (89%)] Loss: 0.361014\n",
      "Train Epoch: 827 [1200/1612 (99%)] Loss: 0.392007\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 828 [0/1612 (0%)] Loss: 0.395151\n",
      "Train Epoch: 828 [160/1612 (10%)] Loss: 0.468870\n",
      "Train Epoch: 828 [320/1612 (20%)] Loss: 0.407827\n",
      "Train Epoch: 828 [480/1612 (30%)] Loss: 0.270695\n",
      "Train Epoch: 828 [640/1612 (40%)] Loss: 0.251642\n",
      "Train Epoch: 828 [800/1612 (50%)] Loss: 0.168432\n",
      "Train Epoch: 828 [960/1612 (59%)] Loss: 0.467063\n",
      "Train Epoch: 828 [1120/1612 (69%)] Loss: 0.244436\n",
      "Train Epoch: 828 [1280/1612 (79%)] Loss: 0.267054\n",
      "Train Epoch: 828 [1440/1612 (89%)] Loss: 0.232541\n",
      "Train Epoch: 828 [1200/1612 (99%)] Loss: 0.231463\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 829 [0/1612 (0%)] Loss: 0.379917\n",
      "Train Epoch: 829 [160/1612 (10%)] Loss: 0.250322\n",
      "Train Epoch: 829 [320/1612 (20%)] Loss: 0.265660\n",
      "Train Epoch: 829 [480/1612 (30%)] Loss: 0.452418\n",
      "Train Epoch: 829 [640/1612 (40%)] Loss: 0.423715\n",
      "Train Epoch: 829 [800/1612 (50%)] Loss: 0.299575\n",
      "Train Epoch: 829 [960/1612 (59%)] Loss: 0.384583\n",
      "Train Epoch: 829 [1120/1612 (69%)] Loss: 0.227069\n",
      "Train Epoch: 829 [1280/1612 (79%)] Loss: 0.380749\n",
      "Train Epoch: 829 [1440/1612 (89%)] Loss: 0.357211\n",
      "Train Epoch: 829 [1200/1612 (99%)] Loss: 0.337476\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 830 [0/1612 (0%)] Loss: 0.330523\n",
      "Train Epoch: 830 [160/1612 (10%)] Loss: 0.150688\n",
      "Train Epoch: 830 [320/1612 (20%)] Loss: 0.166535\n",
      "Train Epoch: 830 [480/1612 (30%)] Loss: 0.283923\n",
      "Train Epoch: 830 [640/1612 (40%)] Loss: 0.372214\n",
      "Train Epoch: 830 [800/1612 (50%)] Loss: 0.370095\n",
      "Train Epoch: 830 [960/1612 (59%)] Loss: 0.312498\n",
      "Train Epoch: 830 [1120/1612 (69%)] Loss: 0.283059\n",
      "Train Epoch: 830 [1280/1612 (79%)] Loss: 0.424720\n",
      "Train Epoch: 830 [1440/1612 (89%)] Loss: 0.150349\n",
      "Train Epoch: 830 [1200/1612 (99%)] Loss: 0.372571\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 831 [0/1612 (0%)] Loss: 0.355089\n",
      "Train Epoch: 831 [160/1612 (10%)] Loss: 0.325239\n",
      "Train Epoch: 831 [320/1612 (20%)] Loss: 0.299819\n",
      "Train Epoch: 831 [480/1612 (30%)] Loss: 0.143086\n",
      "Train Epoch: 831 [640/1612 (40%)] Loss: 0.083407\n",
      "Train Epoch: 831 [800/1612 (50%)] Loss: 0.420116\n",
      "Train Epoch: 831 [960/1612 (59%)] Loss: 0.263278\n",
      "Train Epoch: 831 [1120/1612 (69%)] Loss: 0.167587\n",
      "Train Epoch: 831 [1280/1612 (79%)] Loss: 0.711495\n",
      "Train Epoch: 831 [1440/1612 (89%)] Loss: 0.323906\n",
      "Train Epoch: 831 [1200/1612 (99%)] Loss: 0.555785\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 832 [0/1612 (0%)] Loss: 0.373729\n",
      "Train Epoch: 832 [160/1612 (10%)] Loss: 0.328298\n",
      "Train Epoch: 832 [320/1612 (20%)] Loss: 0.408506\n",
      "Train Epoch: 832 [480/1612 (30%)] Loss: 0.206384\n",
      "Train Epoch: 832 [640/1612 (40%)] Loss: 0.264095\n",
      "Train Epoch: 832 [800/1612 (50%)] Loss: 0.385914\n",
      "Train Epoch: 832 [960/1612 (59%)] Loss: 0.393742\n",
      "Train Epoch: 832 [1120/1612 (69%)] Loss: 0.509146\n",
      "Train Epoch: 832 [1280/1612 (79%)] Loss: 0.217862\n",
      "Train Epoch: 832 [1440/1612 (89%)] Loss: 0.388015\n",
      "Train Epoch: 832 [1200/1612 (99%)] Loss: 0.256729\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 833 [0/1612 (0%)] Loss: 0.144560\n",
      "Train Epoch: 833 [160/1612 (10%)] Loss: 0.409118\n",
      "Train Epoch: 833 [320/1612 (20%)] Loss: 0.191809\n",
      "Train Epoch: 833 [480/1612 (30%)] Loss: 0.179490\n",
      "Train Epoch: 833 [640/1612 (40%)] Loss: 0.281663\n",
      "Train Epoch: 833 [800/1612 (50%)] Loss: 0.544022\n",
      "Train Epoch: 833 [960/1612 (59%)] Loss: 0.290377\n",
      "Train Epoch: 833 [1120/1612 (69%)] Loss: 0.243232\n",
      "Train Epoch: 833 [1280/1612 (79%)] Loss: 0.203019\n",
      "Train Epoch: 833 [1440/1612 (89%)] Loss: 0.456426\n",
      "Train Epoch: 833 [1200/1612 (99%)] Loss: 0.209759\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 834 [0/1612 (0%)] Loss: 0.348545\n",
      "Train Epoch: 834 [160/1612 (10%)] Loss: 0.277946\n",
      "Train Epoch: 834 [320/1612 (20%)] Loss: 0.281938\n",
      "Train Epoch: 834 [480/1612 (30%)] Loss: 0.158736\n",
      "Train Epoch: 834 [640/1612 (40%)] Loss: 0.256674\n",
      "Train Epoch: 834 [800/1612 (50%)] Loss: 0.306347\n",
      "Train Epoch: 834 [960/1612 (59%)] Loss: 0.282607\n",
      "Train Epoch: 834 [1120/1612 (69%)] Loss: 0.218038\n",
      "Train Epoch: 834 [1280/1612 (79%)] Loss: 0.440793\n",
      "Train Epoch: 834 [1440/1612 (89%)] Loss: 0.541596\n",
      "Train Epoch: 834 [1200/1612 (99%)] Loss: 0.278334\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 835 [0/1612 (0%)] Loss: 0.271888\n",
      "Train Epoch: 835 [160/1612 (10%)] Loss: 0.298666\n",
      "Train Epoch: 835 [320/1612 (20%)] Loss: 0.389265\n",
      "Train Epoch: 835 [480/1612 (30%)] Loss: 0.165694\n",
      "Train Epoch: 835 [640/1612 (40%)] Loss: 0.223920\n",
      "Train Epoch: 835 [800/1612 (50%)] Loss: 0.183816\n",
      "Train Epoch: 835 [960/1612 (59%)] Loss: 0.254927\n",
      "Train Epoch: 835 [1120/1612 (69%)] Loss: 0.292149\n",
      "Train Epoch: 835 [1280/1612 (79%)] Loss: 0.255624\n",
      "Train Epoch: 835 [1440/1612 (89%)] Loss: 0.240729\n",
      "Train Epoch: 835 [1200/1612 (99%)] Loss: 0.322891\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 836 [0/1612 (0%)] Loss: 0.361945\n",
      "Train Epoch: 836 [160/1612 (10%)] Loss: 0.504614\n",
      "Train Epoch: 836 [320/1612 (20%)] Loss: 0.324539\n",
      "Train Epoch: 836 [480/1612 (30%)] Loss: 0.212932\n",
      "Train Epoch: 836 [640/1612 (40%)] Loss: 0.531704\n",
      "Train Epoch: 836 [800/1612 (50%)] Loss: 0.130227\n",
      "Train Epoch: 836 [960/1612 (59%)] Loss: 0.290419\n",
      "Train Epoch: 836 [1120/1612 (69%)] Loss: 0.225904\n",
      "Train Epoch: 836 [1280/1612 (79%)] Loss: 0.260952\n",
      "Train Epoch: 836 [1440/1612 (89%)] Loss: 0.243865\n",
      "Train Epoch: 836 [1200/1612 (99%)] Loss: 0.746980\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 837 [0/1612 (0%)] Loss: 0.382004\n",
      "Train Epoch: 837 [160/1612 (10%)] Loss: 0.326481\n",
      "Train Epoch: 837 [320/1612 (20%)] Loss: 0.315502\n",
      "Train Epoch: 837 [480/1612 (30%)] Loss: 0.224301\n",
      "Train Epoch: 837 [640/1612 (40%)] Loss: 0.466898\n",
      "Train Epoch: 837 [800/1612 (50%)] Loss: 0.267108\n",
      "Train Epoch: 837 [960/1612 (59%)] Loss: 0.340328\n",
      "Train Epoch: 837 [1120/1612 (69%)] Loss: 0.315132\n",
      "Train Epoch: 837 [1280/1612 (79%)] Loss: 0.418621\n",
      "Train Epoch: 837 [1440/1612 (89%)] Loss: 0.405574\n",
      "Train Epoch: 837 [1200/1612 (99%)] Loss: 0.385661\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 838 [0/1612 (0%)] Loss: 0.484742\n",
      "Train Epoch: 838 [160/1612 (10%)] Loss: 0.356090\n",
      "Train Epoch: 838 [320/1612 (20%)] Loss: 0.292011\n",
      "Train Epoch: 838 [480/1612 (30%)] Loss: 0.240089\n",
      "Train Epoch: 838 [640/1612 (40%)] Loss: 0.268206\n",
      "Train Epoch: 838 [800/1612 (50%)] Loss: 0.325082\n",
      "Train Epoch: 838 [960/1612 (59%)] Loss: 0.589285\n",
      "Train Epoch: 838 [1120/1612 (69%)] Loss: 0.378503\n",
      "Train Epoch: 838 [1280/1612 (79%)] Loss: 0.242522\n",
      "Train Epoch: 838 [1440/1612 (89%)] Loss: 0.169118\n",
      "Train Epoch: 838 [1200/1612 (99%)] Loss: 0.359331\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 839 [0/1612 (0%)] Loss: 0.377945\n",
      "Train Epoch: 839 [160/1612 (10%)] Loss: 0.153713\n",
      "Train Epoch: 839 [320/1612 (20%)] Loss: 0.235503\n",
      "Train Epoch: 839 [480/1612 (30%)] Loss: 0.461259\n",
      "Train Epoch: 839 [640/1612 (40%)] Loss: 0.413561\n",
      "Train Epoch: 839 [800/1612 (50%)] Loss: 0.526733\n",
      "Train Epoch: 839 [960/1612 (59%)] Loss: 0.499883\n",
      "Train Epoch: 839 [1120/1612 (69%)] Loss: 0.300362\n",
      "Train Epoch: 839 [1280/1612 (79%)] Loss: 0.198349\n",
      "Train Epoch: 839 [1440/1612 (89%)] Loss: 0.298331\n",
      "Train Epoch: 839 [1200/1612 (99%)] Loss: 0.133325\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 840 [0/1612 (0%)] Loss: 0.602411\n",
      "Train Epoch: 840 [160/1612 (10%)] Loss: 0.231659\n",
      "Train Epoch: 840 [320/1612 (20%)] Loss: 0.258674\n",
      "Train Epoch: 840 [480/1612 (30%)] Loss: 0.194201\n",
      "Train Epoch: 840 [640/1612 (40%)] Loss: 0.279336\n",
      "Train Epoch: 840 [800/1612 (50%)] Loss: 0.196697\n",
      "Train Epoch: 840 [960/1612 (59%)] Loss: 0.351634\n",
      "Train Epoch: 840 [1120/1612 (69%)] Loss: 0.322125\n",
      "Train Epoch: 840 [1280/1612 (79%)] Loss: 0.315715\n",
      "Train Epoch: 840 [1440/1612 (89%)] Loss: 0.259554\n",
      "Train Epoch: 840 [1200/1612 (99%)] Loss: 0.166579\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 841 [0/1612 (0%)] Loss: 0.309865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 841 [160/1612 (10%)] Loss: 0.393087\n",
      "Train Epoch: 841 [320/1612 (20%)] Loss: 0.228929\n",
      "Train Epoch: 841 [480/1612 (30%)] Loss: 0.145285\n",
      "Train Epoch: 841 [640/1612 (40%)] Loss: 0.337732\n",
      "Train Epoch: 841 [800/1612 (50%)] Loss: 0.381760\n",
      "Train Epoch: 841 [960/1612 (59%)] Loss: 0.440863\n",
      "Train Epoch: 841 [1120/1612 (69%)] Loss: 0.279857\n",
      "Train Epoch: 841 [1280/1612 (79%)] Loss: 0.372038\n",
      "Train Epoch: 841 [1440/1612 (89%)] Loss: 0.175783\n",
      "Train Epoch: 841 [1200/1612 (99%)] Loss: 0.053928\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 842 [0/1612 (0%)] Loss: 0.388970\n",
      "Train Epoch: 842 [160/1612 (10%)] Loss: 0.330335\n",
      "Train Epoch: 842 [320/1612 (20%)] Loss: 0.443830\n",
      "Train Epoch: 842 [480/1612 (30%)] Loss: 0.159794\n",
      "Train Epoch: 842 [640/1612 (40%)] Loss: 0.219285\n",
      "Train Epoch: 842 [800/1612 (50%)] Loss: 0.283339\n",
      "Train Epoch: 842 [960/1612 (59%)] Loss: 0.370659\n",
      "Train Epoch: 842 [1120/1612 (69%)] Loss: 0.261153\n",
      "Train Epoch: 842 [1280/1612 (79%)] Loss: 0.144906\n",
      "Train Epoch: 842 [1440/1612 (89%)] Loss: 0.418195\n",
      "Train Epoch: 842 [1200/1612 (99%)] Loss: 0.331888\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 843 [0/1612 (0%)] Loss: 0.460808\n",
      "Train Epoch: 843 [160/1612 (10%)] Loss: 0.412431\n",
      "Train Epoch: 843 [320/1612 (20%)] Loss: 0.321374\n",
      "Train Epoch: 843 [480/1612 (30%)] Loss: 0.320350\n",
      "Train Epoch: 843 [640/1612 (40%)] Loss: 0.324677\n",
      "Train Epoch: 843 [800/1612 (50%)] Loss: 0.336620\n",
      "Train Epoch: 843 [960/1612 (59%)] Loss: 0.228179\n",
      "Train Epoch: 843 [1120/1612 (69%)] Loss: 0.446507\n",
      "Train Epoch: 843 [1280/1612 (79%)] Loss: 0.321620\n",
      "Train Epoch: 843 [1440/1612 (89%)] Loss: 0.318356\n",
      "Train Epoch: 843 [1200/1612 (99%)] Loss: 0.321341\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 844 [0/1612 (0%)] Loss: 0.283449\n",
      "Train Epoch: 844 [160/1612 (10%)] Loss: 0.133876\n",
      "Train Epoch: 844 [320/1612 (20%)] Loss: 0.411223\n",
      "Train Epoch: 844 [480/1612 (30%)] Loss: 0.392625\n",
      "Train Epoch: 844 [640/1612 (40%)] Loss: 0.487688\n",
      "Train Epoch: 844 [800/1612 (50%)] Loss: 0.137361\n",
      "Train Epoch: 844 [960/1612 (59%)] Loss: 0.527315\n",
      "Train Epoch: 844 [1120/1612 (69%)] Loss: 0.258944\n",
      "Train Epoch: 844 [1280/1612 (79%)] Loss: 0.192038\n",
      "Train Epoch: 844 [1440/1612 (89%)] Loss: 0.425841\n",
      "Train Epoch: 844 [1200/1612 (99%)] Loss: 0.298401\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 845 [0/1612 (0%)] Loss: 0.310242\n",
      "Train Epoch: 845 [160/1612 (10%)] Loss: 0.389516\n",
      "Train Epoch: 845 [320/1612 (20%)] Loss: 0.257631\n",
      "Train Epoch: 845 [480/1612 (30%)] Loss: 0.215396\n",
      "Train Epoch: 845 [640/1612 (40%)] Loss: 0.342734\n",
      "Train Epoch: 845 [800/1612 (50%)] Loss: 0.142921\n",
      "Train Epoch: 845 [960/1612 (59%)] Loss: 0.233752\n",
      "Train Epoch: 845 [1120/1612 (69%)] Loss: 0.289923\n",
      "Train Epoch: 845 [1280/1612 (79%)] Loss: 0.272369\n",
      "Train Epoch: 845 [1440/1612 (89%)] Loss: 0.457603\n",
      "Train Epoch: 845 [1200/1612 (99%)] Loss: 0.463121\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 846 [0/1612 (0%)] Loss: 0.236319\n",
      "Train Epoch: 846 [160/1612 (10%)] Loss: 0.162559\n",
      "Train Epoch: 846 [320/1612 (20%)] Loss: 0.229507\n",
      "Train Epoch: 846 [480/1612 (30%)] Loss: 0.123463\n",
      "Train Epoch: 846 [640/1612 (40%)] Loss: 0.254223\n",
      "Train Epoch: 846 [800/1612 (50%)] Loss: 0.219594\n",
      "Train Epoch: 846 [960/1612 (59%)] Loss: 0.232857\n",
      "Train Epoch: 846 [1120/1612 (69%)] Loss: 0.188699\n",
      "Train Epoch: 846 [1280/1612 (79%)] Loss: 0.320341\n",
      "Train Epoch: 846 [1440/1612 (89%)] Loss: 0.598480\n",
      "Train Epoch: 846 [1200/1612 (99%)] Loss: 0.345058\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 847 [0/1612 (0%)] Loss: 0.371768\n",
      "Train Epoch: 847 [160/1612 (10%)] Loss: 0.241841\n",
      "Train Epoch: 847 [320/1612 (20%)] Loss: 0.392137\n",
      "Train Epoch: 847 [480/1612 (30%)] Loss: 0.163251\n",
      "Train Epoch: 847 [640/1612 (40%)] Loss: 0.261321\n",
      "Train Epoch: 847 [800/1612 (50%)] Loss: 0.176224\n",
      "Train Epoch: 847 [960/1612 (59%)] Loss: 0.326374\n",
      "Train Epoch: 847 [1120/1612 (69%)] Loss: 0.166231\n",
      "Train Epoch: 847 [1280/1612 (79%)] Loss: 0.629132\n",
      "Train Epoch: 847 [1440/1612 (89%)] Loss: 0.157663\n",
      "Train Epoch: 847 [1200/1612 (99%)] Loss: 0.295679\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 848 [0/1612 (0%)] Loss: 0.429693\n",
      "Train Epoch: 848 [160/1612 (10%)] Loss: 0.184433\n",
      "Train Epoch: 848 [320/1612 (20%)] Loss: 0.254680\n",
      "Train Epoch: 848 [480/1612 (30%)] Loss: 0.281214\n",
      "Train Epoch: 848 [640/1612 (40%)] Loss: 0.357602\n",
      "Train Epoch: 848 [800/1612 (50%)] Loss: 0.579785\n",
      "Train Epoch: 848 [960/1612 (59%)] Loss: 0.504739\n",
      "Train Epoch: 848 [1120/1612 (69%)] Loss: 0.162015\n",
      "Train Epoch: 848 [1280/1612 (79%)] Loss: 0.179604\n",
      "Train Epoch: 848 [1440/1612 (89%)] Loss: 0.411404\n",
      "Train Epoch: 848 [1200/1612 (99%)] Loss: 0.416459\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 849 [0/1612 (0%)] Loss: 0.255739\n",
      "Train Epoch: 849 [160/1612 (10%)] Loss: 0.342682\n",
      "Train Epoch: 849 [320/1612 (20%)] Loss: 0.237888\n",
      "Train Epoch: 849 [480/1612 (30%)] Loss: 0.239657\n",
      "Train Epoch: 849 [640/1612 (40%)] Loss: 0.250053\n",
      "Train Epoch: 849 [800/1612 (50%)] Loss: 0.127988\n",
      "Train Epoch: 849 [960/1612 (59%)] Loss: 0.382960\n",
      "Train Epoch: 849 [1120/1612 (69%)] Loss: 0.245853\n",
      "Train Epoch: 849 [1280/1612 (79%)] Loss: 0.327668\n",
      "Train Epoch: 849 [1440/1612 (89%)] Loss: 0.359979\n",
      "Train Epoch: 849 [1200/1612 (99%)] Loss: 0.316125\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 850 [0/1612 (0%)] Loss: 0.148507\n",
      "Train Epoch: 850 [160/1612 (10%)] Loss: 0.402778\n",
      "Train Epoch: 850 [320/1612 (20%)] Loss: 0.269812\n",
      "Train Epoch: 850 [480/1612 (30%)] Loss: 0.175195\n",
      "Train Epoch: 850 [640/1612 (40%)] Loss: 0.110496\n",
      "Train Epoch: 850 [800/1612 (50%)] Loss: 0.123557\n",
      "Train Epoch: 850 [960/1612 (59%)] Loss: 0.500820\n",
      "Train Epoch: 850 [1120/1612 (69%)] Loss: 0.389973\n",
      "Train Epoch: 850 [1280/1612 (79%)] Loss: 0.320795\n",
      "Train Epoch: 850 [1440/1612 (89%)] Loss: 0.329926\n",
      "Train Epoch: 850 [1200/1612 (99%)] Loss: 0.394138\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 851 [0/1612 (0%)] Loss: 0.161213\n",
      "Train Epoch: 851 [160/1612 (10%)] Loss: 0.184175\n",
      "Train Epoch: 851 [320/1612 (20%)] Loss: 0.413535\n",
      "Train Epoch: 851 [480/1612 (30%)] Loss: 0.284872\n",
      "Train Epoch: 851 [640/1612 (40%)] Loss: 0.361471\n",
      "Train Epoch: 851 [800/1612 (50%)] Loss: 0.279647\n",
      "Train Epoch: 851 [960/1612 (59%)] Loss: 0.246898\n",
      "Train Epoch: 851 [1120/1612 (69%)] Loss: 0.335262\n",
      "Train Epoch: 851 [1280/1612 (79%)] Loss: 0.186886\n",
      "Train Epoch: 851 [1440/1612 (89%)] Loss: 0.278707\n",
      "Train Epoch: 851 [1200/1612 (99%)] Loss: 0.287938\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 852 [0/1612 (0%)] Loss: 0.228654\n",
      "Train Epoch: 852 [160/1612 (10%)] Loss: 0.205276\n",
      "Train Epoch: 852 [320/1612 (20%)] Loss: 0.480872\n",
      "Train Epoch: 852 [480/1612 (30%)] Loss: 0.434985\n",
      "Train Epoch: 852 [640/1612 (40%)] Loss: 0.216002\n",
      "Train Epoch: 852 [800/1612 (50%)] Loss: 0.240687\n",
      "Train Epoch: 852 [960/1612 (59%)] Loss: 0.415728\n",
      "Train Epoch: 852 [1120/1612 (69%)] Loss: 0.291760\n",
      "Train Epoch: 852 [1280/1612 (79%)] Loss: 0.130731\n",
      "Train Epoch: 852 [1440/1612 (89%)] Loss: 0.237121\n",
      "Train Epoch: 852 [1200/1612 (99%)] Loss: 0.293245\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 853 [0/1612 (0%)] Loss: 0.345250\n",
      "Train Epoch: 853 [160/1612 (10%)] Loss: 0.444435\n",
      "Train Epoch: 853 [320/1612 (20%)] Loss: 0.127886\n",
      "Train Epoch: 853 [480/1612 (30%)] Loss: 0.321380\n",
      "Train Epoch: 853 [640/1612 (40%)] Loss: 0.428073\n",
      "Train Epoch: 853 [800/1612 (50%)] Loss: 0.277650\n",
      "Train Epoch: 853 [960/1612 (59%)] Loss: 0.199707\n",
      "Train Epoch: 853 [1120/1612 (69%)] Loss: 0.397707\n",
      "Train Epoch: 853 [1280/1612 (79%)] Loss: 0.297030\n",
      "Train Epoch: 853 [1440/1612 (89%)] Loss: 0.228813\n",
      "Train Epoch: 853 [1200/1612 (99%)] Loss: 0.367563\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 854 [0/1612 (0%)] Loss: 0.329456\n",
      "Train Epoch: 854 [160/1612 (10%)] Loss: 0.445483\n",
      "Train Epoch: 854 [320/1612 (20%)] Loss: 0.601370\n",
      "Train Epoch: 854 [480/1612 (30%)] Loss: 0.291587\n",
      "Train Epoch: 854 [640/1612 (40%)] Loss: 0.392057\n",
      "Train Epoch: 854 [800/1612 (50%)] Loss: 0.189317\n",
      "Train Epoch: 854 [960/1612 (59%)] Loss: 0.145647\n",
      "Train Epoch: 854 [1120/1612 (69%)] Loss: 0.269539\n",
      "Train Epoch: 854 [1280/1612 (79%)] Loss: 0.229509\n",
      "Train Epoch: 854 [1440/1612 (89%)] Loss: 0.380343\n",
      "Train Epoch: 854 [1200/1612 (99%)] Loss: 0.195528\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 855 [0/1612 (0%)] Loss: 0.291225\n",
      "Train Epoch: 855 [160/1612 (10%)] Loss: 0.194855\n",
      "Train Epoch: 855 [320/1612 (20%)] Loss: 0.291541\n",
      "Train Epoch: 855 [480/1612 (30%)] Loss: 0.269894\n",
      "Train Epoch: 855 [640/1612 (40%)] Loss: 0.335164\n",
      "Train Epoch: 855 [800/1612 (50%)] Loss: 0.413931\n",
      "Train Epoch: 855 [960/1612 (59%)] Loss: 0.436031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 855 [1120/1612 (69%)] Loss: 0.258421\n",
      "Train Epoch: 855 [1280/1612 (79%)] Loss: 0.410655\n",
      "Train Epoch: 855 [1440/1612 (89%)] Loss: 0.232294\n",
      "Train Epoch: 855 [1200/1612 (99%)] Loss: 0.202775\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 856 [0/1612 (0%)] Loss: 0.120355\n",
      "Train Epoch: 856 [160/1612 (10%)] Loss: 0.121632\n",
      "Train Epoch: 856 [320/1612 (20%)] Loss: 0.194443\n",
      "Train Epoch: 856 [480/1612 (30%)] Loss: 0.213943\n",
      "Train Epoch: 856 [640/1612 (40%)] Loss: 0.285008\n",
      "Train Epoch: 856 [800/1612 (50%)] Loss: 0.332675\n",
      "Train Epoch: 856 [960/1612 (59%)] Loss: 0.185149\n",
      "Train Epoch: 856 [1120/1612 (69%)] Loss: 0.445324\n",
      "Train Epoch: 856 [1280/1612 (79%)] Loss: 0.199267\n",
      "Train Epoch: 856 [1440/1612 (89%)] Loss: 0.328395\n",
      "Train Epoch: 856 [1200/1612 (99%)] Loss: 0.158588\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 857 [0/1612 (0%)] Loss: 0.200712\n",
      "Train Epoch: 857 [160/1612 (10%)] Loss: 0.167699\n",
      "Train Epoch: 857 [320/1612 (20%)] Loss: 0.350373\n",
      "Train Epoch: 857 [480/1612 (30%)] Loss: 0.334290\n",
      "Train Epoch: 857 [640/1612 (40%)] Loss: 0.253492\n",
      "Train Epoch: 857 [800/1612 (50%)] Loss: 0.184050\n",
      "Train Epoch: 857 [960/1612 (59%)] Loss: 0.271444\n",
      "Train Epoch: 857 [1120/1612 (69%)] Loss: 0.442146\n",
      "Train Epoch: 857 [1280/1612 (79%)] Loss: 0.416840\n",
      "Train Epoch: 857 [1440/1612 (89%)] Loss: 0.099109\n",
      "Train Epoch: 857 [1200/1612 (99%)] Loss: 0.483610\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 858 [0/1612 (0%)] Loss: 0.180193\n",
      "Train Epoch: 858 [160/1612 (10%)] Loss: 0.447878\n",
      "Train Epoch: 858 [320/1612 (20%)] Loss: 0.239689\n",
      "Train Epoch: 858 [480/1612 (30%)] Loss: 0.379632\n",
      "Train Epoch: 858 [640/1612 (40%)] Loss: 0.321629\n",
      "Train Epoch: 858 [800/1612 (50%)] Loss: 0.251728\n",
      "Train Epoch: 858 [960/1612 (59%)] Loss: 0.188837\n",
      "Train Epoch: 858 [1120/1612 (69%)] Loss: 0.147491\n",
      "Train Epoch: 858 [1280/1612 (79%)] Loss: 0.150268\n",
      "Train Epoch: 858 [1440/1612 (89%)] Loss: 0.154018\n",
      "Train Epoch: 858 [1200/1612 (99%)] Loss: 0.360874\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 859 [0/1612 (0%)] Loss: 0.398843\n",
      "Train Epoch: 859 [160/1612 (10%)] Loss: 0.161801\n",
      "Train Epoch: 859 [320/1612 (20%)] Loss: 0.249264\n",
      "Train Epoch: 859 [480/1612 (30%)] Loss: 0.270818\n",
      "Train Epoch: 859 [640/1612 (40%)] Loss: 0.501947\n",
      "Train Epoch: 859 [800/1612 (50%)] Loss: 0.165056\n",
      "Train Epoch: 859 [960/1612 (59%)] Loss: 0.316286\n",
      "Train Epoch: 859 [1120/1612 (69%)] Loss: 0.206615\n",
      "Train Epoch: 859 [1280/1612 (79%)] Loss: 0.268020\n",
      "Train Epoch: 859 [1440/1612 (89%)] Loss: 0.505520\n",
      "Train Epoch: 859 [1200/1612 (99%)] Loss: 0.245451\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 860 [0/1612 (0%)] Loss: 0.254041\n",
      "Train Epoch: 860 [160/1612 (10%)] Loss: 0.350054\n",
      "Train Epoch: 860 [320/1612 (20%)] Loss: 0.461042\n",
      "Train Epoch: 860 [480/1612 (30%)] Loss: 0.264386\n",
      "Train Epoch: 860 [640/1612 (40%)] Loss: 0.395337\n",
      "Train Epoch: 860 [800/1612 (50%)] Loss: 0.399005\n",
      "Train Epoch: 860 [960/1612 (59%)] Loss: 0.387721\n",
      "Train Epoch: 860 [1120/1612 (69%)] Loss: 0.286735\n",
      "Train Epoch: 860 [1280/1612 (79%)] Loss: 0.217103\n",
      "Train Epoch: 860 [1440/1612 (89%)] Loss: 0.352735\n",
      "Train Epoch: 860 [1200/1612 (99%)] Loss: 0.099831\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 861 [0/1612 (0%)] Loss: 0.397890\n",
      "Train Epoch: 861 [160/1612 (10%)] Loss: 0.255470\n",
      "Train Epoch: 861 [320/1612 (20%)] Loss: 0.207949\n",
      "Train Epoch: 861 [480/1612 (30%)] Loss: 0.484169\n",
      "Train Epoch: 861 [640/1612 (40%)] Loss: 0.099486\n",
      "Train Epoch: 861 [800/1612 (50%)] Loss: 0.282360\n",
      "Train Epoch: 861 [960/1612 (59%)] Loss: 0.459578\n",
      "Train Epoch: 861 [1120/1612 (69%)] Loss: 0.234447\n",
      "Train Epoch: 861 [1280/1612 (79%)] Loss: 0.329518\n",
      "Train Epoch: 861 [1440/1612 (89%)] Loss: 0.400334\n",
      "Train Epoch: 861 [1200/1612 (99%)] Loss: 0.328208\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 862 [0/1612 (0%)] Loss: 0.401889\n",
      "Train Epoch: 862 [160/1612 (10%)] Loss: 0.627553\n",
      "Train Epoch: 862 [320/1612 (20%)] Loss: 0.263607\n",
      "Train Epoch: 862 [480/1612 (30%)] Loss: 0.271037\n",
      "Train Epoch: 862 [640/1612 (40%)] Loss: 0.323356\n",
      "Train Epoch: 862 [800/1612 (50%)] Loss: 0.247291\n",
      "Train Epoch: 862 [960/1612 (59%)] Loss: 0.290101\n",
      "Train Epoch: 862 [1120/1612 (69%)] Loss: 0.101565\n",
      "Train Epoch: 862 [1280/1612 (79%)] Loss: 0.285211\n",
      "Train Epoch: 862 [1440/1612 (89%)] Loss: 0.310366\n",
      "Train Epoch: 862 [1200/1612 (99%)] Loss: 0.230141\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 863 [0/1612 (0%)] Loss: 0.125094\n",
      "Train Epoch: 863 [160/1612 (10%)] Loss: 0.285659\n",
      "Train Epoch: 863 [320/1612 (20%)] Loss: 0.323318\n",
      "Train Epoch: 863 [480/1612 (30%)] Loss: 0.143302\n",
      "Train Epoch: 863 [640/1612 (40%)] Loss: 0.307261\n",
      "Train Epoch: 863 [800/1612 (50%)] Loss: 0.279731\n",
      "Train Epoch: 863 [960/1612 (59%)] Loss: 0.503384\n",
      "Train Epoch: 863 [1120/1612 (69%)] Loss: 0.529828\n",
      "Train Epoch: 863 [1280/1612 (79%)] Loss: 0.304175\n",
      "Train Epoch: 863 [1440/1612 (89%)] Loss: 0.294060\n",
      "Train Epoch: 863 [1200/1612 (99%)] Loss: 0.380732\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 864 [0/1612 (0%)] Loss: 0.145484\n",
      "Train Epoch: 864 [160/1612 (10%)] Loss: 0.491004\n",
      "Train Epoch: 864 [320/1612 (20%)] Loss: 0.513296\n",
      "Train Epoch: 864 [480/1612 (30%)] Loss: 0.374429\n",
      "Train Epoch: 864 [640/1612 (40%)] Loss: 0.388274\n",
      "Train Epoch: 864 [800/1612 (50%)] Loss: 0.119325\n",
      "Train Epoch: 864 [960/1612 (59%)] Loss: 0.225842\n",
      "Train Epoch: 864 [1120/1612 (69%)] Loss: 0.511804\n",
      "Train Epoch: 864 [1280/1612 (79%)] Loss: 0.251885\n",
      "Train Epoch: 864 [1440/1612 (89%)] Loss: 0.204648\n",
      "Train Epoch: 864 [1200/1612 (99%)] Loss: 0.374937\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 865 [0/1612 (0%)] Loss: 0.237329\n",
      "Train Epoch: 865 [160/1612 (10%)] Loss: 0.342687\n",
      "Train Epoch: 865 [320/1612 (20%)] Loss: 0.251357\n",
      "Train Epoch: 865 [480/1612 (30%)] Loss: 0.130245\n",
      "Train Epoch: 865 [640/1612 (40%)] Loss: 0.442054\n",
      "Train Epoch: 865 [800/1612 (50%)] Loss: 0.276336\n",
      "Train Epoch: 865 [960/1612 (59%)] Loss: 0.321867\n",
      "Train Epoch: 865 [1120/1612 (69%)] Loss: 0.243825\n",
      "Train Epoch: 865 [1280/1612 (79%)] Loss: 0.178736\n",
      "Train Epoch: 865 [1440/1612 (89%)] Loss: 0.193739\n",
      "Train Epoch: 865 [1200/1612 (99%)] Loss: 0.157244\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 866 [0/1612 (0%)] Loss: 0.148029\n",
      "Train Epoch: 866 [160/1612 (10%)] Loss: 0.384995\n",
      "Train Epoch: 866 [320/1612 (20%)] Loss: 0.210822\n",
      "Train Epoch: 866 [480/1612 (30%)] Loss: 0.091522\n",
      "Train Epoch: 866 [640/1612 (40%)] Loss: 0.364966\n",
      "Train Epoch: 866 [800/1612 (50%)] Loss: 0.363150\n",
      "Train Epoch: 866 [960/1612 (59%)] Loss: 0.240095\n",
      "Train Epoch: 866 [1120/1612 (69%)] Loss: 0.367094\n",
      "Train Epoch: 866 [1280/1612 (79%)] Loss: 0.378865\n",
      "Train Epoch: 866 [1440/1612 (89%)] Loss: 0.256086\n",
      "Train Epoch: 866 [1200/1612 (99%)] Loss: 0.495714\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 867 [0/1612 (0%)] Loss: 0.279549\n",
      "Train Epoch: 867 [160/1612 (10%)] Loss: 0.254929\n",
      "Train Epoch: 867 [320/1612 (20%)] Loss: 0.187332\n",
      "Train Epoch: 867 [480/1612 (30%)] Loss: 0.651747\n",
      "Train Epoch: 867 [640/1612 (40%)] Loss: 0.115109\n",
      "Train Epoch: 867 [800/1612 (50%)] Loss: 0.159668\n",
      "Train Epoch: 867 [960/1612 (59%)] Loss: 0.119168\n",
      "Train Epoch: 867 [1120/1612 (69%)] Loss: 0.320105\n",
      "Train Epoch: 867 [1280/1612 (79%)] Loss: 0.186615\n",
      "Train Epoch: 867 [1440/1612 (89%)] Loss: 0.225880\n",
      "Train Epoch: 867 [1200/1612 (99%)] Loss: 0.119468\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 868 [0/1612 (0%)] Loss: 0.305863\n",
      "Train Epoch: 868 [160/1612 (10%)] Loss: 0.251806\n",
      "Train Epoch: 868 [320/1612 (20%)] Loss: 0.352917\n",
      "Train Epoch: 868 [480/1612 (30%)] Loss: 0.375371\n",
      "Train Epoch: 868 [640/1612 (40%)] Loss: 0.443730\n",
      "Train Epoch: 868 [800/1612 (50%)] Loss: 0.353632\n",
      "Train Epoch: 868 [960/1612 (59%)] Loss: 0.367555\n",
      "Train Epoch: 868 [1120/1612 (69%)] Loss: 0.350325\n",
      "Train Epoch: 868 [1280/1612 (79%)] Loss: 0.354605\n",
      "Train Epoch: 868 [1440/1612 (89%)] Loss: 0.229679\n",
      "Train Epoch: 868 [1200/1612 (99%)] Loss: 0.331141\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 869 [0/1612 (0%)] Loss: 0.217971\n",
      "Train Epoch: 869 [160/1612 (10%)] Loss: 0.606302\n",
      "Train Epoch: 869 [320/1612 (20%)] Loss: 0.202769\n",
      "Train Epoch: 869 [480/1612 (30%)] Loss: 0.187718\n",
      "Train Epoch: 869 [640/1612 (40%)] Loss: 0.399346\n",
      "Train Epoch: 869 [800/1612 (50%)] Loss: 0.316216\n",
      "Train Epoch: 869 [960/1612 (59%)] Loss: 0.346191\n",
      "Train Epoch: 869 [1120/1612 (69%)] Loss: 0.215265\n",
      "Train Epoch: 869 [1280/1612 (79%)] Loss: 0.321689\n",
      "Train Epoch: 869 [1440/1612 (89%)] Loss: 0.224843\n",
      "Train Epoch: 869 [1200/1612 (99%)] Loss: 0.095241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 870 [0/1612 (0%)] Loss: 0.374134\n",
      "Train Epoch: 870 [160/1612 (10%)] Loss: 0.237201\n",
      "Train Epoch: 870 [320/1612 (20%)] Loss: 0.366303\n",
      "Train Epoch: 870 [480/1612 (30%)] Loss: 0.178209\n",
      "Train Epoch: 870 [640/1612 (40%)] Loss: 0.139597\n",
      "Train Epoch: 870 [800/1612 (50%)] Loss: 0.239247\n",
      "Train Epoch: 870 [960/1612 (59%)] Loss: 0.484998\n",
      "Train Epoch: 870 [1120/1612 (69%)] Loss: 0.162515\n",
      "Train Epoch: 870 [1280/1612 (79%)] Loss: 0.346128\n",
      "Train Epoch: 870 [1440/1612 (89%)] Loss: 0.436324\n",
      "Train Epoch: 870 [1200/1612 (99%)] Loss: 0.354383\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 871 [0/1612 (0%)] Loss: 0.185769\n",
      "Train Epoch: 871 [160/1612 (10%)] Loss: 0.267213\n",
      "Train Epoch: 871 [320/1612 (20%)] Loss: 0.146390\n",
      "Train Epoch: 871 [480/1612 (30%)] Loss: 0.277378\n",
      "Train Epoch: 871 [640/1612 (40%)] Loss: 0.353817\n",
      "Train Epoch: 871 [800/1612 (50%)] Loss: 0.348725\n",
      "Train Epoch: 871 [960/1612 (59%)] Loss: 0.354139\n",
      "Train Epoch: 871 [1120/1612 (69%)] Loss: 0.422041\n",
      "Train Epoch: 871 [1280/1612 (79%)] Loss: 0.443671\n",
      "Train Epoch: 871 [1440/1612 (89%)] Loss: 0.118540\n",
      "Train Epoch: 871 [1200/1612 (99%)] Loss: 0.133491\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 872 [0/1612 (0%)] Loss: 0.317353\n",
      "Train Epoch: 872 [160/1612 (10%)] Loss: 0.246888\n",
      "Train Epoch: 872 [320/1612 (20%)] Loss: 0.723807\n",
      "Train Epoch: 872 [480/1612 (30%)] Loss: 0.330712\n",
      "Train Epoch: 872 [640/1612 (40%)] Loss: 0.300370\n",
      "Train Epoch: 872 [800/1612 (50%)] Loss: 0.315959\n",
      "Train Epoch: 872 [960/1612 (59%)] Loss: 0.386284\n",
      "Train Epoch: 872 [1120/1612 (69%)] Loss: 0.273400\n",
      "Train Epoch: 872 [1280/1612 (79%)] Loss: 0.338772\n",
      "Train Epoch: 872 [1440/1612 (89%)] Loss: 0.455243\n",
      "Train Epoch: 872 [1200/1612 (99%)] Loss: 0.560644\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 873 [0/1612 (0%)] Loss: 0.362399\n",
      "Train Epoch: 873 [160/1612 (10%)] Loss: 0.460030\n",
      "Train Epoch: 873 [320/1612 (20%)] Loss: 0.407620\n",
      "Train Epoch: 873 [480/1612 (30%)] Loss: 0.377391\n",
      "Train Epoch: 873 [640/1612 (40%)] Loss: 0.260605\n",
      "Train Epoch: 873 [800/1612 (50%)] Loss: 0.408074\n",
      "Train Epoch: 873 [960/1612 (59%)] Loss: 0.284312\n",
      "Train Epoch: 873 [1120/1612 (69%)] Loss: 0.213475\n",
      "Train Epoch: 873 [1280/1612 (79%)] Loss: 0.140298\n",
      "Train Epoch: 873 [1440/1612 (89%)] Loss: 0.309005\n",
      "Train Epoch: 873 [1200/1612 (99%)] Loss: 0.269605\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 874 [0/1612 (0%)] Loss: 0.343080\n",
      "Train Epoch: 874 [160/1612 (10%)] Loss: 0.484112\n",
      "Train Epoch: 874 [320/1612 (20%)] Loss: 0.337026\n",
      "Train Epoch: 874 [480/1612 (30%)] Loss: 0.538583\n",
      "Train Epoch: 874 [640/1612 (40%)] Loss: 0.216093\n",
      "Train Epoch: 874 [800/1612 (50%)] Loss: 0.218213\n",
      "Train Epoch: 874 [960/1612 (59%)] Loss: 0.491975\n",
      "Train Epoch: 874 [1120/1612 (69%)] Loss: 0.215035\n",
      "Train Epoch: 874 [1280/1612 (79%)] Loss: 0.198824\n",
      "Train Epoch: 874 [1440/1612 (89%)] Loss: 0.449068\n",
      "Train Epoch: 874 [1200/1612 (99%)] Loss: 0.453577\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 875 [0/1612 (0%)] Loss: 0.380740\n",
      "Train Epoch: 875 [160/1612 (10%)] Loss: 0.399463\n",
      "Train Epoch: 875 [320/1612 (20%)] Loss: 0.325330\n",
      "Train Epoch: 875 [480/1612 (30%)] Loss: 0.367786\n",
      "Train Epoch: 875 [640/1612 (40%)] Loss: 0.174329\n",
      "Train Epoch: 875 [800/1612 (50%)] Loss: 0.293408\n",
      "Train Epoch: 875 [960/1612 (59%)] Loss: 0.539168\n",
      "Train Epoch: 875 [1120/1612 (69%)] Loss: 0.171786\n",
      "Train Epoch: 875 [1280/1612 (79%)] Loss: 0.294175\n",
      "Train Epoch: 875 [1440/1612 (89%)] Loss: 0.350260\n",
      "Train Epoch: 875 [1200/1612 (99%)] Loss: 0.343970\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 876 [0/1612 (0%)] Loss: 0.373485\n",
      "Train Epoch: 876 [160/1612 (10%)] Loss: 0.365936\n",
      "Train Epoch: 876 [320/1612 (20%)] Loss: 0.337228\n",
      "Train Epoch: 876 [480/1612 (30%)] Loss: 0.590244\n",
      "Train Epoch: 876 [640/1612 (40%)] Loss: 0.382360\n",
      "Train Epoch: 876 [800/1612 (50%)] Loss: 0.213162\n",
      "Train Epoch: 876 [960/1612 (59%)] Loss: 0.173498\n",
      "Train Epoch: 876 [1120/1612 (69%)] Loss: 0.339183\n",
      "Train Epoch: 876 [1280/1612 (79%)] Loss: 0.438494\n",
      "Train Epoch: 876 [1440/1612 (89%)] Loss: 0.269097\n",
      "Train Epoch: 876 [1200/1612 (99%)] Loss: 0.257569\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 877 [0/1612 (0%)] Loss: 0.414758\n",
      "Train Epoch: 877 [160/1612 (10%)] Loss: 0.183822\n",
      "Train Epoch: 877 [320/1612 (20%)] Loss: 0.559041\n",
      "Train Epoch: 877 [480/1612 (30%)] Loss: 0.225969\n",
      "Train Epoch: 877 [640/1612 (40%)] Loss: 0.248203\n",
      "Train Epoch: 877 [800/1612 (50%)] Loss: 0.572709\n",
      "Train Epoch: 877 [960/1612 (59%)] Loss: 0.398373\n",
      "Train Epoch: 877 [1120/1612 (69%)] Loss: 0.257355\n",
      "Train Epoch: 877 [1280/1612 (79%)] Loss: 0.177957\n",
      "Train Epoch: 877 [1440/1612 (89%)] Loss: 0.323911\n",
      "Train Epoch: 877 [1200/1612 (99%)] Loss: 0.504557\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 878 [0/1612 (0%)] Loss: 0.280492\n",
      "Train Epoch: 878 [160/1612 (10%)] Loss: 0.387907\n",
      "Train Epoch: 878 [320/1612 (20%)] Loss: 0.236844\n",
      "Train Epoch: 878 [480/1612 (30%)] Loss: 0.129809\n",
      "Train Epoch: 878 [640/1612 (40%)] Loss: 0.249891\n",
      "Train Epoch: 878 [800/1612 (50%)] Loss: 0.261289\n",
      "Train Epoch: 878 [960/1612 (59%)] Loss: 0.311675\n",
      "Train Epoch: 878 [1120/1612 (69%)] Loss: 0.505512\n",
      "Train Epoch: 878 [1280/1612 (79%)] Loss: 0.387624\n",
      "Train Epoch: 878 [1440/1612 (89%)] Loss: 0.327451\n",
      "Train Epoch: 878 [1200/1612 (99%)] Loss: 0.185199\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 879 [0/1612 (0%)] Loss: 0.218212\n",
      "Train Epoch: 879 [160/1612 (10%)] Loss: 0.357332\n",
      "Train Epoch: 879 [320/1612 (20%)] Loss: 0.180760\n",
      "Train Epoch: 879 [480/1612 (30%)] Loss: 0.255174\n",
      "Train Epoch: 879 [640/1612 (40%)] Loss: 0.263120\n",
      "Train Epoch: 879 [800/1612 (50%)] Loss: 0.366625\n",
      "Train Epoch: 879 [960/1612 (59%)] Loss: 0.316518\n",
      "Train Epoch: 879 [1120/1612 (69%)] Loss: 0.436679\n",
      "Train Epoch: 879 [1280/1612 (79%)] Loss: 0.300218\n",
      "Train Epoch: 879 [1440/1612 (89%)] Loss: 0.490376\n",
      "Train Epoch: 879 [1200/1612 (99%)] Loss: 0.162159\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 880 [0/1612 (0%)] Loss: 0.234883\n",
      "Train Epoch: 880 [160/1612 (10%)] Loss: 0.258870\n",
      "Train Epoch: 880 [320/1612 (20%)] Loss: 0.333183\n",
      "Train Epoch: 880 [480/1612 (30%)] Loss: 0.328963\n",
      "Train Epoch: 880 [640/1612 (40%)] Loss: 0.209751\n",
      "Train Epoch: 880 [800/1612 (50%)] Loss: 0.277809\n",
      "Train Epoch: 880 [960/1612 (59%)] Loss: 0.261835\n",
      "Train Epoch: 880 [1120/1612 (69%)] Loss: 0.103985\n",
      "Train Epoch: 880 [1280/1612 (79%)] Loss: 0.205240\n",
      "Train Epoch: 880 [1440/1612 (89%)] Loss: 0.290682\n",
      "Train Epoch: 880 [1200/1612 (99%)] Loss: 0.253869\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 881 [0/1612 (0%)] Loss: 0.223763\n",
      "Train Epoch: 881 [160/1612 (10%)] Loss: 0.289941\n",
      "Train Epoch: 881 [320/1612 (20%)] Loss: 0.196054\n",
      "Train Epoch: 881 [480/1612 (30%)] Loss: 0.272313\n",
      "Train Epoch: 881 [640/1612 (40%)] Loss: 0.156651\n",
      "Train Epoch: 881 [800/1612 (50%)] Loss: 0.532601\n",
      "Train Epoch: 881 [960/1612 (59%)] Loss: 0.188201\n",
      "Train Epoch: 881 [1120/1612 (69%)] Loss: 0.387163\n",
      "Train Epoch: 881 [1280/1612 (79%)] Loss: 0.273753\n",
      "Train Epoch: 881 [1440/1612 (89%)] Loss: 0.278646\n",
      "Train Epoch: 881 [1200/1612 (99%)] Loss: 0.478047\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 882 [0/1612 (0%)] Loss: 0.341867\n",
      "Train Epoch: 882 [160/1612 (10%)] Loss: 0.285325\n",
      "Train Epoch: 882 [320/1612 (20%)] Loss: 0.151575\n",
      "Train Epoch: 882 [480/1612 (30%)] Loss: 0.314663\n",
      "Train Epoch: 882 [640/1612 (40%)] Loss: 0.077667\n",
      "Train Epoch: 882 [800/1612 (50%)] Loss: 0.404830\n",
      "Train Epoch: 882 [960/1612 (59%)] Loss: 0.266800\n",
      "Train Epoch: 882 [1120/1612 (69%)] Loss: 0.264087\n",
      "Train Epoch: 882 [1280/1612 (79%)] Loss: 0.249474\n",
      "Train Epoch: 882 [1440/1612 (89%)] Loss: 0.211321\n",
      "Train Epoch: 882 [1200/1612 (99%)] Loss: 0.310810\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 883 [0/1612 (0%)] Loss: 0.233052\n",
      "Train Epoch: 883 [160/1612 (10%)] Loss: 0.194146\n",
      "Train Epoch: 883 [320/1612 (20%)] Loss: 0.095981\n",
      "Train Epoch: 883 [480/1612 (30%)] Loss: 0.282775\n",
      "Train Epoch: 883 [640/1612 (40%)] Loss: 0.194406\n",
      "Train Epoch: 883 [800/1612 (50%)] Loss: 0.262513\n",
      "Train Epoch: 883 [960/1612 (59%)] Loss: 0.446084\n",
      "Train Epoch: 883 [1120/1612 (69%)] Loss: 0.613143\n",
      "Train Epoch: 883 [1280/1612 (79%)] Loss: 0.481034\n",
      "Train Epoch: 883 [1440/1612 (89%)] Loss: 0.440465\n",
      "Train Epoch: 883 [1200/1612 (99%)] Loss: 0.327227\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 884 [0/1612 (0%)] Loss: 0.333520\n",
      "Train Epoch: 884 [160/1612 (10%)] Loss: 0.236552\n",
      "Train Epoch: 884 [320/1612 (20%)] Loss: 0.353002\n",
      "Train Epoch: 884 [480/1612 (30%)] Loss: 0.235210\n",
      "Train Epoch: 884 [640/1612 (40%)] Loss: 0.251255\n",
      "Train Epoch: 884 [800/1612 (50%)] Loss: 0.175072\n",
      "Train Epoch: 884 [960/1612 (59%)] Loss: 0.288392\n",
      "Train Epoch: 884 [1120/1612 (69%)] Loss: 0.432500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 884 [1280/1612 (79%)] Loss: 0.506188\n",
      "Train Epoch: 884 [1440/1612 (89%)] Loss: 0.435388\n",
      "Train Epoch: 884 [1200/1612 (99%)] Loss: 0.124877\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 885 [0/1612 (0%)] Loss: 0.275043\n",
      "Train Epoch: 885 [160/1612 (10%)] Loss: 0.231639\n",
      "Train Epoch: 885 [320/1612 (20%)] Loss: 0.216012\n",
      "Train Epoch: 885 [480/1612 (30%)] Loss: 0.818133\n",
      "Train Epoch: 885 [640/1612 (40%)] Loss: 0.277772\n",
      "Train Epoch: 885 [800/1612 (50%)] Loss: 0.195187\n",
      "Train Epoch: 885 [960/1612 (59%)] Loss: 0.198971\n",
      "Train Epoch: 885 [1120/1612 (69%)] Loss: 0.216128\n",
      "Train Epoch: 885 [1280/1612 (79%)] Loss: 0.331760\n",
      "Train Epoch: 885 [1440/1612 (89%)] Loss: 0.301974\n",
      "Train Epoch: 885 [1200/1612 (99%)] Loss: 0.343631\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 886 [0/1612 (0%)] Loss: 0.569572\n",
      "Train Epoch: 886 [160/1612 (10%)] Loss: 0.426565\n",
      "Train Epoch: 886 [320/1612 (20%)] Loss: 0.381444\n",
      "Train Epoch: 886 [480/1612 (30%)] Loss: 0.421838\n",
      "Train Epoch: 886 [640/1612 (40%)] Loss: 0.235173\n",
      "Train Epoch: 886 [800/1612 (50%)] Loss: 0.223010\n",
      "Train Epoch: 886 [960/1612 (59%)] Loss: 0.313708\n",
      "Train Epoch: 886 [1120/1612 (69%)] Loss: 0.356317\n",
      "Train Epoch: 886 [1280/1612 (79%)] Loss: 0.270000\n",
      "Train Epoch: 886 [1440/1612 (89%)] Loss: 0.289482\n",
      "Train Epoch: 886 [1200/1612 (99%)] Loss: 0.511427\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 887 [0/1612 (0%)] Loss: 0.273126\n",
      "Train Epoch: 887 [160/1612 (10%)] Loss: 0.410178\n",
      "Train Epoch: 887 [320/1612 (20%)] Loss: 0.339193\n",
      "Train Epoch: 887 [480/1612 (30%)] Loss: 0.355245\n",
      "Train Epoch: 887 [640/1612 (40%)] Loss: 0.378004\n",
      "Train Epoch: 887 [800/1612 (50%)] Loss: 0.315354\n",
      "Train Epoch: 887 [960/1612 (59%)] Loss: 0.416602\n",
      "Train Epoch: 887 [1120/1612 (69%)] Loss: 0.230427\n",
      "Train Epoch: 887 [1280/1612 (79%)] Loss: 0.324736\n",
      "Train Epoch: 887 [1440/1612 (89%)] Loss: 0.504340\n",
      "Train Epoch: 887 [1200/1612 (99%)] Loss: 0.308942\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 888 [0/1612 (0%)] Loss: 0.419976\n",
      "Train Epoch: 888 [160/1612 (10%)] Loss: 0.380297\n",
      "Train Epoch: 888 [320/1612 (20%)] Loss: 0.250360\n",
      "Train Epoch: 888 [480/1612 (30%)] Loss: 0.250592\n",
      "Train Epoch: 888 [640/1612 (40%)] Loss: 0.336638\n",
      "Train Epoch: 888 [800/1612 (50%)] Loss: 0.381855\n",
      "Train Epoch: 888 [960/1612 (59%)] Loss: 0.334141\n",
      "Train Epoch: 888 [1120/1612 (69%)] Loss: 0.350650\n",
      "Train Epoch: 888 [1280/1612 (79%)] Loss: 0.188269\n",
      "Train Epoch: 888 [1440/1612 (89%)] Loss: 0.330685\n",
      "Train Epoch: 888 [1200/1612 (99%)] Loss: 0.351140\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 889 [0/1612 (0%)] Loss: 0.371928\n",
      "Train Epoch: 889 [160/1612 (10%)] Loss: 0.238870\n",
      "Train Epoch: 889 [320/1612 (20%)] Loss: 0.379429\n",
      "Train Epoch: 889 [480/1612 (30%)] Loss: 0.242003\n",
      "Train Epoch: 889 [640/1612 (40%)] Loss: 0.353416\n",
      "Train Epoch: 889 [800/1612 (50%)] Loss: 0.339863\n",
      "Train Epoch: 889 [960/1612 (59%)] Loss: 0.331675\n",
      "Train Epoch: 889 [1120/1612 (69%)] Loss: 0.366813\n",
      "Train Epoch: 889 [1280/1612 (79%)] Loss: 0.220927\n",
      "Train Epoch: 889 [1440/1612 (89%)] Loss: 0.352361\n",
      "Train Epoch: 889 [1200/1612 (99%)] Loss: 0.241498\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 890 [0/1612 (0%)] Loss: 0.279281\n",
      "Train Epoch: 890 [160/1612 (10%)] Loss: 0.274550\n",
      "Train Epoch: 890 [320/1612 (20%)] Loss: 0.241550\n",
      "Train Epoch: 890 [480/1612 (30%)] Loss: 0.137734\n",
      "Train Epoch: 890 [640/1612 (40%)] Loss: 0.323991\n",
      "Train Epoch: 890 [800/1612 (50%)] Loss: 0.251665\n",
      "Train Epoch: 890 [960/1612 (59%)] Loss: 0.311811\n",
      "Train Epoch: 890 [1120/1612 (69%)] Loss: 0.294888\n",
      "Train Epoch: 890 [1280/1612 (79%)] Loss: 0.106051\n",
      "Train Epoch: 890 [1440/1612 (89%)] Loss: 0.340344\n",
      "Train Epoch: 890 [1200/1612 (99%)] Loss: 0.204534\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 891 [0/1612 (0%)] Loss: 0.327012\n",
      "Train Epoch: 891 [160/1612 (10%)] Loss: 0.379917\n",
      "Train Epoch: 891 [320/1612 (20%)] Loss: 0.378686\n",
      "Train Epoch: 891 [480/1612 (30%)] Loss: 0.454429\n",
      "Train Epoch: 891 [640/1612 (40%)] Loss: 0.213477\n",
      "Train Epoch: 891 [800/1612 (50%)] Loss: 0.611410\n",
      "Train Epoch: 891 [960/1612 (59%)] Loss: 0.211454\n",
      "Train Epoch: 891 [1120/1612 (69%)] Loss: 0.663766\n",
      "Train Epoch: 891 [1280/1612 (79%)] Loss: 0.141740\n",
      "Train Epoch: 891 [1440/1612 (89%)] Loss: 0.234185\n",
      "Train Epoch: 891 [1200/1612 (99%)] Loss: 0.249857\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 892 [0/1612 (0%)] Loss: 0.408044\n",
      "Train Epoch: 892 [160/1612 (10%)] Loss: 0.148153\n",
      "Train Epoch: 892 [320/1612 (20%)] Loss: 0.366471\n",
      "Train Epoch: 892 [480/1612 (30%)] Loss: 0.343971\n",
      "Train Epoch: 892 [640/1612 (40%)] Loss: 0.446732\n",
      "Train Epoch: 892 [800/1612 (50%)] Loss: 0.506011\n",
      "Train Epoch: 892 [960/1612 (59%)] Loss: 0.393547\n",
      "Train Epoch: 892 [1120/1612 (69%)] Loss: 0.281625\n",
      "Train Epoch: 892 [1280/1612 (79%)] Loss: 0.236436\n",
      "Train Epoch: 892 [1440/1612 (89%)] Loss: 0.155281\n",
      "Train Epoch: 892 [1200/1612 (99%)] Loss: 0.396513\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 893 [0/1612 (0%)] Loss: 0.302052\n",
      "Train Epoch: 893 [160/1612 (10%)] Loss: 0.253283\n",
      "Train Epoch: 893 [320/1612 (20%)] Loss: 0.380065\n",
      "Train Epoch: 893 [480/1612 (30%)] Loss: 0.184843\n",
      "Train Epoch: 893 [640/1612 (40%)] Loss: 0.128728\n",
      "Train Epoch: 893 [800/1612 (50%)] Loss: 0.306500\n",
      "Train Epoch: 893 [960/1612 (59%)] Loss: 0.264445\n",
      "Train Epoch: 893 [1120/1612 (69%)] Loss: 0.321811\n",
      "Train Epoch: 893 [1280/1612 (79%)] Loss: 0.402943\n",
      "Train Epoch: 893 [1440/1612 (89%)] Loss: 0.332883\n",
      "Train Epoch: 893 [1200/1612 (99%)] Loss: 0.173752\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 894 [0/1612 (0%)] Loss: 0.311091\n",
      "Train Epoch: 894 [160/1612 (10%)] Loss: 0.268126\n",
      "Train Epoch: 894 [320/1612 (20%)] Loss: 0.368760\n",
      "Train Epoch: 894 [480/1612 (30%)] Loss: 0.436513\n",
      "Train Epoch: 894 [640/1612 (40%)] Loss: 0.223344\n",
      "Train Epoch: 894 [800/1612 (50%)] Loss: 0.221993\n",
      "Train Epoch: 894 [960/1612 (59%)] Loss: 0.334616\n",
      "Train Epoch: 894 [1120/1612 (69%)] Loss: 0.246478\n",
      "Train Epoch: 894 [1280/1612 (79%)] Loss: 0.274226\n",
      "Train Epoch: 894 [1440/1612 (89%)] Loss: 0.282535\n",
      "Train Epoch: 894 [1200/1612 (99%)] Loss: 0.485497\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 895 [0/1612 (0%)] Loss: 0.233805\n",
      "Train Epoch: 895 [160/1612 (10%)] Loss: 0.221453\n",
      "Train Epoch: 895 [320/1612 (20%)] Loss: 0.454867\n",
      "Train Epoch: 895 [480/1612 (30%)] Loss: 0.394789\n",
      "Train Epoch: 895 [640/1612 (40%)] Loss: 0.196935\n",
      "Train Epoch: 895 [800/1612 (50%)] Loss: 0.316721\n",
      "Train Epoch: 895 [960/1612 (59%)] Loss: 0.505353\n",
      "Train Epoch: 895 [1120/1612 (69%)] Loss: 0.312348\n",
      "Train Epoch: 895 [1280/1612 (79%)] Loss: 0.220168\n",
      "Train Epoch: 895 [1440/1612 (89%)] Loss: 0.301950\n",
      "Train Epoch: 895 [1200/1612 (99%)] Loss: 0.147800\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 896 [0/1612 (0%)] Loss: 0.200493\n",
      "Train Epoch: 896 [160/1612 (10%)] Loss: 0.223476\n",
      "Train Epoch: 896 [320/1612 (20%)] Loss: 0.283370\n",
      "Train Epoch: 896 [480/1612 (30%)] Loss: 0.145630\n",
      "Train Epoch: 896 [640/1612 (40%)] Loss: 0.436869\n",
      "Train Epoch: 896 [800/1612 (50%)] Loss: 0.228791\n",
      "Train Epoch: 896 [960/1612 (59%)] Loss: 0.195047\n",
      "Train Epoch: 896 [1120/1612 (69%)] Loss: 0.178154\n",
      "Train Epoch: 896 [1280/1612 (79%)] Loss: 0.135901\n",
      "Train Epoch: 896 [1440/1612 (89%)] Loss: 0.242383\n",
      "Train Epoch: 896 [1200/1612 (99%)] Loss: 0.129847\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 897 [0/1612 (0%)] Loss: 0.211447\n",
      "Train Epoch: 897 [160/1612 (10%)] Loss: 0.401275\n",
      "Train Epoch: 897 [320/1612 (20%)] Loss: 0.427298\n",
      "Train Epoch: 897 [480/1612 (30%)] Loss: 0.120802\n",
      "Train Epoch: 897 [640/1612 (40%)] Loss: 0.440254\n",
      "Train Epoch: 897 [800/1612 (50%)] Loss: 0.250472\n",
      "Train Epoch: 897 [960/1612 (59%)] Loss: 0.472589\n",
      "Train Epoch: 897 [1120/1612 (69%)] Loss: 0.168071\n",
      "Train Epoch: 897 [1280/1612 (79%)] Loss: 0.254480\n",
      "Train Epoch: 897 [1440/1612 (89%)] Loss: 0.216766\n",
      "Train Epoch: 897 [1200/1612 (99%)] Loss: 0.133331\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 898 [0/1612 (0%)] Loss: 0.215184\n",
      "Train Epoch: 898 [160/1612 (10%)] Loss: 0.469536\n",
      "Train Epoch: 898 [320/1612 (20%)] Loss: 0.370105\n",
      "Train Epoch: 898 [480/1612 (30%)] Loss: 0.341409\n",
      "Train Epoch: 898 [640/1612 (40%)] Loss: 0.237797\n",
      "Train Epoch: 898 [800/1612 (50%)] Loss: 0.282552\n",
      "Train Epoch: 898 [960/1612 (59%)] Loss: 0.200415\n",
      "Train Epoch: 898 [1120/1612 (69%)] Loss: 0.344918\n",
      "Train Epoch: 898 [1280/1612 (79%)] Loss: 0.129626\n",
      "Train Epoch: 898 [1440/1612 (89%)] Loss: 0.212482\n",
      "Train Epoch: 898 [1200/1612 (99%)] Loss: 0.320714\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 899 [0/1612 (0%)] Loss: 0.181530\n",
      "Train Epoch: 899 [160/1612 (10%)] Loss: 0.471268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 899 [320/1612 (20%)] Loss: 0.240675\n",
      "Train Epoch: 899 [480/1612 (30%)] Loss: 0.198226\n",
      "Train Epoch: 899 [640/1612 (40%)] Loss: 0.467163\n",
      "Train Epoch: 899 [800/1612 (50%)] Loss: 0.398634\n",
      "Train Epoch: 899 [960/1612 (59%)] Loss: 0.086173\n",
      "Train Epoch: 899 [1120/1612 (69%)] Loss: 0.261325\n",
      "Train Epoch: 899 [1280/1612 (79%)] Loss: 0.356988\n",
      "Train Epoch: 899 [1440/1612 (89%)] Loss: 0.529599\n",
      "Train Epoch: 899 [1200/1612 (99%)] Loss: 0.252309\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 900 [0/1612 (0%)] Loss: 0.301961\n",
      "Train Epoch: 900 [160/1612 (10%)] Loss: 0.381155\n",
      "Train Epoch: 900 [320/1612 (20%)] Loss: 0.303743\n",
      "Train Epoch: 900 [480/1612 (30%)] Loss: 0.281081\n",
      "Train Epoch: 900 [640/1612 (40%)] Loss: 0.354930\n",
      "Train Epoch: 900 [800/1612 (50%)] Loss: 0.243829\n",
      "Train Epoch: 900 [960/1612 (59%)] Loss: 0.158649\n",
      "Train Epoch: 900 [1120/1612 (69%)] Loss: 0.358922\n",
      "Train Epoch: 900 [1280/1612 (79%)] Loss: 0.330220\n",
      "Train Epoch: 900 [1440/1612 (89%)] Loss: 0.175723\n",
      "Train Epoch: 900 [1200/1612 (99%)] Loss: 0.182394\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 901 [0/1612 (0%)] Loss: 0.542085\n",
      "Train Epoch: 901 [160/1612 (10%)] Loss: 0.285155\n",
      "Train Epoch: 901 [320/1612 (20%)] Loss: 0.310966\n",
      "Train Epoch: 901 [480/1612 (30%)] Loss: 0.327320\n",
      "Train Epoch: 901 [640/1612 (40%)] Loss: 0.468709\n",
      "Train Epoch: 901 [800/1612 (50%)] Loss: 0.304113\n",
      "Train Epoch: 901 [960/1612 (59%)] Loss: 0.177434\n",
      "Train Epoch: 901 [1120/1612 (69%)] Loss: 0.201771\n",
      "Train Epoch: 901 [1280/1612 (79%)] Loss: 0.255199\n",
      "Train Epoch: 901 [1440/1612 (89%)] Loss: 0.178977\n",
      "Train Epoch: 901 [1200/1612 (99%)] Loss: 0.235052\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 902 [0/1612 (0%)] Loss: 0.248578\n",
      "Train Epoch: 902 [160/1612 (10%)] Loss: 0.217945\n",
      "Train Epoch: 902 [320/1612 (20%)] Loss: 0.285279\n",
      "Train Epoch: 902 [480/1612 (30%)] Loss: 0.206598\n",
      "Train Epoch: 902 [640/1612 (40%)] Loss: 0.413042\n",
      "Train Epoch: 902 [800/1612 (50%)] Loss: 0.755832\n",
      "Train Epoch: 902 [960/1612 (59%)] Loss: 0.326970\n",
      "Train Epoch: 902 [1120/1612 (69%)] Loss: 0.226801\n",
      "Train Epoch: 902 [1280/1612 (79%)] Loss: 0.113852\n",
      "Train Epoch: 902 [1440/1612 (89%)] Loss: 0.455778\n",
      "Train Epoch: 902 [1200/1612 (99%)] Loss: 0.281989\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 903 [0/1612 (0%)] Loss: 0.265758\n",
      "Train Epoch: 903 [160/1612 (10%)] Loss: 0.242067\n",
      "Train Epoch: 903 [320/1612 (20%)] Loss: 0.596567\n",
      "Train Epoch: 903 [480/1612 (30%)] Loss: 0.308880\n",
      "Train Epoch: 903 [640/1612 (40%)] Loss: 0.279795\n",
      "Train Epoch: 903 [800/1612 (50%)] Loss: 0.205951\n",
      "Train Epoch: 903 [960/1612 (59%)] Loss: 0.466567\n",
      "Train Epoch: 903 [1120/1612 (69%)] Loss: 0.499888\n",
      "Train Epoch: 903 [1280/1612 (79%)] Loss: 0.176395\n",
      "Train Epoch: 903 [1440/1612 (89%)] Loss: 0.672505\n",
      "Train Epoch: 903 [1200/1612 (99%)] Loss: 0.298756\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 904 [0/1612 (0%)] Loss: 0.263792\n",
      "Train Epoch: 904 [160/1612 (10%)] Loss: 0.272209\n",
      "Train Epoch: 904 [320/1612 (20%)] Loss: 0.230367\n",
      "Train Epoch: 904 [480/1612 (30%)] Loss: 0.323554\n",
      "Train Epoch: 904 [640/1612 (40%)] Loss: 0.519664\n",
      "Train Epoch: 904 [800/1612 (50%)] Loss: 0.502731\n",
      "Train Epoch: 904 [960/1612 (59%)] Loss: 0.267910\n",
      "Train Epoch: 904 [1120/1612 (69%)] Loss: 0.228906\n",
      "Train Epoch: 904 [1280/1612 (79%)] Loss: 0.311560\n",
      "Train Epoch: 904 [1440/1612 (89%)] Loss: 0.373336\n",
      "Train Epoch: 904 [1200/1612 (99%)] Loss: 0.157417\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 905 [0/1612 (0%)] Loss: 0.084886\n",
      "Train Epoch: 905 [160/1612 (10%)] Loss: 0.300979\n",
      "Train Epoch: 905 [320/1612 (20%)] Loss: 0.428331\n",
      "Train Epoch: 905 [480/1612 (30%)] Loss: 0.303483\n",
      "Train Epoch: 905 [640/1612 (40%)] Loss: 0.225292\n",
      "Train Epoch: 905 [800/1612 (50%)] Loss: 0.369028\n",
      "Train Epoch: 905 [960/1612 (59%)] Loss: 0.247092\n",
      "Train Epoch: 905 [1120/1612 (69%)] Loss: 0.279822\n",
      "Train Epoch: 905 [1280/1612 (79%)] Loss: 0.271448\n",
      "Train Epoch: 905 [1440/1612 (89%)] Loss: 0.245227\n",
      "Train Epoch: 905 [1200/1612 (99%)] Loss: 0.219441\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 906 [0/1612 (0%)] Loss: 0.522443\n",
      "Train Epoch: 906 [160/1612 (10%)] Loss: 0.354222\n",
      "Train Epoch: 906 [320/1612 (20%)] Loss: 0.419059\n",
      "Train Epoch: 906 [480/1612 (30%)] Loss: 0.062612\n",
      "Train Epoch: 906 [640/1612 (40%)] Loss: 0.142947\n",
      "Train Epoch: 906 [800/1612 (50%)] Loss: 0.255901\n",
      "Train Epoch: 906 [960/1612 (59%)] Loss: 0.364187\n",
      "Train Epoch: 906 [1120/1612 (69%)] Loss: 0.277306\n",
      "Train Epoch: 906 [1280/1612 (79%)] Loss: 0.353368\n",
      "Train Epoch: 906 [1440/1612 (89%)] Loss: 0.145151\n",
      "Train Epoch: 906 [1200/1612 (99%)] Loss: 0.313565\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 907 [0/1612 (0%)] Loss: 0.426804\n",
      "Train Epoch: 907 [160/1612 (10%)] Loss: 0.193965\n",
      "Train Epoch: 907 [320/1612 (20%)] Loss: 0.129587\n",
      "Train Epoch: 907 [480/1612 (30%)] Loss: 0.290372\n",
      "Train Epoch: 907 [640/1612 (40%)] Loss: 0.448538\n",
      "Train Epoch: 907 [800/1612 (50%)] Loss: 0.247695\n",
      "Train Epoch: 907 [960/1612 (59%)] Loss: 0.386682\n",
      "Train Epoch: 907 [1120/1612 (69%)] Loss: 0.369734\n",
      "Train Epoch: 907 [1280/1612 (79%)] Loss: 0.249636\n",
      "Train Epoch: 907 [1440/1612 (89%)] Loss: 0.457199\n",
      "Train Epoch: 907 [1200/1612 (99%)] Loss: 0.308259\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 908 [0/1612 (0%)] Loss: 0.391404\n",
      "Train Epoch: 908 [160/1612 (10%)] Loss: 0.164236\n",
      "Train Epoch: 908 [320/1612 (20%)] Loss: 0.144494\n",
      "Train Epoch: 908 [480/1612 (30%)] Loss: 0.183833\n",
      "Train Epoch: 908 [640/1612 (40%)] Loss: 0.589028\n",
      "Train Epoch: 908 [800/1612 (50%)] Loss: 0.285892\n",
      "Train Epoch: 908 [960/1612 (59%)] Loss: 0.452340\n",
      "Train Epoch: 908 [1120/1612 (69%)] Loss: 0.396997\n",
      "Train Epoch: 908 [1280/1612 (79%)] Loss: 0.317683\n",
      "Train Epoch: 908 [1440/1612 (89%)] Loss: 0.235132\n",
      "Train Epoch: 908 [1200/1612 (99%)] Loss: 0.267806\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 909 [0/1612 (0%)] Loss: 0.203989\n",
      "Train Epoch: 909 [160/1612 (10%)] Loss: 0.293098\n",
      "Train Epoch: 909 [320/1612 (20%)] Loss: 0.532281\n",
      "Train Epoch: 909 [480/1612 (30%)] Loss: 0.276036\n",
      "Train Epoch: 909 [640/1612 (40%)] Loss: 0.338514\n",
      "Train Epoch: 909 [800/1612 (50%)] Loss: 0.155391\n",
      "Train Epoch: 909 [960/1612 (59%)] Loss: 0.433624\n",
      "Train Epoch: 909 [1120/1612 (69%)] Loss: 0.337163\n",
      "Train Epoch: 909 [1280/1612 (79%)] Loss: 0.371821\n",
      "Train Epoch: 909 [1440/1612 (89%)] Loss: 0.378583\n",
      "Train Epoch: 909 [1200/1612 (99%)] Loss: 0.558235\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 910 [0/1612 (0%)] Loss: 0.257562\n",
      "Train Epoch: 910 [160/1612 (10%)] Loss: 0.209674\n",
      "Train Epoch: 910 [320/1612 (20%)] Loss: 0.250424\n",
      "Train Epoch: 910 [480/1612 (30%)] Loss: 0.371218\n",
      "Train Epoch: 910 [640/1612 (40%)] Loss: 0.197246\n",
      "Train Epoch: 910 [800/1612 (50%)] Loss: 0.266795\n",
      "Train Epoch: 910 [960/1612 (59%)] Loss: 0.279108\n",
      "Train Epoch: 910 [1120/1612 (69%)] Loss: 0.288175\n",
      "Train Epoch: 910 [1280/1612 (79%)] Loss: 0.426761\n",
      "Train Epoch: 910 [1440/1612 (89%)] Loss: 0.280046\n",
      "Train Epoch: 910 [1200/1612 (99%)] Loss: 0.141587\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 911 [0/1612 (0%)] Loss: 0.168972\n",
      "Train Epoch: 911 [160/1612 (10%)] Loss: 0.177041\n",
      "Train Epoch: 911 [320/1612 (20%)] Loss: 0.274901\n",
      "Train Epoch: 911 [480/1612 (30%)] Loss: 0.295664\n",
      "Train Epoch: 911 [640/1612 (40%)] Loss: 0.441169\n",
      "Train Epoch: 911 [800/1612 (50%)] Loss: 0.102187\n",
      "Train Epoch: 911 [960/1612 (59%)] Loss: 0.185563\n",
      "Train Epoch: 911 [1120/1612 (69%)] Loss: 0.223420\n",
      "Train Epoch: 911 [1280/1612 (79%)] Loss: 0.172929\n",
      "Train Epoch: 911 [1440/1612 (89%)] Loss: 0.184608\n",
      "Train Epoch: 911 [1200/1612 (99%)] Loss: 0.276456\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 912 [0/1612 (0%)] Loss: 0.329846\n",
      "Train Epoch: 912 [160/1612 (10%)] Loss: 0.313191\n",
      "Train Epoch: 912 [320/1612 (20%)] Loss: 0.316620\n",
      "Train Epoch: 912 [480/1612 (30%)] Loss: 0.414102\n",
      "Train Epoch: 912 [640/1612 (40%)] Loss: 0.243930\n",
      "Train Epoch: 912 [800/1612 (50%)] Loss: 0.263076\n",
      "Train Epoch: 912 [960/1612 (59%)] Loss: 0.191357\n",
      "Train Epoch: 912 [1120/1612 (69%)] Loss: 0.337483\n",
      "Train Epoch: 912 [1280/1612 (79%)] Loss: 0.270757\n",
      "Train Epoch: 912 [1440/1612 (89%)] Loss: 0.301238\n",
      "Train Epoch: 912 [1200/1612 (99%)] Loss: 0.294678\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 913 [0/1612 (0%)] Loss: 0.223055\n",
      "Train Epoch: 913 [160/1612 (10%)] Loss: 0.192804\n",
      "Train Epoch: 913 [320/1612 (20%)] Loss: 0.230509\n",
      "Train Epoch: 913 [480/1612 (30%)] Loss: 0.243220\n",
      "Train Epoch: 913 [640/1612 (40%)] Loss: 0.367975\n",
      "Train Epoch: 913 [800/1612 (50%)] Loss: 0.211193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 913 [960/1612 (59%)] Loss: 0.347437\n",
      "Train Epoch: 913 [1120/1612 (69%)] Loss: 0.085526\n",
      "Train Epoch: 913 [1280/1612 (79%)] Loss: 0.096152\n",
      "Train Epoch: 913 [1440/1612 (89%)] Loss: 0.225692\n",
      "Train Epoch: 913 [1200/1612 (99%)] Loss: 0.148060\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 914 [0/1612 (0%)] Loss: 0.218740\n",
      "Train Epoch: 914 [160/1612 (10%)] Loss: 0.279221\n",
      "Train Epoch: 914 [320/1612 (20%)] Loss: 0.432602\n",
      "Train Epoch: 914 [480/1612 (30%)] Loss: 0.337213\n",
      "Train Epoch: 914 [640/1612 (40%)] Loss: 0.160215\n",
      "Train Epoch: 914 [800/1612 (50%)] Loss: 0.401000\n",
      "Train Epoch: 914 [960/1612 (59%)] Loss: 0.175276\n",
      "Train Epoch: 914 [1120/1612 (69%)] Loss: 0.214776\n",
      "Train Epoch: 914 [1280/1612 (79%)] Loss: 0.356903\n",
      "Train Epoch: 914 [1440/1612 (89%)] Loss: 0.430434\n",
      "Train Epoch: 914 [1200/1612 (99%)] Loss: 0.374166\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 915 [0/1612 (0%)] Loss: 0.342462\n",
      "Train Epoch: 915 [160/1612 (10%)] Loss: 0.342368\n",
      "Train Epoch: 915 [320/1612 (20%)] Loss: 0.531617\n",
      "Train Epoch: 915 [480/1612 (30%)] Loss: 0.370963\n",
      "Train Epoch: 915 [640/1612 (40%)] Loss: 0.400038\n",
      "Train Epoch: 915 [800/1612 (50%)] Loss: 0.155858\n",
      "Train Epoch: 915 [960/1612 (59%)] Loss: 0.162544\n",
      "Train Epoch: 915 [1120/1612 (69%)] Loss: 0.241592\n",
      "Train Epoch: 915 [1280/1612 (79%)] Loss: 0.137591\n",
      "Train Epoch: 915 [1440/1612 (89%)] Loss: 0.306298\n",
      "Train Epoch: 915 [1200/1612 (99%)] Loss: 0.210517\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 916 [0/1612 (0%)] Loss: 0.367126\n",
      "Train Epoch: 916 [160/1612 (10%)] Loss: 0.216616\n",
      "Train Epoch: 916 [320/1612 (20%)] Loss: 0.193009\n",
      "Train Epoch: 916 [480/1612 (30%)] Loss: 0.193350\n",
      "Train Epoch: 916 [640/1612 (40%)] Loss: 0.340312\n",
      "Train Epoch: 916 [800/1612 (50%)] Loss: 0.429539\n",
      "Train Epoch: 916 [960/1612 (59%)] Loss: 0.220830\n",
      "Train Epoch: 916 [1120/1612 (69%)] Loss: 0.214619\n",
      "Train Epoch: 916 [1280/1612 (79%)] Loss: 0.205205\n",
      "Train Epoch: 916 [1440/1612 (89%)] Loss: 0.458444\n",
      "Train Epoch: 916 [1200/1612 (99%)] Loss: 0.321704\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 917 [0/1612 (0%)] Loss: 0.466632\n",
      "Train Epoch: 917 [160/1612 (10%)] Loss: 0.368894\n",
      "Train Epoch: 917 [320/1612 (20%)] Loss: 0.251018\n",
      "Train Epoch: 917 [480/1612 (30%)] Loss: 0.254144\n",
      "Train Epoch: 917 [640/1612 (40%)] Loss: 0.535398\n",
      "Train Epoch: 917 [800/1612 (50%)] Loss: 0.257703\n",
      "Train Epoch: 917 [960/1612 (59%)] Loss: 0.293578\n",
      "Train Epoch: 917 [1120/1612 (69%)] Loss: 0.483068\n",
      "Train Epoch: 917 [1280/1612 (79%)] Loss: 0.492184\n",
      "Train Epoch: 917 [1440/1612 (89%)] Loss: 0.177332\n",
      "Train Epoch: 917 [1200/1612 (99%)] Loss: 0.386844\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 918 [0/1612 (0%)] Loss: 0.260099\n",
      "Train Epoch: 918 [160/1612 (10%)] Loss: 0.403245\n",
      "Train Epoch: 918 [320/1612 (20%)] Loss: 0.346713\n",
      "Train Epoch: 918 [480/1612 (30%)] Loss: 0.201903\n",
      "Train Epoch: 918 [640/1612 (40%)] Loss: 0.470711\n",
      "Train Epoch: 918 [800/1612 (50%)] Loss: 0.202982\n",
      "Train Epoch: 918 [960/1612 (59%)] Loss: 0.797093\n",
      "Train Epoch: 918 [1120/1612 (69%)] Loss: 0.300619\n",
      "Train Epoch: 918 [1280/1612 (79%)] Loss: 0.308617\n",
      "Train Epoch: 918 [1440/1612 (89%)] Loss: 0.303167\n",
      "Train Epoch: 918 [1200/1612 (99%)] Loss: 0.193702\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 919 [0/1612 (0%)] Loss: 0.102294\n",
      "Train Epoch: 919 [160/1612 (10%)] Loss: 0.341190\n",
      "Train Epoch: 919 [320/1612 (20%)] Loss: 0.319465\n",
      "Train Epoch: 919 [480/1612 (30%)] Loss: 0.329758\n",
      "Train Epoch: 919 [640/1612 (40%)] Loss: 0.343121\n",
      "Train Epoch: 919 [800/1612 (50%)] Loss: 0.302437\n",
      "Train Epoch: 919 [960/1612 (59%)] Loss: 0.316424\n",
      "Train Epoch: 919 [1120/1612 (69%)] Loss: 0.267017\n",
      "Train Epoch: 919 [1280/1612 (79%)] Loss: 0.320243\n",
      "Train Epoch: 919 [1440/1612 (89%)] Loss: 0.206650\n",
      "Train Epoch: 919 [1200/1612 (99%)] Loss: 0.415368\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 920 [0/1612 (0%)] Loss: 0.064493\n",
      "Train Epoch: 920 [160/1612 (10%)] Loss: 0.214652\n",
      "Train Epoch: 920 [320/1612 (20%)] Loss: 0.142545\n",
      "Train Epoch: 920 [480/1612 (30%)] Loss: 0.234855\n",
      "Train Epoch: 920 [640/1612 (40%)] Loss: 0.302774\n",
      "Train Epoch: 920 [800/1612 (50%)] Loss: 0.380368\n",
      "Train Epoch: 920 [960/1612 (59%)] Loss: 0.289253\n",
      "Train Epoch: 920 [1120/1612 (69%)] Loss: 0.454580\n",
      "Train Epoch: 920 [1280/1612 (79%)] Loss: 0.204807\n",
      "Train Epoch: 920 [1440/1612 (89%)] Loss: 0.284461\n",
      "Train Epoch: 920 [1200/1612 (99%)] Loss: 0.171387\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 921 [0/1612 (0%)] Loss: 0.340172\n",
      "Train Epoch: 921 [160/1612 (10%)] Loss: 0.406336\n",
      "Train Epoch: 921 [320/1612 (20%)] Loss: 0.291853\n",
      "Train Epoch: 921 [480/1612 (30%)] Loss: 0.350091\n",
      "Train Epoch: 921 [640/1612 (40%)] Loss: 0.214818\n",
      "Train Epoch: 921 [800/1612 (50%)] Loss: 0.312301\n",
      "Train Epoch: 921 [960/1612 (59%)] Loss: 0.123796\n",
      "Train Epoch: 921 [1120/1612 (69%)] Loss: 0.206719\n",
      "Train Epoch: 921 [1280/1612 (79%)] Loss: 0.239156\n",
      "Train Epoch: 921 [1440/1612 (89%)] Loss: 0.534613\n",
      "Train Epoch: 921 [1200/1612 (99%)] Loss: 0.339854\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 922 [0/1612 (0%)] Loss: 0.130618\n",
      "Train Epoch: 922 [160/1612 (10%)] Loss: 0.481225\n",
      "Train Epoch: 922 [320/1612 (20%)] Loss: 0.218818\n",
      "Train Epoch: 922 [480/1612 (30%)] Loss: 0.462995\n",
      "Train Epoch: 922 [640/1612 (40%)] Loss: 0.264057\n",
      "Train Epoch: 922 [800/1612 (50%)] Loss: 0.480569\n",
      "Train Epoch: 922 [960/1612 (59%)] Loss: 0.236445\n",
      "Train Epoch: 922 [1120/1612 (69%)] Loss: 0.471452\n",
      "Train Epoch: 922 [1280/1612 (79%)] Loss: 0.493235\n",
      "Train Epoch: 922 [1440/1612 (89%)] Loss: 0.381074\n",
      "Train Epoch: 922 [1200/1612 (99%)] Loss: 0.259156\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 923 [0/1612 (0%)] Loss: 0.313723\n",
      "Train Epoch: 923 [160/1612 (10%)] Loss: 0.193361\n",
      "Train Epoch: 923 [320/1612 (20%)] Loss: 0.323472\n",
      "Train Epoch: 923 [480/1612 (30%)] Loss: 0.370685\n",
      "Train Epoch: 923 [640/1612 (40%)] Loss: 0.351731\n",
      "Train Epoch: 923 [800/1612 (50%)] Loss: 0.622535\n",
      "Train Epoch: 923 [960/1612 (59%)] Loss: 0.148010\n",
      "Train Epoch: 923 [1120/1612 (69%)] Loss: 0.530115\n",
      "Train Epoch: 923 [1280/1612 (79%)] Loss: 0.252745\n",
      "Train Epoch: 923 [1440/1612 (89%)] Loss: 0.336842\n",
      "Train Epoch: 923 [1200/1612 (99%)] Loss: 0.370339\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 924 [0/1612 (0%)] Loss: 0.339318\n",
      "Train Epoch: 924 [160/1612 (10%)] Loss: 0.348697\n",
      "Train Epoch: 924 [320/1612 (20%)] Loss: 0.420094\n",
      "Train Epoch: 924 [480/1612 (30%)] Loss: 0.429079\n",
      "Train Epoch: 924 [640/1612 (40%)] Loss: 0.297956\n",
      "Train Epoch: 924 [800/1612 (50%)] Loss: 0.380648\n",
      "Train Epoch: 924 [960/1612 (59%)] Loss: 0.181207\n",
      "Train Epoch: 924 [1120/1612 (69%)] Loss: 0.212621\n",
      "Train Epoch: 924 [1280/1612 (79%)] Loss: 0.227385\n",
      "Train Epoch: 924 [1440/1612 (89%)] Loss: 0.516495\n",
      "Train Epoch: 924 [1200/1612 (99%)] Loss: 0.206376\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 925 [0/1612 (0%)] Loss: 0.136516\n",
      "Train Epoch: 925 [160/1612 (10%)] Loss: 0.307050\n",
      "Train Epoch: 925 [320/1612 (20%)] Loss: 0.461440\n",
      "Train Epoch: 925 [480/1612 (30%)] Loss: 0.304541\n",
      "Train Epoch: 925 [640/1612 (40%)] Loss: 0.187815\n",
      "Train Epoch: 925 [800/1612 (50%)] Loss: 0.245339\n",
      "Train Epoch: 925 [960/1612 (59%)] Loss: 0.287711\n",
      "Train Epoch: 925 [1120/1612 (69%)] Loss: 0.353831\n",
      "Train Epoch: 925 [1280/1612 (79%)] Loss: 0.186317\n",
      "Train Epoch: 925 [1440/1612 (89%)] Loss: 0.297124\n",
      "Train Epoch: 925 [1200/1612 (99%)] Loss: 0.622880\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 926 [0/1612 (0%)] Loss: 0.225126\n",
      "Train Epoch: 926 [160/1612 (10%)] Loss: 0.585262\n",
      "Train Epoch: 926 [320/1612 (20%)] Loss: 0.309323\n",
      "Train Epoch: 926 [480/1612 (30%)] Loss: 0.294667\n",
      "Train Epoch: 926 [640/1612 (40%)] Loss: 0.436875\n",
      "Train Epoch: 926 [800/1612 (50%)] Loss: 0.186577\n",
      "Train Epoch: 926 [960/1612 (59%)] Loss: 0.529598\n",
      "Train Epoch: 926 [1120/1612 (69%)] Loss: 0.211999\n",
      "Train Epoch: 926 [1280/1612 (79%)] Loss: 0.287842\n",
      "Train Epoch: 926 [1440/1612 (89%)] Loss: 0.224628\n",
      "Train Epoch: 926 [1200/1612 (99%)] Loss: 0.476266\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 927 [0/1612 (0%)] Loss: 0.211466\n",
      "Train Epoch: 927 [160/1612 (10%)] Loss: 0.263388\n",
      "Train Epoch: 927 [320/1612 (20%)] Loss: 0.112567\n",
      "Train Epoch: 927 [480/1612 (30%)] Loss: 0.240402\n",
      "Train Epoch: 927 [640/1612 (40%)] Loss: 0.251549\n",
      "Train Epoch: 927 [800/1612 (50%)] Loss: 0.504448\n",
      "Train Epoch: 927 [960/1612 (59%)] Loss: 0.376857\n",
      "Train Epoch: 927 [1120/1612 (69%)] Loss: 0.235187\n",
      "Train Epoch: 927 [1280/1612 (79%)] Loss: 0.333455\n",
      "Train Epoch: 927 [1440/1612 (89%)] Loss: 0.319708\n",
      "Train Epoch: 927 [1200/1612 (99%)] Loss: 0.241980\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 928 [0/1612 (0%)] Loss: 0.240015\n",
      "Train Epoch: 928 [160/1612 (10%)] Loss: 0.333790\n",
      "Train Epoch: 928 [320/1612 (20%)] Loss: 0.500759\n",
      "Train Epoch: 928 [480/1612 (30%)] Loss: 0.323582\n",
      "Train Epoch: 928 [640/1612 (40%)] Loss: 0.277258\n",
      "Train Epoch: 928 [800/1612 (50%)] Loss: 0.303541\n",
      "Train Epoch: 928 [960/1612 (59%)] Loss: 0.265707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 928 [1120/1612 (69%)] Loss: 0.275185\n",
      "Train Epoch: 928 [1280/1612 (79%)] Loss: 0.192722\n",
      "Train Epoch: 928 [1440/1612 (89%)] Loss: 0.176557\n",
      "Train Epoch: 928 [1200/1612 (99%)] Loss: 0.368971\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 929 [0/1612 (0%)] Loss: 0.466243\n",
      "Train Epoch: 929 [160/1612 (10%)] Loss: 0.173231\n",
      "Train Epoch: 929 [320/1612 (20%)] Loss: 0.366527\n",
      "Train Epoch: 929 [480/1612 (30%)] Loss: 0.252870\n",
      "Train Epoch: 929 [640/1612 (40%)] Loss: 0.315511\n",
      "Train Epoch: 929 [800/1612 (50%)] Loss: 0.221010\n",
      "Train Epoch: 929 [960/1612 (59%)] Loss: 0.094293\n",
      "Train Epoch: 929 [1120/1612 (69%)] Loss: 0.174425\n",
      "Train Epoch: 929 [1280/1612 (79%)] Loss: 0.242015\n",
      "Train Epoch: 929 [1440/1612 (89%)] Loss: 0.287784\n",
      "Train Epoch: 929 [1200/1612 (99%)] Loss: 0.315912\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 930 [0/1612 (0%)] Loss: 0.250897\n",
      "Train Epoch: 930 [160/1612 (10%)] Loss: 0.315232\n",
      "Train Epoch: 930 [320/1612 (20%)] Loss: 0.164400\n",
      "Train Epoch: 930 [480/1612 (30%)] Loss: 0.389263\n",
      "Train Epoch: 930 [640/1612 (40%)] Loss: 0.131632\n",
      "Train Epoch: 930 [800/1612 (50%)] Loss: 0.314406\n",
      "Train Epoch: 930 [960/1612 (59%)] Loss: 0.340614\n",
      "Train Epoch: 930 [1120/1612 (69%)] Loss: 0.220089\n",
      "Train Epoch: 930 [1280/1612 (79%)] Loss: 0.598785\n",
      "Train Epoch: 930 [1440/1612 (89%)] Loss: 0.224600\n",
      "Train Epoch: 930 [1200/1612 (99%)] Loss: 0.190876\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 931 [0/1612 (0%)] Loss: 0.372268\n",
      "Train Epoch: 931 [160/1612 (10%)] Loss: 0.085853\n",
      "Train Epoch: 931 [320/1612 (20%)] Loss: 0.573076\n",
      "Train Epoch: 931 [480/1612 (30%)] Loss: 0.501204\n",
      "Train Epoch: 931 [640/1612 (40%)] Loss: 0.283265\n",
      "Train Epoch: 931 [800/1612 (50%)] Loss: 0.313413\n",
      "Train Epoch: 931 [960/1612 (59%)] Loss: 0.284210\n",
      "Train Epoch: 931 [1120/1612 (69%)] Loss: 0.503157\n",
      "Train Epoch: 931 [1280/1612 (79%)] Loss: 0.229256\n",
      "Train Epoch: 931 [1440/1612 (89%)] Loss: 0.408386\n",
      "Train Epoch: 931 [1200/1612 (99%)] Loss: 0.343974\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 932 [0/1612 (0%)] Loss: 0.322937\n",
      "Train Epoch: 932 [160/1612 (10%)] Loss: 0.458115\n",
      "Train Epoch: 932 [320/1612 (20%)] Loss: 0.324113\n",
      "Train Epoch: 932 [480/1612 (30%)] Loss: 0.342502\n",
      "Train Epoch: 932 [640/1612 (40%)] Loss: 0.242145\n",
      "Train Epoch: 932 [800/1612 (50%)] Loss: 0.306812\n",
      "Train Epoch: 932 [960/1612 (59%)] Loss: 0.451161\n",
      "Train Epoch: 932 [1120/1612 (69%)] Loss: 0.392912\n",
      "Train Epoch: 932 [1280/1612 (79%)] Loss: 0.177120\n",
      "Train Epoch: 932 [1440/1612 (89%)] Loss: 0.185428\n",
      "Train Epoch: 932 [1200/1612 (99%)] Loss: 0.372676\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 933 [0/1612 (0%)] Loss: 0.252121\n",
      "Train Epoch: 933 [160/1612 (10%)] Loss: 0.515371\n",
      "Train Epoch: 933 [320/1612 (20%)] Loss: 0.291113\n",
      "Train Epoch: 933 [480/1612 (30%)] Loss: 0.242103\n",
      "Train Epoch: 933 [640/1612 (40%)] Loss: 0.325552\n",
      "Train Epoch: 933 [800/1612 (50%)] Loss: 0.328840\n",
      "Train Epoch: 933 [960/1612 (59%)] Loss: 0.289735\n",
      "Train Epoch: 933 [1120/1612 (69%)] Loss: 0.237242\n",
      "Train Epoch: 933 [1280/1612 (79%)] Loss: 0.282585\n",
      "Train Epoch: 933 [1440/1612 (89%)] Loss: 0.260827\n",
      "Train Epoch: 933 [1200/1612 (99%)] Loss: 0.191437\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 934 [0/1612 (0%)] Loss: 0.463372\n",
      "Train Epoch: 934 [160/1612 (10%)] Loss: 0.403465\n",
      "Train Epoch: 934 [320/1612 (20%)] Loss: 0.253737\n",
      "Train Epoch: 934 [480/1612 (30%)] Loss: 0.152187\n",
      "Train Epoch: 934 [640/1612 (40%)] Loss: 0.236813\n",
      "Train Epoch: 934 [800/1612 (50%)] Loss: 0.360008\n",
      "Train Epoch: 934 [960/1612 (59%)] Loss: 0.113605\n",
      "Train Epoch: 934 [1120/1612 (69%)] Loss: 0.195618\n",
      "Train Epoch: 934 [1280/1612 (79%)] Loss: 0.295379\n",
      "Train Epoch: 934 [1440/1612 (89%)] Loss: 0.192274\n",
      "Train Epoch: 934 [1200/1612 (99%)] Loss: 0.060832\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 935 [0/1612 (0%)] Loss: 0.231050\n",
      "Train Epoch: 935 [160/1612 (10%)] Loss: 0.385468\n",
      "Train Epoch: 935 [320/1612 (20%)] Loss: 0.216531\n",
      "Train Epoch: 935 [480/1612 (30%)] Loss: 0.251460\n",
      "Train Epoch: 935 [640/1612 (40%)] Loss: 0.375722\n",
      "Train Epoch: 935 [800/1612 (50%)] Loss: 0.529618\n",
      "Train Epoch: 935 [960/1612 (59%)] Loss: 0.580188\n",
      "Train Epoch: 935 [1120/1612 (69%)] Loss: 0.170011\n",
      "Train Epoch: 935 [1280/1612 (79%)] Loss: 0.263659\n",
      "Train Epoch: 935 [1440/1612 (89%)] Loss: 0.177336\n",
      "Train Epoch: 935 [1200/1612 (99%)] Loss: 0.253602\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 936 [0/1612 (0%)] Loss: 0.235739\n",
      "Train Epoch: 936 [160/1612 (10%)] Loss: 0.291742\n",
      "Train Epoch: 936 [320/1612 (20%)] Loss: 0.114526\n",
      "Train Epoch: 936 [480/1612 (30%)] Loss: 0.257223\n",
      "Train Epoch: 936 [640/1612 (40%)] Loss: 0.492861\n",
      "Train Epoch: 936 [800/1612 (50%)] Loss: 0.291504\n",
      "Train Epoch: 936 [960/1612 (59%)] Loss: 0.321807\n",
      "Train Epoch: 936 [1120/1612 (69%)] Loss: 0.215621\n",
      "Train Epoch: 936 [1280/1612 (79%)] Loss: 0.145512\n",
      "Train Epoch: 936 [1440/1612 (89%)] Loss: 0.240527\n",
      "Train Epoch: 936 [1200/1612 (99%)] Loss: 0.361345\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 937 [0/1612 (0%)] Loss: 0.368983\n",
      "Train Epoch: 937 [160/1612 (10%)] Loss: 0.358951\n",
      "Train Epoch: 937 [320/1612 (20%)] Loss: 0.214649\n",
      "Train Epoch: 937 [480/1612 (30%)] Loss: 0.399272\n",
      "Train Epoch: 937 [640/1612 (40%)] Loss: 0.349329\n",
      "Train Epoch: 937 [800/1612 (50%)] Loss: 0.317422\n",
      "Train Epoch: 937 [960/1612 (59%)] Loss: 0.343777\n",
      "Train Epoch: 937 [1120/1612 (69%)] Loss: 0.280195\n",
      "Train Epoch: 937 [1280/1612 (79%)] Loss: 0.171127\n",
      "Train Epoch: 937 [1440/1612 (89%)] Loss: 0.269119\n",
      "Train Epoch: 937 [1200/1612 (99%)] Loss: 0.447127\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 938 [0/1612 (0%)] Loss: 0.227225\n",
      "Train Epoch: 938 [160/1612 (10%)] Loss: 0.419603\n",
      "Train Epoch: 938 [320/1612 (20%)] Loss: 0.512867\n",
      "Train Epoch: 938 [480/1612 (30%)] Loss: 0.443111\n",
      "Train Epoch: 938 [640/1612 (40%)] Loss: 0.278664\n",
      "Train Epoch: 938 [800/1612 (50%)] Loss: 0.230798\n",
      "Train Epoch: 938 [960/1612 (59%)] Loss: 0.222525\n",
      "Train Epoch: 938 [1120/1612 (69%)] Loss: 0.348333\n",
      "Train Epoch: 938 [1280/1612 (79%)] Loss: 0.416626\n",
      "Train Epoch: 938 [1440/1612 (89%)] Loss: 0.466241\n",
      "Train Epoch: 938 [1200/1612 (99%)] Loss: 0.284286\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 939 [0/1612 (0%)] Loss: 0.502305\n",
      "Train Epoch: 939 [160/1612 (10%)] Loss: 0.361541\n",
      "Train Epoch: 939 [320/1612 (20%)] Loss: 0.418640\n",
      "Train Epoch: 939 [480/1612 (30%)] Loss: 0.353543\n",
      "Train Epoch: 939 [640/1612 (40%)] Loss: 0.211466\n",
      "Train Epoch: 939 [800/1612 (50%)] Loss: 0.375619\n",
      "Train Epoch: 939 [960/1612 (59%)] Loss: 0.434626\n",
      "Train Epoch: 939 [1120/1612 (69%)] Loss: 0.337786\n",
      "Train Epoch: 939 [1280/1612 (79%)] Loss: 0.571340\n",
      "Train Epoch: 939 [1440/1612 (89%)] Loss: 0.191891\n",
      "Train Epoch: 939 [1200/1612 (99%)] Loss: 0.244427\n",
      "\n",
      "Test set: Average loss: 0.0246, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 940 [0/1612 (0%)] Loss: 0.284419\n",
      "Train Epoch: 940 [160/1612 (10%)] Loss: 0.300541\n",
      "Train Epoch: 940 [320/1612 (20%)] Loss: 0.399151\n",
      "Train Epoch: 940 [480/1612 (30%)] Loss: 0.348077\n",
      "Train Epoch: 940 [640/1612 (40%)] Loss: 0.240637\n",
      "Train Epoch: 940 [800/1612 (50%)] Loss: 0.519225\n",
      "Train Epoch: 940 [960/1612 (59%)] Loss: 0.435016\n",
      "Train Epoch: 940 [1120/1612 (69%)] Loss: 0.440012\n",
      "Train Epoch: 940 [1280/1612 (79%)] Loss: 0.095018\n",
      "Train Epoch: 940 [1440/1612 (89%)] Loss: 0.434499\n",
      "Train Epoch: 940 [1200/1612 (99%)] Loss: 0.198889\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 941 [0/1612 (0%)] Loss: 0.242949\n",
      "Train Epoch: 941 [160/1612 (10%)] Loss: 0.291560\n",
      "Train Epoch: 941 [320/1612 (20%)] Loss: 0.403400\n",
      "Train Epoch: 941 [480/1612 (30%)] Loss: 0.565468\n",
      "Train Epoch: 941 [640/1612 (40%)] Loss: 0.464591\n",
      "Train Epoch: 941 [800/1612 (50%)] Loss: 0.529586\n",
      "Train Epoch: 941 [960/1612 (59%)] Loss: 0.269761\n",
      "Train Epoch: 941 [1120/1612 (69%)] Loss: 0.370061\n",
      "Train Epoch: 941 [1280/1612 (79%)] Loss: 0.289859\n",
      "Train Epoch: 941 [1440/1612 (89%)] Loss: 0.376540\n",
      "Train Epoch: 941 [1200/1612 (99%)] Loss: 0.291021\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 942 [0/1612 (0%)] Loss: 0.308820\n",
      "Train Epoch: 942 [160/1612 (10%)] Loss: 0.384666\n",
      "Train Epoch: 942 [320/1612 (20%)] Loss: 0.590718\n",
      "Train Epoch: 942 [480/1612 (30%)] Loss: 0.407738\n",
      "Train Epoch: 942 [640/1612 (40%)] Loss: 0.195304\n",
      "Train Epoch: 942 [800/1612 (50%)] Loss: 0.193874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 942 [960/1612 (59%)] Loss: 0.416199\n",
      "Train Epoch: 942 [1120/1612 (69%)] Loss: 0.360238\n",
      "Train Epoch: 942 [1280/1612 (79%)] Loss: 0.336064\n",
      "Train Epoch: 942 [1440/1612 (89%)] Loss: 0.207984\n",
      "Train Epoch: 942 [1200/1612 (99%)] Loss: 0.181272\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 943 [0/1612 (0%)] Loss: 0.246920\n",
      "Train Epoch: 943 [160/1612 (10%)] Loss: 0.342782\n",
      "Train Epoch: 943 [320/1612 (20%)] Loss: 0.190334\n",
      "Train Epoch: 943 [480/1612 (30%)] Loss: 0.248397\n",
      "Train Epoch: 943 [640/1612 (40%)] Loss: 0.195516\n",
      "Train Epoch: 943 [800/1612 (50%)] Loss: 0.179642\n",
      "Train Epoch: 943 [960/1612 (59%)] Loss: 0.258033\n",
      "Train Epoch: 943 [1120/1612 (69%)] Loss: 0.452571\n",
      "Train Epoch: 943 [1280/1612 (79%)] Loss: 0.339067\n",
      "Train Epoch: 943 [1440/1612 (89%)] Loss: 0.378243\n",
      "Train Epoch: 943 [1200/1612 (99%)] Loss: 0.325165\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 944 [0/1612 (0%)] Loss: 0.160747\n",
      "Train Epoch: 944 [160/1612 (10%)] Loss: 0.243992\n",
      "Train Epoch: 944 [320/1612 (20%)] Loss: 0.737088\n",
      "Train Epoch: 944 [480/1612 (30%)] Loss: 0.419983\n",
      "Train Epoch: 944 [640/1612 (40%)] Loss: 0.319054\n",
      "Train Epoch: 944 [800/1612 (50%)] Loss: 0.344214\n",
      "Train Epoch: 944 [960/1612 (59%)] Loss: 0.178577\n",
      "Train Epoch: 944 [1120/1612 (69%)] Loss: 0.315572\n",
      "Train Epoch: 944 [1280/1612 (79%)] Loss: 0.290883\n",
      "Train Epoch: 944 [1440/1612 (89%)] Loss: 0.368368\n",
      "Train Epoch: 944 [1200/1612 (99%)] Loss: 0.626582\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 945 [0/1612 (0%)] Loss: 0.184070\n",
      "Train Epoch: 945 [160/1612 (10%)] Loss: 0.200796\n",
      "Train Epoch: 945 [320/1612 (20%)] Loss: 0.321501\n",
      "Train Epoch: 945 [480/1612 (30%)] Loss: 0.633956\n",
      "Train Epoch: 945 [640/1612 (40%)] Loss: 0.540707\n",
      "Train Epoch: 945 [800/1612 (50%)] Loss: 0.279764\n",
      "Train Epoch: 945 [960/1612 (59%)] Loss: 0.515926\n",
      "Train Epoch: 945 [1120/1612 (69%)] Loss: 0.461835\n",
      "Train Epoch: 945 [1280/1612 (79%)] Loss: 0.398530\n",
      "Train Epoch: 945 [1440/1612 (89%)] Loss: 0.256371\n",
      "Train Epoch: 945 [1200/1612 (99%)] Loss: 0.338643\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 946 [0/1612 (0%)] Loss: 0.395717\n",
      "Train Epoch: 946 [160/1612 (10%)] Loss: 0.361873\n",
      "Train Epoch: 946 [320/1612 (20%)] Loss: 0.384721\n",
      "Train Epoch: 946 [480/1612 (30%)] Loss: 0.058461\n",
      "Train Epoch: 946 [640/1612 (40%)] Loss: 0.506992\n",
      "Train Epoch: 946 [800/1612 (50%)] Loss: 0.494402\n",
      "Train Epoch: 946 [960/1612 (59%)] Loss: 0.367749\n",
      "Train Epoch: 946 [1120/1612 (69%)] Loss: 0.411466\n",
      "Train Epoch: 946 [1280/1612 (79%)] Loss: 0.257694\n",
      "Train Epoch: 946 [1440/1612 (89%)] Loss: 0.268528\n",
      "Train Epoch: 946 [1200/1612 (99%)] Loss: 0.084782\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 947 [0/1612 (0%)] Loss: 0.370022\n",
      "Train Epoch: 947 [160/1612 (10%)] Loss: 0.363238\n",
      "Train Epoch: 947 [320/1612 (20%)] Loss: 0.274485\n",
      "Train Epoch: 947 [480/1612 (30%)] Loss: 0.264324\n",
      "Train Epoch: 947 [640/1612 (40%)] Loss: 0.379574\n",
      "Train Epoch: 947 [800/1612 (50%)] Loss: 0.228617\n",
      "Train Epoch: 947 [960/1612 (59%)] Loss: 0.376400\n",
      "Train Epoch: 947 [1120/1612 (69%)] Loss: 0.108178\n",
      "Train Epoch: 947 [1280/1612 (79%)] Loss: 0.213664\n",
      "Train Epoch: 947 [1440/1612 (89%)] Loss: 0.273708\n",
      "Train Epoch: 947 [1200/1612 (99%)] Loss: 0.238778\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 948 [0/1612 (0%)] Loss: 0.184196\n",
      "Train Epoch: 948 [160/1612 (10%)] Loss: 0.250911\n",
      "Train Epoch: 948 [320/1612 (20%)] Loss: 0.290947\n",
      "Train Epoch: 948 [480/1612 (30%)] Loss: 0.332083\n",
      "Train Epoch: 948 [640/1612 (40%)] Loss: 0.397026\n",
      "Train Epoch: 948 [800/1612 (50%)] Loss: 0.216854\n",
      "Train Epoch: 948 [960/1612 (59%)] Loss: 0.557414\n",
      "Train Epoch: 948 [1120/1612 (69%)] Loss: 0.213242\n",
      "Train Epoch: 948 [1280/1612 (79%)] Loss: 0.362583\n",
      "Train Epoch: 948 [1440/1612 (89%)] Loss: 0.294831\n",
      "Train Epoch: 948 [1200/1612 (99%)] Loss: 0.096310\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 949 [0/1612 (0%)] Loss: 0.201478\n",
      "Train Epoch: 949 [160/1612 (10%)] Loss: 0.401835\n",
      "Train Epoch: 949 [320/1612 (20%)] Loss: 0.228004\n",
      "Train Epoch: 949 [480/1612 (30%)] Loss: 0.445127\n",
      "Train Epoch: 949 [640/1612 (40%)] Loss: 0.533413\n",
      "Train Epoch: 949 [800/1612 (50%)] Loss: 0.284270\n",
      "Train Epoch: 949 [960/1612 (59%)] Loss: 0.141965\n",
      "Train Epoch: 949 [1120/1612 (69%)] Loss: 0.363017\n",
      "Train Epoch: 949 [1280/1612 (79%)] Loss: 0.333799\n",
      "Train Epoch: 949 [1440/1612 (89%)] Loss: 0.210238\n",
      "Train Epoch: 949 [1200/1612 (99%)] Loss: 0.223799\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 950 [0/1612 (0%)] Loss: 0.349277\n",
      "Train Epoch: 950 [160/1612 (10%)] Loss: 0.182215\n",
      "Train Epoch: 950 [320/1612 (20%)] Loss: 0.186582\n",
      "Train Epoch: 950 [480/1612 (30%)] Loss: 0.323739\n",
      "Train Epoch: 950 [640/1612 (40%)] Loss: 0.274052\n",
      "Train Epoch: 950 [800/1612 (50%)] Loss: 0.492599\n",
      "Train Epoch: 950 [960/1612 (59%)] Loss: 0.221093\n",
      "Train Epoch: 950 [1120/1612 (69%)] Loss: 0.152674\n",
      "Train Epoch: 950 [1280/1612 (79%)] Loss: 0.148772\n",
      "Train Epoch: 950 [1440/1612 (89%)] Loss: 0.385392\n",
      "Train Epoch: 950 [1200/1612 (99%)] Loss: 0.309106\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 951 [0/1612 (0%)] Loss: 0.254415\n",
      "Train Epoch: 951 [160/1612 (10%)] Loss: 0.300586\n",
      "Train Epoch: 951 [320/1612 (20%)] Loss: 0.477792\n",
      "Train Epoch: 951 [480/1612 (30%)] Loss: 0.120282\n",
      "Train Epoch: 951 [640/1612 (40%)] Loss: 0.214775\n",
      "Train Epoch: 951 [800/1612 (50%)] Loss: 0.146695\n",
      "Train Epoch: 951 [960/1612 (59%)] Loss: 0.331594\n",
      "Train Epoch: 951 [1120/1612 (69%)] Loss: 0.158475\n",
      "Train Epoch: 951 [1280/1612 (79%)] Loss: 0.293600\n",
      "Train Epoch: 951 [1440/1612 (89%)] Loss: 0.541939\n",
      "Train Epoch: 951 [1200/1612 (99%)] Loss: 0.340119\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 952 [0/1612 (0%)] Loss: 0.506047\n",
      "Train Epoch: 952 [160/1612 (10%)] Loss: 0.271762\n",
      "Train Epoch: 952 [320/1612 (20%)] Loss: 0.331976\n",
      "Train Epoch: 952 [480/1612 (30%)] Loss: 0.325892\n",
      "Train Epoch: 952 [640/1612 (40%)] Loss: 0.299790\n",
      "Train Epoch: 952 [800/1612 (50%)] Loss: 0.641631\n",
      "Train Epoch: 952 [960/1612 (59%)] Loss: 0.273547\n",
      "Train Epoch: 952 [1120/1612 (69%)] Loss: 0.578058\n",
      "Train Epoch: 952 [1280/1612 (79%)] Loss: 0.257340\n",
      "Train Epoch: 952 [1440/1612 (89%)] Loss: 0.178216\n",
      "Train Epoch: 952 [1200/1612 (99%)] Loss: 0.208992\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 953 [0/1612 (0%)] Loss: 0.322589\n",
      "Train Epoch: 953 [160/1612 (10%)] Loss: 0.165086\n",
      "Train Epoch: 953 [320/1612 (20%)] Loss: 0.394401\n",
      "Train Epoch: 953 [480/1612 (30%)] Loss: 0.461785\n",
      "Train Epoch: 953 [640/1612 (40%)] Loss: 0.198240\n",
      "Train Epoch: 953 [800/1612 (50%)] Loss: 0.459109\n",
      "Train Epoch: 953 [960/1612 (59%)] Loss: 0.293559\n",
      "Train Epoch: 953 [1120/1612 (69%)] Loss: 0.225411\n",
      "Train Epoch: 953 [1280/1612 (79%)] Loss: 0.392392\n",
      "Train Epoch: 953 [1440/1612 (89%)] Loss: 0.121490\n",
      "Train Epoch: 953 [1200/1612 (99%)] Loss: 0.215714\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 954 [0/1612 (0%)] Loss: 0.183145\n",
      "Train Epoch: 954 [160/1612 (10%)] Loss: 0.309527\n",
      "Train Epoch: 954 [320/1612 (20%)] Loss: 0.348232\n",
      "Train Epoch: 954 [480/1612 (30%)] Loss: 0.225938\n",
      "Train Epoch: 954 [640/1612 (40%)] Loss: 0.425783\n",
      "Train Epoch: 954 [800/1612 (50%)] Loss: 0.131183\n",
      "Train Epoch: 954 [960/1612 (59%)] Loss: 0.162942\n",
      "Train Epoch: 954 [1120/1612 (69%)] Loss: 0.345100\n",
      "Train Epoch: 954 [1280/1612 (79%)] Loss: 0.317832\n",
      "Train Epoch: 954 [1440/1612 (89%)] Loss: 0.139135\n",
      "Train Epoch: 954 [1200/1612 (99%)] Loss: 0.365315\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 955 [0/1612 (0%)] Loss: 0.383150\n",
      "Train Epoch: 955 [160/1612 (10%)] Loss: 0.115006\n",
      "Train Epoch: 955 [320/1612 (20%)] Loss: 0.228387\n",
      "Train Epoch: 955 [480/1612 (30%)] Loss: 0.381887\n",
      "Train Epoch: 955 [640/1612 (40%)] Loss: 0.238990\n",
      "Train Epoch: 955 [800/1612 (50%)] Loss: 0.414385\n",
      "Train Epoch: 955 [960/1612 (59%)] Loss: 0.597136\n",
      "Train Epoch: 955 [1120/1612 (69%)] Loss: 0.198144\n",
      "Train Epoch: 955 [1280/1612 (79%)] Loss: 0.489146\n",
      "Train Epoch: 955 [1440/1612 (89%)] Loss: 0.367096\n",
      "Train Epoch: 955 [1200/1612 (99%)] Loss: 0.426268\n",
      "\n",
      "Test set: Average loss: 0.0295, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 956 [0/1612 (0%)] Loss: 0.200133\n",
      "Train Epoch: 956 [160/1612 (10%)] Loss: 0.168128\n",
      "Train Epoch: 956 [320/1612 (20%)] Loss: 0.336398\n",
      "Train Epoch: 956 [480/1612 (30%)] Loss: 0.299908\n",
      "Train Epoch: 956 [640/1612 (40%)] Loss: 0.212242\n",
      "Train Epoch: 956 [800/1612 (50%)] Loss: 0.336585\n",
      "Train Epoch: 956 [960/1612 (59%)] Loss: 0.257225\n",
      "Train Epoch: 956 [1120/1612 (69%)] Loss: 0.186933\n",
      "Train Epoch: 956 [1280/1612 (79%)] Loss: 0.557214\n",
      "Train Epoch: 956 [1440/1612 (89%)] Loss: 0.402036\n",
      "Train Epoch: 956 [1200/1612 (99%)] Loss: 0.182077\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 957 [0/1612 (0%)] Loss: 0.371415\n",
      "Train Epoch: 957 [160/1612 (10%)] Loss: 0.262763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 957 [320/1612 (20%)] Loss: 0.344588\n",
      "Train Epoch: 957 [480/1612 (30%)] Loss: 0.709260\n",
      "Train Epoch: 957 [640/1612 (40%)] Loss: 0.256684\n",
      "Train Epoch: 957 [800/1612 (50%)] Loss: 0.244384\n",
      "Train Epoch: 957 [960/1612 (59%)] Loss: 0.292614\n",
      "Train Epoch: 957 [1120/1612 (69%)] Loss: 0.265014\n",
      "Train Epoch: 957 [1280/1612 (79%)] Loss: 0.311340\n",
      "Train Epoch: 957 [1440/1612 (89%)] Loss: 0.238337\n",
      "Train Epoch: 957 [1200/1612 (99%)] Loss: 0.205137\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 958 [0/1612 (0%)] Loss: 0.199112\n",
      "Train Epoch: 958 [160/1612 (10%)] Loss: 0.350200\n",
      "Train Epoch: 958 [320/1612 (20%)] Loss: 0.310920\n",
      "Train Epoch: 958 [480/1612 (30%)] Loss: 0.396973\n",
      "Train Epoch: 958 [640/1612 (40%)] Loss: 0.540786\n",
      "Train Epoch: 958 [800/1612 (50%)] Loss: 0.263714\n",
      "Train Epoch: 958 [960/1612 (59%)] Loss: 0.175513\n",
      "Train Epoch: 958 [1120/1612 (69%)] Loss: 0.135426\n",
      "Train Epoch: 958 [1280/1612 (79%)] Loss: 0.309795\n",
      "Train Epoch: 958 [1440/1612 (89%)] Loss: 0.143740\n",
      "Train Epoch: 958 [1200/1612 (99%)] Loss: 0.247064\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 959 [0/1612 (0%)] Loss: 0.288572\n",
      "Train Epoch: 959 [160/1612 (10%)] Loss: 0.646119\n",
      "Train Epoch: 959 [320/1612 (20%)] Loss: 0.602206\n",
      "Train Epoch: 959 [480/1612 (30%)] Loss: 0.181043\n",
      "Train Epoch: 959 [640/1612 (40%)] Loss: 0.215545\n",
      "Train Epoch: 959 [800/1612 (50%)] Loss: 0.516871\n",
      "Train Epoch: 959 [960/1612 (59%)] Loss: 0.200628\n",
      "Train Epoch: 959 [1120/1612 (69%)] Loss: 0.330569\n",
      "Train Epoch: 959 [1280/1612 (79%)] Loss: 0.179963\n",
      "Train Epoch: 959 [1440/1612 (89%)] Loss: 0.224759\n",
      "Train Epoch: 959 [1200/1612 (99%)] Loss: 0.436910\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 960 [0/1612 (0%)] Loss: 0.288797\n",
      "Train Epoch: 960 [160/1612 (10%)] Loss: 0.522002\n",
      "Train Epoch: 960 [320/1612 (20%)] Loss: 0.197727\n",
      "Train Epoch: 960 [480/1612 (30%)] Loss: 0.108194\n",
      "Train Epoch: 960 [640/1612 (40%)] Loss: 0.341101\n",
      "Train Epoch: 960 [800/1612 (50%)] Loss: 0.333832\n",
      "Train Epoch: 960 [960/1612 (59%)] Loss: 0.189811\n",
      "Train Epoch: 960 [1120/1612 (69%)] Loss: 0.359310\n",
      "Train Epoch: 960 [1280/1612 (79%)] Loss: 0.368277\n",
      "Train Epoch: 960 [1440/1612 (89%)] Loss: 0.619234\n",
      "Train Epoch: 960 [1200/1612 (99%)] Loss: 0.289099\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 961 [0/1612 (0%)] Loss: 0.148047\n",
      "Train Epoch: 961 [160/1612 (10%)] Loss: 0.379043\n",
      "Train Epoch: 961 [320/1612 (20%)] Loss: 0.318776\n",
      "Train Epoch: 961 [480/1612 (30%)] Loss: 0.128916\n",
      "Train Epoch: 961 [640/1612 (40%)] Loss: 0.595701\n",
      "Train Epoch: 961 [800/1612 (50%)] Loss: 0.296136\n",
      "Train Epoch: 961 [960/1612 (59%)] Loss: 0.264466\n",
      "Train Epoch: 961 [1120/1612 (69%)] Loss: 0.250971\n",
      "Train Epoch: 961 [1280/1612 (79%)] Loss: 0.535912\n",
      "Train Epoch: 961 [1440/1612 (89%)] Loss: 0.071741\n",
      "Train Epoch: 961 [1200/1612 (99%)] Loss: 0.440095\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 962 [0/1612 (0%)] Loss: 0.147801\n",
      "Train Epoch: 962 [160/1612 (10%)] Loss: 0.170663\n",
      "Train Epoch: 962 [320/1612 (20%)] Loss: 0.245871\n",
      "Train Epoch: 962 [480/1612 (30%)] Loss: 0.426648\n",
      "Train Epoch: 962 [640/1612 (40%)] Loss: 0.371706\n",
      "Train Epoch: 962 [800/1612 (50%)] Loss: 0.268285\n",
      "Train Epoch: 962 [960/1612 (59%)] Loss: 0.304493\n",
      "Train Epoch: 962 [1120/1612 (69%)] Loss: 0.344160\n",
      "Train Epoch: 962 [1280/1612 (79%)] Loss: 0.279892\n",
      "Train Epoch: 962 [1440/1612 (89%)] Loss: 0.243902\n",
      "Train Epoch: 962 [1200/1612 (99%)] Loss: 0.501803\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 963 [0/1612 (0%)] Loss: 0.229884\n",
      "Train Epoch: 963 [160/1612 (10%)] Loss: 0.378804\n",
      "Train Epoch: 963 [320/1612 (20%)] Loss: 0.347926\n",
      "Train Epoch: 963 [480/1612 (30%)] Loss: 0.351652\n",
      "Train Epoch: 963 [640/1612 (40%)] Loss: 0.238040\n",
      "Train Epoch: 963 [800/1612 (50%)] Loss: 0.383545\n",
      "Train Epoch: 963 [960/1612 (59%)] Loss: 0.190109\n",
      "Train Epoch: 963 [1120/1612 (69%)] Loss: 0.404938\n",
      "Train Epoch: 963 [1280/1612 (79%)] Loss: 0.341557\n",
      "Train Epoch: 963 [1440/1612 (89%)] Loss: 0.435501\n",
      "Train Epoch: 963 [1200/1612 (99%)] Loss: 0.268481\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 964 [0/1612 (0%)] Loss: 0.349721\n",
      "Train Epoch: 964 [160/1612 (10%)] Loss: 0.395878\n",
      "Train Epoch: 964 [320/1612 (20%)] Loss: 0.187389\n",
      "Train Epoch: 964 [480/1612 (30%)] Loss: 0.525766\n",
      "Train Epoch: 964 [640/1612 (40%)] Loss: 0.203950\n",
      "Train Epoch: 964 [800/1612 (50%)] Loss: 0.291903\n",
      "Train Epoch: 964 [960/1612 (59%)] Loss: 0.182884\n",
      "Train Epoch: 964 [1120/1612 (69%)] Loss: 0.343346\n",
      "Train Epoch: 964 [1280/1612 (79%)] Loss: 0.365911\n",
      "Train Epoch: 964 [1440/1612 (89%)] Loss: 0.334709\n",
      "Train Epoch: 964 [1200/1612 (99%)] Loss: 0.172008\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 965 [0/1612 (0%)] Loss: 0.099448\n",
      "Train Epoch: 965 [160/1612 (10%)] Loss: 0.418687\n",
      "Train Epoch: 965 [320/1612 (20%)] Loss: 0.189169\n",
      "Train Epoch: 965 [480/1612 (30%)] Loss: 0.406609\n",
      "Train Epoch: 965 [640/1612 (40%)] Loss: 0.155343\n",
      "Train Epoch: 965 [800/1612 (50%)] Loss: 0.474371\n",
      "Train Epoch: 965 [960/1612 (59%)] Loss: 0.477452\n",
      "Train Epoch: 965 [1120/1612 (69%)] Loss: 0.298758\n",
      "Train Epoch: 965 [1280/1612 (79%)] Loss: 0.304016\n",
      "Train Epoch: 965 [1440/1612 (89%)] Loss: 0.228950\n",
      "Train Epoch: 965 [1200/1612 (99%)] Loss: 0.293532\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 966 [0/1612 (0%)] Loss: 0.207915\n",
      "Train Epoch: 966 [160/1612 (10%)] Loss: 0.477583\n",
      "Train Epoch: 966 [320/1612 (20%)] Loss: 0.361378\n",
      "Train Epoch: 966 [480/1612 (30%)] Loss: 0.143796\n",
      "Train Epoch: 966 [640/1612 (40%)] Loss: 0.104634\n",
      "Train Epoch: 966 [800/1612 (50%)] Loss: 0.112573\n",
      "Train Epoch: 966 [960/1612 (59%)] Loss: 0.477073\n",
      "Train Epoch: 966 [1120/1612 (69%)] Loss: 0.232610\n",
      "Train Epoch: 966 [1280/1612 (79%)] Loss: 0.201506\n",
      "Train Epoch: 966 [1440/1612 (89%)] Loss: 0.510510\n",
      "Train Epoch: 966 [1200/1612 (99%)] Loss: 0.057611\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 967 [0/1612 (0%)] Loss: 0.313877\n",
      "Train Epoch: 967 [160/1612 (10%)] Loss: 0.192069\n",
      "Train Epoch: 967 [320/1612 (20%)] Loss: 0.611435\n",
      "Train Epoch: 967 [480/1612 (30%)] Loss: 0.336229\n",
      "Train Epoch: 967 [640/1612 (40%)] Loss: 0.235338\n",
      "Train Epoch: 967 [800/1612 (50%)] Loss: 0.266494\n",
      "Train Epoch: 967 [960/1612 (59%)] Loss: 0.206593\n",
      "Train Epoch: 967 [1120/1612 (69%)] Loss: 0.241110\n",
      "Train Epoch: 967 [1280/1612 (79%)] Loss: 0.228176\n",
      "Train Epoch: 967 [1440/1612 (89%)] Loss: 0.271908\n",
      "Train Epoch: 967 [1200/1612 (99%)] Loss: 0.230472\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 968 [0/1612 (0%)] Loss: 0.193520\n",
      "Train Epoch: 968 [160/1612 (10%)] Loss: 0.265793\n",
      "Train Epoch: 968 [320/1612 (20%)] Loss: 0.415079\n",
      "Train Epoch: 968 [480/1612 (30%)] Loss: 0.655451\n",
      "Train Epoch: 968 [640/1612 (40%)] Loss: 0.440323\n",
      "Train Epoch: 968 [800/1612 (50%)] Loss: 0.359243\n",
      "Train Epoch: 968 [960/1612 (59%)] Loss: 0.351869\n",
      "Train Epoch: 968 [1120/1612 (69%)] Loss: 0.308838\n",
      "Train Epoch: 968 [1280/1612 (79%)] Loss: 0.205091\n",
      "Train Epoch: 968 [1440/1612 (89%)] Loss: 0.471912\n",
      "Train Epoch: 968 [1200/1612 (99%)] Loss: 0.320905\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 969 [0/1612 (0%)] Loss: 0.317345\n",
      "Train Epoch: 969 [160/1612 (10%)] Loss: 0.326199\n",
      "Train Epoch: 969 [320/1612 (20%)] Loss: 0.373190\n",
      "Train Epoch: 969 [480/1612 (30%)] Loss: 0.346149\n",
      "Train Epoch: 969 [640/1612 (40%)] Loss: 0.283777\n",
      "Train Epoch: 969 [800/1612 (50%)] Loss: 0.176518\n",
      "Train Epoch: 969 [960/1612 (59%)] Loss: 0.327845\n",
      "Train Epoch: 969 [1120/1612 (69%)] Loss: 0.223500\n",
      "Train Epoch: 969 [1280/1612 (79%)] Loss: 0.362291\n",
      "Train Epoch: 969 [1440/1612 (89%)] Loss: 0.289024\n",
      "Train Epoch: 969 [1200/1612 (99%)] Loss: 0.397337\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 970 [0/1612 (0%)] Loss: 0.362066\n",
      "Train Epoch: 970 [160/1612 (10%)] Loss: 0.588968\n",
      "Train Epoch: 970 [320/1612 (20%)] Loss: 0.304178\n",
      "Train Epoch: 970 [480/1612 (30%)] Loss: 0.173350\n",
      "Train Epoch: 970 [640/1612 (40%)] Loss: 0.275764\n",
      "Train Epoch: 970 [800/1612 (50%)] Loss: 0.199871\n",
      "Train Epoch: 970 [960/1612 (59%)] Loss: 0.554537\n",
      "Train Epoch: 970 [1120/1612 (69%)] Loss: 0.193083\n",
      "Train Epoch: 970 [1280/1612 (79%)] Loss: 0.260979\n",
      "Train Epoch: 970 [1440/1612 (89%)] Loss: 0.319776\n",
      "Train Epoch: 970 [1200/1612 (99%)] Loss: 0.451657\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 971 [0/1612 (0%)] Loss: 0.168815\n",
      "Train Epoch: 971 [160/1612 (10%)] Loss: 0.580297\n",
      "Train Epoch: 971 [320/1612 (20%)] Loss: 0.333376\n",
      "Train Epoch: 971 [480/1612 (30%)] Loss: 0.377223\n",
      "Train Epoch: 971 [640/1612 (40%)] Loss: 0.414926\n",
      "Train Epoch: 971 [800/1612 (50%)] Loss: 0.084182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 971 [960/1612 (59%)] Loss: 0.293822\n",
      "Train Epoch: 971 [1120/1612 (69%)] Loss: 0.532313\n",
      "Train Epoch: 971 [1280/1612 (79%)] Loss: 0.155313\n",
      "Train Epoch: 971 [1440/1612 (89%)] Loss: 0.298443\n",
      "Train Epoch: 971 [1200/1612 (99%)] Loss: 0.438700\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 972 [0/1612 (0%)] Loss: 0.206910\n",
      "Train Epoch: 972 [160/1612 (10%)] Loss: 0.402952\n",
      "Train Epoch: 972 [320/1612 (20%)] Loss: 0.329712\n",
      "Train Epoch: 972 [480/1612 (30%)] Loss: 0.541804\n",
      "Train Epoch: 972 [640/1612 (40%)] Loss: 0.194228\n",
      "Train Epoch: 972 [800/1612 (50%)] Loss: 0.390554\n",
      "Train Epoch: 972 [960/1612 (59%)] Loss: 0.319421\n",
      "Train Epoch: 972 [1120/1612 (69%)] Loss: 0.362842\n",
      "Train Epoch: 972 [1280/1612 (79%)] Loss: 0.159786\n",
      "Train Epoch: 972 [1440/1612 (89%)] Loss: 0.146692\n",
      "Train Epoch: 972 [1200/1612 (99%)] Loss: 0.246222\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 973 [0/1612 (0%)] Loss: 0.350482\n",
      "Train Epoch: 973 [160/1612 (10%)] Loss: 0.238056\n",
      "Train Epoch: 973 [320/1612 (20%)] Loss: 0.370772\n",
      "Train Epoch: 973 [480/1612 (30%)] Loss: 0.268446\n",
      "Train Epoch: 973 [640/1612 (40%)] Loss: 0.156360\n",
      "Train Epoch: 973 [800/1612 (50%)] Loss: 0.511016\n",
      "Train Epoch: 973 [960/1612 (59%)] Loss: 0.329181\n",
      "Train Epoch: 973 [1120/1612 (69%)] Loss: 0.243103\n",
      "Train Epoch: 973 [1280/1612 (79%)] Loss: 0.390948\n",
      "Train Epoch: 973 [1440/1612 (89%)] Loss: 0.533763\n",
      "Train Epoch: 973 [1200/1612 (99%)] Loss: 0.171219\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 974 [0/1612 (0%)] Loss: 0.164852\n",
      "Train Epoch: 974 [160/1612 (10%)] Loss: 0.172200\n",
      "Train Epoch: 974 [320/1612 (20%)] Loss: 0.278875\n",
      "Train Epoch: 974 [480/1612 (30%)] Loss: 0.283927\n",
      "Train Epoch: 974 [640/1612 (40%)] Loss: 0.417644\n",
      "Train Epoch: 974 [800/1612 (50%)] Loss: 0.108417\n",
      "Train Epoch: 974 [960/1612 (59%)] Loss: 0.276915\n",
      "Train Epoch: 974 [1120/1612 (69%)] Loss: 0.370129\n",
      "Train Epoch: 974 [1280/1612 (79%)] Loss: 0.440105\n",
      "Train Epoch: 974 [1440/1612 (89%)] Loss: 0.182311\n",
      "Train Epoch: 974 [1200/1612 (99%)] Loss: 0.279642\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 975 [0/1612 (0%)] Loss: 0.277305\n",
      "Train Epoch: 975 [160/1612 (10%)] Loss: 0.338731\n",
      "Train Epoch: 975 [320/1612 (20%)] Loss: 0.273536\n",
      "Train Epoch: 975 [480/1612 (30%)] Loss: 0.550696\n",
      "Train Epoch: 975 [640/1612 (40%)] Loss: 0.262089\n",
      "Train Epoch: 975 [800/1612 (50%)] Loss: 0.148645\n",
      "Train Epoch: 975 [960/1612 (59%)] Loss: 0.248416\n",
      "Train Epoch: 975 [1120/1612 (69%)] Loss: 0.493863\n",
      "Train Epoch: 975 [1280/1612 (79%)] Loss: 0.089817\n",
      "Train Epoch: 975 [1440/1612 (89%)] Loss: 0.275700\n",
      "Train Epoch: 975 [1200/1612 (99%)] Loss: 0.351122\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 976 [0/1612 (0%)] Loss: 0.331643\n",
      "Train Epoch: 976 [160/1612 (10%)] Loss: 0.377077\n",
      "Train Epoch: 976 [320/1612 (20%)] Loss: 0.350332\n",
      "Train Epoch: 976 [480/1612 (30%)] Loss: 0.718229\n",
      "Train Epoch: 976 [640/1612 (40%)] Loss: 0.206568\n",
      "Train Epoch: 976 [800/1612 (50%)] Loss: 0.335920\n",
      "Train Epoch: 976 [960/1612 (59%)] Loss: 0.796414\n",
      "Train Epoch: 976 [1120/1612 (69%)] Loss: 0.360423\n",
      "Train Epoch: 976 [1280/1612 (79%)] Loss: 0.221969\n",
      "Train Epoch: 976 [1440/1612 (89%)] Loss: 0.163487\n",
      "Train Epoch: 976 [1200/1612 (99%)] Loss: 0.042986\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 977 [0/1612 (0%)] Loss: 0.309519\n",
      "Train Epoch: 977 [160/1612 (10%)] Loss: 0.405560\n",
      "Train Epoch: 977 [320/1612 (20%)] Loss: 0.436892\n",
      "Train Epoch: 977 [480/1612 (30%)] Loss: 0.395481\n",
      "Train Epoch: 977 [640/1612 (40%)] Loss: 0.356891\n",
      "Train Epoch: 977 [800/1612 (50%)] Loss: 0.316723\n",
      "Train Epoch: 977 [960/1612 (59%)] Loss: 0.338469\n",
      "Train Epoch: 977 [1120/1612 (69%)] Loss: 0.437688\n",
      "Train Epoch: 977 [1280/1612 (79%)] Loss: 0.185552\n",
      "Train Epoch: 977 [1440/1612 (89%)] Loss: 0.307774\n",
      "Train Epoch: 977 [1200/1612 (99%)] Loss: 0.342899\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 978 [0/1612 (0%)] Loss: 0.416398\n",
      "Train Epoch: 978 [160/1612 (10%)] Loss: 0.485849\n",
      "Train Epoch: 978 [320/1612 (20%)] Loss: 0.191021\n",
      "Train Epoch: 978 [480/1612 (30%)] Loss: 0.335873\n",
      "Train Epoch: 978 [640/1612 (40%)] Loss: 0.392788\n",
      "Train Epoch: 978 [800/1612 (50%)] Loss: 0.235014\n",
      "Train Epoch: 978 [960/1612 (59%)] Loss: 0.290390\n",
      "Train Epoch: 978 [1120/1612 (69%)] Loss: 0.353687\n",
      "Train Epoch: 978 [1280/1612 (79%)] Loss: 0.334664\n",
      "Train Epoch: 978 [1440/1612 (89%)] Loss: 0.261419\n",
      "Train Epoch: 978 [1200/1612 (99%)] Loss: 0.640920\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 979 [0/1612 (0%)] Loss: 0.235544\n",
      "Train Epoch: 979 [160/1612 (10%)] Loss: 0.193719\n",
      "Train Epoch: 979 [320/1612 (20%)] Loss: 0.260273\n",
      "Train Epoch: 979 [480/1612 (30%)] Loss: 0.261094\n",
      "Train Epoch: 979 [640/1612 (40%)] Loss: 0.423677\n",
      "Train Epoch: 979 [800/1612 (50%)] Loss: 0.369601\n",
      "Train Epoch: 979 [960/1612 (59%)] Loss: 0.254785\n",
      "Train Epoch: 979 [1120/1612 (69%)] Loss: 0.216342\n",
      "Train Epoch: 979 [1280/1612 (79%)] Loss: 0.272961\n",
      "Train Epoch: 979 [1440/1612 (89%)] Loss: 0.304356\n",
      "Train Epoch: 979 [1200/1612 (99%)] Loss: 0.315618\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 980 [0/1612 (0%)] Loss: 0.149536\n",
      "Train Epoch: 980 [160/1612 (10%)] Loss: 0.281693\n",
      "Train Epoch: 980 [320/1612 (20%)] Loss: 0.527775\n",
      "Train Epoch: 980 [480/1612 (30%)] Loss: 0.376367\n",
      "Train Epoch: 980 [640/1612 (40%)] Loss: 0.417323\n",
      "Train Epoch: 980 [800/1612 (50%)] Loss: 0.119161\n",
      "Train Epoch: 980 [960/1612 (59%)] Loss: 0.149893\n",
      "Train Epoch: 980 [1120/1612 (69%)] Loss: 0.304623\n",
      "Train Epoch: 980 [1280/1612 (79%)] Loss: 0.334753\n",
      "Train Epoch: 980 [1440/1612 (89%)] Loss: 0.355893\n",
      "Train Epoch: 980 [1200/1612 (99%)] Loss: 0.534967\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 981 [0/1612 (0%)] Loss: 0.510213\n",
      "Train Epoch: 981 [160/1612 (10%)] Loss: 0.318694\n",
      "Train Epoch: 981 [320/1612 (20%)] Loss: 0.312708\n",
      "Train Epoch: 981 [480/1612 (30%)] Loss: 0.243359\n",
      "Train Epoch: 981 [640/1612 (40%)] Loss: 0.595053\n",
      "Train Epoch: 981 [800/1612 (50%)] Loss: 0.381328\n",
      "Train Epoch: 981 [960/1612 (59%)] Loss: 0.384005\n",
      "Train Epoch: 981 [1120/1612 (69%)] Loss: 0.184983\n",
      "Train Epoch: 981 [1280/1612 (79%)] Loss: 0.288711\n",
      "Train Epoch: 981 [1440/1612 (89%)] Loss: 0.351371\n",
      "Train Epoch: 981 [1200/1612 (99%)] Loss: 0.419194\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 982 [0/1612 (0%)] Loss: 0.168499\n",
      "Train Epoch: 982 [160/1612 (10%)] Loss: 0.294178\n",
      "Train Epoch: 982 [320/1612 (20%)] Loss: 0.371245\n",
      "Train Epoch: 982 [480/1612 (30%)] Loss: 0.484473\n",
      "Train Epoch: 982 [640/1612 (40%)] Loss: 0.275237\n",
      "Train Epoch: 982 [800/1612 (50%)] Loss: 0.175473\n",
      "Train Epoch: 982 [960/1612 (59%)] Loss: 0.349501\n",
      "Train Epoch: 982 [1120/1612 (69%)] Loss: 0.431602\n",
      "Train Epoch: 982 [1280/1612 (79%)] Loss: 0.424127\n",
      "Train Epoch: 982 [1440/1612 (89%)] Loss: 0.416296\n",
      "Train Epoch: 982 [1200/1612 (99%)] Loss: 0.247102\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 983 [0/1612 (0%)] Loss: 0.234609\n",
      "Train Epoch: 983 [160/1612 (10%)] Loss: 0.232772\n",
      "Train Epoch: 983 [320/1612 (20%)] Loss: 0.481357\n",
      "Train Epoch: 983 [480/1612 (30%)] Loss: 0.147908\n",
      "Train Epoch: 983 [640/1612 (40%)] Loss: 0.213836\n",
      "Train Epoch: 983 [800/1612 (50%)] Loss: 0.197671\n",
      "Train Epoch: 983 [960/1612 (59%)] Loss: 0.245838\n",
      "Train Epoch: 983 [1120/1612 (69%)] Loss: 0.407229\n",
      "Train Epoch: 983 [1280/1612 (79%)] Loss: 0.260157\n",
      "Train Epoch: 983 [1440/1612 (89%)] Loss: 0.326019\n",
      "Train Epoch: 983 [1200/1612 (99%)] Loss: 0.258035\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 984 [0/1612 (0%)] Loss: 0.368249\n",
      "Train Epoch: 984 [160/1612 (10%)] Loss: 0.209154\n",
      "Train Epoch: 984 [320/1612 (20%)] Loss: 0.311853\n",
      "Train Epoch: 984 [480/1612 (30%)] Loss: 0.261010\n",
      "Train Epoch: 984 [640/1612 (40%)] Loss: 0.471263\n",
      "Train Epoch: 984 [800/1612 (50%)] Loss: 0.178396\n",
      "Train Epoch: 984 [960/1612 (59%)] Loss: 0.232270\n",
      "Train Epoch: 984 [1120/1612 (69%)] Loss: 0.309279\n",
      "Train Epoch: 984 [1280/1612 (79%)] Loss: 0.508830\n",
      "Train Epoch: 984 [1440/1612 (89%)] Loss: 0.436030\n",
      "Train Epoch: 984 [1200/1612 (99%)] Loss: 0.361864\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 985 [0/1612 (0%)] Loss: 0.341912\n",
      "Train Epoch: 985 [160/1612 (10%)] Loss: 0.437883\n",
      "Train Epoch: 985 [320/1612 (20%)] Loss: 0.361451\n",
      "Train Epoch: 985 [480/1612 (30%)] Loss: 0.248322\n",
      "Train Epoch: 985 [640/1612 (40%)] Loss: 0.265196\n",
      "Train Epoch: 985 [800/1612 (50%)] Loss: 0.470879\n",
      "Train Epoch: 985 [960/1612 (59%)] Loss: 0.440431\n",
      "Train Epoch: 985 [1120/1612 (69%)] Loss: 0.477211\n",
      "Train Epoch: 985 [1280/1612 (79%)] Loss: 0.314158\n",
      "Train Epoch: 985 [1440/1612 (89%)] Loss: 0.525104\n",
      "Train Epoch: 985 [1200/1612 (99%)] Loss: 0.113552\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 986 [0/1612 (0%)] Loss: 0.210512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 986 [160/1612 (10%)] Loss: 0.637627\n",
      "Train Epoch: 986 [320/1612 (20%)] Loss: 0.282569\n",
      "Train Epoch: 986 [480/1612 (30%)] Loss: 0.297574\n",
      "Train Epoch: 986 [640/1612 (40%)] Loss: 0.237276\n",
      "Train Epoch: 986 [800/1612 (50%)] Loss: 0.091148\n",
      "Train Epoch: 986 [960/1612 (59%)] Loss: 0.307596\n",
      "Train Epoch: 986 [1120/1612 (69%)] Loss: 0.382486\n",
      "Train Epoch: 986 [1280/1612 (79%)] Loss: 0.210665\n",
      "Train Epoch: 986 [1440/1612 (89%)] Loss: 0.137219\n",
      "Train Epoch: 986 [1200/1612 (99%)] Loss: 0.434833\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 987 [0/1612 (0%)] Loss: 0.449711\n",
      "Train Epoch: 987 [160/1612 (10%)] Loss: 0.182417\n",
      "Train Epoch: 987 [320/1612 (20%)] Loss: 0.244840\n",
      "Train Epoch: 987 [480/1612 (30%)] Loss: 0.292401\n",
      "Train Epoch: 987 [640/1612 (40%)] Loss: 0.162201\n",
      "Train Epoch: 987 [800/1612 (50%)] Loss: 0.284747\n",
      "Train Epoch: 987 [960/1612 (59%)] Loss: 0.340457\n",
      "Train Epoch: 987 [1120/1612 (69%)] Loss: 0.337526\n",
      "Train Epoch: 987 [1280/1612 (79%)] Loss: 0.220148\n",
      "Train Epoch: 987 [1440/1612 (89%)] Loss: 0.255554\n",
      "Train Epoch: 987 [1200/1612 (99%)] Loss: 0.087860\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 988 [0/1612 (0%)] Loss: 0.092971\n",
      "Train Epoch: 988 [160/1612 (10%)] Loss: 0.106818\n",
      "Train Epoch: 988 [320/1612 (20%)] Loss: 0.272750\n",
      "Train Epoch: 988 [480/1612 (30%)] Loss: 0.246152\n",
      "Train Epoch: 988 [640/1612 (40%)] Loss: 0.265913\n",
      "Train Epoch: 988 [800/1612 (50%)] Loss: 0.344583\n",
      "Train Epoch: 988 [960/1612 (59%)] Loss: 0.169147\n",
      "Train Epoch: 988 [1120/1612 (69%)] Loss: 0.168824\n",
      "Train Epoch: 988 [1280/1612 (79%)] Loss: 0.185181\n",
      "Train Epoch: 988 [1440/1612 (89%)] Loss: 0.169992\n",
      "Train Epoch: 988 [1200/1612 (99%)] Loss: 0.287466\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 989 [0/1612 (0%)] Loss: 0.190868\n",
      "Train Epoch: 989 [160/1612 (10%)] Loss: 0.173747\n",
      "Train Epoch: 989 [320/1612 (20%)] Loss: 0.183864\n",
      "Train Epoch: 989 [480/1612 (30%)] Loss: 0.455036\n",
      "Train Epoch: 989 [640/1612 (40%)] Loss: 0.505456\n",
      "Train Epoch: 989 [800/1612 (50%)] Loss: 0.305221\n",
      "Train Epoch: 989 [960/1612 (59%)] Loss: 0.465292\n",
      "Train Epoch: 989 [1120/1612 (69%)] Loss: 0.283248\n",
      "Train Epoch: 989 [1280/1612 (79%)] Loss: 0.224743\n",
      "Train Epoch: 989 [1440/1612 (89%)] Loss: 0.289019\n",
      "Train Epoch: 989 [1200/1612 (99%)] Loss: 0.274702\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 990 [0/1612 (0%)] Loss: 0.312011\n",
      "Train Epoch: 990 [160/1612 (10%)] Loss: 0.136862\n",
      "Train Epoch: 990 [320/1612 (20%)] Loss: 0.293685\n",
      "Train Epoch: 990 [480/1612 (30%)] Loss: 0.104522\n",
      "Train Epoch: 990 [640/1612 (40%)] Loss: 0.311396\n",
      "Train Epoch: 990 [800/1612 (50%)] Loss: 0.245117\n",
      "Train Epoch: 990 [960/1612 (59%)] Loss: 0.409730\n",
      "Train Epoch: 990 [1120/1612 (69%)] Loss: 0.409562\n",
      "Train Epoch: 990 [1280/1612 (79%)] Loss: 0.335345\n",
      "Train Epoch: 990 [1440/1612 (89%)] Loss: 0.486992\n",
      "Train Epoch: 990 [1200/1612 (99%)] Loss: 0.440450\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 991 [0/1612 (0%)] Loss: 0.325106\n",
      "Train Epoch: 991 [160/1612 (10%)] Loss: 0.283563\n",
      "Train Epoch: 991 [320/1612 (20%)] Loss: 0.112468\n",
      "Train Epoch: 991 [480/1612 (30%)] Loss: 0.183470\n",
      "Train Epoch: 991 [640/1612 (40%)] Loss: 0.348931\n",
      "Train Epoch: 991 [800/1612 (50%)] Loss: 0.278861\n",
      "Train Epoch: 991 [960/1612 (59%)] Loss: 0.250883\n",
      "Train Epoch: 991 [1120/1612 (69%)] Loss: 0.387831\n",
      "Train Epoch: 991 [1280/1612 (79%)] Loss: 0.250804\n",
      "Train Epoch: 991 [1440/1612 (89%)] Loss: 0.141581\n",
      "Train Epoch: 991 [1200/1612 (99%)] Loss: 0.235215\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 992 [0/1612 (0%)] Loss: 0.427895\n",
      "Train Epoch: 992 [160/1612 (10%)] Loss: 0.221712\n",
      "Train Epoch: 992 [320/1612 (20%)] Loss: 0.183108\n",
      "Train Epoch: 992 [480/1612 (30%)] Loss: 0.208573\n",
      "Train Epoch: 992 [640/1612 (40%)] Loss: 0.311067\n",
      "Train Epoch: 992 [800/1612 (50%)] Loss: 0.081830\n",
      "Train Epoch: 992 [960/1612 (59%)] Loss: 0.066029\n",
      "Train Epoch: 992 [1120/1612 (69%)] Loss: 0.199843\n",
      "Train Epoch: 992 [1280/1612 (79%)] Loss: 0.210916\n",
      "Train Epoch: 992 [1440/1612 (89%)] Loss: 0.504691\n",
      "Train Epoch: 992 [1200/1612 (99%)] Loss: 0.192817\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 993 [0/1612 (0%)] Loss: 0.357986\n",
      "Train Epoch: 993 [160/1612 (10%)] Loss: 0.125701\n",
      "Train Epoch: 993 [320/1612 (20%)] Loss: 0.173505\n",
      "Train Epoch: 993 [480/1612 (30%)] Loss: 0.272681\n",
      "Train Epoch: 993 [640/1612 (40%)] Loss: 0.314281\n",
      "Train Epoch: 993 [800/1612 (50%)] Loss: 0.228712\n",
      "Train Epoch: 993 [960/1612 (59%)] Loss: 0.185539\n",
      "Train Epoch: 993 [1120/1612 (69%)] Loss: 0.607290\n",
      "Train Epoch: 993 [1280/1612 (79%)] Loss: 0.333735\n",
      "Train Epoch: 993 [1440/1612 (89%)] Loss: 0.378403\n",
      "Train Epoch: 993 [1200/1612 (99%)] Loss: 0.336858\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 994 [0/1612 (0%)] Loss: 0.571229\n",
      "Train Epoch: 994 [160/1612 (10%)] Loss: 0.246843\n",
      "Train Epoch: 994 [320/1612 (20%)] Loss: 0.267806\n",
      "Train Epoch: 994 [480/1612 (30%)] Loss: 0.217142\n",
      "Train Epoch: 994 [640/1612 (40%)] Loss: 0.465919\n",
      "Train Epoch: 994 [800/1612 (50%)] Loss: 0.111964\n",
      "Train Epoch: 994 [960/1612 (59%)] Loss: 0.228255\n",
      "Train Epoch: 994 [1120/1612 (69%)] Loss: 0.117157\n",
      "Train Epoch: 994 [1280/1612 (79%)] Loss: 0.195524\n",
      "Train Epoch: 994 [1440/1612 (89%)] Loss: 0.164419\n",
      "Train Epoch: 994 [1200/1612 (99%)] Loss: 0.324338\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 995 [0/1612 (0%)] Loss: 0.126380\n",
      "Train Epoch: 995 [160/1612 (10%)] Loss: 0.207226\n",
      "Train Epoch: 995 [320/1612 (20%)] Loss: 0.324577\n",
      "Train Epoch: 995 [480/1612 (30%)] Loss: 0.160008\n",
      "Train Epoch: 995 [640/1612 (40%)] Loss: 0.194345\n",
      "Train Epoch: 995 [800/1612 (50%)] Loss: 0.311208\n",
      "Train Epoch: 995 [960/1612 (59%)] Loss: 0.337047\n",
      "Train Epoch: 995 [1120/1612 (69%)] Loss: 0.366742\n",
      "Train Epoch: 995 [1280/1612 (79%)] Loss: 0.543489\n",
      "Train Epoch: 995 [1440/1612 (89%)] Loss: 0.228695\n",
      "Train Epoch: 995 [1200/1612 (99%)] Loss: 0.192331\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 996 [0/1612 (0%)] Loss: 0.292917\n",
      "Train Epoch: 996 [160/1612 (10%)] Loss: 0.121801\n",
      "Train Epoch: 996 [320/1612 (20%)] Loss: 0.214553\n",
      "Train Epoch: 996 [480/1612 (30%)] Loss: 0.354247\n",
      "Train Epoch: 996 [640/1612 (40%)] Loss: 0.465309\n",
      "Train Epoch: 996 [800/1612 (50%)] Loss: 0.218670\n",
      "Train Epoch: 996 [960/1612 (59%)] Loss: 0.364024\n",
      "Train Epoch: 996 [1120/1612 (69%)] Loss: 0.228064\n",
      "Train Epoch: 996 [1280/1612 (79%)] Loss: 0.277559\n",
      "Train Epoch: 996 [1440/1612 (89%)] Loss: 0.196622\n",
      "Train Epoch: 996 [1200/1612 (99%)] Loss: 0.173972\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 997 [0/1612 (0%)] Loss: 0.203176\n",
      "Train Epoch: 997 [160/1612 (10%)] Loss: 0.338750\n",
      "Train Epoch: 997 [320/1612 (20%)] Loss: 0.198621\n",
      "Train Epoch: 997 [480/1612 (30%)] Loss: 0.215272\n",
      "Train Epoch: 997 [640/1612 (40%)] Loss: 0.442391\n",
      "Train Epoch: 997 [800/1612 (50%)] Loss: 0.289853\n",
      "Train Epoch: 997 [960/1612 (59%)] Loss: 0.282571\n",
      "Train Epoch: 997 [1120/1612 (69%)] Loss: 0.432243\n",
      "Train Epoch: 997 [1280/1612 (79%)] Loss: 0.054094\n",
      "Train Epoch: 997 [1440/1612 (89%)] Loss: 0.487822\n",
      "Train Epoch: 997 [1200/1612 (99%)] Loss: 0.425922\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 998 [0/1612 (0%)] Loss: 0.220920\n",
      "Train Epoch: 998 [160/1612 (10%)] Loss: 0.409063\n",
      "Train Epoch: 998 [320/1612 (20%)] Loss: 0.120714\n",
      "Train Epoch: 998 [480/1612 (30%)] Loss: 0.254963\n",
      "Train Epoch: 998 [640/1612 (40%)] Loss: 0.375029\n",
      "Train Epoch: 998 [800/1612 (50%)] Loss: 0.483125\n",
      "Train Epoch: 998 [960/1612 (59%)] Loss: 0.253461\n",
      "Train Epoch: 998 [1120/1612 (69%)] Loss: 0.333233\n",
      "Train Epoch: 998 [1280/1612 (79%)] Loss: 0.178766\n",
      "Train Epoch: 998 [1440/1612 (89%)] Loss: 0.129180\n",
      "Train Epoch: 998 [1200/1612 (99%)] Loss: 0.294951\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 999 [0/1612 (0%)] Loss: 0.295193\n",
      "Train Epoch: 999 [160/1612 (10%)] Loss: 0.224926\n",
      "Train Epoch: 999 [320/1612 (20%)] Loss: 0.256545\n",
      "Train Epoch: 999 [480/1612 (30%)] Loss: 0.474132\n",
      "Train Epoch: 999 [640/1612 (40%)] Loss: 0.210080\n",
      "Train Epoch: 999 [800/1612 (50%)] Loss: 0.328889\n",
      "Train Epoch: 999 [960/1612 (59%)] Loss: 0.191717\n",
      "Train Epoch: 999 [1120/1612 (69%)] Loss: 0.190988\n",
      "Train Epoch: 999 [1280/1612 (79%)] Loss: 0.274649\n",
      "Train Epoch: 999 [1440/1612 (89%)] Loss: 0.268597\n",
      "Train Epoch: 999 [1200/1612 (99%)] Loss: 0.217778\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1000 [0/1612 (0%)] Loss: 0.275188\n",
      "Train Epoch: 1000 [160/1612 (10%)] Loss: 0.175807\n",
      "Train Epoch: 1000 [320/1612 (20%)] Loss: 0.220387\n",
      "Train Epoch: 1000 [480/1612 (30%)] Loss: 0.355032\n",
      "Train Epoch: 1000 [640/1612 (40%)] Loss: 0.351014\n",
      "Train Epoch: 1000 [800/1612 (50%)] Loss: 0.134301\n",
      "Train Epoch: 1000 [960/1612 (59%)] Loss: 0.335753\n",
      "Train Epoch: 1000 [1120/1612 (69%)] Loss: 0.414625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1000 [1280/1612 (79%)] Loss: 0.300955\n",
      "Train Epoch: 1000 [1440/1612 (89%)] Loss: 0.430967\n",
      "Train Epoch: 1000 [1200/1612 (99%)] Loss: 0.612192\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1001 [0/1612 (0%)] Loss: 0.342621\n",
      "Train Epoch: 1001 [160/1612 (10%)] Loss: 0.266432\n",
      "Train Epoch: 1001 [320/1612 (20%)] Loss: 0.411807\n",
      "Train Epoch: 1001 [480/1612 (30%)] Loss: 0.483489\n",
      "Train Epoch: 1001 [640/1612 (40%)] Loss: 0.290491\n",
      "Train Epoch: 1001 [800/1612 (50%)] Loss: 0.299345\n",
      "Train Epoch: 1001 [960/1612 (59%)] Loss: 0.437595\n",
      "Train Epoch: 1001 [1120/1612 (69%)] Loss: 0.186492\n",
      "Train Epoch: 1001 [1280/1612 (79%)] Loss: 0.316800\n",
      "Train Epoch: 1001 [1440/1612 (89%)] Loss: 0.173076\n",
      "Train Epoch: 1001 [1200/1612 (99%)] Loss: 0.106602\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1002 [0/1612 (0%)] Loss: 0.261765\n",
      "Train Epoch: 1002 [160/1612 (10%)] Loss: 0.360336\n",
      "Train Epoch: 1002 [320/1612 (20%)] Loss: 0.280545\n",
      "Train Epoch: 1002 [480/1612 (30%)] Loss: 0.098252\n",
      "Train Epoch: 1002 [640/1612 (40%)] Loss: 0.485425\n",
      "Train Epoch: 1002 [800/1612 (50%)] Loss: 0.235362\n",
      "Train Epoch: 1002 [960/1612 (59%)] Loss: 0.359394\n",
      "Train Epoch: 1002 [1120/1612 (69%)] Loss: 0.195998\n",
      "Train Epoch: 1002 [1280/1612 (79%)] Loss: 0.287556\n",
      "Train Epoch: 1002 [1440/1612 (89%)] Loss: 0.151248\n",
      "Train Epoch: 1002 [1200/1612 (99%)] Loss: 0.396479\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1003 [0/1612 (0%)] Loss: 0.182720\n",
      "Train Epoch: 1003 [160/1612 (10%)] Loss: 0.067655\n",
      "Train Epoch: 1003 [320/1612 (20%)] Loss: 0.301388\n",
      "Train Epoch: 1003 [480/1612 (30%)] Loss: 0.680836\n",
      "Train Epoch: 1003 [640/1612 (40%)] Loss: 0.382306\n",
      "Train Epoch: 1003 [800/1612 (50%)] Loss: 0.549286\n",
      "Train Epoch: 1003 [960/1612 (59%)] Loss: 0.331687\n",
      "Train Epoch: 1003 [1120/1612 (69%)] Loss: 0.388688\n",
      "Train Epoch: 1003 [1280/1612 (79%)] Loss: 0.373165\n",
      "Train Epoch: 1003 [1440/1612 (89%)] Loss: 0.482879\n",
      "Train Epoch: 1003 [1200/1612 (99%)] Loss: 1.011304\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1004 [0/1612 (0%)] Loss: 0.130326\n",
      "Train Epoch: 1004 [160/1612 (10%)] Loss: 0.302082\n",
      "Train Epoch: 1004 [320/1612 (20%)] Loss: 0.383855\n",
      "Train Epoch: 1004 [480/1612 (30%)] Loss: 0.205204\n",
      "Train Epoch: 1004 [640/1612 (40%)] Loss: 0.609230\n",
      "Train Epoch: 1004 [800/1612 (50%)] Loss: 0.418683\n",
      "Train Epoch: 1004 [960/1612 (59%)] Loss: 0.395419\n",
      "Train Epoch: 1004 [1120/1612 (69%)] Loss: 0.170441\n",
      "Train Epoch: 1004 [1280/1612 (79%)] Loss: 0.206574\n",
      "Train Epoch: 1004 [1440/1612 (89%)] Loss: 0.122539\n",
      "Train Epoch: 1004 [1200/1612 (99%)] Loss: 0.234879\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1005 [0/1612 (0%)] Loss: 0.134487\n",
      "Train Epoch: 1005 [160/1612 (10%)] Loss: 0.176537\n",
      "Train Epoch: 1005 [320/1612 (20%)] Loss: 0.208994\n",
      "Train Epoch: 1005 [480/1612 (30%)] Loss: 0.336650\n",
      "Train Epoch: 1005 [640/1612 (40%)] Loss: 0.380570\n",
      "Train Epoch: 1005 [800/1612 (50%)] Loss: 0.258057\n",
      "Train Epoch: 1005 [960/1612 (59%)] Loss: 0.197855\n",
      "Train Epoch: 1005 [1120/1612 (69%)] Loss: 0.208092\n",
      "Train Epoch: 1005 [1280/1612 (79%)] Loss: 0.285951\n",
      "Train Epoch: 1005 [1440/1612 (89%)] Loss: 0.334015\n",
      "Train Epoch: 1005 [1200/1612 (99%)] Loss: 0.276077\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1006 [0/1612 (0%)] Loss: 0.171946\n",
      "Train Epoch: 1006 [160/1612 (10%)] Loss: 0.129021\n",
      "Train Epoch: 1006 [320/1612 (20%)] Loss: 0.329439\n",
      "Train Epoch: 1006 [480/1612 (30%)] Loss: 0.178938\n",
      "Train Epoch: 1006 [640/1612 (40%)] Loss: 0.145812\n",
      "Train Epoch: 1006 [800/1612 (50%)] Loss: 0.360415\n",
      "Train Epoch: 1006 [960/1612 (59%)] Loss: 0.496245\n",
      "Train Epoch: 1006 [1120/1612 (69%)] Loss: 0.295148\n",
      "Train Epoch: 1006 [1280/1612 (79%)] Loss: 0.347334\n",
      "Train Epoch: 1006 [1440/1612 (89%)] Loss: 0.351572\n",
      "Train Epoch: 1006 [1200/1612 (99%)] Loss: 0.135618\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1007 [0/1612 (0%)] Loss: 0.368970\n",
      "Train Epoch: 1007 [160/1612 (10%)] Loss: 0.206188\n",
      "Train Epoch: 1007 [320/1612 (20%)] Loss: 0.157613\n",
      "Train Epoch: 1007 [480/1612 (30%)] Loss: 0.301853\n",
      "Train Epoch: 1007 [640/1612 (40%)] Loss: 0.185128\n",
      "Train Epoch: 1007 [800/1612 (50%)] Loss: 0.267684\n",
      "Train Epoch: 1007 [960/1612 (59%)] Loss: 0.524793\n",
      "Train Epoch: 1007 [1120/1612 (69%)] Loss: 0.426918\n",
      "Train Epoch: 1007 [1280/1612 (79%)] Loss: 0.403061\n",
      "Train Epoch: 1007 [1440/1612 (89%)] Loss: 0.626476\n",
      "Train Epoch: 1007 [1200/1612 (99%)] Loss: 0.218756\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1008 [0/1612 (0%)] Loss: 0.369417\n",
      "Train Epoch: 1008 [160/1612 (10%)] Loss: 0.287479\n",
      "Train Epoch: 1008 [320/1612 (20%)] Loss: 0.176303\n",
      "Train Epoch: 1008 [480/1612 (30%)] Loss: 0.392964\n",
      "Train Epoch: 1008 [640/1612 (40%)] Loss: 0.134056\n",
      "Train Epoch: 1008 [800/1612 (50%)] Loss: 0.428857\n",
      "Train Epoch: 1008 [960/1612 (59%)] Loss: 0.361668\n",
      "Train Epoch: 1008 [1120/1612 (69%)] Loss: 0.298850\n",
      "Train Epoch: 1008 [1280/1612 (79%)] Loss: 0.111167\n",
      "Train Epoch: 1008 [1440/1612 (89%)] Loss: 0.312049\n",
      "Train Epoch: 1008 [1200/1612 (99%)] Loss: 0.399204\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1009 [0/1612 (0%)] Loss: 0.306544\n",
      "Train Epoch: 1009 [160/1612 (10%)] Loss: 0.356541\n",
      "Train Epoch: 1009 [320/1612 (20%)] Loss: 0.552302\n",
      "Train Epoch: 1009 [480/1612 (30%)] Loss: 0.277495\n",
      "Train Epoch: 1009 [640/1612 (40%)] Loss: 0.299625\n",
      "Train Epoch: 1009 [800/1612 (50%)] Loss: 0.562724\n",
      "Train Epoch: 1009 [960/1612 (59%)] Loss: 0.328007\n",
      "Train Epoch: 1009 [1120/1612 (69%)] Loss: 0.257853\n",
      "Train Epoch: 1009 [1280/1612 (79%)] Loss: 0.626046\n",
      "Train Epoch: 1009 [1440/1612 (89%)] Loss: 0.353185\n",
      "Train Epoch: 1009 [1200/1612 (99%)] Loss: 0.263422\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1010 [0/1612 (0%)] Loss: 0.222153\n",
      "Train Epoch: 1010 [160/1612 (10%)] Loss: 0.269702\n",
      "Train Epoch: 1010 [320/1612 (20%)] Loss: 0.246937\n",
      "Train Epoch: 1010 [480/1612 (30%)] Loss: 0.240666\n",
      "Train Epoch: 1010 [640/1612 (40%)] Loss: 0.175017\n",
      "Train Epoch: 1010 [800/1612 (50%)] Loss: 0.271404\n",
      "Train Epoch: 1010 [960/1612 (59%)] Loss: 0.275505\n",
      "Train Epoch: 1010 [1120/1612 (69%)] Loss: 0.200783\n",
      "Train Epoch: 1010 [1280/1612 (79%)] Loss: 0.431521\n",
      "Train Epoch: 1010 [1440/1612 (89%)] Loss: 0.376496\n",
      "Train Epoch: 1010 [1200/1612 (99%)] Loss: 0.202425\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1011 [0/1612 (0%)] Loss: 0.241090\n",
      "Train Epoch: 1011 [160/1612 (10%)] Loss: 0.323005\n",
      "Train Epoch: 1011 [320/1612 (20%)] Loss: 0.208113\n",
      "Train Epoch: 1011 [480/1612 (30%)] Loss: 0.228966\n",
      "Train Epoch: 1011 [640/1612 (40%)] Loss: 0.391993\n",
      "Train Epoch: 1011 [800/1612 (50%)] Loss: 0.320548\n",
      "Train Epoch: 1011 [960/1612 (59%)] Loss: 0.184034\n",
      "Train Epoch: 1011 [1120/1612 (69%)] Loss: 0.197982\n",
      "Train Epoch: 1011 [1280/1612 (79%)] Loss: 0.249580\n",
      "Train Epoch: 1011 [1440/1612 (89%)] Loss: 0.426311\n",
      "Train Epoch: 1011 [1200/1612 (99%)] Loss: 0.290314\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1012 [0/1612 (0%)] Loss: 0.252761\n",
      "Train Epoch: 1012 [160/1612 (10%)] Loss: 0.561859\n",
      "Train Epoch: 1012 [320/1612 (20%)] Loss: 0.317720\n",
      "Train Epoch: 1012 [480/1612 (30%)] Loss: 0.213849\n",
      "Train Epoch: 1012 [640/1612 (40%)] Loss: 0.292877\n",
      "Train Epoch: 1012 [800/1612 (50%)] Loss: 0.383475\n",
      "Train Epoch: 1012 [960/1612 (59%)] Loss: 0.485130\n",
      "Train Epoch: 1012 [1120/1612 (69%)] Loss: 0.430941\n",
      "Train Epoch: 1012 [1280/1612 (79%)] Loss: 0.429400\n",
      "Train Epoch: 1012 [1440/1612 (89%)] Loss: 0.226352\n",
      "Train Epoch: 1012 [1200/1612 (99%)] Loss: 0.190469\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1013 [0/1612 (0%)] Loss: 0.213324\n",
      "Train Epoch: 1013 [160/1612 (10%)] Loss: 0.315033\n",
      "Train Epoch: 1013 [320/1612 (20%)] Loss: 0.310880\n",
      "Train Epoch: 1013 [480/1612 (30%)] Loss: 0.134830\n",
      "Train Epoch: 1013 [640/1612 (40%)] Loss: 0.180884\n",
      "Train Epoch: 1013 [800/1612 (50%)] Loss: 0.136417\n",
      "Train Epoch: 1013 [960/1612 (59%)] Loss: 0.330583\n",
      "Train Epoch: 1013 [1120/1612 (69%)] Loss: 0.190886\n",
      "Train Epoch: 1013 [1280/1612 (79%)] Loss: 0.142587\n",
      "Train Epoch: 1013 [1440/1612 (89%)] Loss: 0.372360\n",
      "Train Epoch: 1013 [1200/1612 (99%)] Loss: 0.286518\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1014 [0/1612 (0%)] Loss: 0.437093\n",
      "Train Epoch: 1014 [160/1612 (10%)] Loss: 0.233722\n",
      "Train Epoch: 1014 [320/1612 (20%)] Loss: 0.172686\n",
      "Train Epoch: 1014 [480/1612 (30%)] Loss: 0.280124\n",
      "Train Epoch: 1014 [640/1612 (40%)] Loss: 0.324163\n",
      "Train Epoch: 1014 [800/1612 (50%)] Loss: 0.474823\n",
      "Train Epoch: 1014 [960/1612 (59%)] Loss: 0.488245\n",
      "Train Epoch: 1014 [1120/1612 (69%)] Loss: 0.290692\n",
      "Train Epoch: 1014 [1280/1612 (79%)] Loss: 0.295272\n",
      "Train Epoch: 1014 [1440/1612 (89%)] Loss: 0.341334\n",
      "Train Epoch: 1014 [1200/1612 (99%)] Loss: 0.337848\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1015 [0/1612 (0%)] Loss: 0.386190\n",
      "Train Epoch: 1015 [160/1612 (10%)] Loss: 0.209119\n",
      "Train Epoch: 1015 [320/1612 (20%)] Loss: 0.403028\n",
      "Train Epoch: 1015 [480/1612 (30%)] Loss: 0.311953\n",
      "Train Epoch: 1015 [640/1612 (40%)] Loss: 0.272870\n",
      "Train Epoch: 1015 [800/1612 (50%)] Loss: 0.278249\n",
      "Train Epoch: 1015 [960/1612 (59%)] Loss: 0.343979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1015 [1120/1612 (69%)] Loss: 0.218523\n",
      "Train Epoch: 1015 [1280/1612 (79%)] Loss: 0.223238\n",
      "Train Epoch: 1015 [1440/1612 (89%)] Loss: 0.242366\n",
      "Train Epoch: 1015 [1200/1612 (99%)] Loss: 0.307278\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1016 [0/1612 (0%)] Loss: 0.376223\n",
      "Train Epoch: 1016 [160/1612 (10%)] Loss: 0.156744\n",
      "Train Epoch: 1016 [320/1612 (20%)] Loss: 0.393707\n",
      "Train Epoch: 1016 [480/1612 (30%)] Loss: 0.349847\n",
      "Train Epoch: 1016 [640/1612 (40%)] Loss: 0.388508\n",
      "Train Epoch: 1016 [800/1612 (50%)] Loss: 0.283944\n",
      "Train Epoch: 1016 [960/1612 (59%)] Loss: 0.172152\n",
      "Train Epoch: 1016 [1120/1612 (69%)] Loss: 0.399650\n",
      "Train Epoch: 1016 [1280/1612 (79%)] Loss: 0.308232\n",
      "Train Epoch: 1016 [1440/1612 (89%)] Loss: 0.161217\n",
      "Train Epoch: 1016 [1200/1612 (99%)] Loss: 0.481084\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1017 [0/1612 (0%)] Loss: 0.365817\n",
      "Train Epoch: 1017 [160/1612 (10%)] Loss: 0.260203\n",
      "Train Epoch: 1017 [320/1612 (20%)] Loss: 0.246565\n",
      "Train Epoch: 1017 [480/1612 (30%)] Loss: 0.423573\n",
      "Train Epoch: 1017 [640/1612 (40%)] Loss: 0.227591\n",
      "Train Epoch: 1017 [800/1612 (50%)] Loss: 0.358085\n",
      "Train Epoch: 1017 [960/1612 (59%)] Loss: 0.377907\n",
      "Train Epoch: 1017 [1120/1612 (69%)] Loss: 0.307545\n",
      "Train Epoch: 1017 [1280/1612 (79%)] Loss: 0.130516\n",
      "Train Epoch: 1017 [1440/1612 (89%)] Loss: 0.401097\n",
      "Train Epoch: 1017 [1200/1612 (99%)] Loss: 0.260334\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1018 [0/1612 (0%)] Loss: 0.368289\n",
      "Train Epoch: 1018 [160/1612 (10%)] Loss: 0.376956\n",
      "Train Epoch: 1018 [320/1612 (20%)] Loss: 0.259941\n",
      "Train Epoch: 1018 [480/1612 (30%)] Loss: 0.192302\n",
      "Train Epoch: 1018 [640/1612 (40%)] Loss: 0.267045\n",
      "Train Epoch: 1018 [800/1612 (50%)] Loss: 0.209666\n",
      "Train Epoch: 1018 [960/1612 (59%)] Loss: 0.352067\n",
      "Train Epoch: 1018 [1120/1612 (69%)] Loss: 0.282885\n",
      "Train Epoch: 1018 [1280/1612 (79%)] Loss: 0.235975\n",
      "Train Epoch: 1018 [1440/1612 (89%)] Loss: 0.250893\n",
      "Train Epoch: 1018 [1200/1612 (99%)] Loss: 0.234744\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1019 [0/1612 (0%)] Loss: 0.215149\n",
      "Train Epoch: 1019 [160/1612 (10%)] Loss: 0.710921\n",
      "Train Epoch: 1019 [320/1612 (20%)] Loss: 0.223571\n",
      "Train Epoch: 1019 [480/1612 (30%)] Loss: 0.184247\n",
      "Train Epoch: 1019 [640/1612 (40%)] Loss: 0.175449\n",
      "Train Epoch: 1019 [800/1612 (50%)] Loss: 0.394569\n",
      "Train Epoch: 1019 [960/1612 (59%)] Loss: 0.199453\n",
      "Train Epoch: 1019 [1120/1612 (69%)] Loss: 0.262287\n",
      "Train Epoch: 1019 [1280/1612 (79%)] Loss: 0.276302\n",
      "Train Epoch: 1019 [1440/1612 (89%)] Loss: 0.487431\n",
      "Train Epoch: 1019 [1200/1612 (99%)] Loss: 0.532648\n",
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1020 [0/1612 (0%)] Loss: 0.129857\n",
      "Train Epoch: 1020 [160/1612 (10%)] Loss: 0.367198\n",
      "Train Epoch: 1020 [320/1612 (20%)] Loss: 0.366775\n",
      "Train Epoch: 1020 [480/1612 (30%)] Loss: 0.123172\n",
      "Train Epoch: 1020 [640/1612 (40%)] Loss: 0.219564\n",
      "Train Epoch: 1020 [800/1612 (50%)] Loss: 0.225080\n",
      "Train Epoch: 1020 [960/1612 (59%)] Loss: 0.231976\n",
      "Train Epoch: 1020 [1120/1612 (69%)] Loss: 0.245469\n",
      "Train Epoch: 1020 [1280/1612 (79%)] Loss: 0.315197\n",
      "Train Epoch: 1020 [1440/1612 (89%)] Loss: 0.190648\n",
      "Train Epoch: 1020 [1200/1612 (99%)] Loss: 0.103339\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1021 [0/1612 (0%)] Loss: 0.169271\n",
      "Train Epoch: 1021 [160/1612 (10%)] Loss: 0.349408\n",
      "Train Epoch: 1021 [320/1612 (20%)] Loss: 0.259625\n",
      "Train Epoch: 1021 [480/1612 (30%)] Loss: 0.319952\n",
      "Train Epoch: 1021 [640/1612 (40%)] Loss: 0.253401\n",
      "Train Epoch: 1021 [800/1612 (50%)] Loss: 0.327024\n",
      "Train Epoch: 1021 [960/1612 (59%)] Loss: 0.230256\n",
      "Train Epoch: 1021 [1120/1612 (69%)] Loss: 0.468005\n",
      "Train Epoch: 1021 [1280/1612 (79%)] Loss: 0.449163\n",
      "Train Epoch: 1021 [1440/1612 (89%)] Loss: 0.246070\n",
      "Train Epoch: 1021 [1200/1612 (99%)] Loss: 0.477471\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1022 [0/1612 (0%)] Loss: 0.423599\n",
      "Train Epoch: 1022 [160/1612 (10%)] Loss: 0.161088\n",
      "Train Epoch: 1022 [320/1612 (20%)] Loss: 0.209867\n",
      "Train Epoch: 1022 [480/1612 (30%)] Loss: 0.343430\n",
      "Train Epoch: 1022 [640/1612 (40%)] Loss: 0.583412\n",
      "Train Epoch: 1022 [800/1612 (50%)] Loss: 0.300137\n",
      "Train Epoch: 1022 [960/1612 (59%)] Loss: 0.161500\n",
      "Train Epoch: 1022 [1120/1612 (69%)] Loss: 0.449791\n",
      "Train Epoch: 1022 [1280/1612 (79%)] Loss: 0.241733\n",
      "Train Epoch: 1022 [1440/1612 (89%)] Loss: 0.216560\n",
      "Train Epoch: 1022 [1200/1612 (99%)] Loss: 0.218305\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1023 [0/1612 (0%)] Loss: 0.158797\n",
      "Train Epoch: 1023 [160/1612 (10%)] Loss: 0.197001\n",
      "Train Epoch: 1023 [320/1612 (20%)] Loss: 0.299361\n",
      "Train Epoch: 1023 [480/1612 (30%)] Loss: 0.203986\n",
      "Train Epoch: 1023 [640/1612 (40%)] Loss: 0.326948\n",
      "Train Epoch: 1023 [800/1612 (50%)] Loss: 0.419942\n",
      "Train Epoch: 1023 [960/1612 (59%)] Loss: 0.355439\n",
      "Train Epoch: 1023 [1120/1612 (69%)] Loss: 0.487447\n",
      "Train Epoch: 1023 [1280/1612 (79%)] Loss: 0.369294\n",
      "Train Epoch: 1023 [1440/1612 (89%)] Loss: 0.364987\n",
      "Train Epoch: 1023 [1200/1612 (99%)] Loss: 0.265353\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1024 [0/1612 (0%)] Loss: 0.215069\n",
      "Train Epoch: 1024 [160/1612 (10%)] Loss: 0.181572\n",
      "Train Epoch: 1024 [320/1612 (20%)] Loss: 0.256970\n",
      "Train Epoch: 1024 [480/1612 (30%)] Loss: 0.382233\n",
      "Train Epoch: 1024 [640/1612 (40%)] Loss: 0.298362\n",
      "Train Epoch: 1024 [800/1612 (50%)] Loss: 0.263324\n",
      "Train Epoch: 1024 [960/1612 (59%)] Loss: 0.282207\n",
      "Train Epoch: 1024 [1120/1612 (69%)] Loss: 0.291724\n",
      "Train Epoch: 1024 [1280/1612 (79%)] Loss: 0.544600\n",
      "Train Epoch: 1024 [1440/1612 (89%)] Loss: 0.577951\n",
      "Train Epoch: 1024 [1200/1612 (99%)] Loss: 0.197399\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1025 [0/1612 (0%)] Loss: 0.239066\n",
      "Train Epoch: 1025 [160/1612 (10%)] Loss: 0.406570\n",
      "Train Epoch: 1025 [320/1612 (20%)] Loss: 0.344272\n",
      "Train Epoch: 1025 [480/1612 (30%)] Loss: 0.247470\n",
      "Train Epoch: 1025 [640/1612 (40%)] Loss: 0.207797\n",
      "Train Epoch: 1025 [800/1612 (50%)] Loss: 0.455892\n",
      "Train Epoch: 1025 [960/1612 (59%)] Loss: 0.185859\n",
      "Train Epoch: 1025 [1120/1612 (69%)] Loss: 0.105836\n",
      "Train Epoch: 1025 [1280/1612 (79%)] Loss: 0.582563\n",
      "Train Epoch: 1025 [1440/1612 (89%)] Loss: 0.406027\n",
      "Train Epoch: 1025 [1200/1612 (99%)] Loss: 0.372475\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1026 [0/1612 (0%)] Loss: 0.199685\n",
      "Train Epoch: 1026 [160/1612 (10%)] Loss: 0.254283\n",
      "Train Epoch: 1026 [320/1612 (20%)] Loss: 0.125296\n",
      "Train Epoch: 1026 [480/1612 (30%)] Loss: 0.258830\n",
      "Train Epoch: 1026 [640/1612 (40%)] Loss: 0.163211\n",
      "Train Epoch: 1026 [800/1612 (50%)] Loss: 0.400485\n",
      "Train Epoch: 1026 [960/1612 (59%)] Loss: 0.287931\n",
      "Train Epoch: 1026 [1120/1612 (69%)] Loss: 0.359348\n",
      "Train Epoch: 1026 [1280/1612 (79%)] Loss: 0.436493\n",
      "Train Epoch: 1026 [1440/1612 (89%)] Loss: 0.171633\n",
      "Train Epoch: 1026 [1200/1612 (99%)] Loss: 0.081262\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1027 [0/1612 (0%)] Loss: 0.726353\n",
      "Train Epoch: 1027 [160/1612 (10%)] Loss: 0.343365\n",
      "Train Epoch: 1027 [320/1612 (20%)] Loss: 0.585451\n",
      "Train Epoch: 1027 [480/1612 (30%)] Loss: 0.313042\n",
      "Train Epoch: 1027 [640/1612 (40%)] Loss: 0.101608\n",
      "Train Epoch: 1027 [800/1612 (50%)] Loss: 0.484424\n",
      "Train Epoch: 1027 [960/1612 (59%)] Loss: 0.629429\n",
      "Train Epoch: 1027 [1120/1612 (69%)] Loss: 0.250479\n",
      "Train Epoch: 1027 [1280/1612 (79%)] Loss: 0.364493\n",
      "Train Epoch: 1027 [1440/1612 (89%)] Loss: 0.153190\n",
      "Train Epoch: 1027 [1200/1612 (99%)] Loss: 0.321147\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1028 [0/1612 (0%)] Loss: 0.450792\n",
      "Train Epoch: 1028 [160/1612 (10%)] Loss: 0.349329\n",
      "Train Epoch: 1028 [320/1612 (20%)] Loss: 0.484433\n",
      "Train Epoch: 1028 [480/1612 (30%)] Loss: 0.276068\n",
      "Train Epoch: 1028 [640/1612 (40%)] Loss: 0.350575\n",
      "Train Epoch: 1028 [800/1612 (50%)] Loss: 0.337542\n",
      "Train Epoch: 1028 [960/1612 (59%)] Loss: 0.132813\n",
      "Train Epoch: 1028 [1120/1612 (69%)] Loss: 0.082691\n",
      "Train Epoch: 1028 [1280/1612 (79%)] Loss: 0.371295\n",
      "Train Epoch: 1028 [1440/1612 (89%)] Loss: 0.180602\n",
      "Train Epoch: 1028 [1200/1612 (99%)] Loss: 0.357658\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1029 [0/1612 (0%)] Loss: 0.194991\n",
      "Train Epoch: 1029 [160/1612 (10%)] Loss: 0.179669\n",
      "Train Epoch: 1029 [320/1612 (20%)] Loss: 0.201214\n",
      "Train Epoch: 1029 [480/1612 (30%)] Loss: 0.189220\n",
      "Train Epoch: 1029 [640/1612 (40%)] Loss: 0.530975\n",
      "Train Epoch: 1029 [800/1612 (50%)] Loss: 0.221375\n",
      "Train Epoch: 1029 [960/1612 (59%)] Loss: 0.266446\n",
      "Train Epoch: 1029 [1120/1612 (69%)] Loss: 0.241480\n",
      "Train Epoch: 1029 [1280/1612 (79%)] Loss: 0.344528\n",
      "Train Epoch: 1029 [1440/1612 (89%)] Loss: 0.431901\n",
      "Train Epoch: 1029 [1200/1612 (99%)] Loss: 0.480175\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1030 [0/1612 (0%)] Loss: 0.296641\n",
      "Train Epoch: 1030 [160/1612 (10%)] Loss: 0.402880\n",
      "Train Epoch: 1030 [320/1612 (20%)] Loss: 0.235133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1030 [480/1612 (30%)] Loss: 0.291679\n",
      "Train Epoch: 1030 [640/1612 (40%)] Loss: 0.207897\n",
      "Train Epoch: 1030 [800/1612 (50%)] Loss: 0.235967\n",
      "Train Epoch: 1030 [960/1612 (59%)] Loss: 0.267554\n",
      "Train Epoch: 1030 [1120/1612 (69%)] Loss: 0.648446\n",
      "Train Epoch: 1030 [1280/1612 (79%)] Loss: 0.238109\n",
      "Train Epoch: 1030 [1440/1612 (89%)] Loss: 0.220590\n",
      "Train Epoch: 1030 [1200/1612 (99%)] Loss: 0.432145\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1031 [0/1612 (0%)] Loss: 0.525584\n",
      "Train Epoch: 1031 [160/1612 (10%)] Loss: 0.516294\n",
      "Train Epoch: 1031 [320/1612 (20%)] Loss: 0.354245\n",
      "Train Epoch: 1031 [480/1612 (30%)] Loss: 0.245592\n",
      "Train Epoch: 1031 [640/1612 (40%)] Loss: 0.255164\n",
      "Train Epoch: 1031 [800/1612 (50%)] Loss: 0.479673\n",
      "Train Epoch: 1031 [960/1612 (59%)] Loss: 0.088246\n",
      "Train Epoch: 1031 [1120/1612 (69%)] Loss: 0.333379\n",
      "Train Epoch: 1031 [1280/1612 (79%)] Loss: 0.319295\n",
      "Train Epoch: 1031 [1440/1612 (89%)] Loss: 0.339359\n",
      "Train Epoch: 1031 [1200/1612 (99%)] Loss: 0.389841\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1032 [0/1612 (0%)] Loss: 0.476341\n",
      "Train Epoch: 1032 [160/1612 (10%)] Loss: 0.233443\n",
      "Train Epoch: 1032 [320/1612 (20%)] Loss: 0.348389\n",
      "Train Epoch: 1032 [480/1612 (30%)] Loss: 0.370108\n",
      "Train Epoch: 1032 [640/1612 (40%)] Loss: 0.149360\n",
      "Train Epoch: 1032 [800/1612 (50%)] Loss: 0.444553\n",
      "Train Epoch: 1032 [960/1612 (59%)] Loss: 0.333527\n",
      "Train Epoch: 1032 [1120/1612 (69%)] Loss: 0.322636\n",
      "Train Epoch: 1032 [1280/1612 (79%)] Loss: 0.190197\n",
      "Train Epoch: 1032 [1440/1612 (89%)] Loss: 0.152143\n",
      "Train Epoch: 1032 [1200/1612 (99%)] Loss: 0.137653\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1033 [0/1612 (0%)] Loss: 0.198805\n",
      "Train Epoch: 1033 [160/1612 (10%)] Loss: 0.458108\n",
      "Train Epoch: 1033 [320/1612 (20%)] Loss: 0.629992\n",
      "Train Epoch: 1033 [480/1612 (30%)] Loss: 0.196734\n",
      "Train Epoch: 1033 [640/1612 (40%)] Loss: 0.398137\n",
      "Train Epoch: 1033 [800/1612 (50%)] Loss: 0.486496\n",
      "Train Epoch: 1033 [960/1612 (59%)] Loss: 0.313262\n",
      "Train Epoch: 1033 [1120/1612 (69%)] Loss: 0.567156\n",
      "Train Epoch: 1033 [1280/1612 (79%)] Loss: 0.325897\n",
      "Train Epoch: 1033 [1440/1612 (89%)] Loss: 0.304876\n",
      "Train Epoch: 1033 [1200/1612 (99%)] Loss: 0.224345\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1034 [0/1612 (0%)] Loss: 0.458642\n",
      "Train Epoch: 1034 [160/1612 (10%)] Loss: 0.390990\n",
      "Train Epoch: 1034 [320/1612 (20%)] Loss: 0.208820\n",
      "Train Epoch: 1034 [480/1612 (30%)] Loss: 0.349003\n",
      "Train Epoch: 1034 [640/1612 (40%)] Loss: 0.246153\n",
      "Train Epoch: 1034 [800/1612 (50%)] Loss: 0.303014\n",
      "Train Epoch: 1034 [960/1612 (59%)] Loss: 0.462033\n",
      "Train Epoch: 1034 [1120/1612 (69%)] Loss: 0.217343\n",
      "Train Epoch: 1034 [1280/1612 (79%)] Loss: 0.460861\n",
      "Train Epoch: 1034 [1440/1612 (89%)] Loss: 0.405077\n",
      "Train Epoch: 1034 [1200/1612 (99%)] Loss: 0.205330\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1035 [0/1612 (0%)] Loss: 0.364043\n",
      "Train Epoch: 1035 [160/1612 (10%)] Loss: 0.207640\n",
      "Train Epoch: 1035 [320/1612 (20%)] Loss: 0.091710\n",
      "Train Epoch: 1035 [480/1612 (30%)] Loss: 0.127073\n",
      "Train Epoch: 1035 [640/1612 (40%)] Loss: 0.405621\n",
      "Train Epoch: 1035 [800/1612 (50%)] Loss: 0.352773\n",
      "Train Epoch: 1035 [960/1612 (59%)] Loss: 0.189406\n",
      "Train Epoch: 1035 [1120/1612 (69%)] Loss: 0.294256\n",
      "Train Epoch: 1035 [1280/1612 (79%)] Loss: 0.210559\n",
      "Train Epoch: 1035 [1440/1612 (89%)] Loss: 0.252292\n",
      "Train Epoch: 1035 [1200/1612 (99%)] Loss: 0.457298\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1036 [0/1612 (0%)] Loss: 0.234778\n",
      "Train Epoch: 1036 [160/1612 (10%)] Loss: 0.531534\n",
      "Train Epoch: 1036 [320/1612 (20%)] Loss: 0.410581\n",
      "Train Epoch: 1036 [480/1612 (30%)] Loss: 0.190850\n",
      "Train Epoch: 1036 [640/1612 (40%)] Loss: 0.176512\n",
      "Train Epoch: 1036 [800/1612 (50%)] Loss: 0.251861\n",
      "Train Epoch: 1036 [960/1612 (59%)] Loss: 0.308542\n",
      "Train Epoch: 1036 [1120/1612 (69%)] Loss: 0.256955\n",
      "Train Epoch: 1036 [1280/1612 (79%)] Loss: 0.354027\n",
      "Train Epoch: 1036 [1440/1612 (89%)] Loss: 0.266476\n",
      "Train Epoch: 1036 [1200/1612 (99%)] Loss: 0.236236\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1037 [0/1612 (0%)] Loss: 0.276770\n",
      "Train Epoch: 1037 [160/1612 (10%)] Loss: 0.353126\n",
      "Train Epoch: 1037 [320/1612 (20%)] Loss: 0.420247\n",
      "Train Epoch: 1037 [480/1612 (30%)] Loss: 0.404337\n",
      "Train Epoch: 1037 [640/1612 (40%)] Loss: 0.296208\n",
      "Train Epoch: 1037 [800/1612 (50%)] Loss: 0.283239\n",
      "Train Epoch: 1037 [960/1612 (59%)] Loss: 0.221627\n",
      "Train Epoch: 1037 [1120/1612 (69%)] Loss: 0.346013\n",
      "Train Epoch: 1037 [1280/1612 (79%)] Loss: 0.381573\n",
      "Train Epoch: 1037 [1440/1612 (89%)] Loss: 0.380479\n",
      "Train Epoch: 1037 [1200/1612 (99%)] Loss: 0.192171\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1038 [0/1612 (0%)] Loss: 0.564086\n",
      "Train Epoch: 1038 [160/1612 (10%)] Loss: 0.172889\n",
      "Train Epoch: 1038 [320/1612 (20%)] Loss: 0.166503\n",
      "Train Epoch: 1038 [480/1612 (30%)] Loss: 0.121994\n",
      "Train Epoch: 1038 [640/1612 (40%)] Loss: 0.284926\n",
      "Train Epoch: 1038 [800/1612 (50%)] Loss: 0.360256\n",
      "Train Epoch: 1038 [960/1612 (59%)] Loss: 0.333596\n",
      "Train Epoch: 1038 [1120/1612 (69%)] Loss: 0.336966\n",
      "Train Epoch: 1038 [1280/1612 (79%)] Loss: 0.201746\n",
      "Train Epoch: 1038 [1440/1612 (89%)] Loss: 0.305282\n",
      "Train Epoch: 1038 [1200/1612 (99%)] Loss: 0.210640\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1039 [0/1612 (0%)] Loss: 0.268485\n",
      "Train Epoch: 1039 [160/1612 (10%)] Loss: 0.255658\n",
      "Train Epoch: 1039 [320/1612 (20%)] Loss: 0.493889\n",
      "Train Epoch: 1039 [480/1612 (30%)] Loss: 0.295151\n",
      "Train Epoch: 1039 [640/1612 (40%)] Loss: 0.224020\n",
      "Train Epoch: 1039 [800/1612 (50%)] Loss: 0.251778\n",
      "Train Epoch: 1039 [960/1612 (59%)] Loss: 0.384125\n",
      "Train Epoch: 1039 [1120/1612 (69%)] Loss: 0.401288\n",
      "Train Epoch: 1039 [1280/1612 (79%)] Loss: 0.253026\n",
      "Train Epoch: 1039 [1440/1612 (89%)] Loss: 0.068234\n",
      "Train Epoch: 1039 [1200/1612 (99%)] Loss: 0.298273\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1040 [0/1612 (0%)] Loss: 0.348033\n",
      "Train Epoch: 1040 [160/1612 (10%)] Loss: 0.552154\n",
      "Train Epoch: 1040 [320/1612 (20%)] Loss: 0.202472\n",
      "Train Epoch: 1040 [480/1612 (30%)] Loss: 0.194365\n",
      "Train Epoch: 1040 [640/1612 (40%)] Loss: 0.229068\n",
      "Train Epoch: 1040 [800/1612 (50%)] Loss: 0.541640\n",
      "Train Epoch: 1040 [960/1612 (59%)] Loss: 0.328415\n",
      "Train Epoch: 1040 [1120/1612 (69%)] Loss: 0.221129\n",
      "Train Epoch: 1040 [1280/1612 (79%)] Loss: 0.504648\n",
      "Train Epoch: 1040 [1440/1612 (89%)] Loss: 0.166861\n",
      "Train Epoch: 1040 [1200/1612 (99%)] Loss: 0.336644\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1041 [0/1612 (0%)] Loss: 0.389626\n",
      "Train Epoch: 1041 [160/1612 (10%)] Loss: 0.245051\n",
      "Train Epoch: 1041 [320/1612 (20%)] Loss: 0.199558\n",
      "Train Epoch: 1041 [480/1612 (30%)] Loss: 0.288235\n",
      "Train Epoch: 1041 [640/1612 (40%)] Loss: 0.297644\n",
      "Train Epoch: 1041 [800/1612 (50%)] Loss: 0.364233\n",
      "Train Epoch: 1041 [960/1612 (59%)] Loss: 0.548244\n",
      "Train Epoch: 1041 [1120/1612 (69%)] Loss: 0.265142\n",
      "Train Epoch: 1041 [1280/1612 (79%)] Loss: 0.453585\n",
      "Train Epoch: 1041 [1440/1612 (89%)] Loss: 0.309645\n",
      "Train Epoch: 1041 [1200/1612 (99%)] Loss: 0.224522\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1042 [0/1612 (0%)] Loss: 0.137361\n",
      "Train Epoch: 1042 [160/1612 (10%)] Loss: 0.812221\n",
      "Train Epoch: 1042 [320/1612 (20%)] Loss: 0.303517\n",
      "Train Epoch: 1042 [480/1612 (30%)] Loss: 0.275473\n",
      "Train Epoch: 1042 [640/1612 (40%)] Loss: 0.365458\n",
      "Train Epoch: 1042 [800/1612 (50%)] Loss: 0.325363\n",
      "Train Epoch: 1042 [960/1612 (59%)] Loss: 0.046088\n",
      "Train Epoch: 1042 [1120/1612 (69%)] Loss: 0.502914\n",
      "Train Epoch: 1042 [1280/1612 (79%)] Loss: 0.407549\n",
      "Train Epoch: 1042 [1440/1612 (89%)] Loss: 0.250721\n",
      "Train Epoch: 1042 [1200/1612 (99%)] Loss: 0.425628\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1043 [0/1612 (0%)] Loss: 0.312157\n",
      "Train Epoch: 1043 [160/1612 (10%)] Loss: 0.289632\n",
      "Train Epoch: 1043 [320/1612 (20%)] Loss: 0.322625\n",
      "Train Epoch: 1043 [480/1612 (30%)] Loss: 0.276530\n",
      "Train Epoch: 1043 [640/1612 (40%)] Loss: 0.384434\n",
      "Train Epoch: 1043 [800/1612 (50%)] Loss: 0.197943\n",
      "Train Epoch: 1043 [960/1612 (59%)] Loss: 0.306079\n",
      "Train Epoch: 1043 [1120/1612 (69%)] Loss: 0.171023\n",
      "Train Epoch: 1043 [1280/1612 (79%)] Loss: 0.257683\n",
      "Train Epoch: 1043 [1440/1612 (89%)] Loss: 0.226777\n",
      "Train Epoch: 1043 [1200/1612 (99%)] Loss: 0.332497\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1044 [0/1612 (0%)] Loss: 0.388740\n",
      "Train Epoch: 1044 [160/1612 (10%)] Loss: 0.303298\n",
      "Train Epoch: 1044 [320/1612 (20%)] Loss: 0.328896\n",
      "Train Epoch: 1044 [480/1612 (30%)] Loss: 0.470159\n",
      "Train Epoch: 1044 [640/1612 (40%)] Loss: 0.449371\n",
      "Train Epoch: 1044 [800/1612 (50%)] Loss: 0.287743\n",
      "Train Epoch: 1044 [960/1612 (59%)] Loss: 0.316749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1044 [1120/1612 (69%)] Loss: 0.284023\n",
      "Train Epoch: 1044 [1280/1612 (79%)] Loss: 0.239113\n",
      "Train Epoch: 1044 [1440/1612 (89%)] Loss: 0.149167\n",
      "Train Epoch: 1044 [1200/1612 (99%)] Loss: 0.123762\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1045 [0/1612 (0%)] Loss: 0.364991\n",
      "Train Epoch: 1045 [160/1612 (10%)] Loss: 0.349456\n",
      "Train Epoch: 1045 [320/1612 (20%)] Loss: 0.409337\n",
      "Train Epoch: 1045 [480/1612 (30%)] Loss: 0.076337\n",
      "Train Epoch: 1045 [640/1612 (40%)] Loss: 0.151359\n",
      "Train Epoch: 1045 [800/1612 (50%)] Loss: 0.433698\n",
      "Train Epoch: 1045 [960/1612 (59%)] Loss: 0.176554\n",
      "Train Epoch: 1045 [1120/1612 (69%)] Loss: 0.309599\n",
      "Train Epoch: 1045 [1280/1612 (79%)] Loss: 0.182583\n",
      "Train Epoch: 1045 [1440/1612 (89%)] Loss: 0.245073\n",
      "Train Epoch: 1045 [1200/1612 (99%)] Loss: 0.263388\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1046 [0/1612 (0%)] Loss: 0.247999\n",
      "Train Epoch: 1046 [160/1612 (10%)] Loss: 0.251559\n",
      "Train Epoch: 1046 [320/1612 (20%)] Loss: 0.271925\n",
      "Train Epoch: 1046 [480/1612 (30%)] Loss: 0.283477\n",
      "Train Epoch: 1046 [640/1612 (40%)] Loss: 0.391108\n",
      "Train Epoch: 1046 [800/1612 (50%)] Loss: 0.346187\n",
      "Train Epoch: 1046 [960/1612 (59%)] Loss: 0.352680\n",
      "Train Epoch: 1046 [1120/1612 (69%)] Loss: 0.530993\n",
      "Train Epoch: 1046 [1280/1612 (79%)] Loss: 0.434871\n",
      "Train Epoch: 1046 [1440/1612 (89%)] Loss: 0.458233\n",
      "Train Epoch: 1046 [1200/1612 (99%)] Loss: 0.412078\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1047 [0/1612 (0%)] Loss: 0.238219\n",
      "Train Epoch: 1047 [160/1612 (10%)] Loss: 0.297006\n",
      "Train Epoch: 1047 [320/1612 (20%)] Loss: 0.083556\n",
      "Train Epoch: 1047 [480/1612 (30%)] Loss: 0.240762\n",
      "Train Epoch: 1047 [640/1612 (40%)] Loss: 0.288725\n",
      "Train Epoch: 1047 [800/1612 (50%)] Loss: 0.151858\n",
      "Train Epoch: 1047 [960/1612 (59%)] Loss: 0.194198\n",
      "Train Epoch: 1047 [1120/1612 (69%)] Loss: 0.278779\n",
      "Train Epoch: 1047 [1280/1612 (79%)] Loss: 0.246967\n",
      "Train Epoch: 1047 [1440/1612 (89%)] Loss: 0.180550\n",
      "Train Epoch: 1047 [1200/1612 (99%)] Loss: 0.299029\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1048 [0/1612 (0%)] Loss: 0.283717\n",
      "Train Epoch: 1048 [160/1612 (10%)] Loss: 0.072891\n",
      "Train Epoch: 1048 [320/1612 (20%)] Loss: 0.269801\n",
      "Train Epoch: 1048 [480/1612 (30%)] Loss: 0.342373\n",
      "Train Epoch: 1048 [640/1612 (40%)] Loss: 0.269456\n",
      "Train Epoch: 1048 [800/1612 (50%)] Loss: 0.069909\n",
      "Train Epoch: 1048 [960/1612 (59%)] Loss: 0.356476\n",
      "Train Epoch: 1048 [1120/1612 (69%)] Loss: 0.505256\n",
      "Train Epoch: 1048 [1280/1612 (79%)] Loss: 0.240057\n",
      "Train Epoch: 1048 [1440/1612 (89%)] Loss: 0.429390\n",
      "Train Epoch: 1048 [1200/1612 (99%)] Loss: 0.313274\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1049 [0/1612 (0%)] Loss: 0.185950\n",
      "Train Epoch: 1049 [160/1612 (10%)] Loss: 0.635312\n",
      "Train Epoch: 1049 [320/1612 (20%)] Loss: 0.622583\n",
      "Train Epoch: 1049 [480/1612 (30%)] Loss: 0.287770\n",
      "Train Epoch: 1049 [640/1612 (40%)] Loss: 0.199441\n",
      "Train Epoch: 1049 [800/1612 (50%)] Loss: 0.209750\n",
      "Train Epoch: 1049 [960/1612 (59%)] Loss: 0.544452\n",
      "Train Epoch: 1049 [1120/1612 (69%)] Loss: 0.434070\n",
      "Train Epoch: 1049 [1280/1612 (79%)] Loss: 0.461716\n",
      "Train Epoch: 1049 [1440/1612 (89%)] Loss: 0.186627\n",
      "Train Epoch: 1049 [1200/1612 (99%)] Loss: 0.273611\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1050 [0/1612 (0%)] Loss: 0.066152\n",
      "Train Epoch: 1050 [160/1612 (10%)] Loss: 0.108005\n",
      "Train Epoch: 1050 [320/1612 (20%)] Loss: 0.337970\n",
      "Train Epoch: 1050 [480/1612 (30%)] Loss: 0.172009\n",
      "Train Epoch: 1050 [640/1612 (40%)] Loss: 0.140041\n",
      "Train Epoch: 1050 [800/1612 (50%)] Loss: 0.282481\n",
      "Train Epoch: 1050 [960/1612 (59%)] Loss: 0.244730\n",
      "Train Epoch: 1050 [1120/1612 (69%)] Loss: 0.218019\n",
      "Train Epoch: 1050 [1280/1612 (79%)] Loss: 0.637828\n",
      "Train Epoch: 1050 [1440/1612 (89%)] Loss: 0.316323\n",
      "Train Epoch: 1050 [1200/1612 (99%)] Loss: 0.352134\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1051 [0/1612 (0%)] Loss: 0.526979\n",
      "Train Epoch: 1051 [160/1612 (10%)] Loss: 0.250189\n",
      "Train Epoch: 1051 [320/1612 (20%)] Loss: 0.573963\n",
      "Train Epoch: 1051 [480/1612 (30%)] Loss: 0.116253\n",
      "Train Epoch: 1051 [640/1612 (40%)] Loss: 0.495674\n",
      "Train Epoch: 1051 [800/1612 (50%)] Loss: 0.314682\n",
      "Train Epoch: 1051 [960/1612 (59%)] Loss: 0.467830\n",
      "Train Epoch: 1051 [1120/1612 (69%)] Loss: 0.270961\n",
      "Train Epoch: 1051 [1280/1612 (79%)] Loss: 0.125547\n",
      "Train Epoch: 1051 [1440/1612 (89%)] Loss: 0.261102\n",
      "Train Epoch: 1051 [1200/1612 (99%)] Loss: 0.241805\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1052 [0/1612 (0%)] Loss: 0.277582\n",
      "Train Epoch: 1052 [160/1612 (10%)] Loss: 0.200383\n",
      "Train Epoch: 1052 [320/1612 (20%)] Loss: 0.340110\n",
      "Train Epoch: 1052 [480/1612 (30%)] Loss: 0.263047\n",
      "Train Epoch: 1052 [640/1612 (40%)] Loss: 0.337404\n",
      "Train Epoch: 1052 [800/1612 (50%)] Loss: 0.136299\n",
      "Train Epoch: 1052 [960/1612 (59%)] Loss: 0.381742\n",
      "Train Epoch: 1052 [1120/1612 (69%)] Loss: 0.393216\n",
      "Train Epoch: 1052 [1280/1612 (79%)] Loss: 0.183037\n",
      "Train Epoch: 1052 [1440/1612 (89%)] Loss: 0.255547\n",
      "Train Epoch: 1052 [1200/1612 (99%)] Loss: 0.299687\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1053 [0/1612 (0%)] Loss: 0.396978\n",
      "Train Epoch: 1053 [160/1612 (10%)] Loss: 0.272823\n",
      "Train Epoch: 1053 [320/1612 (20%)] Loss: 0.323520\n",
      "Train Epoch: 1053 [480/1612 (30%)] Loss: 0.383021\n",
      "Train Epoch: 1053 [640/1612 (40%)] Loss: 0.316600\n",
      "Train Epoch: 1053 [800/1612 (50%)] Loss: 0.352880\n",
      "Train Epoch: 1053 [960/1612 (59%)] Loss: 0.311128\n",
      "Train Epoch: 1053 [1120/1612 (69%)] Loss: 0.371066\n",
      "Train Epoch: 1053 [1280/1612 (79%)] Loss: 0.370174\n",
      "Train Epoch: 1053 [1440/1612 (89%)] Loss: 0.196963\n",
      "Train Epoch: 1053 [1200/1612 (99%)] Loss: 0.406435\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1054 [0/1612 (0%)] Loss: 0.357236\n",
      "Train Epoch: 1054 [160/1612 (10%)] Loss: 0.291204\n",
      "Train Epoch: 1054 [320/1612 (20%)] Loss: 0.255701\n",
      "Train Epoch: 1054 [480/1612 (30%)] Loss: 0.550889\n",
      "Train Epoch: 1054 [640/1612 (40%)] Loss: 0.222036\n",
      "Train Epoch: 1054 [800/1612 (50%)] Loss: 0.496370\n",
      "Train Epoch: 1054 [960/1612 (59%)] Loss: 0.138436\n",
      "Train Epoch: 1054 [1120/1612 (69%)] Loss: 0.117397\n",
      "Train Epoch: 1054 [1280/1612 (79%)] Loss: 0.166014\n",
      "Train Epoch: 1054 [1440/1612 (89%)] Loss: 0.165543\n",
      "Train Epoch: 1054 [1200/1612 (99%)] Loss: 0.383569\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1055 [0/1612 (0%)] Loss: 0.285470\n",
      "Train Epoch: 1055 [160/1612 (10%)] Loss: 0.177255\n",
      "Train Epoch: 1055 [320/1612 (20%)] Loss: 0.442139\n",
      "Train Epoch: 1055 [480/1612 (30%)] Loss: 0.437335\n",
      "Train Epoch: 1055 [640/1612 (40%)] Loss: 0.287364\n",
      "Train Epoch: 1055 [800/1612 (50%)] Loss: 0.450533\n",
      "Train Epoch: 1055 [960/1612 (59%)] Loss: 0.400985\n",
      "Train Epoch: 1055 [1120/1612 (69%)] Loss: 0.317148\n",
      "Train Epoch: 1055 [1280/1612 (79%)] Loss: 0.438747\n",
      "Train Epoch: 1055 [1440/1612 (89%)] Loss: 0.597333\n",
      "Train Epoch: 1055 [1200/1612 (99%)] Loss: 0.400074\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1056 [0/1612 (0%)] Loss: 0.183655\n",
      "Train Epoch: 1056 [160/1612 (10%)] Loss: 0.412252\n",
      "Train Epoch: 1056 [320/1612 (20%)] Loss: 0.160385\n",
      "Train Epoch: 1056 [480/1612 (30%)] Loss: 0.394966\n",
      "Train Epoch: 1056 [640/1612 (40%)] Loss: 0.172717\n",
      "Train Epoch: 1056 [800/1612 (50%)] Loss: 0.396097\n",
      "Train Epoch: 1056 [960/1612 (59%)] Loss: 0.251443\n",
      "Train Epoch: 1056 [1120/1612 (69%)] Loss: 0.417689\n",
      "Train Epoch: 1056 [1280/1612 (79%)] Loss: 0.504858\n",
      "Train Epoch: 1056 [1440/1612 (89%)] Loss: 0.266122\n",
      "Train Epoch: 1056 [1200/1612 (99%)] Loss: 0.268958\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1057 [0/1612 (0%)] Loss: 0.304941\n",
      "Train Epoch: 1057 [160/1612 (10%)] Loss: 0.356392\n",
      "Train Epoch: 1057 [320/1612 (20%)] Loss: 0.317527\n",
      "Train Epoch: 1057 [480/1612 (30%)] Loss: 0.114969\n",
      "Train Epoch: 1057 [640/1612 (40%)] Loss: 0.643458\n",
      "Train Epoch: 1057 [800/1612 (50%)] Loss: 0.232389\n",
      "Train Epoch: 1057 [960/1612 (59%)] Loss: 0.231421\n",
      "Train Epoch: 1057 [1120/1612 (69%)] Loss: 0.090225\n",
      "Train Epoch: 1057 [1280/1612 (79%)] Loss: 0.343183\n",
      "Train Epoch: 1057 [1440/1612 (89%)] Loss: 0.320414\n",
      "Train Epoch: 1057 [1200/1612 (99%)] Loss: 0.335201\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1058 [0/1612 (0%)] Loss: 0.290975\n",
      "Train Epoch: 1058 [160/1612 (10%)] Loss: 0.483087\n",
      "Train Epoch: 1058 [320/1612 (20%)] Loss: 0.269415\n",
      "Train Epoch: 1058 [480/1612 (30%)] Loss: 0.407581\n",
      "Train Epoch: 1058 [640/1612 (40%)] Loss: 0.199241\n",
      "Train Epoch: 1058 [800/1612 (50%)] Loss: 0.190605\n",
      "Train Epoch: 1058 [960/1612 (59%)] Loss: 0.435427\n",
      "Train Epoch: 1058 [1120/1612 (69%)] Loss: 0.332465\n",
      "Train Epoch: 1058 [1280/1612 (79%)] Loss: 0.118310\n",
      "Train Epoch: 1058 [1440/1612 (89%)] Loss: 0.149257\n",
      "Train Epoch: 1058 [1200/1612 (99%)] Loss: 0.078316\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1059 [0/1612 (0%)] Loss: 0.374299\n",
      "Train Epoch: 1059 [160/1612 (10%)] Loss: 0.231823\n",
      "Train Epoch: 1059 [320/1612 (20%)] Loss: 0.167113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1059 [480/1612 (30%)] Loss: 0.498975\n",
      "Train Epoch: 1059 [640/1612 (40%)] Loss: 0.382321\n",
      "Train Epoch: 1059 [800/1612 (50%)] Loss: 0.361876\n",
      "Train Epoch: 1059 [960/1612 (59%)] Loss: 0.296038\n",
      "Train Epoch: 1059 [1120/1612 (69%)] Loss: 0.152044\n",
      "Train Epoch: 1059 [1280/1612 (79%)] Loss: 0.237296\n",
      "Train Epoch: 1059 [1440/1612 (89%)] Loss: 0.266116\n",
      "Train Epoch: 1059 [1200/1612 (99%)] Loss: 0.302724\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1060 [0/1612 (0%)] Loss: 0.187374\n",
      "Train Epoch: 1060 [160/1612 (10%)] Loss: 0.264655\n",
      "Train Epoch: 1060 [320/1612 (20%)] Loss: 0.394626\n",
      "Train Epoch: 1060 [480/1612 (30%)] Loss: 0.470117\n",
      "Train Epoch: 1060 [640/1612 (40%)] Loss: 0.729164\n",
      "Train Epoch: 1060 [800/1612 (50%)] Loss: 0.449423\n",
      "Train Epoch: 1060 [960/1612 (59%)] Loss: 0.345597\n",
      "Train Epoch: 1060 [1120/1612 (69%)] Loss: 0.265163\n",
      "Train Epoch: 1060 [1280/1612 (79%)] Loss: 0.505574\n",
      "Train Epoch: 1060 [1440/1612 (89%)] Loss: 0.296744\n",
      "Train Epoch: 1060 [1200/1612 (99%)] Loss: 0.317244\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1061 [0/1612 (0%)] Loss: 0.348917\n",
      "Train Epoch: 1061 [160/1612 (10%)] Loss: 0.369949\n",
      "Train Epoch: 1061 [320/1612 (20%)] Loss: 0.259624\n",
      "Train Epoch: 1061 [480/1612 (30%)] Loss: 0.305593\n",
      "Train Epoch: 1061 [640/1612 (40%)] Loss: 0.373450\n",
      "Train Epoch: 1061 [800/1612 (50%)] Loss: 0.537259\n",
      "Train Epoch: 1061 [960/1612 (59%)] Loss: 0.484930\n",
      "Train Epoch: 1061 [1120/1612 (69%)] Loss: 0.308584\n",
      "Train Epoch: 1061 [1280/1612 (79%)] Loss: 0.459489\n",
      "Train Epoch: 1061 [1440/1612 (89%)] Loss: 0.282028\n",
      "Train Epoch: 1061 [1200/1612 (99%)] Loss: 0.182010\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1062 [0/1612 (0%)] Loss: 0.301513\n",
      "Train Epoch: 1062 [160/1612 (10%)] Loss: 0.532075\n",
      "Train Epoch: 1062 [320/1612 (20%)] Loss: 0.346800\n",
      "Train Epoch: 1062 [480/1612 (30%)] Loss: 0.259016\n",
      "Train Epoch: 1062 [640/1612 (40%)] Loss: 0.424623\n",
      "Train Epoch: 1062 [800/1612 (50%)] Loss: 0.412174\n",
      "Train Epoch: 1062 [960/1612 (59%)] Loss: 0.193248\n",
      "Train Epoch: 1062 [1120/1612 (69%)] Loss: 0.173210\n",
      "Train Epoch: 1062 [1280/1612 (79%)] Loss: 0.254620\n",
      "Train Epoch: 1062 [1440/1612 (89%)] Loss: 0.358637\n",
      "Train Epoch: 1062 [1200/1612 (99%)] Loss: 0.165345\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1063 [0/1612 (0%)] Loss: 0.289346\n",
      "Train Epoch: 1063 [160/1612 (10%)] Loss: 0.718974\n",
      "Train Epoch: 1063 [320/1612 (20%)] Loss: 0.242711\n",
      "Train Epoch: 1063 [480/1612 (30%)] Loss: 0.227341\n",
      "Train Epoch: 1063 [640/1612 (40%)] Loss: 0.312340\n",
      "Train Epoch: 1063 [800/1612 (50%)] Loss: 0.309073\n",
      "Train Epoch: 1063 [960/1612 (59%)] Loss: 0.183014\n",
      "Train Epoch: 1063 [1120/1612 (69%)] Loss: 0.341024\n",
      "Train Epoch: 1063 [1280/1612 (79%)] Loss: 0.293463\n",
      "Train Epoch: 1063 [1440/1612 (89%)] Loss: 0.496973\n",
      "Train Epoch: 1063 [1200/1612 (99%)] Loss: 0.399555\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1064 [0/1612 (0%)] Loss: 0.386266\n",
      "Train Epoch: 1064 [160/1612 (10%)] Loss: 0.249266\n",
      "Train Epoch: 1064 [320/1612 (20%)] Loss: 0.294441\n",
      "Train Epoch: 1064 [480/1612 (30%)] Loss: 0.291454\n",
      "Train Epoch: 1064 [640/1612 (40%)] Loss: 0.719525\n",
      "Train Epoch: 1064 [800/1612 (50%)] Loss: 0.271510\n",
      "Train Epoch: 1064 [960/1612 (59%)] Loss: 0.192913\n",
      "Train Epoch: 1064 [1120/1612 (69%)] Loss: 0.195883\n",
      "Train Epoch: 1064 [1280/1612 (79%)] Loss: 0.354513\n",
      "Train Epoch: 1064 [1440/1612 (89%)] Loss: 0.239316\n",
      "Train Epoch: 1064 [1200/1612 (99%)] Loss: 0.349032\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1065 [0/1612 (0%)] Loss: 0.261279\n",
      "Train Epoch: 1065 [160/1612 (10%)] Loss: 0.316968\n",
      "Train Epoch: 1065 [320/1612 (20%)] Loss: 0.118156\n",
      "Train Epoch: 1065 [480/1612 (30%)] Loss: 0.334452\n",
      "Train Epoch: 1065 [640/1612 (40%)] Loss: 0.502950\n",
      "Train Epoch: 1065 [800/1612 (50%)] Loss: 0.260122\n",
      "Train Epoch: 1065 [960/1612 (59%)] Loss: 0.215530\n",
      "Train Epoch: 1065 [1120/1612 (69%)] Loss: 0.226427\n",
      "Train Epoch: 1065 [1280/1612 (79%)] Loss: 0.355438\n",
      "Train Epoch: 1065 [1440/1612 (89%)] Loss: 0.270058\n",
      "Train Epoch: 1065 [1200/1612 (99%)] Loss: 0.177177\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1066 [0/1612 (0%)] Loss: 0.275131\n",
      "Train Epoch: 1066 [160/1612 (10%)] Loss: 0.203885\n",
      "Train Epoch: 1066 [320/1612 (20%)] Loss: 0.322728\n",
      "Train Epoch: 1066 [480/1612 (30%)] Loss: 0.164732\n",
      "Train Epoch: 1066 [640/1612 (40%)] Loss: 0.116301\n",
      "Train Epoch: 1066 [800/1612 (50%)] Loss: 0.146762\n",
      "Train Epoch: 1066 [960/1612 (59%)] Loss: 0.505970\n",
      "Train Epoch: 1066 [1120/1612 (69%)] Loss: 0.247278\n",
      "Train Epoch: 1066 [1280/1612 (79%)] Loss: 0.328096\n",
      "Train Epoch: 1066 [1440/1612 (89%)] Loss: 0.239038\n",
      "Train Epoch: 1066 [1200/1612 (99%)] Loss: 0.123342\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1067 [0/1612 (0%)] Loss: 0.147533\n",
      "Train Epoch: 1067 [160/1612 (10%)] Loss: 0.130839\n",
      "Train Epoch: 1067 [320/1612 (20%)] Loss: 0.247380\n",
      "Train Epoch: 1067 [480/1612 (30%)] Loss: 0.193345\n",
      "Train Epoch: 1067 [640/1612 (40%)] Loss: 0.346811\n",
      "Train Epoch: 1067 [800/1612 (50%)] Loss: 0.232664\n",
      "Train Epoch: 1067 [960/1612 (59%)] Loss: 0.345997\n",
      "Train Epoch: 1067 [1120/1612 (69%)] Loss: 0.214655\n",
      "Train Epoch: 1067 [1280/1612 (79%)] Loss: 0.277884\n",
      "Train Epoch: 1067 [1440/1612 (89%)] Loss: 0.440516\n",
      "Train Epoch: 1067 [1200/1612 (99%)] Loss: 0.096237\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1068 [0/1612 (0%)] Loss: 0.552506\n",
      "Train Epoch: 1068 [160/1612 (10%)] Loss: 0.452924\n",
      "Train Epoch: 1068 [320/1612 (20%)] Loss: 0.321108\n",
      "Train Epoch: 1068 [480/1612 (30%)] Loss: 0.310963\n",
      "Train Epoch: 1068 [640/1612 (40%)] Loss: 0.152669\n",
      "Train Epoch: 1068 [800/1612 (50%)] Loss: 0.322732\n",
      "Train Epoch: 1068 [960/1612 (59%)] Loss: 0.179547\n",
      "Train Epoch: 1068 [1120/1612 (69%)] Loss: 0.567021\n",
      "Train Epoch: 1068 [1280/1612 (79%)] Loss: 0.414086\n",
      "Train Epoch: 1068 [1440/1612 (89%)] Loss: 0.416264\n",
      "Train Epoch: 1068 [1200/1612 (99%)] Loss: 0.332328\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1069 [0/1612 (0%)] Loss: 0.235852\n",
      "Train Epoch: 1069 [160/1612 (10%)] Loss: 0.410645\n",
      "Train Epoch: 1069 [320/1612 (20%)] Loss: 0.352012\n",
      "Train Epoch: 1069 [480/1612 (30%)] Loss: 0.310992\n",
      "Train Epoch: 1069 [640/1612 (40%)] Loss: 0.410990\n",
      "Train Epoch: 1069 [800/1612 (50%)] Loss: 0.219835\n",
      "Train Epoch: 1069 [960/1612 (59%)] Loss: 0.263215\n",
      "Train Epoch: 1069 [1120/1612 (69%)] Loss: 0.224033\n",
      "Train Epoch: 1069 [1280/1612 (79%)] Loss: 0.264446\n",
      "Train Epoch: 1069 [1440/1612 (89%)] Loss: 0.278718\n",
      "Train Epoch: 1069 [1200/1612 (99%)] Loss: 0.164758\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1070 [0/1612 (0%)] Loss: 0.289623\n",
      "Train Epoch: 1070 [160/1612 (10%)] Loss: 0.340724\n",
      "Train Epoch: 1070 [320/1612 (20%)] Loss: 0.237752\n",
      "Train Epoch: 1070 [480/1612 (30%)] Loss: 0.214641\n",
      "Train Epoch: 1070 [640/1612 (40%)] Loss: 0.177756\n",
      "Train Epoch: 1070 [800/1612 (50%)] Loss: 0.380886\n",
      "Train Epoch: 1070 [960/1612 (59%)] Loss: 0.351409\n",
      "Train Epoch: 1070 [1120/1612 (69%)] Loss: 0.595547\n",
      "Train Epoch: 1070 [1280/1612 (79%)] Loss: 0.400593\n",
      "Train Epoch: 1070 [1440/1612 (89%)] Loss: 0.241217\n",
      "Train Epoch: 1070 [1200/1612 (99%)] Loss: 0.334995\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1071 [0/1612 (0%)] Loss: 0.308468\n",
      "Train Epoch: 1071 [160/1612 (10%)] Loss: 0.462562\n",
      "Train Epoch: 1071 [320/1612 (20%)] Loss: 0.377800\n",
      "Train Epoch: 1071 [480/1612 (30%)] Loss: 0.319637\n",
      "Train Epoch: 1071 [640/1612 (40%)] Loss: 0.369966\n",
      "Train Epoch: 1071 [800/1612 (50%)] Loss: 0.509259\n",
      "Train Epoch: 1071 [960/1612 (59%)] Loss: 0.361202\n",
      "Train Epoch: 1071 [1120/1612 (69%)] Loss: 0.266982\n",
      "Train Epoch: 1071 [1280/1612 (79%)] Loss: 0.145379\n",
      "Train Epoch: 1071 [1440/1612 (89%)] Loss: 0.485591\n",
      "Train Epoch: 1071 [1200/1612 (99%)] Loss: 0.246830\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1072 [0/1612 (0%)] Loss: 0.291575\n",
      "Train Epoch: 1072 [160/1612 (10%)] Loss: 0.499161\n",
      "Train Epoch: 1072 [320/1612 (20%)] Loss: 0.343227\n",
      "Train Epoch: 1072 [480/1612 (30%)] Loss: 0.537229\n",
      "Train Epoch: 1072 [640/1612 (40%)] Loss: 0.400891\n",
      "Train Epoch: 1072 [800/1612 (50%)] Loss: 0.197964\n",
      "Train Epoch: 1072 [960/1612 (59%)] Loss: 0.270741\n",
      "Train Epoch: 1072 [1120/1612 (69%)] Loss: 0.396186\n",
      "Train Epoch: 1072 [1280/1612 (79%)] Loss: 0.188084\n",
      "Train Epoch: 1072 [1440/1612 (89%)] Loss: 0.241076\n",
      "Train Epoch: 1072 [1200/1612 (99%)] Loss: 0.255382\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1073 [0/1612 (0%)] Loss: 0.221611\n",
      "Train Epoch: 1073 [160/1612 (10%)] Loss: 0.296790\n",
      "Train Epoch: 1073 [320/1612 (20%)] Loss: 0.288240\n",
      "Train Epoch: 1073 [480/1612 (30%)] Loss: 0.425468\n",
      "Train Epoch: 1073 [640/1612 (40%)] Loss: 0.309204\n",
      "Train Epoch: 1073 [800/1612 (50%)] Loss: 0.295353\n",
      "Train Epoch: 1073 [960/1612 (59%)] Loss: 0.286418\n",
      "Train Epoch: 1073 [1120/1612 (69%)] Loss: 0.310858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1073 [1280/1612 (79%)] Loss: 0.267225\n",
      "Train Epoch: 1073 [1440/1612 (89%)] Loss: 0.314784\n",
      "Train Epoch: 1073 [1200/1612 (99%)] Loss: 0.171824\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1074 [0/1612 (0%)] Loss: 0.209095\n",
      "Train Epoch: 1074 [160/1612 (10%)] Loss: 0.348036\n",
      "Train Epoch: 1074 [320/1612 (20%)] Loss: 0.346104\n",
      "Train Epoch: 1074 [480/1612 (30%)] Loss: 0.395316\n",
      "Train Epoch: 1074 [640/1612 (40%)] Loss: 0.328338\n",
      "Train Epoch: 1074 [800/1612 (50%)] Loss: 0.491655\n",
      "Train Epoch: 1074 [960/1612 (59%)] Loss: 0.681019\n",
      "Train Epoch: 1074 [1120/1612 (69%)] Loss: 0.237041\n",
      "Train Epoch: 1074 [1280/1612 (79%)] Loss: 0.259165\n",
      "Train Epoch: 1074 [1440/1612 (89%)] Loss: 0.402741\n",
      "Train Epoch: 1074 [1200/1612 (99%)] Loss: 0.309433\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1075 [0/1612 (0%)] Loss: 0.329966\n",
      "Train Epoch: 1075 [160/1612 (10%)] Loss: 0.274490\n",
      "Train Epoch: 1075 [320/1612 (20%)] Loss: 0.207344\n",
      "Train Epoch: 1075 [480/1612 (30%)] Loss: 0.425841\n",
      "Train Epoch: 1075 [640/1612 (40%)] Loss: 0.257703\n",
      "Train Epoch: 1075 [800/1612 (50%)] Loss: 0.197170\n",
      "Train Epoch: 1075 [960/1612 (59%)] Loss: 0.303223\n",
      "Train Epoch: 1075 [1120/1612 (69%)] Loss: 0.505523\n",
      "Train Epoch: 1075 [1280/1612 (79%)] Loss: 0.344664\n",
      "Train Epoch: 1075 [1440/1612 (89%)] Loss: 0.283249\n",
      "Train Epoch: 1075 [1200/1612 (99%)] Loss: 0.264635\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1076 [0/1612 (0%)] Loss: 0.149051\n",
      "Train Epoch: 1076 [160/1612 (10%)] Loss: 0.210292\n",
      "Train Epoch: 1076 [320/1612 (20%)] Loss: 0.432065\n",
      "Train Epoch: 1076 [480/1612 (30%)] Loss: 0.387010\n",
      "Train Epoch: 1076 [640/1612 (40%)] Loss: 0.369731\n",
      "Train Epoch: 1076 [800/1612 (50%)] Loss: 0.313576\n",
      "Train Epoch: 1076 [960/1612 (59%)] Loss: 0.409315\n",
      "Train Epoch: 1076 [1120/1612 (69%)] Loss: 0.220421\n",
      "Train Epoch: 1076 [1280/1612 (79%)] Loss: 0.280243\n",
      "Train Epoch: 1076 [1440/1612 (89%)] Loss: 0.167120\n",
      "Train Epoch: 1076 [1200/1612 (99%)] Loss: 0.375273\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1077 [0/1612 (0%)] Loss: 0.353568\n",
      "Train Epoch: 1077 [160/1612 (10%)] Loss: 0.270656\n",
      "Train Epoch: 1077 [320/1612 (20%)] Loss: 0.268220\n",
      "Train Epoch: 1077 [480/1612 (30%)] Loss: 0.315811\n",
      "Train Epoch: 1077 [640/1612 (40%)] Loss: 0.477953\n",
      "Train Epoch: 1077 [800/1612 (50%)] Loss: 0.192677\n",
      "Train Epoch: 1077 [960/1612 (59%)] Loss: 0.369538\n",
      "Train Epoch: 1077 [1120/1612 (69%)] Loss: 0.330074\n",
      "Train Epoch: 1077 [1280/1612 (79%)] Loss: 0.345180\n",
      "Train Epoch: 1077 [1440/1612 (89%)] Loss: 0.180761\n",
      "Train Epoch: 1077 [1200/1612 (99%)] Loss: 0.157255\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1078 [0/1612 (0%)] Loss: 0.143928\n",
      "Train Epoch: 1078 [160/1612 (10%)] Loss: 0.156181\n",
      "Train Epoch: 1078 [320/1612 (20%)] Loss: 0.286639\n",
      "Train Epoch: 1078 [480/1612 (30%)] Loss: 0.282696\n",
      "Train Epoch: 1078 [640/1612 (40%)] Loss: 0.382695\n",
      "Train Epoch: 1078 [800/1612 (50%)] Loss: 0.303261\n",
      "Train Epoch: 1078 [960/1612 (59%)] Loss: 0.205440\n",
      "Train Epoch: 1078 [1120/1612 (69%)] Loss: 0.316775\n",
      "Train Epoch: 1078 [1280/1612 (79%)] Loss: 0.296381\n",
      "Train Epoch: 1078 [1440/1612 (89%)] Loss: 0.452027\n",
      "Train Epoch: 1078 [1200/1612 (99%)] Loss: 0.308776\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1079 [0/1612 (0%)] Loss: 0.171975\n",
      "Train Epoch: 1079 [160/1612 (10%)] Loss: 0.366518\n",
      "Train Epoch: 1079 [320/1612 (20%)] Loss: 0.164662\n",
      "Train Epoch: 1079 [480/1612 (30%)] Loss: 0.320503\n",
      "Train Epoch: 1079 [640/1612 (40%)] Loss: 0.530012\n",
      "Train Epoch: 1079 [800/1612 (50%)] Loss: 0.275921\n",
      "Train Epoch: 1079 [960/1612 (59%)] Loss: 0.434942\n",
      "Train Epoch: 1079 [1120/1612 (69%)] Loss: 0.166477\n",
      "Train Epoch: 1079 [1280/1612 (79%)] Loss: 0.386213\n",
      "Train Epoch: 1079 [1440/1612 (89%)] Loss: 0.446161\n",
      "Train Epoch: 1079 [1200/1612 (99%)] Loss: 0.197946\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1080 [0/1612 (0%)] Loss: 0.357879\n",
      "Train Epoch: 1080 [160/1612 (10%)] Loss: 0.213386\n",
      "Train Epoch: 1080 [320/1612 (20%)] Loss: 0.214535\n",
      "Train Epoch: 1080 [480/1612 (30%)] Loss: 0.428808\n",
      "Train Epoch: 1080 [640/1612 (40%)] Loss: 0.305074\n",
      "Train Epoch: 1080 [800/1612 (50%)] Loss: 0.374413\n",
      "Train Epoch: 1080 [960/1612 (59%)] Loss: 0.332986\n",
      "Train Epoch: 1080 [1120/1612 (69%)] Loss: 0.240709\n",
      "Train Epoch: 1080 [1280/1612 (79%)] Loss: 0.157764\n",
      "Train Epoch: 1080 [1440/1612 (89%)] Loss: 0.330825\n",
      "Train Epoch: 1080 [1200/1612 (99%)] Loss: 0.304727\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1081 [0/1612 (0%)] Loss: 0.210940\n",
      "Train Epoch: 1081 [160/1612 (10%)] Loss: 0.360410\n",
      "Train Epoch: 1081 [320/1612 (20%)] Loss: 0.395068\n",
      "Train Epoch: 1081 [480/1612 (30%)] Loss: 0.156556\n",
      "Train Epoch: 1081 [640/1612 (40%)] Loss: 0.219710\n",
      "Train Epoch: 1081 [800/1612 (50%)] Loss: 0.214491\n",
      "Train Epoch: 1081 [960/1612 (59%)] Loss: 0.357117\n",
      "Train Epoch: 1081 [1120/1612 (69%)] Loss: 0.405585\n",
      "Train Epoch: 1081 [1280/1612 (79%)] Loss: 0.394704\n",
      "Train Epoch: 1081 [1440/1612 (89%)] Loss: 0.183536\n",
      "Train Epoch: 1081 [1200/1612 (99%)] Loss: 0.301056\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1082 [0/1612 (0%)] Loss: 0.343888\n",
      "Train Epoch: 1082 [160/1612 (10%)] Loss: 0.243276\n",
      "Train Epoch: 1082 [320/1612 (20%)] Loss: 0.205866\n",
      "Train Epoch: 1082 [480/1612 (30%)] Loss: 0.283907\n",
      "Train Epoch: 1082 [640/1612 (40%)] Loss: 0.235482\n",
      "Train Epoch: 1082 [800/1612 (50%)] Loss: 0.385995\n",
      "Train Epoch: 1082 [960/1612 (59%)] Loss: 0.494002\n",
      "Train Epoch: 1082 [1120/1612 (69%)] Loss: 0.362164\n",
      "Train Epoch: 1082 [1280/1612 (79%)] Loss: 0.221992\n",
      "Train Epoch: 1082 [1440/1612 (89%)] Loss: 0.133257\n",
      "Train Epoch: 1082 [1200/1612 (99%)] Loss: 0.516813\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1083 [0/1612 (0%)] Loss: 0.190826\n",
      "Train Epoch: 1083 [160/1612 (10%)] Loss: 0.336406\n",
      "Train Epoch: 1083 [320/1612 (20%)] Loss: 0.317113\n",
      "Train Epoch: 1083 [480/1612 (30%)] Loss: 0.240873\n",
      "Train Epoch: 1083 [640/1612 (40%)] Loss: 0.353118\n",
      "Train Epoch: 1083 [800/1612 (50%)] Loss: 0.139457\n",
      "Train Epoch: 1083 [960/1612 (59%)] Loss: 0.370330\n",
      "Train Epoch: 1083 [1120/1612 (69%)] Loss: 0.380331\n",
      "Train Epoch: 1083 [1280/1612 (79%)] Loss: 0.196352\n",
      "Train Epoch: 1083 [1440/1612 (89%)] Loss: 0.411765\n",
      "Train Epoch: 1083 [1200/1612 (99%)] Loss: 0.263028\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1084 [0/1612 (0%)] Loss: 0.208521\n",
      "Train Epoch: 1084 [160/1612 (10%)] Loss: 0.301157\n",
      "Train Epoch: 1084 [320/1612 (20%)] Loss: 0.051872\n",
      "Train Epoch: 1084 [480/1612 (30%)] Loss: 0.357919\n",
      "Train Epoch: 1084 [640/1612 (40%)] Loss: 0.441539\n",
      "Train Epoch: 1084 [800/1612 (50%)] Loss: 0.409137\n",
      "Train Epoch: 1084 [960/1612 (59%)] Loss: 0.519228\n",
      "Train Epoch: 1084 [1120/1612 (69%)] Loss: 0.260569\n",
      "Train Epoch: 1084 [1280/1612 (79%)] Loss: 0.450499\n",
      "Train Epoch: 1084 [1440/1612 (89%)] Loss: 0.564681\n",
      "Train Epoch: 1084 [1200/1612 (99%)] Loss: 0.137007\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1085 [0/1612 (0%)] Loss: 0.385100\n",
      "Train Epoch: 1085 [160/1612 (10%)] Loss: 0.182639\n",
      "Train Epoch: 1085 [320/1612 (20%)] Loss: 0.782417\n",
      "Train Epoch: 1085 [480/1612 (30%)] Loss: 0.152191\n",
      "Train Epoch: 1085 [640/1612 (40%)] Loss: 0.309229\n",
      "Train Epoch: 1085 [800/1612 (50%)] Loss: 0.411194\n",
      "Train Epoch: 1085 [960/1612 (59%)] Loss: 0.192729\n",
      "Train Epoch: 1085 [1120/1612 (69%)] Loss: 0.347055\n",
      "Train Epoch: 1085 [1280/1612 (79%)] Loss: 0.326283\n",
      "Train Epoch: 1085 [1440/1612 (89%)] Loss: 0.246274\n",
      "Train Epoch: 1085 [1200/1612 (99%)] Loss: 0.214564\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1086 [0/1612 (0%)] Loss: 0.259330\n",
      "Train Epoch: 1086 [160/1612 (10%)] Loss: 0.386111\n",
      "Train Epoch: 1086 [320/1612 (20%)] Loss: 0.344267\n",
      "Train Epoch: 1086 [480/1612 (30%)] Loss: 0.185892\n",
      "Train Epoch: 1086 [640/1612 (40%)] Loss: 0.691595\n",
      "Train Epoch: 1086 [800/1612 (50%)] Loss: 0.209311\n",
      "Train Epoch: 1086 [960/1612 (59%)] Loss: 0.196006\n",
      "Train Epoch: 1086 [1120/1612 (69%)] Loss: 0.229229\n",
      "Train Epoch: 1086 [1280/1612 (79%)] Loss: 0.146388\n",
      "Train Epoch: 1086 [1440/1612 (89%)] Loss: 0.304326\n",
      "Train Epoch: 1086 [1200/1612 (99%)] Loss: 0.181236\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1087 [0/1612 (0%)] Loss: 0.310320\n",
      "Train Epoch: 1087 [160/1612 (10%)] Loss: 0.189002\n",
      "Train Epoch: 1087 [320/1612 (20%)] Loss: 0.208719\n",
      "Train Epoch: 1087 [480/1612 (30%)] Loss: 0.390111\n",
      "Train Epoch: 1087 [640/1612 (40%)] Loss: 0.179816\n",
      "Train Epoch: 1087 [800/1612 (50%)] Loss: 0.419061\n",
      "Train Epoch: 1087 [960/1612 (59%)] Loss: 0.207144\n",
      "Train Epoch: 1087 [1120/1612 (69%)] Loss: 0.408801\n",
      "Train Epoch: 1087 [1280/1612 (79%)] Loss: 0.379422\n",
      "Train Epoch: 1087 [1440/1612 (89%)] Loss: 0.171481\n",
      "Train Epoch: 1087 [1200/1612 (99%)] Loss: 0.379887\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1088 [0/1612 (0%)] Loss: 0.256115\n",
      "Train Epoch: 1088 [160/1612 (10%)] Loss: 0.259737\n",
      "Train Epoch: 1088 [320/1612 (20%)] Loss: 0.527330\n",
      "Train Epoch: 1088 [480/1612 (30%)] Loss: 0.267018\n",
      "Train Epoch: 1088 [640/1612 (40%)] Loss: 0.350600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1088 [800/1612 (50%)] Loss: 0.531094\n",
      "Train Epoch: 1088 [960/1612 (59%)] Loss: 0.240277\n",
      "Train Epoch: 1088 [1120/1612 (69%)] Loss: 0.311021\n",
      "Train Epoch: 1088 [1280/1612 (79%)] Loss: 0.156906\n",
      "Train Epoch: 1088 [1440/1612 (89%)] Loss: 0.184317\n",
      "Train Epoch: 1088 [1200/1612 (99%)] Loss: 0.204072\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1089 [0/1612 (0%)] Loss: 0.176968\n",
      "Train Epoch: 1089 [160/1612 (10%)] Loss: 0.232169\n",
      "Train Epoch: 1089 [320/1612 (20%)] Loss: 0.076762\n",
      "Train Epoch: 1089 [480/1612 (30%)] Loss: 0.162430\n",
      "Train Epoch: 1089 [640/1612 (40%)] Loss: 0.450039\n",
      "Train Epoch: 1089 [800/1612 (50%)] Loss: 0.256550\n",
      "Train Epoch: 1089 [960/1612 (59%)] Loss: 0.393279\n",
      "Train Epoch: 1089 [1120/1612 (69%)] Loss: 0.179787\n",
      "Train Epoch: 1089 [1280/1612 (79%)] Loss: 0.192931\n",
      "Train Epoch: 1089 [1440/1612 (89%)] Loss: 0.371433\n",
      "Train Epoch: 1089 [1200/1612 (99%)] Loss: 0.680488\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1090 [0/1612 (0%)] Loss: 0.372566\n",
      "Train Epoch: 1090 [160/1612 (10%)] Loss: 0.150750\n",
      "Train Epoch: 1090 [320/1612 (20%)] Loss: 0.373586\n",
      "Train Epoch: 1090 [480/1612 (30%)] Loss: 0.205596\n",
      "Train Epoch: 1090 [640/1612 (40%)] Loss: 0.360132\n",
      "Train Epoch: 1090 [800/1612 (50%)] Loss: 0.250186\n",
      "Train Epoch: 1090 [960/1612 (59%)] Loss: 0.386285\n",
      "Train Epoch: 1090 [1120/1612 (69%)] Loss: 0.464275\n",
      "Train Epoch: 1090 [1280/1612 (79%)] Loss: 0.415731\n",
      "Train Epoch: 1090 [1440/1612 (89%)] Loss: 0.145858\n",
      "Train Epoch: 1090 [1200/1612 (99%)] Loss: 0.399758\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1091 [0/1612 (0%)] Loss: 0.433996\n",
      "Train Epoch: 1091 [160/1612 (10%)] Loss: 0.254872\n",
      "Train Epoch: 1091 [320/1612 (20%)] Loss: 0.443223\n",
      "Train Epoch: 1091 [480/1612 (30%)] Loss: 0.258121\n",
      "Train Epoch: 1091 [640/1612 (40%)] Loss: 0.292840\n",
      "Train Epoch: 1091 [800/1612 (50%)] Loss: 0.393270\n",
      "Train Epoch: 1091 [960/1612 (59%)] Loss: 0.171767\n",
      "Train Epoch: 1091 [1120/1612 (69%)] Loss: 0.329039\n",
      "Train Epoch: 1091 [1280/1612 (79%)] Loss: 0.377003\n",
      "Train Epoch: 1091 [1440/1612 (89%)] Loss: 0.155225\n",
      "Train Epoch: 1091 [1200/1612 (99%)] Loss: 0.366091\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1092 [0/1612 (0%)] Loss: 0.168326\n",
      "Train Epoch: 1092 [160/1612 (10%)] Loss: 0.260123\n",
      "Train Epoch: 1092 [320/1612 (20%)] Loss: 0.447972\n",
      "Train Epoch: 1092 [480/1612 (30%)] Loss: 0.663705\n",
      "Train Epoch: 1092 [640/1612 (40%)] Loss: 0.264421\n",
      "Train Epoch: 1092 [800/1612 (50%)] Loss: 0.237579\n",
      "Train Epoch: 1092 [960/1612 (59%)] Loss: 0.202888\n",
      "Train Epoch: 1092 [1120/1612 (69%)] Loss: 0.341831\n",
      "Train Epoch: 1092 [1280/1612 (79%)] Loss: 0.281314\n",
      "Train Epoch: 1092 [1440/1612 (89%)] Loss: 0.295040\n",
      "Train Epoch: 1092 [1200/1612 (99%)] Loss: 0.183670\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1093 [0/1612 (0%)] Loss: 0.380789\n",
      "Train Epoch: 1093 [160/1612 (10%)] Loss: 0.405361\n",
      "Train Epoch: 1093 [320/1612 (20%)] Loss: 0.479265\n",
      "Train Epoch: 1093 [480/1612 (30%)] Loss: 0.319766\n",
      "Train Epoch: 1093 [640/1612 (40%)] Loss: 0.177513\n",
      "Train Epoch: 1093 [800/1612 (50%)] Loss: 0.294186\n",
      "Train Epoch: 1093 [960/1612 (59%)] Loss: 0.189649\n",
      "Train Epoch: 1093 [1120/1612 (69%)] Loss: 0.346873\n",
      "Train Epoch: 1093 [1280/1612 (79%)] Loss: 0.198526\n",
      "Train Epoch: 1093 [1440/1612 (89%)] Loss: 0.509032\n",
      "Train Epoch: 1093 [1200/1612 (99%)] Loss: 0.355255\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1094 [0/1612 (0%)] Loss: 0.288865\n",
      "Train Epoch: 1094 [160/1612 (10%)] Loss: 0.394490\n",
      "Train Epoch: 1094 [320/1612 (20%)] Loss: 0.222772\n",
      "Train Epoch: 1094 [480/1612 (30%)] Loss: 0.409806\n",
      "Train Epoch: 1094 [640/1612 (40%)] Loss: 0.217289\n",
      "Train Epoch: 1094 [800/1612 (50%)] Loss: 0.218087\n",
      "Train Epoch: 1094 [960/1612 (59%)] Loss: 0.458489\n",
      "Train Epoch: 1094 [1120/1612 (69%)] Loss: 0.138777\n",
      "Train Epoch: 1094 [1280/1612 (79%)] Loss: 0.185916\n",
      "Train Epoch: 1094 [1440/1612 (89%)] Loss: 0.224119\n",
      "Train Epoch: 1094 [1200/1612 (99%)] Loss: 0.277799\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1095 [0/1612 (0%)] Loss: 0.363816\n",
      "Train Epoch: 1095 [160/1612 (10%)] Loss: 0.395751\n",
      "Train Epoch: 1095 [320/1612 (20%)] Loss: 0.413978\n",
      "Train Epoch: 1095 [480/1612 (30%)] Loss: 0.210530\n",
      "Train Epoch: 1095 [640/1612 (40%)] Loss: 0.107489\n",
      "Train Epoch: 1095 [800/1612 (50%)] Loss: 0.147624\n",
      "Train Epoch: 1095 [960/1612 (59%)] Loss: 0.247763\n",
      "Train Epoch: 1095 [1120/1612 (69%)] Loss: 0.351767\n",
      "Train Epoch: 1095 [1280/1612 (79%)] Loss: 0.270594\n",
      "Train Epoch: 1095 [1440/1612 (89%)] Loss: 0.273998\n",
      "Train Epoch: 1095 [1200/1612 (99%)] Loss: 0.355754\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1096 [0/1612 (0%)] Loss: 0.264803\n",
      "Train Epoch: 1096 [160/1612 (10%)] Loss: 0.162295\n",
      "Train Epoch: 1096 [320/1612 (20%)] Loss: 0.349128\n",
      "Train Epoch: 1096 [480/1612 (30%)] Loss: 0.206168\n",
      "Train Epoch: 1096 [640/1612 (40%)] Loss: 0.283053\n",
      "Train Epoch: 1096 [800/1612 (50%)] Loss: 0.336676\n",
      "Train Epoch: 1096 [960/1612 (59%)] Loss: 0.326117\n",
      "Train Epoch: 1096 [1120/1612 (69%)] Loss: 0.250581\n",
      "Train Epoch: 1096 [1280/1612 (79%)] Loss: 0.155902\n",
      "Train Epoch: 1096 [1440/1612 (89%)] Loss: 0.299456\n",
      "Train Epoch: 1096 [1200/1612 (99%)] Loss: 0.290849\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1097 [0/1612 (0%)] Loss: 0.188347\n",
      "Train Epoch: 1097 [160/1612 (10%)] Loss: 0.279271\n",
      "Train Epoch: 1097 [320/1612 (20%)] Loss: 0.520264\n",
      "Train Epoch: 1097 [480/1612 (30%)] Loss: 0.237503\n",
      "Train Epoch: 1097 [640/1612 (40%)] Loss: 0.253076\n",
      "Train Epoch: 1097 [800/1612 (50%)] Loss: 0.141589\n",
      "Train Epoch: 1097 [960/1612 (59%)] Loss: 0.175112\n",
      "Train Epoch: 1097 [1120/1612 (69%)] Loss: 0.398616\n",
      "Train Epoch: 1097 [1280/1612 (79%)] Loss: 0.346010\n",
      "Train Epoch: 1097 [1440/1612 (89%)] Loss: 0.373106\n",
      "Train Epoch: 1097 [1200/1612 (99%)] Loss: 0.404168\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1098 [0/1612 (0%)] Loss: 0.306262\n",
      "Train Epoch: 1098 [160/1612 (10%)] Loss: 0.200293\n",
      "Train Epoch: 1098 [320/1612 (20%)] Loss: 0.208646\n",
      "Train Epoch: 1098 [480/1612 (30%)] Loss: 0.341166\n",
      "Train Epoch: 1098 [640/1612 (40%)] Loss: 0.312883\n",
      "Train Epoch: 1098 [800/1612 (50%)] Loss: 0.276658\n",
      "Train Epoch: 1098 [960/1612 (59%)] Loss: 0.291006\n",
      "Train Epoch: 1098 [1120/1612 (69%)] Loss: 0.220063\n",
      "Train Epoch: 1098 [1280/1612 (79%)] Loss: 0.365349\n",
      "Train Epoch: 1098 [1440/1612 (89%)] Loss: 0.316989\n",
      "Train Epoch: 1098 [1200/1612 (99%)] Loss: 0.318565\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1099 [0/1612 (0%)] Loss: 0.406728\n",
      "Train Epoch: 1099 [160/1612 (10%)] Loss: 0.222193\n",
      "Train Epoch: 1099 [320/1612 (20%)] Loss: 0.210769\n",
      "Train Epoch: 1099 [480/1612 (30%)] Loss: 0.288055\n",
      "Train Epoch: 1099 [640/1612 (40%)] Loss: 0.387593\n",
      "Train Epoch: 1099 [800/1612 (50%)] Loss: 0.447865\n",
      "Train Epoch: 1099 [960/1612 (59%)] Loss: 0.240562\n",
      "Train Epoch: 1099 [1120/1612 (69%)] Loss: 0.261852\n",
      "Train Epoch: 1099 [1280/1612 (79%)] Loss: 0.232316\n",
      "Train Epoch: 1099 [1440/1612 (89%)] Loss: 0.141455\n",
      "Train Epoch: 1099 [1200/1612 (99%)] Loss: 0.220188\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1100 [0/1612 (0%)] Loss: 0.256432\n",
      "Train Epoch: 1100 [160/1612 (10%)] Loss: 0.291315\n",
      "Train Epoch: 1100 [320/1612 (20%)] Loss: 0.159651\n",
      "Train Epoch: 1100 [480/1612 (30%)] Loss: 0.140523\n",
      "Train Epoch: 1100 [640/1612 (40%)] Loss: 0.339519\n",
      "Train Epoch: 1100 [800/1612 (50%)] Loss: 0.433216\n",
      "Train Epoch: 1100 [960/1612 (59%)] Loss: 0.490076\n",
      "Train Epoch: 1100 [1120/1612 (69%)] Loss: 0.292463\n",
      "Train Epoch: 1100 [1280/1612 (79%)] Loss: 0.445519\n",
      "Train Epoch: 1100 [1440/1612 (89%)] Loss: 0.259896\n",
      "Train Epoch: 1100 [1200/1612 (99%)] Loss: 0.250516\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1101 [0/1612 (0%)] Loss: 0.218361\n",
      "Train Epoch: 1101 [160/1612 (10%)] Loss: 0.381265\n",
      "Train Epoch: 1101 [320/1612 (20%)] Loss: 0.207660\n",
      "Train Epoch: 1101 [480/1612 (30%)] Loss: 0.100637\n",
      "Train Epoch: 1101 [640/1612 (40%)] Loss: 0.372492\n",
      "Train Epoch: 1101 [800/1612 (50%)] Loss: 0.264511\n",
      "Train Epoch: 1101 [960/1612 (59%)] Loss: 0.186928\n",
      "Train Epoch: 1101 [1120/1612 (69%)] Loss: 0.231630\n",
      "Train Epoch: 1101 [1280/1612 (79%)] Loss: 0.219487\n",
      "Train Epoch: 1101 [1440/1612 (89%)] Loss: 0.154352\n",
      "Train Epoch: 1101 [1200/1612 (99%)] Loss: 0.414011\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1102 [0/1612 (0%)] Loss: 0.277819\n",
      "Train Epoch: 1102 [160/1612 (10%)] Loss: 0.394892\n",
      "Train Epoch: 1102 [320/1612 (20%)] Loss: 0.311231\n",
      "Train Epoch: 1102 [480/1612 (30%)] Loss: 0.365020\n",
      "Train Epoch: 1102 [640/1612 (40%)] Loss: 0.386512\n",
      "Train Epoch: 1102 [800/1612 (50%)] Loss: 0.380421\n",
      "Train Epoch: 1102 [960/1612 (59%)] Loss: 0.234465\n",
      "Train Epoch: 1102 [1120/1612 (69%)] Loss: 0.385157\n",
      "Train Epoch: 1102 [1280/1612 (79%)] Loss: 0.254188\n",
      "Train Epoch: 1102 [1440/1612 (89%)] Loss: 0.348889\n",
      "Train Epoch: 1102 [1200/1612 (99%)] Loss: 0.431491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1103 [0/1612 (0%)] Loss: 0.278623\n",
      "Train Epoch: 1103 [160/1612 (10%)] Loss: 0.359801\n",
      "Train Epoch: 1103 [320/1612 (20%)] Loss: 0.392769\n",
      "Train Epoch: 1103 [480/1612 (30%)] Loss: 0.279260\n",
      "Train Epoch: 1103 [640/1612 (40%)] Loss: 0.410320\n",
      "Train Epoch: 1103 [800/1612 (50%)] Loss: 0.171818\n",
      "Train Epoch: 1103 [960/1612 (59%)] Loss: 0.253685\n",
      "Train Epoch: 1103 [1120/1612 (69%)] Loss: 0.192524\n",
      "Train Epoch: 1103 [1280/1612 (79%)] Loss: 0.135372\n",
      "Train Epoch: 1103 [1440/1612 (89%)] Loss: 0.173298\n",
      "Train Epoch: 1103 [1200/1612 (99%)] Loss: 0.382272\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1104 [0/1612 (0%)] Loss: 0.447975\n",
      "Train Epoch: 1104 [160/1612 (10%)] Loss: 0.131820\n",
      "Train Epoch: 1104 [320/1612 (20%)] Loss: 0.268097\n",
      "Train Epoch: 1104 [480/1612 (30%)] Loss: 0.494641\n",
      "Train Epoch: 1104 [640/1612 (40%)] Loss: 0.197273\n",
      "Train Epoch: 1104 [800/1612 (50%)] Loss: 0.397632\n",
      "Train Epoch: 1104 [960/1612 (59%)] Loss: 0.241793\n",
      "Train Epoch: 1104 [1120/1612 (69%)] Loss: 0.283839\n",
      "Train Epoch: 1104 [1280/1612 (79%)] Loss: 0.201992\n",
      "Train Epoch: 1104 [1440/1612 (89%)] Loss: 0.262077\n",
      "Train Epoch: 1104 [1200/1612 (99%)] Loss: 0.458804\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1105 [0/1612 (0%)] Loss: 0.289816\n",
      "Train Epoch: 1105 [160/1612 (10%)] Loss: 0.327911\n",
      "Train Epoch: 1105 [320/1612 (20%)] Loss: 0.297904\n",
      "Train Epoch: 1105 [480/1612 (30%)] Loss: 0.150440\n",
      "Train Epoch: 1105 [640/1612 (40%)] Loss: 0.305498\n",
      "Train Epoch: 1105 [800/1612 (50%)] Loss: 0.423069\n",
      "Train Epoch: 1105 [960/1612 (59%)] Loss: 0.440655\n",
      "Train Epoch: 1105 [1120/1612 (69%)] Loss: 0.230506\n",
      "Train Epoch: 1105 [1280/1612 (79%)] Loss: 0.082263\n",
      "Train Epoch: 1105 [1440/1612 (89%)] Loss: 0.188087\n",
      "Train Epoch: 1105 [1200/1612 (99%)] Loss: 0.271561\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1106 [0/1612 (0%)] Loss: 0.291581\n",
      "Train Epoch: 1106 [160/1612 (10%)] Loss: 0.473236\n",
      "Train Epoch: 1106 [320/1612 (20%)] Loss: 0.086063\n",
      "Train Epoch: 1106 [480/1612 (30%)] Loss: 0.413114\n",
      "Train Epoch: 1106 [640/1612 (40%)] Loss: 0.254932\n",
      "Train Epoch: 1106 [800/1612 (50%)] Loss: 0.283728\n",
      "Train Epoch: 1106 [960/1612 (59%)] Loss: 0.118415\n",
      "Train Epoch: 1106 [1120/1612 (69%)] Loss: 0.558014\n",
      "Train Epoch: 1106 [1280/1612 (79%)] Loss: 0.283571\n",
      "Train Epoch: 1106 [1440/1612 (89%)] Loss: 0.176594\n",
      "Train Epoch: 1106 [1200/1612 (99%)] Loss: 0.383252\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1107 [0/1612 (0%)] Loss: 0.281311\n",
      "Train Epoch: 1107 [160/1612 (10%)] Loss: 0.244473\n",
      "Train Epoch: 1107 [320/1612 (20%)] Loss: 0.344681\n",
      "Train Epoch: 1107 [480/1612 (30%)] Loss: 0.344329\n",
      "Train Epoch: 1107 [640/1612 (40%)] Loss: 0.199295\n",
      "Train Epoch: 1107 [800/1612 (50%)] Loss: 0.233883\n",
      "Train Epoch: 1107 [960/1612 (59%)] Loss: 0.385765\n",
      "Train Epoch: 1107 [1120/1612 (69%)] Loss: 0.387583\n",
      "Train Epoch: 1107 [1280/1612 (79%)] Loss: 0.231176\n",
      "Train Epoch: 1107 [1440/1612 (89%)] Loss: 0.197565\n",
      "Train Epoch: 1107 [1200/1612 (99%)] Loss: 0.229407\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1108 [0/1612 (0%)] Loss: 0.152809\n",
      "Train Epoch: 1108 [160/1612 (10%)] Loss: 0.337564\n",
      "Train Epoch: 1108 [320/1612 (20%)] Loss: 0.610828\n",
      "Train Epoch: 1108 [480/1612 (30%)] Loss: 0.707689\n",
      "Train Epoch: 1108 [640/1612 (40%)] Loss: 0.191156\n",
      "Train Epoch: 1108 [800/1612 (50%)] Loss: 0.426385\n",
      "Train Epoch: 1108 [960/1612 (59%)] Loss: 0.351494\n",
      "Train Epoch: 1108 [1120/1612 (69%)] Loss: 0.352335\n",
      "Train Epoch: 1108 [1280/1612 (79%)] Loss: 0.336649\n",
      "Train Epoch: 1108 [1440/1612 (89%)] Loss: 0.370207\n",
      "Train Epoch: 1108 [1200/1612 (99%)] Loss: 0.123038\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1109 [0/1612 (0%)] Loss: 0.355426\n",
      "Train Epoch: 1109 [160/1612 (10%)] Loss: 0.263366\n",
      "Train Epoch: 1109 [320/1612 (20%)] Loss: 0.413626\n",
      "Train Epoch: 1109 [480/1612 (30%)] Loss: 0.214174\n",
      "Train Epoch: 1109 [640/1612 (40%)] Loss: 0.358067\n",
      "Train Epoch: 1109 [800/1612 (50%)] Loss: 0.458470\n",
      "Train Epoch: 1109 [960/1612 (59%)] Loss: 0.365656\n",
      "Train Epoch: 1109 [1120/1612 (69%)] Loss: 0.117163\n",
      "Train Epoch: 1109 [1280/1612 (79%)] Loss: 0.335915\n",
      "Train Epoch: 1109 [1440/1612 (89%)] Loss: 0.084155\n",
      "Train Epoch: 1109 [1200/1612 (99%)] Loss: 0.403133\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1110 [0/1612 (0%)] Loss: 0.443441\n",
      "Train Epoch: 1110 [160/1612 (10%)] Loss: 0.512221\n",
      "Train Epoch: 1110 [320/1612 (20%)] Loss: 0.244256\n",
      "Train Epoch: 1110 [480/1612 (30%)] Loss: 0.244363\n",
      "Train Epoch: 1110 [640/1612 (40%)] Loss: 0.171799\n",
      "Train Epoch: 1110 [800/1612 (50%)] Loss: 0.186727\n",
      "Train Epoch: 1110 [960/1612 (59%)] Loss: 0.381247\n",
      "Train Epoch: 1110 [1120/1612 (69%)] Loss: 0.283624\n",
      "Train Epoch: 1110 [1280/1612 (79%)] Loss: 0.182641\n",
      "Train Epoch: 1110 [1440/1612 (89%)] Loss: 0.402712\n",
      "Train Epoch: 1110 [1200/1612 (99%)] Loss: 0.255220\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1111 [0/1612 (0%)] Loss: 0.036404\n",
      "Train Epoch: 1111 [160/1612 (10%)] Loss: 0.190692\n",
      "Train Epoch: 1111 [320/1612 (20%)] Loss: 0.091189\n",
      "Train Epoch: 1111 [480/1612 (30%)] Loss: 0.386614\n",
      "Train Epoch: 1111 [640/1612 (40%)] Loss: 0.292000\n",
      "Train Epoch: 1111 [800/1612 (50%)] Loss: 0.281204\n",
      "Train Epoch: 1111 [960/1612 (59%)] Loss: 0.346066\n",
      "Train Epoch: 1111 [1120/1612 (69%)] Loss: 0.225376\n",
      "Train Epoch: 1111 [1280/1612 (79%)] Loss: 0.450446\n",
      "Train Epoch: 1111 [1440/1612 (89%)] Loss: 0.316299\n",
      "Train Epoch: 1111 [1200/1612 (99%)] Loss: 0.226920\n",
      "\n",
      "Test set: Average loss: 0.0294, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1112 [0/1612 (0%)] Loss: 0.333763\n",
      "Train Epoch: 1112 [160/1612 (10%)] Loss: 0.154875\n",
      "Train Epoch: 1112 [320/1612 (20%)] Loss: 0.494757\n",
      "Train Epoch: 1112 [480/1612 (30%)] Loss: 0.221654\n",
      "Train Epoch: 1112 [640/1612 (40%)] Loss: 0.204031\n",
      "Train Epoch: 1112 [800/1612 (50%)] Loss: 0.178828\n",
      "Train Epoch: 1112 [960/1612 (59%)] Loss: 0.545612\n",
      "Train Epoch: 1112 [1120/1612 (69%)] Loss: 0.119637\n",
      "Train Epoch: 1112 [1280/1612 (79%)] Loss: 0.215813\n",
      "Train Epoch: 1112 [1440/1612 (89%)] Loss: 0.193698\n",
      "Train Epoch: 1112 [1200/1612 (99%)] Loss: 0.198656\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1113 [0/1612 (0%)] Loss: 0.259403\n",
      "Train Epoch: 1113 [160/1612 (10%)] Loss: 0.145392\n",
      "Train Epoch: 1113 [320/1612 (20%)] Loss: 0.531242\n",
      "Train Epoch: 1113 [480/1612 (30%)] Loss: 0.168092\n",
      "Train Epoch: 1113 [640/1612 (40%)] Loss: 0.433218\n",
      "Train Epoch: 1113 [800/1612 (50%)] Loss: 0.381185\n",
      "Train Epoch: 1113 [960/1612 (59%)] Loss: 0.177225\n",
      "Train Epoch: 1113 [1120/1612 (69%)] Loss: 0.295465\n",
      "Train Epoch: 1113 [1280/1612 (79%)] Loss: 0.516846\n",
      "Train Epoch: 1113 [1440/1612 (89%)] Loss: 0.070812\n",
      "Train Epoch: 1113 [1200/1612 (99%)] Loss: 0.500843\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1114 [0/1612 (0%)] Loss: 0.219541\n",
      "Train Epoch: 1114 [160/1612 (10%)] Loss: 0.273162\n",
      "Train Epoch: 1114 [320/1612 (20%)] Loss: 0.142329\n",
      "Train Epoch: 1114 [480/1612 (30%)] Loss: 0.216506\n",
      "Train Epoch: 1114 [640/1612 (40%)] Loss: 0.440690\n",
      "Train Epoch: 1114 [800/1612 (50%)] Loss: 0.204211\n",
      "Train Epoch: 1114 [960/1612 (59%)] Loss: 0.153621\n",
      "Train Epoch: 1114 [1120/1612 (69%)] Loss: 0.440984\n",
      "Train Epoch: 1114 [1280/1612 (79%)] Loss: 0.305438\n",
      "Train Epoch: 1114 [1440/1612 (89%)] Loss: 0.145691\n",
      "Train Epoch: 1114 [1200/1612 (99%)] Loss: 0.100822\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1115 [0/1612 (0%)] Loss: 0.169948\n",
      "Train Epoch: 1115 [160/1612 (10%)] Loss: 0.262825\n",
      "Train Epoch: 1115 [320/1612 (20%)] Loss: 0.112105\n",
      "Train Epoch: 1115 [480/1612 (30%)] Loss: 0.341840\n",
      "Train Epoch: 1115 [640/1612 (40%)] Loss: 0.432416\n",
      "Train Epoch: 1115 [800/1612 (50%)] Loss: 0.216232\n",
      "Train Epoch: 1115 [960/1612 (59%)] Loss: 0.297935\n",
      "Train Epoch: 1115 [1120/1612 (69%)] Loss: 0.329372\n",
      "Train Epoch: 1115 [1280/1612 (79%)] Loss: 0.130022\n",
      "Train Epoch: 1115 [1440/1612 (89%)] Loss: 0.340737\n",
      "Train Epoch: 1115 [1200/1612 (99%)] Loss: 0.214196\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1116 [0/1612 (0%)] Loss: 0.320305\n",
      "Train Epoch: 1116 [160/1612 (10%)] Loss: 0.118624\n",
      "Train Epoch: 1116 [320/1612 (20%)] Loss: 0.294002\n",
      "Train Epoch: 1116 [480/1612 (30%)] Loss: 0.109135\n",
      "Train Epoch: 1116 [640/1612 (40%)] Loss: 0.179780\n",
      "Train Epoch: 1116 [800/1612 (50%)] Loss: 0.219921\n",
      "Train Epoch: 1116 [960/1612 (59%)] Loss: 0.154371\n",
      "Train Epoch: 1116 [1120/1612 (69%)] Loss: 0.357787\n",
      "Train Epoch: 1116 [1280/1612 (79%)] Loss: 0.201035\n",
      "Train Epoch: 1116 [1440/1612 (89%)] Loss: 0.275189\n",
      "Train Epoch: 1116 [1200/1612 (99%)] Loss: 0.505929\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1117 [0/1612 (0%)] Loss: 0.198982\n",
      "Train Epoch: 1117 [160/1612 (10%)] Loss: 0.168299\n",
      "Train Epoch: 1117 [320/1612 (20%)] Loss: 0.322223\n",
      "Train Epoch: 1117 [480/1612 (30%)] Loss: 0.312562\n",
      "Train Epoch: 1117 [640/1612 (40%)] Loss: 0.225430\n",
      "Train Epoch: 1117 [800/1612 (50%)] Loss: 0.327777\n",
      "Train Epoch: 1117 [960/1612 (59%)] Loss: 0.218656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1117 [1120/1612 (69%)] Loss: 0.259883\n",
      "Train Epoch: 1117 [1280/1612 (79%)] Loss: 0.310524\n",
      "Train Epoch: 1117 [1440/1612 (89%)] Loss: 0.200173\n",
      "Train Epoch: 1117 [1200/1612 (99%)] Loss: 0.211102\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1118 [0/1612 (0%)] Loss: 0.260520\n",
      "Train Epoch: 1118 [160/1612 (10%)] Loss: 0.303420\n",
      "Train Epoch: 1118 [320/1612 (20%)] Loss: 0.149882\n",
      "Train Epoch: 1118 [480/1612 (30%)] Loss: 0.239010\n",
      "Train Epoch: 1118 [640/1612 (40%)] Loss: 0.345994\n",
      "Train Epoch: 1118 [800/1612 (50%)] Loss: 0.277129\n",
      "Train Epoch: 1118 [960/1612 (59%)] Loss: 0.129691\n",
      "Train Epoch: 1118 [1120/1612 (69%)] Loss: 0.292360\n",
      "Train Epoch: 1118 [1280/1612 (79%)] Loss: 0.242913\n",
      "Train Epoch: 1118 [1440/1612 (89%)] Loss: 0.258687\n",
      "Train Epoch: 1118 [1200/1612 (99%)] Loss: 0.207301\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1119 [0/1612 (0%)] Loss: 0.321762\n",
      "Train Epoch: 1119 [160/1612 (10%)] Loss: 0.150580\n",
      "Train Epoch: 1119 [320/1612 (20%)] Loss: 0.355541\n",
      "Train Epoch: 1119 [480/1612 (30%)] Loss: 0.072802\n",
      "Train Epoch: 1119 [640/1612 (40%)] Loss: 0.277780\n",
      "Train Epoch: 1119 [800/1612 (50%)] Loss: 0.506564\n",
      "Train Epoch: 1119 [960/1612 (59%)] Loss: 0.142687\n",
      "Train Epoch: 1119 [1120/1612 (69%)] Loss: 0.088387\n",
      "Train Epoch: 1119 [1280/1612 (79%)] Loss: 0.347197\n",
      "Train Epoch: 1119 [1440/1612 (89%)] Loss: 0.376257\n",
      "Train Epoch: 1119 [1200/1612 (99%)] Loss: 0.552934\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1120 [0/1612 (0%)] Loss: 0.337386\n",
      "Train Epoch: 1120 [160/1612 (10%)] Loss: 0.298897\n",
      "Train Epoch: 1120 [320/1612 (20%)] Loss: 0.426795\n",
      "Train Epoch: 1120 [480/1612 (30%)] Loss: 0.527416\n",
      "Train Epoch: 1120 [640/1612 (40%)] Loss: 0.400802\n",
      "Train Epoch: 1120 [800/1612 (50%)] Loss: 0.340850\n",
      "Train Epoch: 1120 [960/1612 (59%)] Loss: 0.431448\n",
      "Train Epoch: 1120 [1120/1612 (69%)] Loss: 0.202438\n",
      "Train Epoch: 1120 [1280/1612 (79%)] Loss: 0.307825\n",
      "Train Epoch: 1120 [1440/1612 (89%)] Loss: 0.174706\n",
      "Train Epoch: 1120 [1200/1612 (99%)] Loss: 0.575152\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1121 [0/1612 (0%)] Loss: 0.317389\n",
      "Train Epoch: 1121 [160/1612 (10%)] Loss: 0.207013\n",
      "Train Epoch: 1121 [320/1612 (20%)] Loss: 0.289174\n",
      "Train Epoch: 1121 [480/1612 (30%)] Loss: 0.233685\n",
      "Train Epoch: 1121 [640/1612 (40%)] Loss: 0.421664\n",
      "Train Epoch: 1121 [800/1612 (50%)] Loss: 0.474884\n",
      "Train Epoch: 1121 [960/1612 (59%)] Loss: 0.421189\n",
      "Train Epoch: 1121 [1120/1612 (69%)] Loss: 0.292576\n",
      "Train Epoch: 1121 [1280/1612 (79%)] Loss: 0.158529\n",
      "Train Epoch: 1121 [1440/1612 (89%)] Loss: 0.284484\n",
      "Train Epoch: 1121 [1200/1612 (99%)] Loss: 0.156201\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1122 [0/1612 (0%)] Loss: 0.450090\n",
      "Train Epoch: 1122 [160/1612 (10%)] Loss: 0.378423\n",
      "Train Epoch: 1122 [320/1612 (20%)] Loss: 0.154028\n",
      "Train Epoch: 1122 [480/1612 (30%)] Loss: 0.235294\n",
      "Train Epoch: 1122 [640/1612 (40%)] Loss: 0.314278\n",
      "Train Epoch: 1122 [800/1612 (50%)] Loss: 0.300969\n",
      "Train Epoch: 1122 [960/1612 (59%)] Loss: 0.335228\n",
      "Train Epoch: 1122 [1120/1612 (69%)] Loss: 0.380338\n",
      "Train Epoch: 1122 [1280/1612 (79%)] Loss: 0.388356\n",
      "Train Epoch: 1122 [1440/1612 (89%)] Loss: 0.577453\n",
      "Train Epoch: 1122 [1200/1612 (99%)] Loss: 0.038699\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1123 [0/1612 (0%)] Loss: 0.215318\n",
      "Train Epoch: 1123 [160/1612 (10%)] Loss: 0.164923\n",
      "Train Epoch: 1123 [320/1612 (20%)] Loss: 0.326705\n",
      "Train Epoch: 1123 [480/1612 (30%)] Loss: 0.529958\n",
      "Train Epoch: 1123 [640/1612 (40%)] Loss: 0.478949\n",
      "Train Epoch: 1123 [800/1612 (50%)] Loss: 0.374889\n",
      "Train Epoch: 1123 [960/1612 (59%)] Loss: 0.120382\n",
      "Train Epoch: 1123 [1120/1612 (69%)] Loss: 0.128441\n",
      "Train Epoch: 1123 [1280/1612 (79%)] Loss: 0.508683\n",
      "Train Epoch: 1123 [1440/1612 (89%)] Loss: 0.196406\n",
      "Train Epoch: 1123 [1200/1612 (99%)] Loss: 0.412649\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1124 [0/1612 (0%)] Loss: 0.499105\n",
      "Train Epoch: 1124 [160/1612 (10%)] Loss: 0.214002\n",
      "Train Epoch: 1124 [320/1612 (20%)] Loss: 0.356694\n",
      "Train Epoch: 1124 [480/1612 (30%)] Loss: 0.320811\n",
      "Train Epoch: 1124 [640/1612 (40%)] Loss: 0.618088\n",
      "Train Epoch: 1124 [800/1612 (50%)] Loss: 0.257594\n",
      "Train Epoch: 1124 [960/1612 (59%)] Loss: 0.216284\n",
      "Train Epoch: 1124 [1120/1612 (69%)] Loss: 0.201286\n",
      "Train Epoch: 1124 [1280/1612 (79%)] Loss: 0.421650\n",
      "Train Epoch: 1124 [1440/1612 (89%)] Loss: 0.225300\n",
      "Train Epoch: 1124 [1200/1612 (99%)] Loss: 0.261137\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1125 [0/1612 (0%)] Loss: 0.442808\n",
      "Train Epoch: 1125 [160/1612 (10%)] Loss: 0.127551\n",
      "Train Epoch: 1125 [320/1612 (20%)] Loss: 0.294754\n",
      "Train Epoch: 1125 [480/1612 (30%)] Loss: 0.198107\n",
      "Train Epoch: 1125 [640/1612 (40%)] Loss: 0.358406\n",
      "Train Epoch: 1125 [800/1612 (50%)] Loss: 0.311875\n",
      "Train Epoch: 1125 [960/1612 (59%)] Loss: 0.219829\n",
      "Train Epoch: 1125 [1120/1612 (69%)] Loss: 0.205009\n",
      "Train Epoch: 1125 [1280/1612 (79%)] Loss: 0.190181\n",
      "Train Epoch: 1125 [1440/1612 (89%)] Loss: 0.131213\n",
      "Train Epoch: 1125 [1200/1612 (99%)] Loss: 0.325579\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1126 [0/1612 (0%)] Loss: 0.232467\n",
      "Train Epoch: 1126 [160/1612 (10%)] Loss: 0.186253\n",
      "Train Epoch: 1126 [320/1612 (20%)] Loss: 0.179879\n",
      "Train Epoch: 1126 [480/1612 (30%)] Loss: 0.268931\n",
      "Train Epoch: 1126 [640/1612 (40%)] Loss: 0.329982\n",
      "Train Epoch: 1126 [800/1612 (50%)] Loss: 0.416447\n",
      "Train Epoch: 1126 [960/1612 (59%)] Loss: 0.364257\n",
      "Train Epoch: 1126 [1120/1612 (69%)] Loss: 0.387679\n",
      "Train Epoch: 1126 [1280/1612 (79%)] Loss: 0.204425\n",
      "Train Epoch: 1126 [1440/1612 (89%)] Loss: 0.569857\n",
      "Train Epoch: 1126 [1200/1612 (99%)] Loss: 0.426077\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1127 [0/1612 (0%)] Loss: 0.459568\n",
      "Train Epoch: 1127 [160/1612 (10%)] Loss: 0.417370\n",
      "Train Epoch: 1127 [320/1612 (20%)] Loss: 0.242034\n",
      "Train Epoch: 1127 [480/1612 (30%)] Loss: 0.291099\n",
      "Train Epoch: 1127 [640/1612 (40%)] Loss: 0.511249\n",
      "Train Epoch: 1127 [800/1612 (50%)] Loss: 0.206059\n",
      "Train Epoch: 1127 [960/1612 (59%)] Loss: 0.390063\n",
      "Train Epoch: 1127 [1120/1612 (69%)] Loss: 0.532531\n",
      "Train Epoch: 1127 [1280/1612 (79%)] Loss: 0.378250\n",
      "Train Epoch: 1127 [1440/1612 (89%)] Loss: 0.355175\n",
      "Train Epoch: 1127 [1200/1612 (99%)] Loss: 0.194841\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1128 [0/1612 (0%)] Loss: 0.188198\n",
      "Train Epoch: 1128 [160/1612 (10%)] Loss: 0.328822\n",
      "Train Epoch: 1128 [320/1612 (20%)] Loss: 0.340644\n",
      "Train Epoch: 1128 [480/1612 (30%)] Loss: 0.369609\n",
      "Train Epoch: 1128 [640/1612 (40%)] Loss: 0.090662\n",
      "Train Epoch: 1128 [800/1612 (50%)] Loss: 0.163592\n",
      "Train Epoch: 1128 [960/1612 (59%)] Loss: 0.298439\n",
      "Train Epoch: 1128 [1120/1612 (69%)] Loss: 0.224375\n",
      "Train Epoch: 1128 [1280/1612 (79%)] Loss: 0.255876\n",
      "Train Epoch: 1128 [1440/1612 (89%)] Loss: 0.573454\n",
      "Train Epoch: 1128 [1200/1612 (99%)] Loss: 0.278967\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1129 [0/1612 (0%)] Loss: 0.565244\n",
      "Train Epoch: 1129 [160/1612 (10%)] Loss: 0.261870\n",
      "Train Epoch: 1129 [320/1612 (20%)] Loss: 0.165679\n",
      "Train Epoch: 1129 [480/1612 (30%)] Loss: 0.256836\n",
      "Train Epoch: 1129 [640/1612 (40%)] Loss: 0.466251\n",
      "Train Epoch: 1129 [800/1612 (50%)] Loss: 0.395898\n",
      "Train Epoch: 1129 [960/1612 (59%)] Loss: 0.360569\n",
      "Train Epoch: 1129 [1120/1612 (69%)] Loss: 0.324389\n",
      "Train Epoch: 1129 [1280/1612 (79%)] Loss: 0.393444\n",
      "Train Epoch: 1129 [1440/1612 (89%)] Loss: 0.159007\n",
      "Train Epoch: 1129 [1200/1612 (99%)] Loss: 0.192337\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1130 [0/1612 (0%)] Loss: 0.390564\n",
      "Train Epoch: 1130 [160/1612 (10%)] Loss: 0.344509\n",
      "Train Epoch: 1130 [320/1612 (20%)] Loss: 0.552427\n",
      "Train Epoch: 1130 [480/1612 (30%)] Loss: 0.192127\n",
      "Train Epoch: 1130 [640/1612 (40%)] Loss: 0.313565\n",
      "Train Epoch: 1130 [800/1612 (50%)] Loss: 0.159591\n",
      "Train Epoch: 1130 [960/1612 (59%)] Loss: 0.272434\n",
      "Train Epoch: 1130 [1120/1612 (69%)] Loss: 0.199844\n",
      "Train Epoch: 1130 [1280/1612 (79%)] Loss: 0.259193\n",
      "Train Epoch: 1130 [1440/1612 (89%)] Loss: 0.186710\n",
      "Train Epoch: 1130 [1200/1612 (99%)] Loss: 0.142180\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1131 [0/1612 (0%)] Loss: 0.089911\n",
      "Train Epoch: 1131 [160/1612 (10%)] Loss: 0.357915\n",
      "Train Epoch: 1131 [320/1612 (20%)] Loss: 0.367222\n",
      "Train Epoch: 1131 [480/1612 (30%)] Loss: 0.207102\n",
      "Train Epoch: 1131 [640/1612 (40%)] Loss: 0.487965\n",
      "Train Epoch: 1131 [800/1612 (50%)] Loss: 0.142291\n",
      "Train Epoch: 1131 [960/1612 (59%)] Loss: 0.437643\n",
      "Train Epoch: 1131 [1120/1612 (69%)] Loss: 0.262995\n",
      "Train Epoch: 1131 [1280/1612 (79%)] Loss: 0.534131\n",
      "Train Epoch: 1131 [1440/1612 (89%)] Loss: 0.166714\n",
      "Train Epoch: 1131 [1200/1612 (99%)] Loss: 0.356543\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1132 [0/1612 (0%)] Loss: 0.287842\n",
      "Train Epoch: 1132 [160/1612 (10%)] Loss: 0.294974\n",
      "Train Epoch: 1132 [320/1612 (20%)] Loss: 0.324499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1132 [480/1612 (30%)] Loss: 0.253472\n",
      "Train Epoch: 1132 [640/1612 (40%)] Loss: 0.334162\n",
      "Train Epoch: 1132 [800/1612 (50%)] Loss: 0.588826\n",
      "Train Epoch: 1132 [960/1612 (59%)] Loss: 0.274136\n",
      "Train Epoch: 1132 [1120/1612 (69%)] Loss: 0.110673\n",
      "Train Epoch: 1132 [1280/1612 (79%)] Loss: 0.185295\n",
      "Train Epoch: 1132 [1440/1612 (89%)] Loss: 0.278729\n",
      "Train Epoch: 1132 [1200/1612 (99%)] Loss: 0.317068\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1133 [0/1612 (0%)] Loss: 0.518220\n",
      "Train Epoch: 1133 [160/1612 (10%)] Loss: 0.137616\n",
      "Train Epoch: 1133 [320/1612 (20%)] Loss: 0.131274\n",
      "Train Epoch: 1133 [480/1612 (30%)] Loss: 0.118609\n",
      "Train Epoch: 1133 [640/1612 (40%)] Loss: 0.269875\n",
      "Train Epoch: 1133 [800/1612 (50%)] Loss: 0.202754\n",
      "Train Epoch: 1133 [960/1612 (59%)] Loss: 0.329413\n",
      "Train Epoch: 1133 [1120/1612 (69%)] Loss: 0.431481\n",
      "Train Epoch: 1133 [1280/1612 (79%)] Loss: 0.392417\n",
      "Train Epoch: 1133 [1440/1612 (89%)] Loss: 0.432211\n",
      "Train Epoch: 1133 [1200/1612 (99%)] Loss: 0.453769\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1134 [0/1612 (0%)] Loss: 0.200329\n",
      "Train Epoch: 1134 [160/1612 (10%)] Loss: 0.318610\n",
      "Train Epoch: 1134 [320/1612 (20%)] Loss: 0.246522\n",
      "Train Epoch: 1134 [480/1612 (30%)] Loss: 0.303221\n",
      "Train Epoch: 1134 [640/1612 (40%)] Loss: 0.349501\n",
      "Train Epoch: 1134 [800/1612 (50%)] Loss: 0.407403\n",
      "Train Epoch: 1134 [960/1612 (59%)] Loss: 0.467187\n",
      "Train Epoch: 1134 [1120/1612 (69%)] Loss: 0.647359\n",
      "Train Epoch: 1134 [1280/1612 (79%)] Loss: 0.369015\n",
      "Train Epoch: 1134 [1440/1612 (89%)] Loss: 0.445181\n",
      "Train Epoch: 1134 [1200/1612 (99%)] Loss: 0.078696\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1135 [0/1612 (0%)] Loss: 0.186254\n",
      "Train Epoch: 1135 [160/1612 (10%)] Loss: 0.194149\n",
      "Train Epoch: 1135 [320/1612 (20%)] Loss: 0.430389\n",
      "Train Epoch: 1135 [480/1612 (30%)] Loss: 0.221659\n",
      "Train Epoch: 1135 [640/1612 (40%)] Loss: 0.406973\n",
      "Train Epoch: 1135 [800/1612 (50%)] Loss: 0.194910\n",
      "Train Epoch: 1135 [960/1612 (59%)] Loss: 0.207568\n",
      "Train Epoch: 1135 [1120/1612 (69%)] Loss: 0.246364\n",
      "Train Epoch: 1135 [1280/1612 (79%)] Loss: 0.206291\n",
      "Train Epoch: 1135 [1440/1612 (89%)] Loss: 0.308136\n",
      "Train Epoch: 1135 [1200/1612 (99%)] Loss: 0.402033\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1136 [0/1612 (0%)] Loss: 0.286914\n",
      "Train Epoch: 1136 [160/1612 (10%)] Loss: 0.399906\n",
      "Train Epoch: 1136 [320/1612 (20%)] Loss: 0.306296\n",
      "Train Epoch: 1136 [480/1612 (30%)] Loss: 0.182548\n",
      "Train Epoch: 1136 [640/1612 (40%)] Loss: 0.264363\n",
      "Train Epoch: 1136 [800/1612 (50%)] Loss: 0.427726\n",
      "Train Epoch: 1136 [960/1612 (59%)] Loss: 0.313330\n",
      "Train Epoch: 1136 [1120/1612 (69%)] Loss: 0.551629\n",
      "Train Epoch: 1136 [1280/1612 (79%)] Loss: 0.324525\n",
      "Train Epoch: 1136 [1440/1612 (89%)] Loss: 0.221427\n",
      "Train Epoch: 1136 [1200/1612 (99%)] Loss: 0.180771\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1137 [0/1612 (0%)] Loss: 0.343216\n",
      "Train Epoch: 1137 [160/1612 (10%)] Loss: 0.316303\n",
      "Train Epoch: 1137 [320/1612 (20%)] Loss: 0.585985\n",
      "Train Epoch: 1137 [480/1612 (30%)] Loss: 0.234352\n",
      "Train Epoch: 1137 [640/1612 (40%)] Loss: 0.232739\n",
      "Train Epoch: 1137 [800/1612 (50%)] Loss: 0.329702\n",
      "Train Epoch: 1137 [960/1612 (59%)] Loss: 0.273265\n",
      "Train Epoch: 1137 [1120/1612 (69%)] Loss: 0.235031\n",
      "Train Epoch: 1137 [1280/1612 (79%)] Loss: 0.168659\n",
      "Train Epoch: 1137 [1440/1612 (89%)] Loss: 0.309298\n",
      "Train Epoch: 1137 [1200/1612 (99%)] Loss: 0.217593\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1138 [0/1612 (0%)] Loss: 0.452717\n",
      "Train Epoch: 1138 [160/1612 (10%)] Loss: 0.105009\n",
      "Train Epoch: 1138 [320/1612 (20%)] Loss: 0.284371\n",
      "Train Epoch: 1138 [480/1612 (30%)] Loss: 0.368711\n",
      "Train Epoch: 1138 [640/1612 (40%)] Loss: 0.290132\n",
      "Train Epoch: 1138 [800/1612 (50%)] Loss: 0.423351\n",
      "Train Epoch: 1138 [960/1612 (59%)] Loss: 0.302893\n",
      "Train Epoch: 1138 [1120/1612 (69%)] Loss: 0.211957\n",
      "Train Epoch: 1138 [1280/1612 (79%)] Loss: 0.187635\n",
      "Train Epoch: 1138 [1440/1612 (89%)] Loss: 0.423274\n",
      "Train Epoch: 1138 [1200/1612 (99%)] Loss: 0.386913\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1139 [0/1612 (0%)] Loss: 0.212652\n",
      "Train Epoch: 1139 [160/1612 (10%)] Loss: 0.455699\n",
      "Train Epoch: 1139 [320/1612 (20%)] Loss: 0.213870\n",
      "Train Epoch: 1139 [480/1612 (30%)] Loss: 0.350736\n",
      "Train Epoch: 1139 [640/1612 (40%)] Loss: 0.681533\n",
      "Train Epoch: 1139 [800/1612 (50%)] Loss: 0.319645\n",
      "Train Epoch: 1139 [960/1612 (59%)] Loss: 0.353603\n",
      "Train Epoch: 1139 [1120/1612 (69%)] Loss: 0.128449\n",
      "Train Epoch: 1139 [1280/1612 (79%)] Loss: 0.114861\n",
      "Train Epoch: 1139 [1440/1612 (89%)] Loss: 0.475979\n",
      "Train Epoch: 1139 [1200/1612 (99%)] Loss: 0.612613\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1140 [0/1612 (0%)] Loss: 0.449330\n",
      "Train Epoch: 1140 [160/1612 (10%)] Loss: 0.135959\n",
      "Train Epoch: 1140 [320/1612 (20%)] Loss: 0.196433\n",
      "Train Epoch: 1140 [480/1612 (30%)] Loss: 0.251664\n",
      "Train Epoch: 1140 [640/1612 (40%)] Loss: 0.343772\n",
      "Train Epoch: 1140 [800/1612 (50%)] Loss: 0.297578\n",
      "Train Epoch: 1140 [960/1612 (59%)] Loss: 0.394579\n",
      "Train Epoch: 1140 [1120/1612 (69%)] Loss: 0.225531\n",
      "Train Epoch: 1140 [1280/1612 (79%)] Loss: 0.256719\n",
      "Train Epoch: 1140 [1440/1612 (89%)] Loss: 0.418839\n",
      "Train Epoch: 1140 [1200/1612 (99%)] Loss: 0.284674\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1141 [0/1612 (0%)] Loss: 0.310435\n",
      "Train Epoch: 1141 [160/1612 (10%)] Loss: 0.421965\n",
      "Train Epoch: 1141 [320/1612 (20%)] Loss: 0.201674\n",
      "Train Epoch: 1141 [480/1612 (30%)] Loss: 0.483436\n",
      "Train Epoch: 1141 [640/1612 (40%)] Loss: 0.281390\n",
      "Train Epoch: 1141 [800/1612 (50%)] Loss: 0.345143\n",
      "Train Epoch: 1141 [960/1612 (59%)] Loss: 0.363059\n",
      "Train Epoch: 1141 [1120/1612 (69%)] Loss: 0.075838\n",
      "Train Epoch: 1141 [1280/1612 (79%)] Loss: 0.202534\n",
      "Train Epoch: 1141 [1440/1612 (89%)] Loss: 0.262114\n",
      "Train Epoch: 1141 [1200/1612 (99%)] Loss: 0.480683\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1142 [0/1612 (0%)] Loss: 0.579397\n",
      "Train Epoch: 1142 [160/1612 (10%)] Loss: 0.334859\n",
      "Train Epoch: 1142 [320/1612 (20%)] Loss: 0.178077\n",
      "Train Epoch: 1142 [480/1612 (30%)] Loss: 0.257066\n",
      "Train Epoch: 1142 [640/1612 (40%)] Loss: 0.358580\n",
      "Train Epoch: 1142 [800/1612 (50%)] Loss: 0.201396\n",
      "Train Epoch: 1142 [960/1612 (59%)] Loss: 0.308311\n",
      "Train Epoch: 1142 [1120/1612 (69%)] Loss: 0.444032\n",
      "Train Epoch: 1142 [1280/1612 (79%)] Loss: 0.489183\n",
      "Train Epoch: 1142 [1440/1612 (89%)] Loss: 0.418475\n",
      "Train Epoch: 1142 [1200/1612 (99%)] Loss: 0.265866\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1143 [0/1612 (0%)] Loss: 0.206232\n",
      "Train Epoch: 1143 [160/1612 (10%)] Loss: 0.413768\n",
      "Train Epoch: 1143 [320/1612 (20%)] Loss: 0.546182\n",
      "Train Epoch: 1143 [480/1612 (30%)] Loss: 0.402231\n",
      "Train Epoch: 1143 [640/1612 (40%)] Loss: 0.138265\n",
      "Train Epoch: 1143 [800/1612 (50%)] Loss: 0.135218\n",
      "Train Epoch: 1143 [960/1612 (59%)] Loss: 0.359018\n",
      "Train Epoch: 1143 [1120/1612 (69%)] Loss: 0.268776\n",
      "Train Epoch: 1143 [1280/1612 (79%)] Loss: 0.229480\n",
      "Train Epoch: 1143 [1440/1612 (89%)] Loss: 0.413545\n",
      "Train Epoch: 1143 [1200/1612 (99%)] Loss: 0.512939\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1144 [0/1612 (0%)] Loss: 0.543048\n",
      "Train Epoch: 1144 [160/1612 (10%)] Loss: 0.353627\n",
      "Train Epoch: 1144 [320/1612 (20%)] Loss: 0.235350\n",
      "Train Epoch: 1144 [480/1612 (30%)] Loss: 0.229379\n",
      "Train Epoch: 1144 [640/1612 (40%)] Loss: 0.476431\n",
      "Train Epoch: 1144 [800/1612 (50%)] Loss: 0.290546\n",
      "Train Epoch: 1144 [960/1612 (59%)] Loss: 0.136740\n",
      "Train Epoch: 1144 [1120/1612 (69%)] Loss: 0.229588\n",
      "Train Epoch: 1144 [1280/1612 (79%)] Loss: 0.185475\n",
      "Train Epoch: 1144 [1440/1612 (89%)] Loss: 0.329046\n",
      "Train Epoch: 1144 [1200/1612 (99%)] Loss: 0.286083\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1145 [0/1612 (0%)] Loss: 0.278271\n",
      "Train Epoch: 1145 [160/1612 (10%)] Loss: 0.599431\n",
      "Train Epoch: 1145 [320/1612 (20%)] Loss: 0.375055\n",
      "Train Epoch: 1145 [480/1612 (30%)] Loss: 0.452793\n",
      "Train Epoch: 1145 [640/1612 (40%)] Loss: 0.407645\n",
      "Train Epoch: 1145 [800/1612 (50%)] Loss: 0.323847\n",
      "Train Epoch: 1145 [960/1612 (59%)] Loss: 0.293240\n",
      "Train Epoch: 1145 [1120/1612 (69%)] Loss: 0.276332\n",
      "Train Epoch: 1145 [1280/1612 (79%)] Loss: 0.284642\n",
      "Train Epoch: 1145 [1440/1612 (89%)] Loss: 0.283020\n",
      "Train Epoch: 1145 [1200/1612 (99%)] Loss: 0.135467\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1146 [0/1612 (0%)] Loss: 0.374501\n",
      "Train Epoch: 1146 [160/1612 (10%)] Loss: 0.443884\n",
      "Train Epoch: 1146 [320/1612 (20%)] Loss: 0.167757\n",
      "Train Epoch: 1146 [480/1612 (30%)] Loss: 0.229925\n",
      "Train Epoch: 1146 [640/1612 (40%)] Loss: 0.221576\n",
      "Train Epoch: 1146 [800/1612 (50%)] Loss: 0.138516\n",
      "Train Epoch: 1146 [960/1612 (59%)] Loss: 0.331401\n",
      "Train Epoch: 1146 [1120/1612 (69%)] Loss: 0.161848\n",
      "Train Epoch: 1146 [1280/1612 (79%)] Loss: 0.205841\n",
      "Train Epoch: 1146 [1440/1612 (89%)] Loss: 0.358806\n",
      "Train Epoch: 1146 [1200/1612 (99%)] Loss: 0.317498\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1147 [0/1612 (0%)] Loss: 0.298587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1147 [160/1612 (10%)] Loss: 0.211940\n",
      "Train Epoch: 1147 [320/1612 (20%)] Loss: 0.584945\n",
      "Train Epoch: 1147 [480/1612 (30%)] Loss: 0.314319\n",
      "Train Epoch: 1147 [640/1612 (40%)] Loss: 0.354361\n",
      "Train Epoch: 1147 [800/1612 (50%)] Loss: 0.473181\n",
      "Train Epoch: 1147 [960/1612 (59%)] Loss: 0.257514\n",
      "Train Epoch: 1147 [1120/1612 (69%)] Loss: 0.471088\n",
      "Train Epoch: 1147 [1280/1612 (79%)] Loss: 0.319811\n",
      "Train Epoch: 1147 [1440/1612 (89%)] Loss: 0.225233\n",
      "Train Epoch: 1147 [1200/1612 (99%)] Loss: 0.216156\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1148 [0/1612 (0%)] Loss: 0.095565\n",
      "Train Epoch: 1148 [160/1612 (10%)] Loss: 0.230817\n",
      "Train Epoch: 1148 [320/1612 (20%)] Loss: 0.135703\n",
      "Train Epoch: 1148 [480/1612 (30%)] Loss: 0.318434\n",
      "Train Epoch: 1148 [640/1612 (40%)] Loss: 0.316652\n",
      "Train Epoch: 1148 [800/1612 (50%)] Loss: 0.393209\n",
      "Train Epoch: 1148 [960/1612 (59%)] Loss: 0.258133\n",
      "Train Epoch: 1148 [1120/1612 (69%)] Loss: 0.173676\n",
      "Train Epoch: 1148 [1280/1612 (79%)] Loss: 0.211152\n",
      "Train Epoch: 1148 [1440/1612 (89%)] Loss: 0.259752\n",
      "Train Epoch: 1148 [1200/1612 (99%)] Loss: 0.116943\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1149 [0/1612 (0%)] Loss: 0.223279\n",
      "Train Epoch: 1149 [160/1612 (10%)] Loss: 0.527182\n",
      "Train Epoch: 1149 [320/1612 (20%)] Loss: 0.308605\n",
      "Train Epoch: 1149 [480/1612 (30%)] Loss: 0.350680\n",
      "Train Epoch: 1149 [640/1612 (40%)] Loss: 0.273592\n",
      "Train Epoch: 1149 [800/1612 (50%)] Loss: 0.361480\n",
      "Train Epoch: 1149 [960/1612 (59%)] Loss: 0.345821\n",
      "Train Epoch: 1149 [1120/1612 (69%)] Loss: 0.243427\n",
      "Train Epoch: 1149 [1280/1612 (79%)] Loss: 0.187102\n",
      "Train Epoch: 1149 [1440/1612 (89%)] Loss: 0.087841\n",
      "Train Epoch: 1149 [1200/1612 (99%)] Loss: 0.570004\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1150 [0/1612 (0%)] Loss: 0.364815\n",
      "Train Epoch: 1150 [160/1612 (10%)] Loss: 0.251359\n",
      "Train Epoch: 1150 [320/1612 (20%)] Loss: 0.188901\n",
      "Train Epoch: 1150 [480/1612 (30%)] Loss: 0.404472\n",
      "Train Epoch: 1150 [640/1612 (40%)] Loss: 0.193773\n",
      "Train Epoch: 1150 [800/1612 (50%)] Loss: 0.246928\n",
      "Train Epoch: 1150 [960/1612 (59%)] Loss: 0.346276\n",
      "Train Epoch: 1150 [1120/1612 (69%)] Loss: 0.165478\n",
      "Train Epoch: 1150 [1280/1612 (79%)] Loss: 0.280295\n",
      "Train Epoch: 1150 [1440/1612 (89%)] Loss: 0.518996\n",
      "Train Epoch: 1150 [1200/1612 (99%)] Loss: 0.066215\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1151 [0/1612 (0%)] Loss: 0.183519\n",
      "Train Epoch: 1151 [160/1612 (10%)] Loss: 0.206669\n",
      "Train Epoch: 1151 [320/1612 (20%)] Loss: 0.232830\n",
      "Train Epoch: 1151 [480/1612 (30%)] Loss: 0.248532\n",
      "Train Epoch: 1151 [640/1612 (40%)] Loss: 0.301112\n",
      "Train Epoch: 1151 [800/1612 (50%)] Loss: 0.425626\n",
      "Train Epoch: 1151 [960/1612 (59%)] Loss: 0.297097\n",
      "Train Epoch: 1151 [1120/1612 (69%)] Loss: 0.170030\n",
      "Train Epoch: 1151 [1280/1612 (79%)] Loss: 0.225034\n",
      "Train Epoch: 1151 [1440/1612 (89%)] Loss: 0.441084\n",
      "Train Epoch: 1151 [1200/1612 (99%)] Loss: 0.383778\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1152 [0/1612 (0%)] Loss: 0.245458\n",
      "Train Epoch: 1152 [160/1612 (10%)] Loss: 0.364472\n",
      "Train Epoch: 1152 [320/1612 (20%)] Loss: 0.470992\n",
      "Train Epoch: 1152 [480/1612 (30%)] Loss: 0.431169\n",
      "Train Epoch: 1152 [640/1612 (40%)] Loss: 0.296022\n",
      "Train Epoch: 1152 [800/1612 (50%)] Loss: 0.306205\n",
      "Train Epoch: 1152 [960/1612 (59%)] Loss: 0.106071\n",
      "Train Epoch: 1152 [1120/1612 (69%)] Loss: 0.239607\n",
      "Train Epoch: 1152 [1280/1612 (79%)] Loss: 0.270956\n",
      "Train Epoch: 1152 [1440/1612 (89%)] Loss: 0.216168\n",
      "Train Epoch: 1152 [1200/1612 (99%)] Loss: 0.304950\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1153 [0/1612 (0%)] Loss: 0.312680\n",
      "Train Epoch: 1153 [160/1612 (10%)] Loss: 0.354899\n",
      "Train Epoch: 1153 [320/1612 (20%)] Loss: 0.209176\n",
      "Train Epoch: 1153 [480/1612 (30%)] Loss: 0.177182\n",
      "Train Epoch: 1153 [640/1612 (40%)] Loss: 0.176176\n",
      "Train Epoch: 1153 [800/1612 (50%)] Loss: 0.241338\n",
      "Train Epoch: 1153 [960/1612 (59%)] Loss: 0.229971\n",
      "Train Epoch: 1153 [1120/1612 (69%)] Loss: 0.190824\n",
      "Train Epoch: 1153 [1280/1612 (79%)] Loss: 0.179598\n",
      "Train Epoch: 1153 [1440/1612 (89%)] Loss: 0.348973\n",
      "Train Epoch: 1153 [1200/1612 (99%)] Loss: 0.288386\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1154 [0/1612 (0%)] Loss: 0.395309\n",
      "Train Epoch: 1154 [160/1612 (10%)] Loss: 0.435451\n",
      "Train Epoch: 1154 [320/1612 (20%)] Loss: 0.394635\n",
      "Train Epoch: 1154 [480/1612 (30%)] Loss: 0.481024\n",
      "Train Epoch: 1154 [640/1612 (40%)] Loss: 0.357275\n",
      "Train Epoch: 1154 [800/1612 (50%)] Loss: 0.219658\n",
      "Train Epoch: 1154 [960/1612 (59%)] Loss: 0.341529\n",
      "Train Epoch: 1154 [1120/1612 (69%)] Loss: 0.171270\n",
      "Train Epoch: 1154 [1280/1612 (79%)] Loss: 0.507039\n",
      "Train Epoch: 1154 [1440/1612 (89%)] Loss: 0.258376\n",
      "Train Epoch: 1154 [1200/1612 (99%)] Loss: 0.303070\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1155 [0/1612 (0%)] Loss: 0.121179\n",
      "Train Epoch: 1155 [160/1612 (10%)] Loss: 0.222600\n",
      "Train Epoch: 1155 [320/1612 (20%)] Loss: 0.212352\n",
      "Train Epoch: 1155 [480/1612 (30%)] Loss: 0.287386\n",
      "Train Epoch: 1155 [640/1612 (40%)] Loss: 0.355744\n",
      "Train Epoch: 1155 [800/1612 (50%)] Loss: 0.280691\n",
      "Train Epoch: 1155 [960/1612 (59%)] Loss: 0.358983\n",
      "Train Epoch: 1155 [1120/1612 (69%)] Loss: 0.333629\n",
      "Train Epoch: 1155 [1280/1612 (79%)] Loss: 0.393144\n",
      "Train Epoch: 1155 [1440/1612 (89%)] Loss: 0.237542\n",
      "Train Epoch: 1155 [1200/1612 (99%)] Loss: 0.220768\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1156 [0/1612 (0%)] Loss: 0.227057\n",
      "Train Epoch: 1156 [160/1612 (10%)] Loss: 0.083203\n",
      "Train Epoch: 1156 [320/1612 (20%)] Loss: 0.408039\n",
      "Train Epoch: 1156 [480/1612 (30%)] Loss: 0.109461\n",
      "Train Epoch: 1156 [640/1612 (40%)] Loss: 0.225974\n",
      "Train Epoch: 1156 [800/1612 (50%)] Loss: 0.225427\n",
      "Train Epoch: 1156 [960/1612 (59%)] Loss: 0.361684\n",
      "Train Epoch: 1156 [1120/1612 (69%)] Loss: 0.525180\n",
      "Train Epoch: 1156 [1280/1612 (79%)] Loss: 0.548013\n",
      "Train Epoch: 1156 [1440/1612 (89%)] Loss: 0.176217\n",
      "Train Epoch: 1156 [1200/1612 (99%)] Loss: 0.487809\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1157 [0/1612 (0%)] Loss: 0.088212\n",
      "Train Epoch: 1157 [160/1612 (10%)] Loss: 0.305321\n",
      "Train Epoch: 1157 [320/1612 (20%)] Loss: 0.341461\n",
      "Train Epoch: 1157 [480/1612 (30%)] Loss: 0.271576\n",
      "Train Epoch: 1157 [640/1612 (40%)] Loss: 0.252513\n",
      "Train Epoch: 1157 [800/1612 (50%)] Loss: 0.312217\n",
      "Train Epoch: 1157 [960/1612 (59%)] Loss: 0.177112\n",
      "Train Epoch: 1157 [1120/1612 (69%)] Loss: 0.268195\n",
      "Train Epoch: 1157 [1280/1612 (79%)] Loss: 0.091678\n",
      "Train Epoch: 1157 [1440/1612 (89%)] Loss: 0.549144\n",
      "Train Epoch: 1157 [1200/1612 (99%)] Loss: 0.375338\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1158 [0/1612 (0%)] Loss: 0.239959\n",
      "Train Epoch: 1158 [160/1612 (10%)] Loss: 0.244813\n",
      "Train Epoch: 1158 [320/1612 (20%)] Loss: 0.266436\n",
      "Train Epoch: 1158 [480/1612 (30%)] Loss: 0.366246\n",
      "Train Epoch: 1158 [640/1612 (40%)] Loss: 0.259491\n",
      "Train Epoch: 1158 [800/1612 (50%)] Loss: 0.101337\n",
      "Train Epoch: 1158 [960/1612 (59%)] Loss: 0.422830\n",
      "Train Epoch: 1158 [1120/1612 (69%)] Loss: 0.264669\n",
      "Train Epoch: 1158 [1280/1612 (79%)] Loss: 0.233291\n",
      "Train Epoch: 1158 [1440/1612 (89%)] Loss: 0.140336\n",
      "Train Epoch: 1158 [1200/1612 (99%)] Loss: 0.286081\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1159 [0/1612 (0%)] Loss: 0.344658\n",
      "Train Epoch: 1159 [160/1612 (10%)] Loss: 0.319698\n",
      "Train Epoch: 1159 [320/1612 (20%)] Loss: 0.341997\n",
      "Train Epoch: 1159 [480/1612 (30%)] Loss: 0.410787\n",
      "Train Epoch: 1159 [640/1612 (40%)] Loss: 0.422652\n",
      "Train Epoch: 1159 [800/1612 (50%)] Loss: 0.081073\n",
      "Train Epoch: 1159 [960/1612 (59%)] Loss: 0.296037\n",
      "Train Epoch: 1159 [1120/1612 (69%)] Loss: 0.412606\n",
      "Train Epoch: 1159 [1280/1612 (79%)] Loss: 0.131836\n",
      "Train Epoch: 1159 [1440/1612 (89%)] Loss: 0.251817\n",
      "Train Epoch: 1159 [1200/1612 (99%)] Loss: 0.322191\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1160 [0/1612 (0%)] Loss: 0.322784\n",
      "Train Epoch: 1160 [160/1612 (10%)] Loss: 0.337529\n",
      "Train Epoch: 1160 [320/1612 (20%)] Loss: 0.406867\n",
      "Train Epoch: 1160 [480/1612 (30%)] Loss: 0.265191\n",
      "Train Epoch: 1160 [640/1612 (40%)] Loss: 0.364637\n",
      "Train Epoch: 1160 [800/1612 (50%)] Loss: 0.195519\n",
      "Train Epoch: 1160 [960/1612 (59%)] Loss: 0.419380\n",
      "Train Epoch: 1160 [1120/1612 (69%)] Loss: 0.353107\n",
      "Train Epoch: 1160 [1280/1612 (79%)] Loss: 0.219552\n",
      "Train Epoch: 1160 [1440/1612 (89%)] Loss: 0.097876\n",
      "Train Epoch: 1160 [1200/1612 (99%)] Loss: 0.407214\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1161 [0/1612 (0%)] Loss: 0.345662\n",
      "Train Epoch: 1161 [160/1612 (10%)] Loss: 0.233791\n",
      "Train Epoch: 1161 [320/1612 (20%)] Loss: 0.347363\n",
      "Train Epoch: 1161 [480/1612 (30%)] Loss: 0.162815\n",
      "Train Epoch: 1161 [640/1612 (40%)] Loss: 0.403746\n",
      "Train Epoch: 1161 [800/1612 (50%)] Loss: 0.368188\n",
      "Train Epoch: 1161 [960/1612 (59%)] Loss: 0.238766\n",
      "Train Epoch: 1161 [1120/1612 (69%)] Loss: 0.385698\n",
      "Train Epoch: 1161 [1280/1612 (79%)] Loss: 0.248521\n",
      "Train Epoch: 1161 [1440/1612 (89%)] Loss: 0.370563\n",
      "Train Epoch: 1161 [1200/1612 (99%)] Loss: 0.146883\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1162 [0/1612 (0%)] Loss: 0.386604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1162 [160/1612 (10%)] Loss: 0.372161\n",
      "Train Epoch: 1162 [320/1612 (20%)] Loss: 0.491109\n",
      "Train Epoch: 1162 [480/1612 (30%)] Loss: 0.470003\n",
      "Train Epoch: 1162 [640/1612 (40%)] Loss: 0.355324\n",
      "Train Epoch: 1162 [800/1612 (50%)] Loss: 0.218637\n",
      "Train Epoch: 1162 [960/1612 (59%)] Loss: 0.206067\n",
      "Train Epoch: 1162 [1120/1612 (69%)] Loss: 0.272697\n",
      "Train Epoch: 1162 [1280/1612 (79%)] Loss: 0.217374\n",
      "Train Epoch: 1162 [1440/1612 (89%)] Loss: 0.409812\n",
      "Train Epoch: 1162 [1200/1612 (99%)] Loss: 0.180805\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1163 [0/1612 (0%)] Loss: 0.333557\n",
      "Train Epoch: 1163 [160/1612 (10%)] Loss: 0.692599\n",
      "Train Epoch: 1163 [320/1612 (20%)] Loss: 0.187191\n",
      "Train Epoch: 1163 [480/1612 (30%)] Loss: 0.145020\n",
      "Train Epoch: 1163 [640/1612 (40%)] Loss: 0.271898\n",
      "Train Epoch: 1163 [800/1612 (50%)] Loss: 0.290137\n",
      "Train Epoch: 1163 [960/1612 (59%)] Loss: 0.236464\n",
      "Train Epoch: 1163 [1120/1612 (69%)] Loss: 0.270131\n",
      "Train Epoch: 1163 [1280/1612 (79%)] Loss: 0.207144\n",
      "Train Epoch: 1163 [1440/1612 (89%)] Loss: 0.193894\n",
      "Train Epoch: 1163 [1200/1612 (99%)] Loss: 0.295720\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1164 [0/1612 (0%)] Loss: 0.089254\n",
      "Train Epoch: 1164 [160/1612 (10%)] Loss: 0.362456\n",
      "Train Epoch: 1164 [320/1612 (20%)] Loss: 0.369307\n",
      "Train Epoch: 1164 [480/1612 (30%)] Loss: 0.381736\n",
      "Train Epoch: 1164 [640/1612 (40%)] Loss: 0.307217\n",
      "Train Epoch: 1164 [800/1612 (50%)] Loss: 0.390255\n",
      "Train Epoch: 1164 [960/1612 (59%)] Loss: 0.194350\n",
      "Train Epoch: 1164 [1120/1612 (69%)] Loss: 0.341188\n",
      "Train Epoch: 1164 [1280/1612 (79%)] Loss: 0.491686\n",
      "Train Epoch: 1164 [1440/1612 (89%)] Loss: 0.130084\n",
      "Train Epoch: 1164 [1200/1612 (99%)] Loss: 0.420825\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1165 [0/1612 (0%)] Loss: 0.257609\n",
      "Train Epoch: 1165 [160/1612 (10%)] Loss: 0.180008\n",
      "Train Epoch: 1165 [320/1612 (20%)] Loss: 0.256842\n",
      "Train Epoch: 1165 [480/1612 (30%)] Loss: 0.315806\n",
      "Train Epoch: 1165 [640/1612 (40%)] Loss: 0.447693\n",
      "Train Epoch: 1165 [800/1612 (50%)] Loss: 0.239441\n",
      "Train Epoch: 1165 [960/1612 (59%)] Loss: 0.275326\n",
      "Train Epoch: 1165 [1120/1612 (69%)] Loss: 0.285863\n",
      "Train Epoch: 1165 [1280/1612 (79%)] Loss: 0.344331\n",
      "Train Epoch: 1165 [1440/1612 (89%)] Loss: 0.440357\n",
      "Train Epoch: 1165 [1200/1612 (99%)] Loss: 0.176557\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1166 [0/1612 (0%)] Loss: 0.180925\n",
      "Train Epoch: 1166 [160/1612 (10%)] Loss: 0.347761\n",
      "Train Epoch: 1166 [320/1612 (20%)] Loss: 0.234117\n",
      "Train Epoch: 1166 [480/1612 (30%)] Loss: 0.247973\n",
      "Train Epoch: 1166 [640/1612 (40%)] Loss: 0.339254\n",
      "Train Epoch: 1166 [800/1612 (50%)] Loss: 0.328397\n",
      "Train Epoch: 1166 [960/1612 (59%)] Loss: 0.518834\n",
      "Train Epoch: 1166 [1120/1612 (69%)] Loss: 0.194968\n",
      "Train Epoch: 1166 [1280/1612 (79%)] Loss: 0.292187\n",
      "Train Epoch: 1166 [1440/1612 (89%)] Loss: 0.393982\n",
      "Train Epoch: 1166 [1200/1612 (99%)] Loss: 0.355636\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1167 [0/1612 (0%)] Loss: 0.385102\n",
      "Train Epoch: 1167 [160/1612 (10%)] Loss: 0.254204\n",
      "Train Epoch: 1167 [320/1612 (20%)] Loss: 0.304717\n",
      "Train Epoch: 1167 [480/1612 (30%)] Loss: 0.254141\n",
      "Train Epoch: 1167 [640/1612 (40%)] Loss: 0.473471\n",
      "Train Epoch: 1167 [800/1612 (50%)] Loss: 0.296226\n",
      "Train Epoch: 1167 [960/1612 (59%)] Loss: 0.181398\n",
      "Train Epoch: 1167 [1120/1612 (69%)] Loss: 0.333777\n",
      "Train Epoch: 1167 [1280/1612 (79%)] Loss: 0.292788\n",
      "Train Epoch: 1167 [1440/1612 (89%)] Loss: 0.463483\n",
      "Train Epoch: 1167 [1200/1612 (99%)] Loss: 0.283662\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1168 [0/1612 (0%)] Loss: 0.370933\n",
      "Train Epoch: 1168 [160/1612 (10%)] Loss: 0.283915\n",
      "Train Epoch: 1168 [320/1612 (20%)] Loss: 0.350632\n",
      "Train Epoch: 1168 [480/1612 (30%)] Loss: 0.251609\n",
      "Train Epoch: 1168 [640/1612 (40%)] Loss: 0.504898\n",
      "Train Epoch: 1168 [800/1612 (50%)] Loss: 0.309476\n",
      "Train Epoch: 1168 [960/1612 (59%)] Loss: 0.275996\n",
      "Train Epoch: 1168 [1120/1612 (69%)] Loss: 0.258626\n",
      "Train Epoch: 1168 [1280/1612 (79%)] Loss: 0.331124\n",
      "Train Epoch: 1168 [1440/1612 (89%)] Loss: 0.369343\n",
      "Train Epoch: 1168 [1200/1612 (99%)] Loss: 0.408849\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1169 [0/1612 (0%)] Loss: 0.446792\n",
      "Train Epoch: 1169 [160/1612 (10%)] Loss: 0.327042\n",
      "Train Epoch: 1169 [320/1612 (20%)] Loss: 0.213524\n",
      "Train Epoch: 1169 [480/1612 (30%)] Loss: 0.325448\n",
      "Train Epoch: 1169 [640/1612 (40%)] Loss: 0.460987\n",
      "Train Epoch: 1169 [800/1612 (50%)] Loss: 0.305606\n",
      "Train Epoch: 1169 [960/1612 (59%)] Loss: 0.423469\n",
      "Train Epoch: 1169 [1120/1612 (69%)] Loss: 0.296978\n",
      "Train Epoch: 1169 [1280/1612 (79%)] Loss: 0.476574\n",
      "Train Epoch: 1169 [1440/1612 (89%)] Loss: 0.387307\n",
      "Train Epoch: 1169 [1200/1612 (99%)] Loss: 0.317798\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1170 [0/1612 (0%)] Loss: 0.475054\n",
      "Train Epoch: 1170 [160/1612 (10%)] Loss: 0.199398\n",
      "Train Epoch: 1170 [320/1612 (20%)] Loss: 0.282721\n",
      "Train Epoch: 1170 [480/1612 (30%)] Loss: 0.233985\n",
      "Train Epoch: 1170 [640/1612 (40%)] Loss: 0.248600\n",
      "Train Epoch: 1170 [800/1612 (50%)] Loss: 0.479331\n",
      "Train Epoch: 1170 [960/1612 (59%)] Loss: 0.238517\n",
      "Train Epoch: 1170 [1120/1612 (69%)] Loss: 0.315092\n",
      "Train Epoch: 1170 [1280/1612 (79%)] Loss: 0.341597\n",
      "Train Epoch: 1170 [1440/1612 (89%)] Loss: 0.230262\n",
      "Train Epoch: 1170 [1200/1612 (99%)] Loss: 0.281114\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1171 [0/1612 (0%)] Loss: 0.301198\n",
      "Train Epoch: 1171 [160/1612 (10%)] Loss: 0.114273\n",
      "Train Epoch: 1171 [320/1612 (20%)] Loss: 0.154912\n",
      "Train Epoch: 1171 [480/1612 (30%)] Loss: 0.286697\n",
      "Train Epoch: 1171 [640/1612 (40%)] Loss: 0.416613\n",
      "Train Epoch: 1171 [800/1612 (50%)] Loss: 0.256353\n",
      "Train Epoch: 1171 [960/1612 (59%)] Loss: 0.460291\n",
      "Train Epoch: 1171 [1120/1612 (69%)] Loss: 0.243014\n",
      "Train Epoch: 1171 [1280/1612 (79%)] Loss: 0.389696\n",
      "Train Epoch: 1171 [1440/1612 (89%)] Loss: 0.354371\n",
      "Train Epoch: 1171 [1200/1612 (99%)] Loss: 0.201762\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1172 [0/1612 (0%)] Loss: 0.455735\n",
      "Train Epoch: 1172 [160/1612 (10%)] Loss: 0.133084\n",
      "Train Epoch: 1172 [320/1612 (20%)] Loss: 0.514351\n",
      "Train Epoch: 1172 [480/1612 (30%)] Loss: 0.326325\n",
      "Train Epoch: 1172 [640/1612 (40%)] Loss: 0.294494\n",
      "Train Epoch: 1172 [800/1612 (50%)] Loss: 0.109596\n",
      "Train Epoch: 1172 [960/1612 (59%)] Loss: 0.345046\n",
      "Train Epoch: 1172 [1120/1612 (69%)] Loss: 0.245223\n",
      "Train Epoch: 1172 [1280/1612 (79%)] Loss: 0.339986\n",
      "Train Epoch: 1172 [1440/1612 (89%)] Loss: 0.442694\n",
      "Train Epoch: 1172 [1200/1612 (99%)] Loss: 0.407826\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1173 [0/1612 (0%)] Loss: 0.287436\n",
      "Train Epoch: 1173 [160/1612 (10%)] Loss: 0.295071\n",
      "Train Epoch: 1173 [320/1612 (20%)] Loss: 0.231352\n",
      "Train Epoch: 1173 [480/1612 (30%)] Loss: 0.278275\n",
      "Train Epoch: 1173 [640/1612 (40%)] Loss: 0.542617\n",
      "Train Epoch: 1173 [800/1612 (50%)] Loss: 0.398144\n",
      "Train Epoch: 1173 [960/1612 (59%)] Loss: 0.129044\n",
      "Train Epoch: 1173 [1120/1612 (69%)] Loss: 0.206620\n",
      "Train Epoch: 1173 [1280/1612 (79%)] Loss: 0.328983\n",
      "Train Epoch: 1173 [1440/1612 (89%)] Loss: 0.291048\n",
      "Train Epoch: 1173 [1200/1612 (99%)] Loss: 0.139026\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1174 [0/1612 (0%)] Loss: 0.333683\n",
      "Train Epoch: 1174 [160/1612 (10%)] Loss: 0.544956\n",
      "Train Epoch: 1174 [320/1612 (20%)] Loss: 0.645830\n",
      "Train Epoch: 1174 [480/1612 (30%)] Loss: 0.244456\n",
      "Train Epoch: 1174 [640/1612 (40%)] Loss: 0.226246\n",
      "Train Epoch: 1174 [800/1612 (50%)] Loss: 0.385019\n",
      "Train Epoch: 1174 [960/1612 (59%)] Loss: 0.290445\n",
      "Train Epoch: 1174 [1120/1612 (69%)] Loss: 0.268496\n",
      "Train Epoch: 1174 [1280/1612 (79%)] Loss: 0.496888\n",
      "Train Epoch: 1174 [1440/1612 (89%)] Loss: 0.243557\n",
      "Train Epoch: 1174 [1200/1612 (99%)] Loss: 0.361503\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1175 [0/1612 (0%)] Loss: 0.189016\n",
      "Train Epoch: 1175 [160/1612 (10%)] Loss: 0.249760\n",
      "Train Epoch: 1175 [320/1612 (20%)] Loss: 0.193213\n",
      "Train Epoch: 1175 [480/1612 (30%)] Loss: 0.174976\n",
      "Train Epoch: 1175 [640/1612 (40%)] Loss: 0.191986\n",
      "Train Epoch: 1175 [800/1612 (50%)] Loss: 0.358506\n",
      "Train Epoch: 1175 [960/1612 (59%)] Loss: 0.248512\n",
      "Train Epoch: 1175 [1120/1612 (69%)] Loss: 0.200699\n",
      "Train Epoch: 1175 [1280/1612 (79%)] Loss: 0.488607\n",
      "Train Epoch: 1175 [1440/1612 (89%)] Loss: 0.248183\n",
      "Train Epoch: 1175 [1200/1612 (99%)] Loss: 0.309774\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1176 [0/1612 (0%)] Loss: 0.293670\n",
      "Train Epoch: 1176 [160/1612 (10%)] Loss: 0.367644\n",
      "Train Epoch: 1176 [320/1612 (20%)] Loss: 0.115782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1176 [480/1612 (30%)] Loss: 0.310373\n",
      "Train Epoch: 1176 [640/1612 (40%)] Loss: 0.402712\n",
      "Train Epoch: 1176 [800/1612 (50%)] Loss: 0.279983\n",
      "Train Epoch: 1176 [960/1612 (59%)] Loss: 0.308619\n",
      "Train Epoch: 1176 [1120/1612 (69%)] Loss: 0.280810\n",
      "Train Epoch: 1176 [1280/1612 (79%)] Loss: 0.633594\n",
      "Train Epoch: 1176 [1440/1612 (89%)] Loss: 0.453874\n",
      "Train Epoch: 1176 [1200/1612 (99%)] Loss: 0.230517\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1177 [0/1612 (0%)] Loss: 0.263003\n",
      "Train Epoch: 1177 [160/1612 (10%)] Loss: 0.234242\n",
      "Train Epoch: 1177 [320/1612 (20%)] Loss: 0.193490\n",
      "Train Epoch: 1177 [480/1612 (30%)] Loss: 0.282170\n",
      "Train Epoch: 1177 [640/1612 (40%)] Loss: 0.188673\n",
      "Train Epoch: 1177 [800/1612 (50%)] Loss: 0.470365\n",
      "Train Epoch: 1177 [960/1612 (59%)] Loss: 0.267244\n",
      "Train Epoch: 1177 [1120/1612 (69%)] Loss: 0.560995\n",
      "Train Epoch: 1177 [1280/1612 (79%)] Loss: 0.242519\n",
      "Train Epoch: 1177 [1440/1612 (89%)] Loss: 0.344488\n",
      "Train Epoch: 1177 [1200/1612 (99%)] Loss: 0.540865\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1178 [0/1612 (0%)] Loss: 0.445011\n",
      "Train Epoch: 1178 [160/1612 (10%)] Loss: 0.407587\n",
      "Train Epoch: 1178 [320/1612 (20%)] Loss: 0.452589\n",
      "Train Epoch: 1178 [480/1612 (30%)] Loss: 0.281413\n",
      "Train Epoch: 1178 [640/1612 (40%)] Loss: 0.341164\n",
      "Train Epoch: 1178 [800/1612 (50%)] Loss: 0.240230\n",
      "Train Epoch: 1178 [960/1612 (59%)] Loss: 0.085958\n",
      "Train Epoch: 1178 [1120/1612 (69%)] Loss: 0.487167\n",
      "Train Epoch: 1178 [1280/1612 (79%)] Loss: 0.245651\n",
      "Train Epoch: 1178 [1440/1612 (89%)] Loss: 0.126677\n",
      "Train Epoch: 1178 [1200/1612 (99%)] Loss: 0.229486\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1179 [0/1612 (0%)] Loss: 0.433096\n",
      "Train Epoch: 1179 [160/1612 (10%)] Loss: 0.299424\n",
      "Train Epoch: 1179 [320/1612 (20%)] Loss: 0.300863\n",
      "Train Epoch: 1179 [480/1612 (30%)] Loss: 0.409311\n",
      "Train Epoch: 1179 [640/1612 (40%)] Loss: 0.156700\n",
      "Train Epoch: 1179 [800/1612 (50%)] Loss: 0.242755\n",
      "Train Epoch: 1179 [960/1612 (59%)] Loss: 0.369419\n",
      "Train Epoch: 1179 [1120/1612 (69%)] Loss: 0.144124\n",
      "Train Epoch: 1179 [1280/1612 (79%)] Loss: 0.232377\n",
      "Train Epoch: 1179 [1440/1612 (89%)] Loss: 0.424588\n",
      "Train Epoch: 1179 [1200/1612 (99%)] Loss: 0.528912\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1180 [0/1612 (0%)] Loss: 0.370419\n",
      "Train Epoch: 1180 [160/1612 (10%)] Loss: 0.246153\n",
      "Train Epoch: 1180 [320/1612 (20%)] Loss: 0.333626\n",
      "Train Epoch: 1180 [480/1612 (30%)] Loss: 0.549188\n",
      "Train Epoch: 1180 [640/1612 (40%)] Loss: 0.700747\n",
      "Train Epoch: 1180 [800/1612 (50%)] Loss: 0.172171\n",
      "Train Epoch: 1180 [960/1612 (59%)] Loss: 0.160190\n",
      "Train Epoch: 1180 [1120/1612 (69%)] Loss: 0.429120\n",
      "Train Epoch: 1180 [1280/1612 (79%)] Loss: 0.420823\n",
      "Train Epoch: 1180 [1440/1612 (89%)] Loss: 0.237943\n",
      "Train Epoch: 1180 [1200/1612 (99%)] Loss: 0.192095\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1181 [0/1612 (0%)] Loss: 0.381131\n",
      "Train Epoch: 1181 [160/1612 (10%)] Loss: 0.386704\n",
      "Train Epoch: 1181 [320/1612 (20%)] Loss: 0.219051\n",
      "Train Epoch: 1181 [480/1612 (30%)] Loss: 0.409296\n",
      "Train Epoch: 1181 [640/1612 (40%)] Loss: 0.223924\n",
      "Train Epoch: 1181 [800/1612 (50%)] Loss: 0.188571\n",
      "Train Epoch: 1181 [960/1612 (59%)] Loss: 0.335526\n",
      "Train Epoch: 1181 [1120/1612 (69%)] Loss: 0.137339\n",
      "Train Epoch: 1181 [1280/1612 (79%)] Loss: 0.212757\n",
      "Train Epoch: 1181 [1440/1612 (89%)] Loss: 0.494402\n",
      "Train Epoch: 1181 [1200/1612 (99%)] Loss: 0.306883\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1182 [0/1612 (0%)] Loss: 0.346914\n",
      "Train Epoch: 1182 [160/1612 (10%)] Loss: 0.209467\n",
      "Train Epoch: 1182 [320/1612 (20%)] Loss: 0.300939\n",
      "Train Epoch: 1182 [480/1612 (30%)] Loss: 0.333040\n",
      "Train Epoch: 1182 [640/1612 (40%)] Loss: 0.520840\n",
      "Train Epoch: 1182 [800/1612 (50%)] Loss: 0.370549\n",
      "Train Epoch: 1182 [960/1612 (59%)] Loss: 0.270349\n",
      "Train Epoch: 1182 [1120/1612 (69%)] Loss: 0.234393\n",
      "Train Epoch: 1182 [1280/1612 (79%)] Loss: 0.233895\n",
      "Train Epoch: 1182 [1440/1612 (89%)] Loss: 0.263267\n",
      "Train Epoch: 1182 [1200/1612 (99%)] Loss: 0.411056\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1183 [0/1612 (0%)] Loss: 0.410444\n",
      "Train Epoch: 1183 [160/1612 (10%)] Loss: 0.244034\n",
      "Train Epoch: 1183 [320/1612 (20%)] Loss: 0.167226\n",
      "Train Epoch: 1183 [480/1612 (30%)] Loss: 0.122264\n",
      "Train Epoch: 1183 [640/1612 (40%)] Loss: 0.277732\n",
      "Train Epoch: 1183 [800/1612 (50%)] Loss: 0.174895\n",
      "Train Epoch: 1183 [960/1612 (59%)] Loss: 0.312836\n",
      "Train Epoch: 1183 [1120/1612 (69%)] Loss: 0.235794\n",
      "Train Epoch: 1183 [1280/1612 (79%)] Loss: 0.153533\n",
      "Train Epoch: 1183 [1440/1612 (89%)] Loss: 0.346671\n",
      "Train Epoch: 1183 [1200/1612 (99%)] Loss: 0.205322\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1184 [0/1612 (0%)] Loss: 0.453977\n",
      "Train Epoch: 1184 [160/1612 (10%)] Loss: 0.429280\n",
      "Train Epoch: 1184 [320/1612 (20%)] Loss: 0.231320\n",
      "Train Epoch: 1184 [480/1612 (30%)] Loss: 0.351440\n",
      "Train Epoch: 1184 [640/1612 (40%)] Loss: 0.418412\n",
      "Train Epoch: 1184 [800/1612 (50%)] Loss: 0.160648\n",
      "Train Epoch: 1184 [960/1612 (59%)] Loss: 0.289160\n",
      "Train Epoch: 1184 [1120/1612 (69%)] Loss: 0.125138\n",
      "Train Epoch: 1184 [1280/1612 (79%)] Loss: 0.224535\n",
      "Train Epoch: 1184 [1440/1612 (89%)] Loss: 0.267115\n",
      "Train Epoch: 1184 [1200/1612 (99%)] Loss: 0.481656\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1185 [0/1612 (0%)] Loss: 0.260934\n",
      "Train Epoch: 1185 [160/1612 (10%)] Loss: 0.307169\n",
      "Train Epoch: 1185 [320/1612 (20%)] Loss: 0.288096\n",
      "Train Epoch: 1185 [480/1612 (30%)] Loss: 0.472303\n",
      "Train Epoch: 1185 [640/1612 (40%)] Loss: 0.198333\n",
      "Train Epoch: 1185 [800/1612 (50%)] Loss: 0.234728\n",
      "Train Epoch: 1185 [960/1612 (59%)] Loss: 0.268991\n",
      "Train Epoch: 1185 [1120/1612 (69%)] Loss: 0.273736\n",
      "Train Epoch: 1185 [1280/1612 (79%)] Loss: 0.268809\n",
      "Train Epoch: 1185 [1440/1612 (89%)] Loss: 0.414702\n",
      "Train Epoch: 1185 [1200/1612 (99%)] Loss: 0.348931\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1186 [0/1612 (0%)] Loss: 0.326108\n",
      "Train Epoch: 1186 [160/1612 (10%)] Loss: 0.276475\n",
      "Train Epoch: 1186 [320/1612 (20%)] Loss: 0.272002\n",
      "Train Epoch: 1186 [480/1612 (30%)] Loss: 0.390092\n",
      "Train Epoch: 1186 [640/1612 (40%)] Loss: 0.240175\n",
      "Train Epoch: 1186 [800/1612 (50%)] Loss: 0.365177\n",
      "Train Epoch: 1186 [960/1612 (59%)] Loss: 0.305560\n",
      "Train Epoch: 1186 [1120/1612 (69%)] Loss: 0.209175\n",
      "Train Epoch: 1186 [1280/1612 (79%)] Loss: 0.306621\n",
      "Train Epoch: 1186 [1440/1612 (89%)] Loss: 0.316252\n",
      "Train Epoch: 1186 [1200/1612 (99%)] Loss: 0.517425\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1187 [0/1612 (0%)] Loss: 0.220053\n",
      "Train Epoch: 1187 [160/1612 (10%)] Loss: 0.152280\n",
      "Train Epoch: 1187 [320/1612 (20%)] Loss: 0.238032\n",
      "Train Epoch: 1187 [480/1612 (30%)] Loss: 0.470819\n",
      "Train Epoch: 1187 [640/1612 (40%)] Loss: 0.372072\n",
      "Train Epoch: 1187 [800/1612 (50%)] Loss: 0.131820\n",
      "Train Epoch: 1187 [960/1612 (59%)] Loss: 0.150501\n",
      "Train Epoch: 1187 [1120/1612 (69%)] Loss: 0.431162\n",
      "Train Epoch: 1187 [1280/1612 (79%)] Loss: 0.468306\n",
      "Train Epoch: 1187 [1440/1612 (89%)] Loss: 0.137708\n",
      "Train Epoch: 1187 [1200/1612 (99%)] Loss: 0.481483\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1188 [0/1612 (0%)] Loss: 0.338452\n",
      "Train Epoch: 1188 [160/1612 (10%)] Loss: 0.285055\n",
      "Train Epoch: 1188 [320/1612 (20%)] Loss: 0.330102\n",
      "Train Epoch: 1188 [480/1612 (30%)] Loss: 0.278224\n",
      "Train Epoch: 1188 [640/1612 (40%)] Loss: 0.317159\n",
      "Train Epoch: 1188 [800/1612 (50%)] Loss: 0.080003\n",
      "Train Epoch: 1188 [960/1612 (59%)] Loss: 0.370456\n",
      "Train Epoch: 1188 [1120/1612 (69%)] Loss: 0.093723\n",
      "Train Epoch: 1188 [1280/1612 (79%)] Loss: 0.387062\n",
      "Train Epoch: 1188 [1440/1612 (89%)] Loss: 0.409829\n",
      "Train Epoch: 1188 [1200/1612 (99%)] Loss: 0.219540\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1189 [0/1612 (0%)] Loss: 0.357845\n",
      "Train Epoch: 1189 [160/1612 (10%)] Loss: 0.182596\n",
      "Train Epoch: 1189 [320/1612 (20%)] Loss: 0.290346\n",
      "Train Epoch: 1189 [480/1612 (30%)] Loss: 0.474412\n",
      "Train Epoch: 1189 [640/1612 (40%)] Loss: 0.230723\n",
      "Train Epoch: 1189 [800/1612 (50%)] Loss: 0.336603\n",
      "Train Epoch: 1189 [960/1612 (59%)] Loss: 0.223031\n",
      "Train Epoch: 1189 [1120/1612 (69%)] Loss: 0.301195\n",
      "Train Epoch: 1189 [1280/1612 (79%)] Loss: 0.292643\n",
      "Train Epoch: 1189 [1440/1612 (89%)] Loss: 0.242808\n",
      "Train Epoch: 1189 [1200/1612 (99%)] Loss: 0.387769\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1190 [0/1612 (0%)] Loss: 0.149285\n",
      "Train Epoch: 1190 [160/1612 (10%)] Loss: 0.394214\n",
      "Train Epoch: 1190 [320/1612 (20%)] Loss: 0.254924\n",
      "Train Epoch: 1190 [480/1612 (30%)] Loss: 0.336330\n",
      "Train Epoch: 1190 [640/1612 (40%)] Loss: 0.446330\n",
      "Train Epoch: 1190 [800/1612 (50%)] Loss: 0.552266\n",
      "Train Epoch: 1190 [960/1612 (59%)] Loss: 0.317805\n",
      "Train Epoch: 1190 [1120/1612 (69%)] Loss: 0.230607\n",
      "Train Epoch: 1190 [1280/1612 (79%)] Loss: 0.325825\n",
      "Train Epoch: 1190 [1440/1612 (89%)] Loss: 0.459823\n",
      "Train Epoch: 1190 [1200/1612 (99%)] Loss: 0.272313\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1191 [0/1612 (0%)] Loss: 0.227200\n",
      "Train Epoch: 1191 [160/1612 (10%)] Loss: 0.225334\n",
      "Train Epoch: 1191 [320/1612 (20%)] Loss: 0.279092\n",
      "Train Epoch: 1191 [480/1612 (30%)] Loss: 0.320774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1191 [640/1612 (40%)] Loss: 0.445419\n",
      "Train Epoch: 1191 [800/1612 (50%)] Loss: 0.174788\n",
      "Train Epoch: 1191 [960/1612 (59%)] Loss: 0.502770\n",
      "Train Epoch: 1191 [1120/1612 (69%)] Loss: 0.245207\n",
      "Train Epoch: 1191 [1280/1612 (79%)] Loss: 0.302013\n",
      "Train Epoch: 1191 [1440/1612 (89%)] Loss: 0.568485\n",
      "Train Epoch: 1191 [1200/1612 (99%)] Loss: 0.115319\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1192 [0/1612 (0%)] Loss: 0.224413\n",
      "Train Epoch: 1192 [160/1612 (10%)] Loss: 0.265371\n",
      "Train Epoch: 1192 [320/1612 (20%)] Loss: 0.292533\n",
      "Train Epoch: 1192 [480/1612 (30%)] Loss: 0.342836\n",
      "Train Epoch: 1192 [640/1612 (40%)] Loss: 0.306982\n",
      "Train Epoch: 1192 [800/1612 (50%)] Loss: 0.101463\n",
      "Train Epoch: 1192 [960/1612 (59%)] Loss: 0.477618\n",
      "Train Epoch: 1192 [1120/1612 (69%)] Loss: 0.202845\n",
      "Train Epoch: 1192 [1280/1612 (79%)] Loss: 0.269653\n",
      "Train Epoch: 1192 [1440/1612 (89%)] Loss: 0.308324\n",
      "Train Epoch: 1192 [1200/1612 (99%)] Loss: 0.554788\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1193 [0/1612 (0%)] Loss: 0.309398\n",
      "Train Epoch: 1193 [160/1612 (10%)] Loss: 0.306730\n",
      "Train Epoch: 1193 [320/1612 (20%)] Loss: 0.424128\n",
      "Train Epoch: 1193 [480/1612 (30%)] Loss: 0.358879\n",
      "Train Epoch: 1193 [640/1612 (40%)] Loss: 0.350783\n",
      "Train Epoch: 1193 [800/1612 (50%)] Loss: 0.270275\n",
      "Train Epoch: 1193 [960/1612 (59%)] Loss: 0.347909\n",
      "Train Epoch: 1193 [1120/1612 (69%)] Loss: 0.516980\n",
      "Train Epoch: 1193 [1280/1612 (79%)] Loss: 0.162352\n",
      "Train Epoch: 1193 [1440/1612 (89%)] Loss: 0.325199\n",
      "Train Epoch: 1193 [1200/1612 (99%)] Loss: 0.522241\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1194 [0/1612 (0%)] Loss: 0.195657\n",
      "Train Epoch: 1194 [160/1612 (10%)] Loss: 0.166894\n",
      "Train Epoch: 1194 [320/1612 (20%)] Loss: 0.393518\n",
      "Train Epoch: 1194 [480/1612 (30%)] Loss: 0.455152\n",
      "Train Epoch: 1194 [640/1612 (40%)] Loss: 0.238391\n",
      "Train Epoch: 1194 [800/1612 (50%)] Loss: 0.404491\n",
      "Train Epoch: 1194 [960/1612 (59%)] Loss: 0.330725\n",
      "Train Epoch: 1194 [1120/1612 (69%)] Loss: 0.202673\n",
      "Train Epoch: 1194 [1280/1612 (79%)] Loss: 0.389354\n",
      "Train Epoch: 1194 [1440/1612 (89%)] Loss: 0.343574\n",
      "Train Epoch: 1194 [1200/1612 (99%)] Loss: 0.502690\n",
      "\n",
      "Test set: Average loss: 0.0303, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1195 [0/1612 (0%)] Loss: 0.309763\n",
      "Train Epoch: 1195 [160/1612 (10%)] Loss: 0.294562\n",
      "Train Epoch: 1195 [320/1612 (20%)] Loss: 0.462340\n",
      "Train Epoch: 1195 [480/1612 (30%)] Loss: 0.366323\n",
      "Train Epoch: 1195 [640/1612 (40%)] Loss: 0.206416\n",
      "Train Epoch: 1195 [800/1612 (50%)] Loss: 0.387374\n",
      "Train Epoch: 1195 [960/1612 (59%)] Loss: 0.483180\n",
      "Train Epoch: 1195 [1120/1612 (69%)] Loss: 0.140867\n",
      "Train Epoch: 1195 [1280/1612 (79%)] Loss: 0.256116\n",
      "Train Epoch: 1195 [1440/1612 (89%)] Loss: 0.400959\n",
      "Train Epoch: 1195 [1200/1612 (99%)] Loss: 0.515755\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1196 [0/1612 (0%)] Loss: 0.330207\n",
      "Train Epoch: 1196 [160/1612 (10%)] Loss: 0.319960\n",
      "Train Epoch: 1196 [320/1612 (20%)] Loss: 0.388267\n",
      "Train Epoch: 1196 [480/1612 (30%)] Loss: 0.158790\n",
      "Train Epoch: 1196 [640/1612 (40%)] Loss: 0.196060\n",
      "Train Epoch: 1196 [800/1612 (50%)] Loss: 0.208038\n",
      "Train Epoch: 1196 [960/1612 (59%)] Loss: 0.470031\n",
      "Train Epoch: 1196 [1120/1612 (69%)] Loss: 0.316136\n",
      "Train Epoch: 1196 [1280/1612 (79%)] Loss: 0.346117\n",
      "Train Epoch: 1196 [1440/1612 (89%)] Loss: 0.203084\n",
      "Train Epoch: 1196 [1200/1612 (99%)] Loss: 0.184712\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1197 [0/1612 (0%)] Loss: 0.312740\n",
      "Train Epoch: 1197 [160/1612 (10%)] Loss: 0.212469\n",
      "Train Epoch: 1197 [320/1612 (20%)] Loss: 0.334091\n",
      "Train Epoch: 1197 [480/1612 (30%)] Loss: 0.407069\n",
      "Train Epoch: 1197 [640/1612 (40%)] Loss: 0.556077\n",
      "Train Epoch: 1197 [800/1612 (50%)] Loss: 0.244029\n",
      "Train Epoch: 1197 [960/1612 (59%)] Loss: 0.303321\n",
      "Train Epoch: 1197 [1120/1612 (69%)] Loss: 0.560206\n",
      "Train Epoch: 1197 [1280/1612 (79%)] Loss: 0.303583\n",
      "Train Epoch: 1197 [1440/1612 (89%)] Loss: 0.209959\n",
      "Train Epoch: 1197 [1200/1612 (99%)] Loss: 0.183656\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1198 [0/1612 (0%)] Loss: 0.235667\n",
      "Train Epoch: 1198 [160/1612 (10%)] Loss: 0.201272\n",
      "Train Epoch: 1198 [320/1612 (20%)] Loss: 0.072497\n",
      "Train Epoch: 1198 [480/1612 (30%)] Loss: 0.291531\n",
      "Train Epoch: 1198 [640/1612 (40%)] Loss: 0.153466\n",
      "Train Epoch: 1198 [800/1612 (50%)] Loss: 0.253067\n",
      "Train Epoch: 1198 [960/1612 (59%)] Loss: 0.221758\n",
      "Train Epoch: 1198 [1120/1612 (69%)] Loss: 0.304764\n",
      "Train Epoch: 1198 [1280/1612 (79%)] Loss: 0.186855\n",
      "Train Epoch: 1198 [1440/1612 (89%)] Loss: 0.238890\n",
      "Train Epoch: 1198 [1200/1612 (99%)] Loss: 0.093560\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1199 [0/1612 (0%)] Loss: 0.622518\n",
      "Train Epoch: 1199 [160/1612 (10%)] Loss: 0.317294\n",
      "Train Epoch: 1199 [320/1612 (20%)] Loss: 0.422169\n",
      "Train Epoch: 1199 [480/1612 (30%)] Loss: 0.306237\n",
      "Train Epoch: 1199 [640/1612 (40%)] Loss: 0.205467\n",
      "Train Epoch: 1199 [800/1612 (50%)] Loss: 0.297856\n",
      "Train Epoch: 1199 [960/1612 (59%)] Loss: 0.178188\n",
      "Train Epoch: 1199 [1120/1612 (69%)] Loss: 0.274124\n",
      "Train Epoch: 1199 [1280/1612 (79%)] Loss: 0.154695\n",
      "Train Epoch: 1199 [1440/1612 (89%)] Loss: 0.214668\n",
      "Train Epoch: 1199 [1200/1612 (99%)] Loss: 0.212536\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1200 [0/1612 (0%)] Loss: 0.201761\n",
      "Train Epoch: 1200 [160/1612 (10%)] Loss: 0.209565\n",
      "Train Epoch: 1200 [320/1612 (20%)] Loss: 0.284367\n",
      "Train Epoch: 1200 [480/1612 (30%)] Loss: 0.265446\n",
      "Train Epoch: 1200 [640/1612 (40%)] Loss: 0.260925\n",
      "Train Epoch: 1200 [800/1612 (50%)] Loss: 0.397143\n",
      "Train Epoch: 1200 [960/1612 (59%)] Loss: 0.336203\n",
      "Train Epoch: 1200 [1120/1612 (69%)] Loss: 0.276490\n",
      "Train Epoch: 1200 [1280/1612 (79%)] Loss: 0.102567\n",
      "Train Epoch: 1200 [1440/1612 (89%)] Loss: 0.203110\n",
      "Train Epoch: 1200 [1200/1612 (99%)] Loss: 0.233935\n",
      "\n",
      "Test set: Average loss: 0.0297, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1201 [0/1612 (0%)] Loss: 0.427688\n",
      "Train Epoch: 1201 [160/1612 (10%)] Loss: 0.423261\n",
      "Train Epoch: 1201 [320/1612 (20%)] Loss: 0.236144\n",
      "Train Epoch: 1201 [480/1612 (30%)] Loss: 0.412450\n",
      "Train Epoch: 1201 [640/1612 (40%)] Loss: 0.228166\n",
      "Train Epoch: 1201 [800/1612 (50%)] Loss: 0.287959\n",
      "Train Epoch: 1201 [960/1612 (59%)] Loss: 0.429813\n",
      "Train Epoch: 1201 [1120/1612 (69%)] Loss: 0.244553\n",
      "Train Epoch: 1201 [1280/1612 (79%)] Loss: 0.216047\n",
      "Train Epoch: 1201 [1440/1612 (89%)] Loss: 0.245341\n",
      "Train Epoch: 1201 [1200/1612 (99%)] Loss: 0.365582\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1202 [0/1612 (0%)] Loss: 0.290519\n",
      "Train Epoch: 1202 [160/1612 (10%)] Loss: 0.280641\n",
      "Train Epoch: 1202 [320/1612 (20%)] Loss: 0.295833\n",
      "Train Epoch: 1202 [480/1612 (30%)] Loss: 0.145505\n",
      "Train Epoch: 1202 [640/1612 (40%)] Loss: 0.404003\n",
      "Train Epoch: 1202 [800/1612 (50%)] Loss: 0.317307\n",
      "Train Epoch: 1202 [960/1612 (59%)] Loss: 0.220372\n",
      "Train Epoch: 1202 [1120/1612 (69%)] Loss: 0.470852\n",
      "Train Epoch: 1202 [1280/1612 (79%)] Loss: 0.149658\n",
      "Train Epoch: 1202 [1440/1612 (89%)] Loss: 0.281043\n",
      "Train Epoch: 1202 [1200/1612 (99%)] Loss: 0.229835\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1203 [0/1612 (0%)] Loss: 0.389825\n",
      "Train Epoch: 1203 [160/1612 (10%)] Loss: 0.312885\n",
      "Train Epoch: 1203 [320/1612 (20%)] Loss: 0.327902\n",
      "Train Epoch: 1203 [480/1612 (30%)] Loss: 0.308950\n",
      "Train Epoch: 1203 [640/1612 (40%)] Loss: 0.338682\n",
      "Train Epoch: 1203 [800/1612 (50%)] Loss: 0.226111\n",
      "Train Epoch: 1203 [960/1612 (59%)] Loss: 0.193148\n",
      "Train Epoch: 1203 [1120/1612 (69%)] Loss: 0.419268\n",
      "Train Epoch: 1203 [1280/1612 (79%)] Loss: 0.239220\n",
      "Train Epoch: 1203 [1440/1612 (89%)] Loss: 0.268556\n",
      "Train Epoch: 1203 [1200/1612 (99%)] Loss: 0.553452\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1204 [0/1612 (0%)] Loss: 0.479496\n",
      "Train Epoch: 1204 [160/1612 (10%)] Loss: 0.210445\n",
      "Train Epoch: 1204 [320/1612 (20%)] Loss: 0.210577\n",
      "Train Epoch: 1204 [480/1612 (30%)] Loss: 0.211631\n",
      "Train Epoch: 1204 [640/1612 (40%)] Loss: 0.247810\n",
      "Train Epoch: 1204 [800/1612 (50%)] Loss: 0.206471\n",
      "Train Epoch: 1204 [960/1612 (59%)] Loss: 0.297144\n",
      "Train Epoch: 1204 [1120/1612 (69%)] Loss: 0.292982\n",
      "Train Epoch: 1204 [1280/1612 (79%)] Loss: 0.313098\n",
      "Train Epoch: 1204 [1440/1612 (89%)] Loss: 0.481482\n",
      "Train Epoch: 1204 [1200/1612 (99%)] Loss: 0.537858\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1205 [0/1612 (0%)] Loss: 0.331262\n",
      "Train Epoch: 1205 [160/1612 (10%)] Loss: 0.391303\n",
      "Train Epoch: 1205 [320/1612 (20%)] Loss: 0.193237\n",
      "Train Epoch: 1205 [480/1612 (30%)] Loss: 0.167175\n",
      "Train Epoch: 1205 [640/1612 (40%)] Loss: 0.274584\n",
      "Train Epoch: 1205 [800/1612 (50%)] Loss: 0.450486\n",
      "Train Epoch: 1205 [960/1612 (59%)] Loss: 0.334606\n",
      "Train Epoch: 1205 [1120/1612 (69%)] Loss: 0.270390\n",
      "Train Epoch: 1205 [1280/1612 (79%)] Loss: 0.230363\n",
      "Train Epoch: 1205 [1440/1612 (89%)] Loss: 0.085725\n",
      "Train Epoch: 1205 [1200/1612 (99%)] Loss: 0.338940\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1206 [0/1612 (0%)] Loss: 0.289524\n",
      "Train Epoch: 1206 [160/1612 (10%)] Loss: 0.194650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1206 [320/1612 (20%)] Loss: 0.366880\n",
      "Train Epoch: 1206 [480/1612 (30%)] Loss: 0.280318\n",
      "Train Epoch: 1206 [640/1612 (40%)] Loss: 0.328855\n",
      "Train Epoch: 1206 [800/1612 (50%)] Loss: 0.167878\n",
      "Train Epoch: 1206 [960/1612 (59%)] Loss: 0.245718\n",
      "Train Epoch: 1206 [1120/1612 (69%)] Loss: 0.275632\n",
      "Train Epoch: 1206 [1280/1612 (79%)] Loss: 0.337586\n",
      "Train Epoch: 1206 [1440/1612 (89%)] Loss: 0.398803\n",
      "Train Epoch: 1206 [1200/1612 (99%)] Loss: 0.579781\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1207 [0/1612 (0%)] Loss: 0.184126\n",
      "Train Epoch: 1207 [160/1612 (10%)] Loss: 0.451645\n",
      "Train Epoch: 1207 [320/1612 (20%)] Loss: 0.483778\n",
      "Train Epoch: 1207 [480/1612 (30%)] Loss: 0.245339\n",
      "Train Epoch: 1207 [640/1612 (40%)] Loss: 0.405945\n",
      "Train Epoch: 1207 [800/1612 (50%)] Loss: 0.293655\n",
      "Train Epoch: 1207 [960/1612 (59%)] Loss: 0.281502\n",
      "Train Epoch: 1207 [1120/1612 (69%)] Loss: 0.233045\n",
      "Train Epoch: 1207 [1280/1612 (79%)] Loss: 0.285320\n",
      "Train Epoch: 1207 [1440/1612 (89%)] Loss: 0.249319\n",
      "Train Epoch: 1207 [1200/1612 (99%)] Loss: 0.294384\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1208 [0/1612 (0%)] Loss: 0.206305\n",
      "Train Epoch: 1208 [160/1612 (10%)] Loss: 0.116530\n",
      "Train Epoch: 1208 [320/1612 (20%)] Loss: 0.191463\n",
      "Train Epoch: 1208 [480/1612 (30%)] Loss: 0.221782\n",
      "Train Epoch: 1208 [640/1612 (40%)] Loss: 0.270582\n",
      "Train Epoch: 1208 [800/1612 (50%)] Loss: 0.409535\n",
      "Train Epoch: 1208 [960/1612 (59%)] Loss: 0.416677\n",
      "Train Epoch: 1208 [1120/1612 (69%)] Loss: 0.245938\n",
      "Train Epoch: 1208 [1280/1612 (79%)] Loss: 0.259322\n",
      "Train Epoch: 1208 [1440/1612 (89%)] Loss: 0.182908\n",
      "Train Epoch: 1208 [1200/1612 (99%)] Loss: 0.576435\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1209 [0/1612 (0%)] Loss: 0.185615\n",
      "Train Epoch: 1209 [160/1612 (10%)] Loss: 0.179095\n",
      "Train Epoch: 1209 [320/1612 (20%)] Loss: 0.242490\n",
      "Train Epoch: 1209 [480/1612 (30%)] Loss: 0.276987\n",
      "Train Epoch: 1209 [640/1612 (40%)] Loss: 0.374218\n",
      "Train Epoch: 1209 [800/1612 (50%)] Loss: 0.187813\n",
      "Train Epoch: 1209 [960/1612 (59%)] Loss: 0.484083\n",
      "Train Epoch: 1209 [1120/1612 (69%)] Loss: 0.135325\n",
      "Train Epoch: 1209 [1280/1612 (79%)] Loss: 0.496901\n",
      "Train Epoch: 1209 [1440/1612 (89%)] Loss: 0.107256\n",
      "Train Epoch: 1209 [1200/1612 (99%)] Loss: 0.287063\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1210 [0/1612 (0%)] Loss: 0.397942\n",
      "Train Epoch: 1210 [160/1612 (10%)] Loss: 0.389177\n",
      "Train Epoch: 1210 [320/1612 (20%)] Loss: 0.101250\n",
      "Train Epoch: 1210 [480/1612 (30%)] Loss: 0.190006\n",
      "Train Epoch: 1210 [640/1612 (40%)] Loss: 0.178329\n",
      "Train Epoch: 1210 [800/1612 (50%)] Loss: 0.278695\n",
      "Train Epoch: 1210 [960/1612 (59%)] Loss: 0.322921\n",
      "Train Epoch: 1210 [1120/1612 (69%)] Loss: 0.510355\n",
      "Train Epoch: 1210 [1280/1612 (79%)] Loss: 0.349525\n",
      "Train Epoch: 1210 [1440/1612 (89%)] Loss: 0.671698\n",
      "Train Epoch: 1210 [1200/1612 (99%)] Loss: 0.168282\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1211 [0/1612 (0%)] Loss: 0.204042\n",
      "Train Epoch: 1211 [160/1612 (10%)] Loss: 0.330690\n",
      "Train Epoch: 1211 [320/1612 (20%)] Loss: 0.301314\n",
      "Train Epoch: 1211 [480/1612 (30%)] Loss: 0.148505\n",
      "Train Epoch: 1211 [640/1612 (40%)] Loss: 0.313129\n",
      "Train Epoch: 1211 [800/1612 (50%)] Loss: 0.376817\n",
      "Train Epoch: 1211 [960/1612 (59%)] Loss: 0.361482\n",
      "Train Epoch: 1211 [1120/1612 (69%)] Loss: 0.529804\n",
      "Train Epoch: 1211 [1280/1612 (79%)] Loss: 0.604606\n",
      "Train Epoch: 1211 [1440/1612 (89%)] Loss: 0.364632\n",
      "Train Epoch: 1211 [1200/1612 (99%)] Loss: 0.360988\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1212 [0/1612 (0%)] Loss: 0.491303\n",
      "Train Epoch: 1212 [160/1612 (10%)] Loss: 0.233521\n",
      "Train Epoch: 1212 [320/1612 (20%)] Loss: 0.415894\n",
      "Train Epoch: 1212 [480/1612 (30%)] Loss: 0.125092\n",
      "Train Epoch: 1212 [640/1612 (40%)] Loss: 0.227216\n",
      "Train Epoch: 1212 [800/1612 (50%)] Loss: 0.258558\n",
      "Train Epoch: 1212 [960/1612 (59%)] Loss: 0.181217\n",
      "Train Epoch: 1212 [1120/1612 (69%)] Loss: 0.486897\n",
      "Train Epoch: 1212 [1280/1612 (79%)] Loss: 0.190513\n",
      "Train Epoch: 1212 [1440/1612 (89%)] Loss: 0.216579\n",
      "Train Epoch: 1212 [1200/1612 (99%)] Loss: 0.393010\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1213 [0/1612 (0%)] Loss: 0.335777\n",
      "Train Epoch: 1213 [160/1612 (10%)] Loss: 0.695400\n",
      "Train Epoch: 1213 [320/1612 (20%)] Loss: 0.182940\n",
      "Train Epoch: 1213 [480/1612 (30%)] Loss: 0.380821\n",
      "Train Epoch: 1213 [640/1612 (40%)] Loss: 0.296038\n",
      "Train Epoch: 1213 [800/1612 (50%)] Loss: 0.217415\n",
      "Train Epoch: 1213 [960/1612 (59%)] Loss: 0.209580\n",
      "Train Epoch: 1213 [1120/1612 (69%)] Loss: 0.428147\n",
      "Train Epoch: 1213 [1280/1612 (79%)] Loss: 0.360832\n",
      "Train Epoch: 1213 [1440/1612 (89%)] Loss: 0.270994\n",
      "Train Epoch: 1213 [1200/1612 (99%)] Loss: 0.224415\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1214 [0/1612 (0%)] Loss: 0.363193\n",
      "Train Epoch: 1214 [160/1612 (10%)] Loss: 0.355001\n",
      "Train Epoch: 1214 [320/1612 (20%)] Loss: 0.247131\n",
      "Train Epoch: 1214 [480/1612 (30%)] Loss: 0.375107\n",
      "Train Epoch: 1214 [640/1612 (40%)] Loss: 0.304039\n",
      "Train Epoch: 1214 [800/1612 (50%)] Loss: 0.190857\n",
      "Train Epoch: 1214 [960/1612 (59%)] Loss: 0.075929\n",
      "Train Epoch: 1214 [1120/1612 (69%)] Loss: 0.129474\n",
      "Train Epoch: 1214 [1280/1612 (79%)] Loss: 0.257928\n",
      "Train Epoch: 1214 [1440/1612 (89%)] Loss: 0.455940\n",
      "Train Epoch: 1214 [1200/1612 (99%)] Loss: 0.497731\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1215 [0/1612 (0%)] Loss: 0.231949\n",
      "Train Epoch: 1215 [160/1612 (10%)] Loss: 0.260053\n",
      "Train Epoch: 1215 [320/1612 (20%)] Loss: 0.341581\n",
      "Train Epoch: 1215 [480/1612 (30%)] Loss: 0.168018\n",
      "Train Epoch: 1215 [640/1612 (40%)] Loss: 0.260594\n",
      "Train Epoch: 1215 [800/1612 (50%)] Loss: 0.181221\n",
      "Train Epoch: 1215 [960/1612 (59%)] Loss: 0.376880\n",
      "Train Epoch: 1215 [1120/1612 (69%)] Loss: 0.344258\n",
      "Train Epoch: 1215 [1280/1612 (79%)] Loss: 0.548043\n",
      "Train Epoch: 1215 [1440/1612 (89%)] Loss: 0.136944\n",
      "Train Epoch: 1215 [1200/1612 (99%)] Loss: 0.129824\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1216 [0/1612 (0%)] Loss: 0.371035\n",
      "Train Epoch: 1216 [160/1612 (10%)] Loss: 0.574297\n",
      "Train Epoch: 1216 [320/1612 (20%)] Loss: 0.288701\n",
      "Train Epoch: 1216 [480/1612 (30%)] Loss: 0.323331\n",
      "Train Epoch: 1216 [640/1612 (40%)] Loss: 0.361605\n",
      "Train Epoch: 1216 [800/1612 (50%)] Loss: 0.225363\n",
      "Train Epoch: 1216 [960/1612 (59%)] Loss: 0.244766\n",
      "Train Epoch: 1216 [1120/1612 (69%)] Loss: 0.256749\n",
      "Train Epoch: 1216 [1280/1612 (79%)] Loss: 0.265382\n",
      "Train Epoch: 1216 [1440/1612 (89%)] Loss: 0.252918\n",
      "Train Epoch: 1216 [1200/1612 (99%)] Loss: 0.310380\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1217 [0/1612 (0%)] Loss: 0.196238\n",
      "Train Epoch: 1217 [160/1612 (10%)] Loss: 0.154385\n",
      "Train Epoch: 1217 [320/1612 (20%)] Loss: 0.343058\n",
      "Train Epoch: 1217 [480/1612 (30%)] Loss: 0.375106\n",
      "Train Epoch: 1217 [640/1612 (40%)] Loss: 0.263392\n",
      "Train Epoch: 1217 [800/1612 (50%)] Loss: 0.287900\n",
      "Train Epoch: 1217 [960/1612 (59%)] Loss: 0.560477\n",
      "Train Epoch: 1217 [1120/1612 (69%)] Loss: 0.187509\n",
      "Train Epoch: 1217 [1280/1612 (79%)] Loss: 0.817337\n",
      "Train Epoch: 1217 [1440/1612 (89%)] Loss: 0.240047\n",
      "Train Epoch: 1217 [1200/1612 (99%)] Loss: 0.114057\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1218 [0/1612 (0%)] Loss: 0.194218\n",
      "Train Epoch: 1218 [160/1612 (10%)] Loss: 0.447563\n",
      "Train Epoch: 1218 [320/1612 (20%)] Loss: 0.509487\n",
      "Train Epoch: 1218 [480/1612 (30%)] Loss: 0.284976\n",
      "Train Epoch: 1218 [640/1612 (40%)] Loss: 0.453277\n",
      "Train Epoch: 1218 [800/1612 (50%)] Loss: 0.291168\n",
      "Train Epoch: 1218 [960/1612 (59%)] Loss: 0.237959\n",
      "Train Epoch: 1218 [1120/1612 (69%)] Loss: 0.243423\n",
      "Train Epoch: 1218 [1280/1612 (79%)] Loss: 0.388342\n",
      "Train Epoch: 1218 [1440/1612 (89%)] Loss: 0.535702\n",
      "Train Epoch: 1218 [1200/1612 (99%)] Loss: 0.570604\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1219 [0/1612 (0%)] Loss: 0.132712\n",
      "Train Epoch: 1219 [160/1612 (10%)] Loss: 0.428155\n",
      "Train Epoch: 1219 [320/1612 (20%)] Loss: 0.213190\n",
      "Train Epoch: 1219 [480/1612 (30%)] Loss: 0.169562\n",
      "Train Epoch: 1219 [640/1612 (40%)] Loss: 0.464145\n",
      "Train Epoch: 1219 [800/1612 (50%)] Loss: 0.441291\n",
      "Train Epoch: 1219 [960/1612 (59%)] Loss: 0.102624\n",
      "Train Epoch: 1219 [1120/1612 (69%)] Loss: 0.487443\n",
      "Train Epoch: 1219 [1280/1612 (79%)] Loss: 0.411838\n",
      "Train Epoch: 1219 [1440/1612 (89%)] Loss: 0.247839\n",
      "Train Epoch: 1219 [1200/1612 (99%)] Loss: 0.353375\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1220 [0/1612 (0%)] Loss: 0.263945\n",
      "Train Epoch: 1220 [160/1612 (10%)] Loss: 0.272791\n",
      "Train Epoch: 1220 [320/1612 (20%)] Loss: 0.193290\n",
      "Train Epoch: 1220 [480/1612 (30%)] Loss: 0.235252\n",
      "Train Epoch: 1220 [640/1612 (40%)] Loss: 0.077734\n",
      "Train Epoch: 1220 [800/1612 (50%)] Loss: 0.365837\n",
      "Train Epoch: 1220 [960/1612 (59%)] Loss: 0.469640\n",
      "Train Epoch: 1220 [1120/1612 (69%)] Loss: 0.247945\n",
      "Train Epoch: 1220 [1280/1612 (79%)] Loss: 0.214771\n",
      "Train Epoch: 1220 [1440/1612 (89%)] Loss: 0.441102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1220 [1200/1612 (99%)] Loss: 0.337555\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1221 [0/1612 (0%)] Loss: 0.469384\n",
      "Train Epoch: 1221 [160/1612 (10%)] Loss: 0.219705\n",
      "Train Epoch: 1221 [320/1612 (20%)] Loss: 0.280636\n",
      "Train Epoch: 1221 [480/1612 (30%)] Loss: 0.606102\n",
      "Train Epoch: 1221 [640/1612 (40%)] Loss: 0.179290\n",
      "Train Epoch: 1221 [800/1612 (50%)] Loss: 0.347781\n",
      "Train Epoch: 1221 [960/1612 (59%)] Loss: 0.166476\n",
      "Train Epoch: 1221 [1120/1612 (69%)] Loss: 0.311161\n",
      "Train Epoch: 1221 [1280/1612 (79%)] Loss: 0.379423\n",
      "Train Epoch: 1221 [1440/1612 (89%)] Loss: 0.435183\n",
      "Train Epoch: 1221 [1200/1612 (99%)] Loss: 0.280389\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1222 [0/1612 (0%)] Loss: 0.289741\n",
      "Train Epoch: 1222 [160/1612 (10%)] Loss: 0.416675\n",
      "Train Epoch: 1222 [320/1612 (20%)] Loss: 0.535976\n",
      "Train Epoch: 1222 [480/1612 (30%)] Loss: 0.282300\n",
      "Train Epoch: 1222 [640/1612 (40%)] Loss: 0.367027\n",
      "Train Epoch: 1222 [800/1612 (50%)] Loss: 0.282291\n",
      "Train Epoch: 1222 [960/1612 (59%)] Loss: 0.274974\n",
      "Train Epoch: 1222 [1120/1612 (69%)] Loss: 0.154037\n",
      "Train Epoch: 1222 [1280/1612 (79%)] Loss: 0.253952\n",
      "Train Epoch: 1222 [1440/1612 (89%)] Loss: 0.479870\n",
      "Train Epoch: 1222 [1200/1612 (99%)] Loss: 0.235496\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1223 [0/1612 (0%)] Loss: 0.254961\n",
      "Train Epoch: 1223 [160/1612 (10%)] Loss: 0.314055\n",
      "Train Epoch: 1223 [320/1612 (20%)] Loss: 0.139908\n",
      "Train Epoch: 1223 [480/1612 (30%)] Loss: 0.330171\n",
      "Train Epoch: 1223 [640/1612 (40%)] Loss: 0.240056\n",
      "Train Epoch: 1223 [800/1612 (50%)] Loss: 0.337480\n",
      "Train Epoch: 1223 [960/1612 (59%)] Loss: 0.205639\n",
      "Train Epoch: 1223 [1120/1612 (69%)] Loss: 0.378615\n",
      "Train Epoch: 1223 [1280/1612 (79%)] Loss: 0.147834\n",
      "Train Epoch: 1223 [1440/1612 (89%)] Loss: 0.113518\n",
      "Train Epoch: 1223 [1200/1612 (99%)] Loss: 0.265967\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1224 [0/1612 (0%)] Loss: 0.220654\n",
      "Train Epoch: 1224 [160/1612 (10%)] Loss: 0.318478\n",
      "Train Epoch: 1224 [320/1612 (20%)] Loss: 0.259084\n",
      "Train Epoch: 1224 [480/1612 (30%)] Loss: 0.361297\n",
      "Train Epoch: 1224 [640/1612 (40%)] Loss: 0.283349\n",
      "Train Epoch: 1224 [800/1612 (50%)] Loss: 0.553300\n",
      "Train Epoch: 1224 [960/1612 (59%)] Loss: 0.272257\n",
      "Train Epoch: 1224 [1120/1612 (69%)] Loss: 0.460570\n",
      "Train Epoch: 1224 [1280/1612 (79%)] Loss: 0.305382\n",
      "Train Epoch: 1224 [1440/1612 (89%)] Loss: 0.305052\n",
      "Train Epoch: 1224 [1200/1612 (99%)] Loss: 0.237721\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1225 [0/1612 (0%)] Loss: 0.263433\n",
      "Train Epoch: 1225 [160/1612 (10%)] Loss: 0.124628\n",
      "Train Epoch: 1225 [320/1612 (20%)] Loss: 0.160609\n",
      "Train Epoch: 1225 [480/1612 (30%)] Loss: 0.165750\n",
      "Train Epoch: 1225 [640/1612 (40%)] Loss: 0.207660\n",
      "Train Epoch: 1225 [800/1612 (50%)] Loss: 0.241312\n",
      "Train Epoch: 1225 [960/1612 (59%)] Loss: 0.532296\n",
      "Train Epoch: 1225 [1120/1612 (69%)] Loss: 0.403983\n",
      "Train Epoch: 1225 [1280/1612 (79%)] Loss: 0.402400\n",
      "Train Epoch: 1225 [1440/1612 (89%)] Loss: 0.184666\n",
      "Train Epoch: 1225 [1200/1612 (99%)] Loss: 0.237825\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1226 [0/1612 (0%)] Loss: 0.233811\n",
      "Train Epoch: 1226 [160/1612 (10%)] Loss: 0.220121\n",
      "Train Epoch: 1226 [320/1612 (20%)] Loss: 0.149652\n",
      "Train Epoch: 1226 [480/1612 (30%)] Loss: 0.268585\n",
      "Train Epoch: 1226 [640/1612 (40%)] Loss: 0.304859\n",
      "Train Epoch: 1226 [800/1612 (50%)] Loss: 0.201029\n",
      "Train Epoch: 1226 [960/1612 (59%)] Loss: 0.296801\n",
      "Train Epoch: 1226 [1120/1612 (69%)] Loss: 0.392545\n",
      "Train Epoch: 1226 [1280/1612 (79%)] Loss: 0.386803\n",
      "Train Epoch: 1226 [1440/1612 (89%)] Loss: 0.439538\n",
      "Train Epoch: 1226 [1200/1612 (99%)] Loss: 0.725178\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1227 [0/1612 (0%)] Loss: 0.206838\n",
      "Train Epoch: 1227 [160/1612 (10%)] Loss: 0.180662\n",
      "Train Epoch: 1227 [320/1612 (20%)] Loss: 0.342294\n",
      "Train Epoch: 1227 [480/1612 (30%)] Loss: 0.514443\n",
      "Train Epoch: 1227 [640/1612 (40%)] Loss: 0.147881\n",
      "Train Epoch: 1227 [800/1612 (50%)] Loss: 0.254538\n",
      "Train Epoch: 1227 [960/1612 (59%)] Loss: 0.461933\n",
      "Train Epoch: 1227 [1120/1612 (69%)] Loss: 0.295391\n",
      "Train Epoch: 1227 [1280/1612 (79%)] Loss: 0.403293\n",
      "Train Epoch: 1227 [1440/1612 (89%)] Loss: 0.120296\n",
      "Train Epoch: 1227 [1200/1612 (99%)] Loss: 0.370321\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1228 [0/1612 (0%)] Loss: 0.174991\n",
      "Train Epoch: 1228 [160/1612 (10%)] Loss: 0.149048\n",
      "Train Epoch: 1228 [320/1612 (20%)] Loss: 0.189811\n",
      "Train Epoch: 1228 [480/1612 (30%)] Loss: 0.218451\n",
      "Train Epoch: 1228 [640/1612 (40%)] Loss: 0.229462\n",
      "Train Epoch: 1228 [800/1612 (50%)] Loss: 0.192156\n",
      "Train Epoch: 1228 [960/1612 (59%)] Loss: 0.245740\n",
      "Train Epoch: 1228 [1120/1612 (69%)] Loss: 0.173362\n",
      "Train Epoch: 1228 [1280/1612 (79%)] Loss: 0.255592\n",
      "Train Epoch: 1228 [1440/1612 (89%)] Loss: 0.203972\n",
      "Train Epoch: 1228 [1200/1612 (99%)] Loss: 0.317837\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1229 [0/1612 (0%)] Loss: 0.272026\n",
      "Train Epoch: 1229 [160/1612 (10%)] Loss: 0.224790\n",
      "Train Epoch: 1229 [320/1612 (20%)] Loss: 0.432565\n",
      "Train Epoch: 1229 [480/1612 (30%)] Loss: 0.347661\n",
      "Train Epoch: 1229 [640/1612 (40%)] Loss: 0.402817\n",
      "Train Epoch: 1229 [800/1612 (50%)] Loss: 0.162192\n",
      "Train Epoch: 1229 [960/1612 (59%)] Loss: 0.275013\n",
      "Train Epoch: 1229 [1120/1612 (69%)] Loss: 0.482578\n",
      "Train Epoch: 1229 [1280/1612 (79%)] Loss: 0.196312\n",
      "Train Epoch: 1229 [1440/1612 (89%)] Loss: 0.546436\n",
      "Train Epoch: 1229 [1200/1612 (99%)] Loss: 0.158917\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1230 [0/1612 (0%)] Loss: 0.122969\n",
      "Train Epoch: 1230 [160/1612 (10%)] Loss: 0.141171\n",
      "Train Epoch: 1230 [320/1612 (20%)] Loss: 0.207418\n",
      "Train Epoch: 1230 [480/1612 (30%)] Loss: 0.104474\n",
      "Train Epoch: 1230 [640/1612 (40%)] Loss: 0.375976\n",
      "Train Epoch: 1230 [800/1612 (50%)] Loss: 0.399837\n",
      "Train Epoch: 1230 [960/1612 (59%)] Loss: 0.292909\n",
      "Train Epoch: 1230 [1120/1612 (69%)] Loss: 0.226766\n",
      "Train Epoch: 1230 [1280/1612 (79%)] Loss: 0.212945\n",
      "Train Epoch: 1230 [1440/1612 (89%)] Loss: 0.187754\n",
      "Train Epoch: 1230 [1200/1612 (99%)] Loss: 0.282862\n",
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1231 [0/1612 (0%)] Loss: 0.152534\n",
      "Train Epoch: 1231 [160/1612 (10%)] Loss: 0.187301\n",
      "Train Epoch: 1231 [320/1612 (20%)] Loss: 0.412678\n",
      "Train Epoch: 1231 [480/1612 (30%)] Loss: 0.381097\n",
      "Train Epoch: 1231 [640/1612 (40%)] Loss: 0.331907\n",
      "Train Epoch: 1231 [800/1612 (50%)] Loss: 0.332386\n",
      "Train Epoch: 1231 [960/1612 (59%)] Loss: 0.255875\n",
      "Train Epoch: 1231 [1120/1612 (69%)] Loss: 0.145233\n",
      "Train Epoch: 1231 [1280/1612 (79%)] Loss: 0.365815\n",
      "Train Epoch: 1231 [1440/1612 (89%)] Loss: 0.183237\n",
      "Train Epoch: 1231 [1200/1612 (99%)] Loss: 0.103347\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1232 [0/1612 (0%)] Loss: 0.358383\n",
      "Train Epoch: 1232 [160/1612 (10%)] Loss: 0.423091\n",
      "Train Epoch: 1232 [320/1612 (20%)] Loss: 0.507810\n",
      "Train Epoch: 1232 [480/1612 (30%)] Loss: 0.364803\n",
      "Train Epoch: 1232 [640/1612 (40%)] Loss: 0.410813\n",
      "Train Epoch: 1232 [800/1612 (50%)] Loss: 0.288863\n",
      "Train Epoch: 1232 [960/1612 (59%)] Loss: 0.188046\n",
      "Train Epoch: 1232 [1120/1612 (69%)] Loss: 0.280015\n",
      "Train Epoch: 1232 [1280/1612 (79%)] Loss: 0.304322\n",
      "Train Epoch: 1232 [1440/1612 (89%)] Loss: 0.458975\n",
      "Train Epoch: 1232 [1200/1612 (99%)] Loss: 0.244804\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1233 [0/1612 (0%)] Loss: 0.201493\n",
      "Train Epoch: 1233 [160/1612 (10%)] Loss: 0.075627\n",
      "Train Epoch: 1233 [320/1612 (20%)] Loss: 0.445632\n",
      "Train Epoch: 1233 [480/1612 (30%)] Loss: 0.160615\n",
      "Train Epoch: 1233 [640/1612 (40%)] Loss: 0.493652\n",
      "Train Epoch: 1233 [800/1612 (50%)] Loss: 0.300444\n",
      "Train Epoch: 1233 [960/1612 (59%)] Loss: 0.351441\n",
      "Train Epoch: 1233 [1120/1612 (69%)] Loss: 0.350492\n",
      "Train Epoch: 1233 [1280/1612 (79%)] Loss: 0.153252\n",
      "Train Epoch: 1233 [1440/1612 (89%)] Loss: 0.300195\n",
      "Train Epoch: 1233 [1200/1612 (99%)] Loss: 0.318910\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1234 [0/1612 (0%)] Loss: 0.111394\n",
      "Train Epoch: 1234 [160/1612 (10%)] Loss: 0.304283\n",
      "Train Epoch: 1234 [320/1612 (20%)] Loss: 0.536288\n",
      "Train Epoch: 1234 [480/1612 (30%)] Loss: 0.438223\n",
      "Train Epoch: 1234 [640/1612 (40%)] Loss: 0.217328\n",
      "Train Epoch: 1234 [800/1612 (50%)] Loss: 0.246754\n",
      "Train Epoch: 1234 [960/1612 (59%)] Loss: 0.296333\n",
      "Train Epoch: 1234 [1120/1612 (69%)] Loss: 0.360409\n",
      "Train Epoch: 1234 [1280/1612 (79%)] Loss: 0.211903\n",
      "Train Epoch: 1234 [1440/1612 (89%)] Loss: 0.327873\n",
      "Train Epoch: 1234 [1200/1612 (99%)] Loss: 0.222255\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1235 [0/1612 (0%)] Loss: 0.433376\n",
      "Train Epoch: 1235 [160/1612 (10%)] Loss: 0.706503\n",
      "Train Epoch: 1235 [320/1612 (20%)] Loss: 0.299346\n",
      "Train Epoch: 1235 [480/1612 (30%)] Loss: 0.421628\n",
      "Train Epoch: 1235 [640/1612 (40%)] Loss: 0.448312\n",
      "Train Epoch: 1235 [800/1612 (50%)] Loss: 0.259148\n",
      "Train Epoch: 1235 [960/1612 (59%)] Loss: 0.102445\n",
      "Train Epoch: 1235 [1120/1612 (69%)] Loss: 0.244644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1235 [1280/1612 (79%)] Loss: 0.290133\n",
      "Train Epoch: 1235 [1440/1612 (89%)] Loss: 0.374629\n",
      "Train Epoch: 1235 [1200/1612 (99%)] Loss: 0.113162\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1236 [0/1612 (0%)] Loss: 0.162287\n",
      "Train Epoch: 1236 [160/1612 (10%)] Loss: 0.332039\n",
      "Train Epoch: 1236 [320/1612 (20%)] Loss: 0.524867\n",
      "Train Epoch: 1236 [480/1612 (30%)] Loss: 0.120195\n",
      "Train Epoch: 1236 [640/1612 (40%)] Loss: 0.217061\n",
      "Train Epoch: 1236 [800/1612 (50%)] Loss: 0.480069\n",
      "Train Epoch: 1236 [960/1612 (59%)] Loss: 0.344073\n",
      "Train Epoch: 1236 [1120/1612 (69%)] Loss: 0.370060\n",
      "Train Epoch: 1236 [1280/1612 (79%)] Loss: 0.190479\n",
      "Train Epoch: 1236 [1440/1612 (89%)] Loss: 0.256017\n",
      "Train Epoch: 1236 [1200/1612 (99%)] Loss: 0.487334\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1237 [0/1612 (0%)] Loss: 0.231155\n",
      "Train Epoch: 1237 [160/1612 (10%)] Loss: 0.258175\n",
      "Train Epoch: 1237 [320/1612 (20%)] Loss: 0.168627\n",
      "Train Epoch: 1237 [480/1612 (30%)] Loss: 0.301500\n",
      "Train Epoch: 1237 [640/1612 (40%)] Loss: 0.130000\n",
      "Train Epoch: 1237 [800/1612 (50%)] Loss: 0.283814\n",
      "Train Epoch: 1237 [960/1612 (59%)] Loss: 0.176387\n",
      "Train Epoch: 1237 [1120/1612 (69%)] Loss: 0.315584\n",
      "Train Epoch: 1237 [1280/1612 (79%)] Loss: 0.253901\n",
      "Train Epoch: 1237 [1440/1612 (89%)] Loss: 0.325590\n",
      "Train Epoch: 1237 [1200/1612 (99%)] Loss: 0.449792\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1238 [0/1612 (0%)] Loss: 0.255186\n",
      "Train Epoch: 1238 [160/1612 (10%)] Loss: 0.190915\n",
      "Train Epoch: 1238 [320/1612 (20%)] Loss: 0.223609\n",
      "Train Epoch: 1238 [480/1612 (30%)] Loss: 0.145473\n",
      "Train Epoch: 1238 [640/1612 (40%)] Loss: 0.382626\n",
      "Train Epoch: 1238 [800/1612 (50%)] Loss: 0.385227\n",
      "Train Epoch: 1238 [960/1612 (59%)] Loss: 0.300263\n",
      "Train Epoch: 1238 [1120/1612 (69%)] Loss: 0.135382\n",
      "Train Epoch: 1238 [1280/1612 (79%)] Loss: 0.256418\n",
      "Train Epoch: 1238 [1440/1612 (89%)] Loss: 0.119820\n",
      "Train Epoch: 1238 [1200/1612 (99%)] Loss: 0.104191\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1239 [0/1612 (0%)] Loss: 0.327413\n",
      "Train Epoch: 1239 [160/1612 (10%)] Loss: 0.267950\n",
      "Train Epoch: 1239 [320/1612 (20%)] Loss: 0.198152\n",
      "Train Epoch: 1239 [480/1612 (30%)] Loss: 0.373253\n",
      "Train Epoch: 1239 [640/1612 (40%)] Loss: 0.441674\n",
      "Train Epoch: 1239 [800/1612 (50%)] Loss: 0.541426\n",
      "Train Epoch: 1239 [960/1612 (59%)] Loss: 0.404886\n",
      "Train Epoch: 1239 [1120/1612 (69%)] Loss: 0.141841\n",
      "Train Epoch: 1239 [1280/1612 (79%)] Loss: 0.340176\n",
      "Train Epoch: 1239 [1440/1612 (89%)] Loss: 0.181643\n",
      "Train Epoch: 1239 [1200/1612 (99%)] Loss: 0.059411\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1240 [0/1612 (0%)] Loss: 0.179069\n",
      "Train Epoch: 1240 [160/1612 (10%)] Loss: 0.251921\n",
      "Train Epoch: 1240 [320/1612 (20%)] Loss: 0.236975\n",
      "Train Epoch: 1240 [480/1612 (30%)] Loss: 0.163625\n",
      "Train Epoch: 1240 [640/1612 (40%)] Loss: 0.232280\n",
      "Train Epoch: 1240 [800/1612 (50%)] Loss: 0.384028\n",
      "Train Epoch: 1240 [960/1612 (59%)] Loss: 0.383096\n",
      "Train Epoch: 1240 [1120/1612 (69%)] Loss: 0.340773\n",
      "Train Epoch: 1240 [1280/1612 (79%)] Loss: 0.360032\n",
      "Train Epoch: 1240 [1440/1612 (89%)] Loss: 0.464140\n",
      "Train Epoch: 1240 [1200/1612 (99%)] Loss: 0.638559\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1241 [0/1612 (0%)] Loss: 0.433875\n",
      "Train Epoch: 1241 [160/1612 (10%)] Loss: 0.156552\n",
      "Train Epoch: 1241 [320/1612 (20%)] Loss: 0.228935\n",
      "Train Epoch: 1241 [480/1612 (30%)] Loss: 0.435162\n",
      "Train Epoch: 1241 [640/1612 (40%)] Loss: 0.307637\n",
      "Train Epoch: 1241 [800/1612 (50%)] Loss: 0.416044\n",
      "Train Epoch: 1241 [960/1612 (59%)] Loss: 0.365292\n",
      "Train Epoch: 1241 [1120/1612 (69%)] Loss: 0.189334\n",
      "Train Epoch: 1241 [1280/1612 (79%)] Loss: 0.342313\n",
      "Train Epoch: 1241 [1440/1612 (89%)] Loss: 0.277847\n",
      "Train Epoch: 1241 [1200/1612 (99%)] Loss: 0.279975\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1242 [0/1612 (0%)] Loss: 0.294872\n",
      "Train Epoch: 1242 [160/1612 (10%)] Loss: 0.084148\n",
      "Train Epoch: 1242 [320/1612 (20%)] Loss: 0.378973\n",
      "Train Epoch: 1242 [480/1612 (30%)] Loss: 0.294057\n",
      "Train Epoch: 1242 [640/1612 (40%)] Loss: 0.549575\n",
      "Train Epoch: 1242 [800/1612 (50%)] Loss: 0.335165\n",
      "Train Epoch: 1242 [960/1612 (59%)] Loss: 0.243872\n",
      "Train Epoch: 1242 [1120/1612 (69%)] Loss: 0.390169\n",
      "Train Epoch: 1242 [1280/1612 (79%)] Loss: 0.424189\n",
      "Train Epoch: 1242 [1440/1612 (89%)] Loss: 0.192111\n",
      "Train Epoch: 1242 [1200/1612 (99%)] Loss: 0.182688\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1243 [0/1612 (0%)] Loss: 0.232406\n",
      "Train Epoch: 1243 [160/1612 (10%)] Loss: 0.205322\n",
      "Train Epoch: 1243 [320/1612 (20%)] Loss: 0.246416\n",
      "Train Epoch: 1243 [480/1612 (30%)] Loss: 0.551308\n",
      "Train Epoch: 1243 [640/1612 (40%)] Loss: 0.215025\n",
      "Train Epoch: 1243 [800/1612 (50%)] Loss: 0.464177\n",
      "Train Epoch: 1243 [960/1612 (59%)] Loss: 0.097710\n",
      "Train Epoch: 1243 [1120/1612 (69%)] Loss: 0.173184\n",
      "Train Epoch: 1243 [1280/1612 (79%)] Loss: 0.270785\n",
      "Train Epoch: 1243 [1440/1612 (89%)] Loss: 0.518081\n",
      "Train Epoch: 1243 [1200/1612 (99%)] Loss: 0.217788\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1244 [0/1612 (0%)] Loss: 0.261491\n",
      "Train Epoch: 1244 [160/1612 (10%)] Loss: 0.223176\n",
      "Train Epoch: 1244 [320/1612 (20%)] Loss: 0.234060\n",
      "Train Epoch: 1244 [480/1612 (30%)] Loss: 0.412097\n",
      "Train Epoch: 1244 [640/1612 (40%)] Loss: 0.376824\n",
      "Train Epoch: 1244 [800/1612 (50%)] Loss: 0.215298\n",
      "Train Epoch: 1244 [960/1612 (59%)] Loss: 0.281125\n",
      "Train Epoch: 1244 [1120/1612 (69%)] Loss: 0.264206\n",
      "Train Epoch: 1244 [1280/1612 (79%)] Loss: 0.576708\n",
      "Train Epoch: 1244 [1440/1612 (89%)] Loss: 0.374319\n",
      "Train Epoch: 1244 [1200/1612 (99%)] Loss: 0.304806\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1245 [0/1612 (0%)] Loss: 0.242989\n",
      "Train Epoch: 1245 [160/1612 (10%)] Loss: 0.145253\n",
      "Train Epoch: 1245 [320/1612 (20%)] Loss: 0.205222\n",
      "Train Epoch: 1245 [480/1612 (30%)] Loss: 0.432423\n",
      "Train Epoch: 1245 [640/1612 (40%)] Loss: 0.176134\n",
      "Train Epoch: 1245 [800/1612 (50%)] Loss: 0.372615\n",
      "Train Epoch: 1245 [960/1612 (59%)] Loss: 0.288500\n",
      "Train Epoch: 1245 [1120/1612 (69%)] Loss: 0.113120\n",
      "Train Epoch: 1245 [1280/1612 (79%)] Loss: 0.493324\n",
      "Train Epoch: 1245 [1440/1612 (89%)] Loss: 0.300665\n",
      "Train Epoch: 1245 [1200/1612 (99%)] Loss: 0.271747\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1246 [0/1612 (0%)] Loss: 0.232206\n",
      "Train Epoch: 1246 [160/1612 (10%)] Loss: 0.274696\n",
      "Train Epoch: 1246 [320/1612 (20%)] Loss: 0.187482\n",
      "Train Epoch: 1246 [480/1612 (30%)] Loss: 0.466576\n",
      "Train Epoch: 1246 [640/1612 (40%)] Loss: 0.134147\n",
      "Train Epoch: 1246 [800/1612 (50%)] Loss: 0.188032\n",
      "Train Epoch: 1246 [960/1612 (59%)] Loss: 0.178331\n",
      "Train Epoch: 1246 [1120/1612 (69%)] Loss: 0.220526\n",
      "Train Epoch: 1246 [1280/1612 (79%)] Loss: 0.405225\n",
      "Train Epoch: 1246 [1440/1612 (89%)] Loss: 0.427881\n",
      "Train Epoch: 1246 [1200/1612 (99%)] Loss: 0.250533\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1247 [0/1612 (0%)] Loss: 0.346272\n",
      "Train Epoch: 1247 [160/1612 (10%)] Loss: 0.201774\n",
      "Train Epoch: 1247 [320/1612 (20%)] Loss: 0.337906\n",
      "Train Epoch: 1247 [480/1612 (30%)] Loss: 0.207632\n",
      "Train Epoch: 1247 [640/1612 (40%)] Loss: 0.354470\n",
      "Train Epoch: 1247 [800/1612 (50%)] Loss: 0.375412\n",
      "Train Epoch: 1247 [960/1612 (59%)] Loss: 0.402550\n",
      "Train Epoch: 1247 [1120/1612 (69%)] Loss: 0.302820\n",
      "Train Epoch: 1247 [1280/1612 (79%)] Loss: 0.246725\n",
      "Train Epoch: 1247 [1440/1612 (89%)] Loss: 0.174212\n",
      "Train Epoch: 1247 [1200/1612 (99%)] Loss: 0.142672\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1248 [0/1612 (0%)] Loss: 0.370861\n",
      "Train Epoch: 1248 [160/1612 (10%)] Loss: 0.392225\n",
      "Train Epoch: 1248 [320/1612 (20%)] Loss: 0.192460\n",
      "Train Epoch: 1248 [480/1612 (30%)] Loss: 0.381224\n",
      "Train Epoch: 1248 [640/1612 (40%)] Loss: 0.191991\n",
      "Train Epoch: 1248 [800/1612 (50%)] Loss: 0.386284\n",
      "Train Epoch: 1248 [960/1612 (59%)] Loss: 0.352180\n",
      "Train Epoch: 1248 [1120/1612 (69%)] Loss: 0.250268\n",
      "Train Epoch: 1248 [1280/1612 (79%)] Loss: 0.373989\n",
      "Train Epoch: 1248 [1440/1612 (89%)] Loss: 0.501500\n",
      "Train Epoch: 1248 [1200/1612 (99%)] Loss: 0.236154\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1249 [0/1612 (0%)] Loss: 0.511955\n",
      "Train Epoch: 1249 [160/1612 (10%)] Loss: 0.219940\n",
      "Train Epoch: 1249 [320/1612 (20%)] Loss: 0.220340\n",
      "Train Epoch: 1249 [480/1612 (30%)] Loss: 0.311366\n",
      "Train Epoch: 1249 [640/1612 (40%)] Loss: 0.294711\n",
      "Train Epoch: 1249 [800/1612 (50%)] Loss: 0.267378\n",
      "Train Epoch: 1249 [960/1612 (59%)] Loss: 0.396963\n",
      "Train Epoch: 1249 [1120/1612 (69%)] Loss: 0.191451\n",
      "Train Epoch: 1249 [1280/1612 (79%)] Loss: 0.230338\n",
      "Train Epoch: 1249 [1440/1612 (89%)] Loss: 0.081622\n",
      "Train Epoch: 1249 [1200/1612 (99%)] Loss: 0.157538\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1250 [0/1612 (0%)] Loss: 0.083897\n",
      "Train Epoch: 1250 [160/1612 (10%)] Loss: 0.299447\n",
      "Train Epoch: 1250 [320/1612 (20%)] Loss: 0.280604\n",
      "Train Epoch: 1250 [480/1612 (30%)] Loss: 0.338743\n",
      "Train Epoch: 1250 [640/1612 (40%)] Loss: 0.359238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1250 [800/1612 (50%)] Loss: 0.407937\n",
      "Train Epoch: 1250 [960/1612 (59%)] Loss: 0.308608\n",
      "Train Epoch: 1250 [1120/1612 (69%)] Loss: 0.109663\n",
      "Train Epoch: 1250 [1280/1612 (79%)] Loss: 0.353229\n",
      "Train Epoch: 1250 [1440/1612 (89%)] Loss: 0.254246\n",
      "Train Epoch: 1250 [1200/1612 (99%)] Loss: 0.511017\n",
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1251 [0/1612 (0%)] Loss: 0.228463\n",
      "Train Epoch: 1251 [160/1612 (10%)] Loss: 0.132111\n",
      "Train Epoch: 1251 [320/1612 (20%)] Loss: 0.267801\n",
      "Train Epoch: 1251 [480/1612 (30%)] Loss: 0.347433\n",
      "Train Epoch: 1251 [640/1612 (40%)] Loss: 0.374114\n",
      "Train Epoch: 1251 [800/1612 (50%)] Loss: 0.342406\n",
      "Train Epoch: 1251 [960/1612 (59%)] Loss: 0.277646\n",
      "Train Epoch: 1251 [1120/1612 (69%)] Loss: 0.981504\n",
      "Train Epoch: 1251 [1280/1612 (79%)] Loss: 0.267161\n",
      "Train Epoch: 1251 [1440/1612 (89%)] Loss: 0.362620\n",
      "Train Epoch: 1251 [1200/1612 (99%)] Loss: 0.563874\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1252 [0/1612 (0%)] Loss: 0.230276\n",
      "Train Epoch: 1252 [160/1612 (10%)] Loss: 0.258619\n",
      "Train Epoch: 1252 [320/1612 (20%)] Loss: 0.299492\n",
      "Train Epoch: 1252 [480/1612 (30%)] Loss: 0.328467\n",
      "Train Epoch: 1252 [640/1612 (40%)] Loss: 0.359850\n",
      "Train Epoch: 1252 [800/1612 (50%)] Loss: 0.388750\n",
      "Train Epoch: 1252 [960/1612 (59%)] Loss: 0.252130\n",
      "Train Epoch: 1252 [1120/1612 (69%)] Loss: 0.429947\n",
      "Train Epoch: 1252 [1280/1612 (79%)] Loss: 0.365675\n",
      "Train Epoch: 1252 [1440/1612 (89%)] Loss: 0.356481\n",
      "Train Epoch: 1252 [1200/1612 (99%)] Loss: 0.176702\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1253 [0/1612 (0%)] Loss: 0.418495\n",
      "Train Epoch: 1253 [160/1612 (10%)] Loss: 0.470010\n",
      "Train Epoch: 1253 [320/1612 (20%)] Loss: 0.389017\n",
      "Train Epoch: 1253 [480/1612 (30%)] Loss: 0.302514\n",
      "Train Epoch: 1253 [640/1612 (40%)] Loss: 0.282895\n",
      "Train Epoch: 1253 [800/1612 (50%)] Loss: 0.319941\n",
      "Train Epoch: 1253 [960/1612 (59%)] Loss: 0.183421\n",
      "Train Epoch: 1253 [1120/1612 (69%)] Loss: 0.213404\n",
      "Train Epoch: 1253 [1280/1612 (79%)] Loss: 0.112220\n",
      "Train Epoch: 1253 [1440/1612 (89%)] Loss: 0.309605\n",
      "Train Epoch: 1253 [1200/1612 (99%)] Loss: 0.396402\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1254 [0/1612 (0%)] Loss: 0.255403\n",
      "Train Epoch: 1254 [160/1612 (10%)] Loss: 0.218956\n",
      "Train Epoch: 1254 [320/1612 (20%)] Loss: 0.159438\n",
      "Train Epoch: 1254 [480/1612 (30%)] Loss: 0.189665\n",
      "Train Epoch: 1254 [640/1612 (40%)] Loss: 0.304149\n",
      "Train Epoch: 1254 [800/1612 (50%)] Loss: 0.552746\n",
      "Train Epoch: 1254 [960/1612 (59%)] Loss: 0.304000\n",
      "Train Epoch: 1254 [1120/1612 (69%)] Loss: 0.390801\n",
      "Train Epoch: 1254 [1280/1612 (79%)] Loss: 0.216481\n",
      "Train Epoch: 1254 [1440/1612 (89%)] Loss: 0.741572\n",
      "Train Epoch: 1254 [1200/1612 (99%)] Loss: 0.351508\n",
      "\n",
      "Test set: Average loss: 0.0320, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1255 [0/1612 (0%)] Loss: 0.294044\n",
      "Train Epoch: 1255 [160/1612 (10%)] Loss: 0.329107\n",
      "Train Epoch: 1255 [320/1612 (20%)] Loss: 0.237817\n",
      "Train Epoch: 1255 [480/1612 (30%)] Loss: 0.459125\n",
      "Train Epoch: 1255 [640/1612 (40%)] Loss: 0.181415\n",
      "Train Epoch: 1255 [800/1612 (50%)] Loss: 0.437503\n",
      "Train Epoch: 1255 [960/1612 (59%)] Loss: 0.439980\n",
      "Train Epoch: 1255 [1120/1612 (69%)] Loss: 0.305487\n",
      "Train Epoch: 1255 [1280/1612 (79%)] Loss: 0.191774\n",
      "Train Epoch: 1255 [1440/1612 (89%)] Loss: 0.277538\n",
      "Train Epoch: 1255 [1200/1612 (99%)] Loss: 0.157420\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1256 [0/1612 (0%)] Loss: 0.483438\n",
      "Train Epoch: 1256 [160/1612 (10%)] Loss: 0.165478\n",
      "Train Epoch: 1256 [320/1612 (20%)] Loss: 0.316064\n",
      "Train Epoch: 1256 [480/1612 (30%)] Loss: 0.047250\n",
      "Train Epoch: 1256 [640/1612 (40%)] Loss: 0.123338\n",
      "Train Epoch: 1256 [800/1612 (50%)] Loss: 0.491188\n",
      "Train Epoch: 1256 [960/1612 (59%)] Loss: 0.183274\n",
      "Train Epoch: 1256 [1120/1612 (69%)] Loss: 0.167365\n",
      "Train Epoch: 1256 [1280/1612 (79%)] Loss: 0.252018\n",
      "Train Epoch: 1256 [1440/1612 (89%)] Loss: 0.316255\n",
      "Train Epoch: 1256 [1200/1612 (99%)] Loss: 0.353095\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1257 [0/1612 (0%)] Loss: 0.176131\n",
      "Train Epoch: 1257 [160/1612 (10%)] Loss: 0.146988\n",
      "Train Epoch: 1257 [320/1612 (20%)] Loss: 0.317074\n",
      "Train Epoch: 1257 [480/1612 (30%)] Loss: 0.305496\n",
      "Train Epoch: 1257 [640/1612 (40%)] Loss: 0.524750\n",
      "Train Epoch: 1257 [800/1612 (50%)] Loss: 0.340854\n",
      "Train Epoch: 1257 [960/1612 (59%)] Loss: 0.270692\n",
      "Train Epoch: 1257 [1120/1612 (69%)] Loss: 0.167223\n",
      "Train Epoch: 1257 [1280/1612 (79%)] Loss: 0.301067\n",
      "Train Epoch: 1257 [1440/1612 (89%)] Loss: 0.194704\n",
      "Train Epoch: 1257 [1200/1612 (99%)] Loss: 0.222776\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1258 [0/1612 (0%)] Loss: 0.243871\n",
      "Train Epoch: 1258 [160/1612 (10%)] Loss: 0.375239\n",
      "Train Epoch: 1258 [320/1612 (20%)] Loss: 0.349932\n",
      "Train Epoch: 1258 [480/1612 (30%)] Loss: 0.325472\n",
      "Train Epoch: 1258 [640/1612 (40%)] Loss: 0.256742\n",
      "Train Epoch: 1258 [800/1612 (50%)] Loss: 0.515694\n",
      "Train Epoch: 1258 [960/1612 (59%)] Loss: 0.402242\n",
      "Train Epoch: 1258 [1120/1612 (69%)] Loss: 0.439221\n",
      "Train Epoch: 1258 [1280/1612 (79%)] Loss: 0.379678\n",
      "Train Epoch: 1258 [1440/1612 (89%)] Loss: 0.271847\n",
      "Train Epoch: 1258 [1200/1612 (99%)] Loss: 0.616557\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1259 [0/1612 (0%)] Loss: 0.191684\n",
      "Train Epoch: 1259 [160/1612 (10%)] Loss: 0.200644\n",
      "Train Epoch: 1259 [320/1612 (20%)] Loss: 0.131770\n",
      "Train Epoch: 1259 [480/1612 (30%)] Loss: 0.339142\n",
      "Train Epoch: 1259 [640/1612 (40%)] Loss: 0.180282\n",
      "Train Epoch: 1259 [800/1612 (50%)] Loss: 0.556168\n",
      "Train Epoch: 1259 [960/1612 (59%)] Loss: 0.516008\n",
      "Train Epoch: 1259 [1120/1612 (69%)] Loss: 0.288515\n",
      "Train Epoch: 1259 [1280/1612 (79%)] Loss: 0.192060\n",
      "Train Epoch: 1259 [1440/1612 (89%)] Loss: 0.216623\n",
      "Train Epoch: 1259 [1200/1612 (99%)] Loss: 0.539735\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1260 [0/1612 (0%)] Loss: 0.115323\n",
      "Train Epoch: 1260 [160/1612 (10%)] Loss: 0.394756\n",
      "Train Epoch: 1260 [320/1612 (20%)] Loss: 0.107256\n",
      "Train Epoch: 1260 [480/1612 (30%)] Loss: 0.251531\n",
      "Train Epoch: 1260 [640/1612 (40%)] Loss: 0.244918\n",
      "Train Epoch: 1260 [800/1612 (50%)] Loss: 0.352024\n",
      "Train Epoch: 1260 [960/1612 (59%)] Loss: 0.186582\n",
      "Train Epoch: 1260 [1120/1612 (69%)] Loss: 0.349802\n",
      "Train Epoch: 1260 [1280/1612 (79%)] Loss: 0.379845\n",
      "Train Epoch: 1260 [1440/1612 (89%)] Loss: 0.316039\n",
      "Train Epoch: 1260 [1200/1612 (99%)] Loss: 0.328077\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1261 [0/1612 (0%)] Loss: 0.367749\n",
      "Train Epoch: 1261 [160/1612 (10%)] Loss: 0.260658\n",
      "Train Epoch: 1261 [320/1612 (20%)] Loss: 0.198874\n",
      "Train Epoch: 1261 [480/1612 (30%)] Loss: 0.537401\n",
      "Train Epoch: 1261 [640/1612 (40%)] Loss: 0.526789\n",
      "Train Epoch: 1261 [800/1612 (50%)] Loss: 0.233924\n",
      "Train Epoch: 1261 [960/1612 (59%)] Loss: 0.182037\n",
      "Train Epoch: 1261 [1120/1612 (69%)] Loss: 0.093585\n",
      "Train Epoch: 1261 [1280/1612 (79%)] Loss: 0.223797\n",
      "Train Epoch: 1261 [1440/1612 (89%)] Loss: 0.341657\n",
      "Train Epoch: 1261 [1200/1612 (99%)] Loss: 0.602697\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1262 [0/1612 (0%)] Loss: 0.360954\n",
      "Train Epoch: 1262 [160/1612 (10%)] Loss: 0.311165\n",
      "Train Epoch: 1262 [320/1612 (20%)] Loss: 0.330461\n",
      "Train Epoch: 1262 [480/1612 (30%)] Loss: 0.357849\n",
      "Train Epoch: 1262 [640/1612 (40%)] Loss: 0.265469\n",
      "Train Epoch: 1262 [800/1612 (50%)] Loss: 0.204671\n",
      "Train Epoch: 1262 [960/1612 (59%)] Loss: 0.491880\n",
      "Train Epoch: 1262 [1120/1612 (69%)] Loss: 0.433756\n",
      "Train Epoch: 1262 [1280/1612 (79%)] Loss: 0.328754\n",
      "Train Epoch: 1262 [1440/1612 (89%)] Loss: 0.142831\n",
      "Train Epoch: 1262 [1200/1612 (99%)] Loss: 0.285991\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1263 [0/1612 (0%)] Loss: 0.524420\n",
      "Train Epoch: 1263 [160/1612 (10%)] Loss: 0.368036\n",
      "Train Epoch: 1263 [320/1612 (20%)] Loss: 0.501213\n",
      "Train Epoch: 1263 [480/1612 (30%)] Loss: 0.139063\n",
      "Train Epoch: 1263 [640/1612 (40%)] Loss: 0.241234\n",
      "Train Epoch: 1263 [800/1612 (50%)] Loss: 0.192764\n",
      "Train Epoch: 1263 [960/1612 (59%)] Loss: 0.310709\n",
      "Train Epoch: 1263 [1120/1612 (69%)] Loss: 0.202053\n",
      "Train Epoch: 1263 [1280/1612 (79%)] Loss: 0.278210\n",
      "Train Epoch: 1263 [1440/1612 (89%)] Loss: 0.274965\n",
      "Train Epoch: 1263 [1200/1612 (99%)] Loss: 0.135545\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1264 [0/1612 (0%)] Loss: 0.148533\n",
      "Train Epoch: 1264 [160/1612 (10%)] Loss: 0.222941\n",
      "Train Epoch: 1264 [320/1612 (20%)] Loss: 0.355980\n",
      "Train Epoch: 1264 [480/1612 (30%)] Loss: 0.273313\n",
      "Train Epoch: 1264 [640/1612 (40%)] Loss: 0.212938\n",
      "Train Epoch: 1264 [800/1612 (50%)] Loss: 0.190260\n",
      "Train Epoch: 1264 [960/1612 (59%)] Loss: 0.562056\n",
      "Train Epoch: 1264 [1120/1612 (69%)] Loss: 0.245062\n",
      "Train Epoch: 1264 [1280/1612 (79%)] Loss: 0.458401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1264 [1440/1612 (89%)] Loss: 0.272772\n",
      "Train Epoch: 1264 [1200/1612 (99%)] Loss: 0.418116\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1265 [0/1612 (0%)] Loss: 0.396838\n",
      "Train Epoch: 1265 [160/1612 (10%)] Loss: 0.210558\n",
      "Train Epoch: 1265 [320/1612 (20%)] Loss: 0.254118\n",
      "Train Epoch: 1265 [480/1612 (30%)] Loss: 0.419132\n",
      "Train Epoch: 1265 [640/1612 (40%)] Loss: 0.114620\n",
      "Train Epoch: 1265 [800/1612 (50%)] Loss: 0.383834\n",
      "Train Epoch: 1265 [960/1612 (59%)] Loss: 0.345069\n",
      "Train Epoch: 1265 [1120/1612 (69%)] Loss: 0.241363\n",
      "Train Epoch: 1265 [1280/1612 (79%)] Loss: 0.491663\n",
      "Train Epoch: 1265 [1440/1612 (89%)] Loss: 0.394946\n",
      "Train Epoch: 1265 [1200/1612 (99%)] Loss: 0.418655\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1266 [0/1612 (0%)] Loss: 0.275624\n",
      "Train Epoch: 1266 [160/1612 (10%)] Loss: 0.228479\n",
      "Train Epoch: 1266 [320/1612 (20%)] Loss: 0.178960\n",
      "Train Epoch: 1266 [480/1612 (30%)] Loss: 0.580787\n",
      "Train Epoch: 1266 [640/1612 (40%)] Loss: 0.406411\n",
      "Train Epoch: 1266 [800/1612 (50%)] Loss: 0.185767\n",
      "Train Epoch: 1266 [960/1612 (59%)] Loss: 0.353416\n",
      "Train Epoch: 1266 [1120/1612 (69%)] Loss: 0.184704\n",
      "Train Epoch: 1266 [1280/1612 (79%)] Loss: 0.146054\n",
      "Train Epoch: 1266 [1440/1612 (89%)] Loss: 0.187795\n",
      "Train Epoch: 1266 [1200/1612 (99%)] Loss: 0.365792\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1267 [0/1612 (0%)] Loss: 0.342983\n",
      "Train Epoch: 1267 [160/1612 (10%)] Loss: 0.061148\n",
      "Train Epoch: 1267 [320/1612 (20%)] Loss: 0.259840\n",
      "Train Epoch: 1267 [480/1612 (30%)] Loss: 0.435936\n",
      "Train Epoch: 1267 [640/1612 (40%)] Loss: 0.424001\n",
      "Train Epoch: 1267 [800/1612 (50%)] Loss: 0.297085\n",
      "Train Epoch: 1267 [960/1612 (59%)] Loss: 0.356006\n",
      "Train Epoch: 1267 [1120/1612 (69%)] Loss: 0.759346\n",
      "Train Epoch: 1267 [1280/1612 (79%)] Loss: 0.349594\n",
      "Train Epoch: 1267 [1440/1612 (89%)] Loss: 0.286673\n",
      "Train Epoch: 1267 [1200/1612 (99%)] Loss: 0.341072\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1268 [0/1612 (0%)] Loss: 0.203115\n",
      "Train Epoch: 1268 [160/1612 (10%)] Loss: 0.293840\n",
      "Train Epoch: 1268 [320/1612 (20%)] Loss: 0.318504\n",
      "Train Epoch: 1268 [480/1612 (30%)] Loss: 0.615471\n",
      "Train Epoch: 1268 [640/1612 (40%)] Loss: 0.272637\n",
      "Train Epoch: 1268 [800/1612 (50%)] Loss: 0.209294\n",
      "Train Epoch: 1268 [960/1612 (59%)] Loss: 0.267118\n",
      "Train Epoch: 1268 [1120/1612 (69%)] Loss: 0.609765\n",
      "Train Epoch: 1268 [1280/1612 (79%)] Loss: 0.189240\n",
      "Train Epoch: 1268 [1440/1612 (89%)] Loss: 0.267033\n",
      "Train Epoch: 1268 [1200/1612 (99%)] Loss: 0.322319\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1269 [0/1612 (0%)] Loss: 0.335294\n",
      "Train Epoch: 1269 [160/1612 (10%)] Loss: 0.482328\n",
      "Train Epoch: 1269 [320/1612 (20%)] Loss: 0.108945\n",
      "Train Epoch: 1269 [480/1612 (30%)] Loss: 0.363866\n",
      "Train Epoch: 1269 [640/1612 (40%)] Loss: 0.307362\n",
      "Train Epoch: 1269 [800/1612 (50%)] Loss: 0.271389\n",
      "Train Epoch: 1269 [960/1612 (59%)] Loss: 0.285574\n",
      "Train Epoch: 1269 [1120/1612 (69%)] Loss: 0.256200\n",
      "Train Epoch: 1269 [1280/1612 (79%)] Loss: 0.223122\n",
      "Train Epoch: 1269 [1440/1612 (89%)] Loss: 0.212271\n",
      "Train Epoch: 1269 [1200/1612 (99%)] Loss: 0.378689\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1270 [0/1612 (0%)] Loss: 0.485266\n",
      "Train Epoch: 1270 [160/1612 (10%)] Loss: 0.266766\n",
      "Train Epoch: 1270 [320/1612 (20%)] Loss: 0.231414\n",
      "Train Epoch: 1270 [480/1612 (30%)] Loss: 0.304128\n",
      "Train Epoch: 1270 [640/1612 (40%)] Loss: 0.206986\n",
      "Train Epoch: 1270 [800/1612 (50%)] Loss: 0.212772\n",
      "Train Epoch: 1270 [960/1612 (59%)] Loss: 0.204506\n",
      "Train Epoch: 1270 [1120/1612 (69%)] Loss: 0.315470\n",
      "Train Epoch: 1270 [1280/1612 (79%)] Loss: 0.203193\n",
      "Train Epoch: 1270 [1440/1612 (89%)] Loss: 0.155641\n",
      "Train Epoch: 1270 [1200/1612 (99%)] Loss: 0.238288\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1271 [0/1612 (0%)] Loss: 0.293714\n",
      "Train Epoch: 1271 [160/1612 (10%)] Loss: 0.278734\n",
      "Train Epoch: 1271 [320/1612 (20%)] Loss: 0.201145\n",
      "Train Epoch: 1271 [480/1612 (30%)] Loss: 0.334995\n",
      "Train Epoch: 1271 [640/1612 (40%)] Loss: 0.207539\n",
      "Train Epoch: 1271 [800/1612 (50%)] Loss: 0.524338\n",
      "Train Epoch: 1271 [960/1612 (59%)] Loss: 0.214007\n",
      "Train Epoch: 1271 [1120/1612 (69%)] Loss: 0.303771\n",
      "Train Epoch: 1271 [1280/1612 (79%)] Loss: 0.288870\n",
      "Train Epoch: 1271 [1440/1612 (89%)] Loss: 0.449831\n",
      "Train Epoch: 1271 [1200/1612 (99%)] Loss: 0.186778\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1272 [0/1612 (0%)] Loss: 0.311914\n",
      "Train Epoch: 1272 [160/1612 (10%)] Loss: 0.350535\n",
      "Train Epoch: 1272 [320/1612 (20%)] Loss: 0.214444\n",
      "Train Epoch: 1272 [480/1612 (30%)] Loss: 0.338319\n",
      "Train Epoch: 1272 [640/1612 (40%)] Loss: 0.220278\n",
      "Train Epoch: 1272 [800/1612 (50%)] Loss: 0.345306\n",
      "Train Epoch: 1272 [960/1612 (59%)] Loss: 0.284175\n",
      "Train Epoch: 1272 [1120/1612 (69%)] Loss: 0.311384\n",
      "Train Epoch: 1272 [1280/1612 (79%)] Loss: 0.312322\n",
      "Train Epoch: 1272 [1440/1612 (89%)] Loss: 0.117334\n",
      "Train Epoch: 1272 [1200/1612 (99%)] Loss: 0.316797\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1273 [0/1612 (0%)] Loss: 0.206286\n",
      "Train Epoch: 1273 [160/1612 (10%)] Loss: 0.404020\n",
      "Train Epoch: 1273 [320/1612 (20%)] Loss: 0.194449\n",
      "Train Epoch: 1273 [480/1612 (30%)] Loss: 0.129886\n",
      "Train Epoch: 1273 [640/1612 (40%)] Loss: 0.312289\n",
      "Train Epoch: 1273 [800/1612 (50%)] Loss: 0.105509\n",
      "Train Epoch: 1273 [960/1612 (59%)] Loss: 0.271030\n",
      "Train Epoch: 1273 [1120/1612 (69%)] Loss: 0.346244\n",
      "Train Epoch: 1273 [1280/1612 (79%)] Loss: 0.390380\n",
      "Train Epoch: 1273 [1440/1612 (89%)] Loss: 0.120562\n",
      "Train Epoch: 1273 [1200/1612 (99%)] Loss: 0.338915\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1274 [0/1612 (0%)] Loss: 0.457223\n",
      "Train Epoch: 1274 [160/1612 (10%)] Loss: 0.127199\n",
      "Train Epoch: 1274 [320/1612 (20%)] Loss: 0.234465\n",
      "Train Epoch: 1274 [480/1612 (30%)] Loss: 0.211946\n",
      "Train Epoch: 1274 [640/1612 (40%)] Loss: 0.294675\n",
      "Train Epoch: 1274 [800/1612 (50%)] Loss: 0.414304\n",
      "Train Epoch: 1274 [960/1612 (59%)] Loss: 0.348355\n",
      "Train Epoch: 1274 [1120/1612 (69%)] Loss: 0.259728\n",
      "Train Epoch: 1274 [1280/1612 (79%)] Loss: 0.110750\n",
      "Train Epoch: 1274 [1440/1612 (89%)] Loss: 0.233078\n",
      "Train Epoch: 1274 [1200/1612 (99%)] Loss: 0.301496\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1275 [0/1612 (0%)] Loss: 0.229846\n",
      "Train Epoch: 1275 [160/1612 (10%)] Loss: 0.279341\n",
      "Train Epoch: 1275 [320/1612 (20%)] Loss: 0.199046\n",
      "Train Epoch: 1275 [480/1612 (30%)] Loss: 0.226630\n",
      "Train Epoch: 1275 [640/1612 (40%)] Loss: 0.249188\n",
      "Train Epoch: 1275 [800/1612 (50%)] Loss: 0.407063\n",
      "Train Epoch: 1275 [960/1612 (59%)] Loss: 0.178832\n",
      "Train Epoch: 1275 [1120/1612 (69%)] Loss: 0.232356\n",
      "Train Epoch: 1275 [1280/1612 (79%)] Loss: 0.286375\n",
      "Train Epoch: 1275 [1440/1612 (89%)] Loss: 0.328048\n",
      "Train Epoch: 1275 [1200/1612 (99%)] Loss: 0.278768\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1276 [0/1612 (0%)] Loss: 0.232256\n",
      "Train Epoch: 1276 [160/1612 (10%)] Loss: 0.239724\n",
      "Train Epoch: 1276 [320/1612 (20%)] Loss: 0.445600\n",
      "Train Epoch: 1276 [480/1612 (30%)] Loss: 0.201659\n",
      "Train Epoch: 1276 [640/1612 (40%)] Loss: 0.213137\n",
      "Train Epoch: 1276 [800/1612 (50%)] Loss: 0.293996\n",
      "Train Epoch: 1276 [960/1612 (59%)] Loss: 0.432959\n",
      "Train Epoch: 1276 [1120/1612 (69%)] Loss: 0.371419\n",
      "Train Epoch: 1276 [1280/1612 (79%)] Loss: 0.269934\n",
      "Train Epoch: 1276 [1440/1612 (89%)] Loss: 0.299534\n",
      "Train Epoch: 1276 [1200/1612 (99%)] Loss: 0.493856\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1277 [0/1612 (0%)] Loss: 0.447738\n",
      "Train Epoch: 1277 [160/1612 (10%)] Loss: 0.209702\n",
      "Train Epoch: 1277 [320/1612 (20%)] Loss: 0.579698\n",
      "Train Epoch: 1277 [480/1612 (30%)] Loss: 0.349681\n",
      "Train Epoch: 1277 [640/1612 (40%)] Loss: 0.438420\n",
      "Train Epoch: 1277 [800/1612 (50%)] Loss: 0.120217\n",
      "Train Epoch: 1277 [960/1612 (59%)] Loss: 0.207325\n",
      "Train Epoch: 1277 [1120/1612 (69%)] Loss: 0.357670\n",
      "Train Epoch: 1277 [1280/1612 (79%)] Loss: 0.476168\n",
      "Train Epoch: 1277 [1440/1612 (89%)] Loss: 0.368861\n",
      "Train Epoch: 1277 [1200/1612 (99%)] Loss: 0.212004\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1278 [0/1612 (0%)] Loss: 0.170791\n",
      "Train Epoch: 1278 [160/1612 (10%)] Loss: 0.401719\n",
      "Train Epoch: 1278 [320/1612 (20%)] Loss: 0.239283\n",
      "Train Epoch: 1278 [480/1612 (30%)] Loss: 0.515133\n",
      "Train Epoch: 1278 [640/1612 (40%)] Loss: 0.249015\n",
      "Train Epoch: 1278 [800/1612 (50%)] Loss: 0.211646\n",
      "Train Epoch: 1278 [960/1612 (59%)] Loss: 0.305383\n",
      "Train Epoch: 1278 [1120/1612 (69%)] Loss: 0.370418\n",
      "Train Epoch: 1278 [1280/1612 (79%)] Loss: 0.378924\n",
      "Train Epoch: 1278 [1440/1612 (89%)] Loss: 0.281589\n",
      "Train Epoch: 1278 [1200/1612 (99%)] Loss: 0.229135\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1279 [0/1612 (0%)] Loss: 0.410723\n",
      "Train Epoch: 1279 [160/1612 (10%)] Loss: 0.143919\n",
      "Train Epoch: 1279 [320/1612 (20%)] Loss: 0.256611\n",
      "Train Epoch: 1279 [480/1612 (30%)] Loss: 0.129749\n",
      "Train Epoch: 1279 [640/1612 (40%)] Loss: 0.320315\n",
      "Train Epoch: 1279 [800/1612 (50%)] Loss: 0.261729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1279 [960/1612 (59%)] Loss: 0.220785\n",
      "Train Epoch: 1279 [1120/1612 (69%)] Loss: 0.062454\n",
      "Train Epoch: 1279 [1280/1612 (79%)] Loss: 0.206560\n",
      "Train Epoch: 1279 [1440/1612 (89%)] Loss: 0.221763\n",
      "Train Epoch: 1279 [1200/1612 (99%)] Loss: 0.561416\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1280 [0/1612 (0%)] Loss: 0.312374\n",
      "Train Epoch: 1280 [160/1612 (10%)] Loss: 0.133462\n",
      "Train Epoch: 1280 [320/1612 (20%)] Loss: 0.237395\n",
      "Train Epoch: 1280 [480/1612 (30%)] Loss: 0.281219\n",
      "Train Epoch: 1280 [640/1612 (40%)] Loss: 0.127268\n",
      "Train Epoch: 1280 [800/1612 (50%)] Loss: 0.249576\n",
      "Train Epoch: 1280 [960/1612 (59%)] Loss: 0.238933\n",
      "Train Epoch: 1280 [1120/1612 (69%)] Loss: 0.201009\n",
      "Train Epoch: 1280 [1280/1612 (79%)] Loss: 0.251045\n",
      "Train Epoch: 1280 [1440/1612 (89%)] Loss: 0.482911\n",
      "Train Epoch: 1280 [1200/1612 (99%)] Loss: 0.221005\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1281 [0/1612 (0%)] Loss: 0.399859\n",
      "Train Epoch: 1281 [160/1612 (10%)] Loss: 0.325629\n",
      "Train Epoch: 1281 [320/1612 (20%)] Loss: 0.267818\n",
      "Train Epoch: 1281 [480/1612 (30%)] Loss: 0.236051\n",
      "Train Epoch: 1281 [640/1612 (40%)] Loss: 0.126834\n",
      "Train Epoch: 1281 [800/1612 (50%)] Loss: 0.433394\n",
      "Train Epoch: 1281 [960/1612 (59%)] Loss: 0.447252\n",
      "Train Epoch: 1281 [1120/1612 (69%)] Loss: 0.253097\n",
      "Train Epoch: 1281 [1280/1612 (79%)] Loss: 0.355143\n",
      "Train Epoch: 1281 [1440/1612 (89%)] Loss: 0.395068\n",
      "Train Epoch: 1281 [1200/1612 (99%)] Loss: 0.202632\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1282 [0/1612 (0%)] Loss: 0.222357\n",
      "Train Epoch: 1282 [160/1612 (10%)] Loss: 0.270612\n",
      "Train Epoch: 1282 [320/1612 (20%)] Loss: 0.150608\n",
      "Train Epoch: 1282 [480/1612 (30%)] Loss: 0.371812\n",
      "Train Epoch: 1282 [640/1612 (40%)] Loss: 0.252367\n",
      "Train Epoch: 1282 [800/1612 (50%)] Loss: 0.263453\n",
      "Train Epoch: 1282 [960/1612 (59%)] Loss: 0.350407\n",
      "Train Epoch: 1282 [1120/1612 (69%)] Loss: 0.565521\n",
      "Train Epoch: 1282 [1280/1612 (79%)] Loss: 0.312745\n",
      "Train Epoch: 1282 [1440/1612 (89%)] Loss: 0.424814\n",
      "Train Epoch: 1282 [1200/1612 (99%)] Loss: 0.171754\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1283 [0/1612 (0%)] Loss: 0.325574\n",
      "Train Epoch: 1283 [160/1612 (10%)] Loss: 0.217164\n",
      "Train Epoch: 1283 [320/1612 (20%)] Loss: 0.208079\n",
      "Train Epoch: 1283 [480/1612 (30%)] Loss: 0.235387\n",
      "Train Epoch: 1283 [640/1612 (40%)] Loss: 0.155670\n",
      "Train Epoch: 1283 [800/1612 (50%)] Loss: 0.282491\n",
      "Train Epoch: 1283 [960/1612 (59%)] Loss: 0.203157\n",
      "Train Epoch: 1283 [1120/1612 (69%)] Loss: 0.217597\n",
      "Train Epoch: 1283 [1280/1612 (79%)] Loss: 0.574555\n",
      "Train Epoch: 1283 [1440/1612 (89%)] Loss: 0.400447\n",
      "Train Epoch: 1283 [1200/1612 (99%)] Loss: 0.362539\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1284 [0/1612 (0%)] Loss: 0.103068\n",
      "Train Epoch: 1284 [160/1612 (10%)] Loss: 0.153362\n",
      "Train Epoch: 1284 [320/1612 (20%)] Loss: 0.239541\n",
      "Train Epoch: 1284 [480/1612 (30%)] Loss: 0.375960\n",
      "Train Epoch: 1284 [640/1612 (40%)] Loss: 0.477111\n",
      "Train Epoch: 1284 [800/1612 (50%)] Loss: 0.625567\n",
      "Train Epoch: 1284 [960/1612 (59%)] Loss: 0.293307\n",
      "Train Epoch: 1284 [1120/1612 (69%)] Loss: 0.380346\n",
      "Train Epoch: 1284 [1280/1612 (79%)] Loss: 0.290131\n",
      "Train Epoch: 1284 [1440/1612 (89%)] Loss: 0.470392\n",
      "Train Epoch: 1284 [1200/1612 (99%)] Loss: 0.263356\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1285 [0/1612 (0%)] Loss: 0.308003\n",
      "Train Epoch: 1285 [160/1612 (10%)] Loss: 0.489244\n",
      "Train Epoch: 1285 [320/1612 (20%)] Loss: 0.364473\n",
      "Train Epoch: 1285 [480/1612 (30%)] Loss: 0.325737\n",
      "Train Epoch: 1285 [640/1612 (40%)] Loss: 0.531195\n",
      "Train Epoch: 1285 [800/1612 (50%)] Loss: 0.409184\n",
      "Train Epoch: 1285 [960/1612 (59%)] Loss: 0.297059\n",
      "Train Epoch: 1285 [1120/1612 (69%)] Loss: 0.535291\n",
      "Train Epoch: 1285 [1280/1612 (79%)] Loss: 0.274833\n",
      "Train Epoch: 1285 [1440/1612 (89%)] Loss: 0.176280\n",
      "Train Epoch: 1285 [1200/1612 (99%)] Loss: 0.328457\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1286 [0/1612 (0%)] Loss: 0.282019\n",
      "Train Epoch: 1286 [160/1612 (10%)] Loss: 0.273455\n",
      "Train Epoch: 1286 [320/1612 (20%)] Loss: 0.565208\n",
      "Train Epoch: 1286 [480/1612 (30%)] Loss: 0.298844\n",
      "Train Epoch: 1286 [640/1612 (40%)] Loss: 0.340855\n",
      "Train Epoch: 1286 [800/1612 (50%)] Loss: 0.315507\n",
      "Train Epoch: 1286 [960/1612 (59%)] Loss: 0.227268\n",
      "Train Epoch: 1286 [1120/1612 (69%)] Loss: 0.576192\n",
      "Train Epoch: 1286 [1280/1612 (79%)] Loss: 0.425286\n",
      "Train Epoch: 1286 [1440/1612 (89%)] Loss: 0.409559\n",
      "Train Epoch: 1286 [1200/1612 (99%)] Loss: 0.671851\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1287 [0/1612 (0%)] Loss: 0.356773\n",
      "Train Epoch: 1287 [160/1612 (10%)] Loss: 0.415026\n",
      "Train Epoch: 1287 [320/1612 (20%)] Loss: 0.304444\n",
      "Train Epoch: 1287 [480/1612 (30%)] Loss: 0.245601\n",
      "Train Epoch: 1287 [640/1612 (40%)] Loss: 0.315287\n",
      "Train Epoch: 1287 [800/1612 (50%)] Loss: 0.106876\n",
      "Train Epoch: 1287 [960/1612 (59%)] Loss: 0.315582\n",
      "Train Epoch: 1287 [1120/1612 (69%)] Loss: 0.420278\n",
      "Train Epoch: 1287 [1280/1612 (79%)] Loss: 0.292475\n",
      "Train Epoch: 1287 [1440/1612 (89%)] Loss: 0.138594\n",
      "Train Epoch: 1287 [1200/1612 (99%)] Loss: 0.296788\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1288 [0/1612 (0%)] Loss: 0.528485\n",
      "Train Epoch: 1288 [160/1612 (10%)] Loss: 0.283081\n",
      "Train Epoch: 1288 [320/1612 (20%)] Loss: 0.343539\n",
      "Train Epoch: 1288 [480/1612 (30%)] Loss: 0.273150\n",
      "Train Epoch: 1288 [640/1612 (40%)] Loss: 0.283113\n",
      "Train Epoch: 1288 [800/1612 (50%)] Loss: 0.433591\n",
      "Train Epoch: 1288 [960/1612 (59%)] Loss: 0.398590\n",
      "Train Epoch: 1288 [1120/1612 (69%)] Loss: 0.200562\n",
      "Train Epoch: 1288 [1280/1612 (79%)] Loss: 0.452686\n",
      "Train Epoch: 1288 [1440/1612 (89%)] Loss: 0.167180\n",
      "Train Epoch: 1288 [1200/1612 (99%)] Loss: 0.247128\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1289 [0/1612 (0%)] Loss: 0.216714\n",
      "Train Epoch: 1289 [160/1612 (10%)] Loss: 0.462466\n",
      "Train Epoch: 1289 [320/1612 (20%)] Loss: 0.360869\n",
      "Train Epoch: 1289 [480/1612 (30%)] Loss: 0.218702\n",
      "Train Epoch: 1289 [640/1612 (40%)] Loss: 0.430955\n",
      "Train Epoch: 1289 [800/1612 (50%)] Loss: 0.446492\n",
      "Train Epoch: 1289 [960/1612 (59%)] Loss: 0.272281\n",
      "Train Epoch: 1289 [1120/1612 (69%)] Loss: 0.398868\n",
      "Train Epoch: 1289 [1280/1612 (79%)] Loss: 0.207208\n",
      "Train Epoch: 1289 [1440/1612 (89%)] Loss: 0.294312\n",
      "Train Epoch: 1289 [1200/1612 (99%)] Loss: 0.456772\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1290 [0/1612 (0%)] Loss: 0.267849\n",
      "Train Epoch: 1290 [160/1612 (10%)] Loss: 0.221938\n",
      "Train Epoch: 1290 [320/1612 (20%)] Loss: 0.313250\n",
      "Train Epoch: 1290 [480/1612 (30%)] Loss: 0.151627\n",
      "Train Epoch: 1290 [640/1612 (40%)] Loss: 0.316626\n",
      "Train Epoch: 1290 [800/1612 (50%)] Loss: 0.207642\n",
      "Train Epoch: 1290 [960/1612 (59%)] Loss: 0.564908\n",
      "Train Epoch: 1290 [1120/1612 (69%)] Loss: 0.479380\n",
      "Train Epoch: 1290 [1280/1612 (79%)] Loss: 0.633714\n",
      "Train Epoch: 1290 [1440/1612 (89%)] Loss: 0.328680\n",
      "Train Epoch: 1290 [1200/1612 (99%)] Loss: 0.360190\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1291 [0/1612 (0%)] Loss: 0.291721\n",
      "Train Epoch: 1291 [160/1612 (10%)] Loss: 0.060097\n",
      "Train Epoch: 1291 [320/1612 (20%)] Loss: 0.290253\n",
      "Train Epoch: 1291 [480/1612 (30%)] Loss: 0.445554\n",
      "Train Epoch: 1291 [640/1612 (40%)] Loss: 0.201545\n",
      "Train Epoch: 1291 [800/1612 (50%)] Loss: 0.345038\n",
      "Train Epoch: 1291 [960/1612 (59%)] Loss: 0.504132\n",
      "Train Epoch: 1291 [1120/1612 (69%)] Loss: 0.259723\n",
      "Train Epoch: 1291 [1280/1612 (79%)] Loss: 0.182806\n",
      "Train Epoch: 1291 [1440/1612 (89%)] Loss: 0.412085\n",
      "Train Epoch: 1291 [1200/1612 (99%)] Loss: 0.227250\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1292 [0/1612 (0%)] Loss: 0.170914\n",
      "Train Epoch: 1292 [160/1612 (10%)] Loss: 0.139109\n",
      "Train Epoch: 1292 [320/1612 (20%)] Loss: 0.206422\n",
      "Train Epoch: 1292 [480/1612 (30%)] Loss: 0.356905\n",
      "Train Epoch: 1292 [640/1612 (40%)] Loss: 0.323808\n",
      "Train Epoch: 1292 [800/1612 (50%)] Loss: 0.365240\n",
      "Train Epoch: 1292 [960/1612 (59%)] Loss: 0.306282\n",
      "Train Epoch: 1292 [1120/1612 (69%)] Loss: 0.411818\n",
      "Train Epoch: 1292 [1280/1612 (79%)] Loss: 0.361624\n",
      "Train Epoch: 1292 [1440/1612 (89%)] Loss: 0.311123\n",
      "Train Epoch: 1292 [1200/1612 (99%)] Loss: 0.138714\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1293 [0/1612 (0%)] Loss: 0.150021\n",
      "Train Epoch: 1293 [160/1612 (10%)] Loss: 0.162838\n",
      "Train Epoch: 1293 [320/1612 (20%)] Loss: 0.270536\n",
      "Train Epoch: 1293 [480/1612 (30%)] Loss: 0.298402\n",
      "Train Epoch: 1293 [640/1612 (40%)] Loss: 0.113830\n",
      "Train Epoch: 1293 [800/1612 (50%)] Loss: 0.207737\n",
      "Train Epoch: 1293 [960/1612 (59%)] Loss: 0.344275\n",
      "Train Epoch: 1293 [1120/1612 (69%)] Loss: 0.285659\n",
      "Train Epoch: 1293 [1280/1612 (79%)] Loss: 0.301408\n",
      "Train Epoch: 1293 [1440/1612 (89%)] Loss: 0.521229\n",
      "Train Epoch: 1293 [1200/1612 (99%)] Loss: 0.546884\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1294 [0/1612 (0%)] Loss: 0.168082\n",
      "Train Epoch: 1294 [160/1612 (10%)] Loss: 0.376712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1294 [320/1612 (20%)] Loss: 0.237036\n",
      "Train Epoch: 1294 [480/1612 (30%)] Loss: 0.246588\n",
      "Train Epoch: 1294 [640/1612 (40%)] Loss: 0.215385\n",
      "Train Epoch: 1294 [800/1612 (50%)] Loss: 0.529347\n",
      "Train Epoch: 1294 [960/1612 (59%)] Loss: 0.242109\n",
      "Train Epoch: 1294 [1120/1612 (69%)] Loss: 0.361276\n",
      "Train Epoch: 1294 [1280/1612 (79%)] Loss: 0.431572\n",
      "Train Epoch: 1294 [1440/1612 (89%)] Loss: 0.296035\n",
      "Train Epoch: 1294 [1200/1612 (99%)] Loss: 0.610077\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1295 [0/1612 (0%)] Loss: 0.178275\n",
      "Train Epoch: 1295 [160/1612 (10%)] Loss: 0.258346\n",
      "Train Epoch: 1295 [320/1612 (20%)] Loss: 0.482975\n",
      "Train Epoch: 1295 [480/1612 (30%)] Loss: 0.396540\n",
      "Train Epoch: 1295 [640/1612 (40%)] Loss: 0.443896\n",
      "Train Epoch: 1295 [800/1612 (50%)] Loss: 0.284743\n",
      "Train Epoch: 1295 [960/1612 (59%)] Loss: 0.223240\n",
      "Train Epoch: 1295 [1120/1612 (69%)] Loss: 0.412622\n",
      "Train Epoch: 1295 [1280/1612 (79%)] Loss: 0.242080\n",
      "Train Epoch: 1295 [1440/1612 (89%)] Loss: 0.177402\n",
      "Train Epoch: 1295 [1200/1612 (99%)] Loss: 0.289167\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1296 [0/1612 (0%)] Loss: 0.280138\n",
      "Train Epoch: 1296 [160/1612 (10%)] Loss: 0.238442\n",
      "Train Epoch: 1296 [320/1612 (20%)] Loss: 0.294194\n",
      "Train Epoch: 1296 [480/1612 (30%)] Loss: 0.277778\n",
      "Train Epoch: 1296 [640/1612 (40%)] Loss: 0.337108\n",
      "Train Epoch: 1296 [800/1612 (50%)] Loss: 0.317962\n",
      "Train Epoch: 1296 [960/1612 (59%)] Loss: 0.089167\n",
      "Train Epoch: 1296 [1120/1612 (69%)] Loss: 0.195759\n",
      "Train Epoch: 1296 [1280/1612 (79%)] Loss: 0.258106\n",
      "Train Epoch: 1296 [1440/1612 (89%)] Loss: 0.382525\n",
      "Train Epoch: 1296 [1200/1612 (99%)] Loss: 0.316433\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1297 [0/1612 (0%)] Loss: 0.311907\n",
      "Train Epoch: 1297 [160/1612 (10%)] Loss: 0.186771\n",
      "Train Epoch: 1297 [320/1612 (20%)] Loss: 0.185089\n",
      "Train Epoch: 1297 [480/1612 (30%)] Loss: 0.242418\n",
      "Train Epoch: 1297 [640/1612 (40%)] Loss: 0.285859\n",
      "Train Epoch: 1297 [800/1612 (50%)] Loss: 0.281261\n",
      "Train Epoch: 1297 [960/1612 (59%)] Loss: 0.518061\n",
      "Train Epoch: 1297 [1120/1612 (69%)] Loss: 0.297091\n",
      "Train Epoch: 1297 [1280/1612 (79%)] Loss: 0.458051\n",
      "Train Epoch: 1297 [1440/1612 (89%)] Loss: 0.324808\n",
      "Train Epoch: 1297 [1200/1612 (99%)] Loss: 0.273875\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1298 [0/1612 (0%)] Loss: 0.411614\n",
      "Train Epoch: 1298 [160/1612 (10%)] Loss: 0.159771\n",
      "Train Epoch: 1298 [320/1612 (20%)] Loss: 0.451292\n",
      "Train Epoch: 1298 [480/1612 (30%)] Loss: 0.225786\n",
      "Train Epoch: 1298 [640/1612 (40%)] Loss: 0.464701\n",
      "Train Epoch: 1298 [800/1612 (50%)] Loss: 0.517685\n",
      "Train Epoch: 1298 [960/1612 (59%)] Loss: 0.371540\n",
      "Train Epoch: 1298 [1120/1612 (69%)] Loss: 0.197518\n",
      "Train Epoch: 1298 [1280/1612 (79%)] Loss: 0.295741\n",
      "Train Epoch: 1298 [1440/1612 (89%)] Loss: 0.351150\n",
      "Train Epoch: 1298 [1200/1612 (99%)] Loss: 0.368912\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1299 [0/1612 (0%)] Loss: 0.123986\n",
      "Train Epoch: 1299 [160/1612 (10%)] Loss: 0.363764\n",
      "Train Epoch: 1299 [320/1612 (20%)] Loss: 0.335450\n",
      "Train Epoch: 1299 [480/1612 (30%)] Loss: 0.468086\n",
      "Train Epoch: 1299 [640/1612 (40%)] Loss: 0.302561\n",
      "Train Epoch: 1299 [800/1612 (50%)] Loss: 0.221987\n",
      "Train Epoch: 1299 [960/1612 (59%)] Loss: 0.175175\n",
      "Train Epoch: 1299 [1120/1612 (69%)] Loss: 0.193779\n",
      "Train Epoch: 1299 [1280/1612 (79%)] Loss: 0.347661\n",
      "Train Epoch: 1299 [1440/1612 (89%)] Loss: 0.172240\n",
      "Train Epoch: 1299 [1200/1612 (99%)] Loss: 0.364943\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1300 [0/1612 (0%)] Loss: 0.208175\n",
      "Train Epoch: 1300 [160/1612 (10%)] Loss: 0.182782\n",
      "Train Epoch: 1300 [320/1612 (20%)] Loss: 0.174734\n",
      "Train Epoch: 1300 [480/1612 (30%)] Loss: 0.286340\n",
      "Train Epoch: 1300 [640/1612 (40%)] Loss: 0.200536\n",
      "Train Epoch: 1300 [800/1612 (50%)] Loss: 0.226969\n",
      "Train Epoch: 1300 [960/1612 (59%)] Loss: 0.248935\n",
      "Train Epoch: 1300 [1120/1612 (69%)] Loss: 0.527153\n",
      "Train Epoch: 1300 [1280/1612 (79%)] Loss: 0.250462\n",
      "Train Epoch: 1300 [1440/1612 (89%)] Loss: 0.440996\n",
      "Train Epoch: 1300 [1200/1612 (99%)] Loss: 0.217331\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1301 [0/1612 (0%)] Loss: 0.244344\n",
      "Train Epoch: 1301 [160/1612 (10%)] Loss: 0.329934\n",
      "Train Epoch: 1301 [320/1612 (20%)] Loss: 0.357173\n",
      "Train Epoch: 1301 [480/1612 (30%)] Loss: 0.520422\n",
      "Train Epoch: 1301 [640/1612 (40%)] Loss: 0.270440\n",
      "Train Epoch: 1301 [800/1612 (50%)] Loss: 0.445768\n",
      "Train Epoch: 1301 [960/1612 (59%)] Loss: 0.070323\n",
      "Train Epoch: 1301 [1120/1612 (69%)] Loss: 0.251988\n",
      "Train Epoch: 1301 [1280/1612 (79%)] Loss: 0.547915\n",
      "Train Epoch: 1301 [1440/1612 (89%)] Loss: 0.354680\n",
      "Train Epoch: 1301 [1200/1612 (99%)] Loss: 0.224874\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1302 [0/1612 (0%)] Loss: 0.286705\n",
      "Train Epoch: 1302 [160/1612 (10%)] Loss: 0.157613\n",
      "Train Epoch: 1302 [320/1612 (20%)] Loss: 0.306128\n",
      "Train Epoch: 1302 [480/1612 (30%)] Loss: 0.101074\n",
      "Train Epoch: 1302 [640/1612 (40%)] Loss: 0.092357\n",
      "Train Epoch: 1302 [800/1612 (50%)] Loss: 0.306794\n",
      "Train Epoch: 1302 [960/1612 (59%)] Loss: 0.215020\n",
      "Train Epoch: 1302 [1120/1612 (69%)] Loss: 0.549535\n",
      "Train Epoch: 1302 [1280/1612 (79%)] Loss: 0.316975\n",
      "Train Epoch: 1302 [1440/1612 (89%)] Loss: 0.283781\n",
      "Train Epoch: 1302 [1200/1612 (99%)] Loss: 0.080052\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1303 [0/1612 (0%)] Loss: 0.299515\n",
      "Train Epoch: 1303 [160/1612 (10%)] Loss: 0.241903\n",
      "Train Epoch: 1303 [320/1612 (20%)] Loss: 0.167333\n",
      "Train Epoch: 1303 [480/1612 (30%)] Loss: 0.280310\n",
      "Train Epoch: 1303 [640/1612 (40%)] Loss: 0.186599\n",
      "Train Epoch: 1303 [800/1612 (50%)] Loss: 0.277852\n",
      "Train Epoch: 1303 [960/1612 (59%)] Loss: 0.208794\n",
      "Train Epoch: 1303 [1120/1612 (69%)] Loss: 0.153401\n",
      "Train Epoch: 1303 [1280/1612 (79%)] Loss: 0.312153\n",
      "Train Epoch: 1303 [1440/1612 (89%)] Loss: 0.262291\n",
      "Train Epoch: 1303 [1200/1612 (99%)] Loss: 0.342321\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1304 [0/1612 (0%)] Loss: 0.125683\n",
      "Train Epoch: 1304 [160/1612 (10%)] Loss: 0.468011\n",
      "Train Epoch: 1304 [320/1612 (20%)] Loss: 0.236413\n",
      "Train Epoch: 1304 [480/1612 (30%)] Loss: 0.296790\n",
      "Train Epoch: 1304 [640/1612 (40%)] Loss: 0.247748\n",
      "Train Epoch: 1304 [800/1612 (50%)] Loss: 0.062196\n",
      "Train Epoch: 1304 [960/1612 (59%)] Loss: 0.257794\n",
      "Train Epoch: 1304 [1120/1612 (69%)] Loss: 0.352220\n",
      "Train Epoch: 1304 [1280/1612 (79%)] Loss: 0.241861\n",
      "Train Epoch: 1304 [1440/1612 (89%)] Loss: 0.258362\n",
      "Train Epoch: 1304 [1200/1612 (99%)] Loss: 0.399746\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1305 [0/1612 (0%)] Loss: 0.196308\n",
      "Train Epoch: 1305 [160/1612 (10%)] Loss: 0.121573\n",
      "Train Epoch: 1305 [320/1612 (20%)] Loss: 0.257269\n",
      "Train Epoch: 1305 [480/1612 (30%)] Loss: 0.665434\n",
      "Train Epoch: 1305 [640/1612 (40%)] Loss: 0.280583\n",
      "Train Epoch: 1305 [800/1612 (50%)] Loss: 0.338236\n",
      "Train Epoch: 1305 [960/1612 (59%)] Loss: 0.162710\n",
      "Train Epoch: 1305 [1120/1612 (69%)] Loss: 0.217281\n",
      "Train Epoch: 1305 [1280/1612 (79%)] Loss: 0.372434\n",
      "Train Epoch: 1305 [1440/1612 (89%)] Loss: 0.148430\n",
      "Train Epoch: 1305 [1200/1612 (99%)] Loss: 0.211020\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1306 [0/1612 (0%)] Loss: 0.313258\n",
      "Train Epoch: 1306 [160/1612 (10%)] Loss: 0.219229\n",
      "Train Epoch: 1306 [320/1612 (20%)] Loss: 0.372990\n",
      "Train Epoch: 1306 [480/1612 (30%)] Loss: 0.099138\n",
      "Train Epoch: 1306 [640/1612 (40%)] Loss: 0.572733\n",
      "Train Epoch: 1306 [800/1612 (50%)] Loss: 0.511413\n",
      "Train Epoch: 1306 [960/1612 (59%)] Loss: 0.165453\n",
      "Train Epoch: 1306 [1120/1612 (69%)] Loss: 0.268426\n",
      "Train Epoch: 1306 [1280/1612 (79%)] Loss: 0.417574\n",
      "Train Epoch: 1306 [1440/1612 (89%)] Loss: 0.190036\n",
      "Train Epoch: 1306 [1200/1612 (99%)] Loss: 0.196426\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1307 [0/1612 (0%)] Loss: 0.581639\n",
      "Train Epoch: 1307 [160/1612 (10%)] Loss: 0.271565\n",
      "Train Epoch: 1307 [320/1612 (20%)] Loss: 0.374987\n",
      "Train Epoch: 1307 [480/1612 (30%)] Loss: 0.242958\n",
      "Train Epoch: 1307 [640/1612 (40%)] Loss: 0.557516\n",
      "Train Epoch: 1307 [800/1612 (50%)] Loss: 0.339097\n",
      "Train Epoch: 1307 [960/1612 (59%)] Loss: 0.308840\n",
      "Train Epoch: 1307 [1120/1612 (69%)] Loss: 0.060457\n",
      "Train Epoch: 1307 [1280/1612 (79%)] Loss: 0.378126\n",
      "Train Epoch: 1307 [1440/1612 (89%)] Loss: 0.220764\n",
      "Train Epoch: 1307 [1200/1612 (99%)] Loss: 0.252638\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1308 [0/1612 (0%)] Loss: 0.114360\n",
      "Train Epoch: 1308 [160/1612 (10%)] Loss: 0.354034\n",
      "Train Epoch: 1308 [320/1612 (20%)] Loss: 0.289802\n",
      "Train Epoch: 1308 [480/1612 (30%)] Loss: 0.541897\n",
      "Train Epoch: 1308 [640/1612 (40%)] Loss: 0.313771\n",
      "Train Epoch: 1308 [800/1612 (50%)] Loss: 0.636010\n",
      "Train Epoch: 1308 [960/1612 (59%)] Loss: 0.364741\n",
      "Train Epoch: 1308 [1120/1612 (69%)] Loss: 0.318114\n",
      "Train Epoch: 1308 [1280/1612 (79%)] Loss: 0.319621\n",
      "Train Epoch: 1308 [1440/1612 (89%)] Loss: 0.266703\n",
      "Train Epoch: 1308 [1200/1612 (99%)] Loss: 0.200362\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1309 [0/1612 (0%)] Loss: 0.212632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1309 [160/1612 (10%)] Loss: 0.238954\n",
      "Train Epoch: 1309 [320/1612 (20%)] Loss: 0.426841\n",
      "Train Epoch: 1309 [480/1612 (30%)] Loss: 0.597756\n",
      "Train Epoch: 1309 [640/1612 (40%)] Loss: 0.332501\n",
      "Train Epoch: 1309 [800/1612 (50%)] Loss: 0.190631\n",
      "Train Epoch: 1309 [960/1612 (59%)] Loss: 0.253112\n",
      "Train Epoch: 1309 [1120/1612 (69%)] Loss: 0.150874\n",
      "Train Epoch: 1309 [1280/1612 (79%)] Loss: 0.172683\n",
      "Train Epoch: 1309 [1440/1612 (89%)] Loss: 0.212410\n",
      "Train Epoch: 1309 [1200/1612 (99%)] Loss: 0.631198\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1310 [0/1612 (0%)] Loss: 0.485929\n",
      "Train Epoch: 1310 [160/1612 (10%)] Loss: 0.241337\n",
      "Train Epoch: 1310 [320/1612 (20%)] Loss: 0.249450\n",
      "Train Epoch: 1310 [480/1612 (30%)] Loss: 0.341769\n",
      "Train Epoch: 1310 [640/1612 (40%)] Loss: 0.255879\n",
      "Train Epoch: 1310 [800/1612 (50%)] Loss: 0.273755\n",
      "Train Epoch: 1310 [960/1612 (59%)] Loss: 0.176052\n",
      "Train Epoch: 1310 [1120/1612 (69%)] Loss: 0.121029\n",
      "Train Epoch: 1310 [1280/1612 (79%)] Loss: 0.198904\n",
      "Train Epoch: 1310 [1440/1612 (89%)] Loss: 0.543662\n",
      "Train Epoch: 1310 [1200/1612 (99%)] Loss: 0.220504\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1311 [0/1612 (0%)] Loss: 0.280923\n",
      "Train Epoch: 1311 [160/1612 (10%)] Loss: 0.492842\n",
      "Train Epoch: 1311 [320/1612 (20%)] Loss: 0.253085\n",
      "Train Epoch: 1311 [480/1612 (30%)] Loss: 0.427123\n",
      "Train Epoch: 1311 [640/1612 (40%)] Loss: 0.295372\n",
      "Train Epoch: 1311 [800/1612 (50%)] Loss: 0.424635\n",
      "Train Epoch: 1311 [960/1612 (59%)] Loss: 0.479716\n",
      "Train Epoch: 1311 [1120/1612 (69%)] Loss: 0.402763\n",
      "Train Epoch: 1311 [1280/1612 (79%)] Loss: 0.364132\n",
      "Train Epoch: 1311 [1440/1612 (89%)] Loss: 0.274111\n",
      "Train Epoch: 1311 [1200/1612 (99%)] Loss: 0.359646\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1312 [0/1612 (0%)] Loss: 0.167002\n",
      "Train Epoch: 1312 [160/1612 (10%)] Loss: 0.590741\n",
      "Train Epoch: 1312 [320/1612 (20%)] Loss: 0.193913\n",
      "Train Epoch: 1312 [480/1612 (30%)] Loss: 0.323445\n",
      "Train Epoch: 1312 [640/1612 (40%)] Loss: 0.287874\n",
      "Train Epoch: 1312 [800/1612 (50%)] Loss: 0.268313\n",
      "Train Epoch: 1312 [960/1612 (59%)] Loss: 0.275906\n",
      "Train Epoch: 1312 [1120/1612 (69%)] Loss: 0.609632\n",
      "Train Epoch: 1312 [1280/1612 (79%)] Loss: 0.176034\n",
      "Train Epoch: 1312 [1440/1612 (89%)] Loss: 0.232432\n",
      "Train Epoch: 1312 [1200/1612 (99%)] Loss: 0.257339\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1313 [0/1612 (0%)] Loss: 0.199447\n",
      "Train Epoch: 1313 [160/1612 (10%)] Loss: 0.388905\n",
      "Train Epoch: 1313 [320/1612 (20%)] Loss: 0.122379\n",
      "Train Epoch: 1313 [480/1612 (30%)] Loss: 0.193122\n",
      "Train Epoch: 1313 [640/1612 (40%)] Loss: 0.229799\n",
      "Train Epoch: 1313 [800/1612 (50%)] Loss: 0.181233\n",
      "Train Epoch: 1313 [960/1612 (59%)] Loss: 0.342934\n",
      "Train Epoch: 1313 [1120/1612 (69%)] Loss: 0.282292\n",
      "Train Epoch: 1313 [1280/1612 (79%)] Loss: 0.338678\n",
      "Train Epoch: 1313 [1440/1612 (89%)] Loss: 0.359252\n",
      "Train Epoch: 1313 [1200/1612 (99%)] Loss: 0.515172\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1314 [0/1612 (0%)] Loss: 0.443259\n",
      "Train Epoch: 1314 [160/1612 (10%)] Loss: 0.295299\n",
      "Train Epoch: 1314 [320/1612 (20%)] Loss: 0.463118\n",
      "Train Epoch: 1314 [480/1612 (30%)] Loss: 0.207260\n",
      "Train Epoch: 1314 [640/1612 (40%)] Loss: 0.242155\n",
      "Train Epoch: 1314 [800/1612 (50%)] Loss: 0.152065\n",
      "Train Epoch: 1314 [960/1612 (59%)] Loss: 0.424897\n",
      "Train Epoch: 1314 [1120/1612 (69%)] Loss: 0.232005\n",
      "Train Epoch: 1314 [1280/1612 (79%)] Loss: 0.253250\n",
      "Train Epoch: 1314 [1440/1612 (89%)] Loss: 0.346318\n",
      "Train Epoch: 1314 [1200/1612 (99%)] Loss: 0.217731\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1315 [0/1612 (0%)] Loss: 0.180956\n",
      "Train Epoch: 1315 [160/1612 (10%)] Loss: 0.223488\n",
      "Train Epoch: 1315 [320/1612 (20%)] Loss: 0.270449\n",
      "Train Epoch: 1315 [480/1612 (30%)] Loss: 0.573146\n",
      "Train Epoch: 1315 [640/1612 (40%)] Loss: 0.587055\n",
      "Train Epoch: 1315 [800/1612 (50%)] Loss: 0.392572\n",
      "Train Epoch: 1315 [960/1612 (59%)] Loss: 0.221311\n",
      "Train Epoch: 1315 [1120/1612 (69%)] Loss: 0.181190\n",
      "Train Epoch: 1315 [1280/1612 (79%)] Loss: 0.565587\n",
      "Train Epoch: 1315 [1440/1612 (89%)] Loss: 0.333227\n",
      "Train Epoch: 1315 [1200/1612 (99%)] Loss: 0.353725\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1316 [0/1612 (0%)] Loss: 0.196542\n",
      "Train Epoch: 1316 [160/1612 (10%)] Loss: 0.099995\n",
      "Train Epoch: 1316 [320/1612 (20%)] Loss: 0.100750\n",
      "Train Epoch: 1316 [480/1612 (30%)] Loss: 0.263490\n",
      "Train Epoch: 1316 [640/1612 (40%)] Loss: 0.153509\n",
      "Train Epoch: 1316 [800/1612 (50%)] Loss: 0.637843\n",
      "Train Epoch: 1316 [960/1612 (59%)] Loss: 0.459938\n",
      "Train Epoch: 1316 [1120/1612 (69%)] Loss: 0.388587\n",
      "Train Epoch: 1316 [1280/1612 (79%)] Loss: 0.237202\n",
      "Train Epoch: 1316 [1440/1612 (89%)] Loss: 0.164208\n",
      "Train Epoch: 1316 [1200/1612 (99%)] Loss: 0.345484\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1317 [0/1612 (0%)] Loss: 0.287825\n",
      "Train Epoch: 1317 [160/1612 (10%)] Loss: 0.602389\n",
      "Train Epoch: 1317 [320/1612 (20%)] Loss: 0.207874\n",
      "Train Epoch: 1317 [480/1612 (30%)] Loss: 0.478641\n",
      "Train Epoch: 1317 [640/1612 (40%)] Loss: 0.541180\n",
      "Train Epoch: 1317 [800/1612 (50%)] Loss: 0.510109\n",
      "Train Epoch: 1317 [960/1612 (59%)] Loss: 0.257434\n",
      "Train Epoch: 1317 [1120/1612 (69%)] Loss: 0.304611\n",
      "Train Epoch: 1317 [1280/1612 (79%)] Loss: 0.208595\n",
      "Train Epoch: 1317 [1440/1612 (89%)] Loss: 0.222388\n",
      "Train Epoch: 1317 [1200/1612 (99%)] Loss: 0.066813\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1318 [0/1612 (0%)] Loss: 0.107573\n",
      "Train Epoch: 1318 [160/1612 (10%)] Loss: 0.325195\n",
      "Train Epoch: 1318 [320/1612 (20%)] Loss: 0.255520\n",
      "Train Epoch: 1318 [480/1612 (30%)] Loss: 0.376266\n",
      "Train Epoch: 1318 [640/1612 (40%)] Loss: 0.600909\n",
      "Train Epoch: 1318 [800/1612 (50%)] Loss: 0.227523\n",
      "Train Epoch: 1318 [960/1612 (59%)] Loss: 0.388091\n",
      "Train Epoch: 1318 [1120/1612 (69%)] Loss: 0.326401\n",
      "Train Epoch: 1318 [1280/1612 (79%)] Loss: 0.208892\n",
      "Train Epoch: 1318 [1440/1612 (89%)] Loss: 0.273321\n",
      "Train Epoch: 1318 [1200/1612 (99%)] Loss: 0.216840\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1319 [0/1612 (0%)] Loss: 0.170769\n",
      "Train Epoch: 1319 [160/1612 (10%)] Loss: 0.211439\n",
      "Train Epoch: 1319 [320/1612 (20%)] Loss: 0.167822\n",
      "Train Epoch: 1319 [480/1612 (30%)] Loss: 0.272216\n",
      "Train Epoch: 1319 [640/1612 (40%)] Loss: 0.129274\n",
      "Train Epoch: 1319 [800/1612 (50%)] Loss: 0.307681\n",
      "Train Epoch: 1319 [960/1612 (59%)] Loss: 0.459105\n",
      "Train Epoch: 1319 [1120/1612 (69%)] Loss: 0.401552\n",
      "Train Epoch: 1319 [1280/1612 (79%)] Loss: 0.221253\n",
      "Train Epoch: 1319 [1440/1612 (89%)] Loss: 0.188689\n",
      "Train Epoch: 1319 [1200/1612 (99%)] Loss: 0.410905\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1320 [0/1612 (0%)] Loss: 0.513935\n",
      "Train Epoch: 1320 [160/1612 (10%)] Loss: 0.446684\n",
      "Train Epoch: 1320 [320/1612 (20%)] Loss: 0.406202\n",
      "Train Epoch: 1320 [480/1612 (30%)] Loss: 0.443452\n",
      "Train Epoch: 1320 [640/1612 (40%)] Loss: 0.072539\n",
      "Train Epoch: 1320 [800/1612 (50%)] Loss: 0.295965\n",
      "Train Epoch: 1320 [960/1612 (59%)] Loss: 0.257691\n",
      "Train Epoch: 1320 [1120/1612 (69%)] Loss: 0.682800\n",
      "Train Epoch: 1320 [1280/1612 (79%)] Loss: 0.357277\n",
      "Train Epoch: 1320 [1440/1612 (89%)] Loss: 0.392671\n",
      "Train Epoch: 1320 [1200/1612 (99%)] Loss: 0.348131\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1321 [0/1612 (0%)] Loss: 0.437371\n",
      "Train Epoch: 1321 [160/1612 (10%)] Loss: 0.411696\n",
      "Train Epoch: 1321 [320/1612 (20%)] Loss: 0.235724\n",
      "Train Epoch: 1321 [480/1612 (30%)] Loss: 0.290997\n",
      "Train Epoch: 1321 [640/1612 (40%)] Loss: 0.126103\n",
      "Train Epoch: 1321 [800/1612 (50%)] Loss: 0.468876\n",
      "Train Epoch: 1321 [960/1612 (59%)] Loss: 0.173217\n",
      "Train Epoch: 1321 [1120/1612 (69%)] Loss: 0.382609\n",
      "Train Epoch: 1321 [1280/1612 (79%)] Loss: 0.322921\n",
      "Train Epoch: 1321 [1440/1612 (89%)] Loss: 0.296470\n",
      "Train Epoch: 1321 [1200/1612 (99%)] Loss: 0.113347\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1322 [0/1612 (0%)] Loss: 0.261186\n",
      "Train Epoch: 1322 [160/1612 (10%)] Loss: 0.187281\n",
      "Train Epoch: 1322 [320/1612 (20%)] Loss: 0.393925\n",
      "Train Epoch: 1322 [480/1612 (30%)] Loss: 0.202797\n",
      "Train Epoch: 1322 [640/1612 (40%)] Loss: 0.268416\n",
      "Train Epoch: 1322 [800/1612 (50%)] Loss: 0.526050\n",
      "Train Epoch: 1322 [960/1612 (59%)] Loss: 0.341336\n",
      "Train Epoch: 1322 [1120/1612 (69%)] Loss: 0.228333\n",
      "Train Epoch: 1322 [1280/1612 (79%)] Loss: 0.279868\n",
      "Train Epoch: 1322 [1440/1612 (89%)] Loss: 0.448724\n",
      "Train Epoch: 1322 [1200/1612 (99%)] Loss: 0.340360\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1323 [0/1612 (0%)] Loss: 0.205254\n",
      "Train Epoch: 1323 [160/1612 (10%)] Loss: 0.267791\n",
      "Train Epoch: 1323 [320/1612 (20%)] Loss: 0.367540\n",
      "Train Epoch: 1323 [480/1612 (30%)] Loss: 0.315018\n",
      "Train Epoch: 1323 [640/1612 (40%)] Loss: 0.090010\n",
      "Train Epoch: 1323 [800/1612 (50%)] Loss: 0.151114\n",
      "Train Epoch: 1323 [960/1612 (59%)] Loss: 0.284006\n",
      "Train Epoch: 1323 [1120/1612 (69%)] Loss: 0.154824\n",
      "Train Epoch: 1323 [1280/1612 (79%)] Loss: 0.238499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1323 [1440/1612 (89%)] Loss: 0.396032\n",
      "Train Epoch: 1323 [1200/1612 (99%)] Loss: 0.238767\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1324 [0/1612 (0%)] Loss: 0.305703\n",
      "Train Epoch: 1324 [160/1612 (10%)] Loss: 0.173176\n",
      "Train Epoch: 1324 [320/1612 (20%)] Loss: 0.364938\n",
      "Train Epoch: 1324 [480/1612 (30%)] Loss: 0.178229\n",
      "Train Epoch: 1324 [640/1612 (40%)] Loss: 0.320428\n",
      "Train Epoch: 1324 [800/1612 (50%)] Loss: 0.174483\n",
      "Train Epoch: 1324 [960/1612 (59%)] Loss: 0.614510\n",
      "Train Epoch: 1324 [1120/1612 (69%)] Loss: 0.188797\n",
      "Train Epoch: 1324 [1280/1612 (79%)] Loss: 0.257210\n",
      "Train Epoch: 1324 [1440/1612 (89%)] Loss: 0.398171\n",
      "Train Epoch: 1324 [1200/1612 (99%)] Loss: 0.378540\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1325 [0/1612 (0%)] Loss: 0.360863\n",
      "Train Epoch: 1325 [160/1612 (10%)] Loss: 0.358381\n",
      "Train Epoch: 1325 [320/1612 (20%)] Loss: 0.234910\n",
      "Train Epoch: 1325 [480/1612 (30%)] Loss: 0.359511\n",
      "Train Epoch: 1325 [640/1612 (40%)] Loss: 0.125302\n",
      "Train Epoch: 1325 [800/1612 (50%)] Loss: 0.353738\n",
      "Train Epoch: 1325 [960/1612 (59%)] Loss: 0.161777\n",
      "Train Epoch: 1325 [1120/1612 (69%)] Loss: 0.363565\n",
      "Train Epoch: 1325 [1280/1612 (79%)] Loss: 0.227927\n",
      "Train Epoch: 1325 [1440/1612 (89%)] Loss: 0.382379\n",
      "Train Epoch: 1325 [1200/1612 (99%)] Loss: 0.437112\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1326 [0/1612 (0%)] Loss: 0.398492\n",
      "Train Epoch: 1326 [160/1612 (10%)] Loss: 0.281235\n",
      "Train Epoch: 1326 [320/1612 (20%)] Loss: 0.320290\n",
      "Train Epoch: 1326 [480/1612 (30%)] Loss: 0.319751\n",
      "Train Epoch: 1326 [640/1612 (40%)] Loss: 0.268092\n",
      "Train Epoch: 1326 [800/1612 (50%)] Loss: 0.367712\n",
      "Train Epoch: 1326 [960/1612 (59%)] Loss: 0.162678\n",
      "Train Epoch: 1326 [1120/1612 (69%)] Loss: 0.351440\n",
      "Train Epoch: 1326 [1280/1612 (79%)] Loss: 0.492707\n",
      "Train Epoch: 1326 [1440/1612 (89%)] Loss: 0.260984\n",
      "Train Epoch: 1326 [1200/1612 (99%)] Loss: 0.311355\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1327 [0/1612 (0%)] Loss: 0.099425\n",
      "Train Epoch: 1327 [160/1612 (10%)] Loss: 0.254296\n",
      "Train Epoch: 1327 [320/1612 (20%)] Loss: 0.323023\n",
      "Train Epoch: 1327 [480/1612 (30%)] Loss: 0.332074\n",
      "Train Epoch: 1327 [640/1612 (40%)] Loss: 0.232499\n",
      "Train Epoch: 1327 [800/1612 (50%)] Loss: 0.363745\n",
      "Train Epoch: 1327 [960/1612 (59%)] Loss: 0.378489\n",
      "Train Epoch: 1327 [1120/1612 (69%)] Loss: 0.252974\n",
      "Train Epoch: 1327 [1280/1612 (79%)] Loss: 0.361238\n",
      "Train Epoch: 1327 [1440/1612 (89%)] Loss: 0.336900\n",
      "Train Epoch: 1327 [1200/1612 (99%)] Loss: 0.114855\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1328 [0/1612 (0%)] Loss: 0.213761\n",
      "Train Epoch: 1328 [160/1612 (10%)] Loss: 0.395577\n",
      "Train Epoch: 1328 [320/1612 (20%)] Loss: 0.534594\n",
      "Train Epoch: 1328 [480/1612 (30%)] Loss: 0.453303\n",
      "Train Epoch: 1328 [640/1612 (40%)] Loss: 0.409661\n",
      "Train Epoch: 1328 [800/1612 (50%)] Loss: 0.222587\n",
      "Train Epoch: 1328 [960/1612 (59%)] Loss: 0.501695\n",
      "Train Epoch: 1328 [1120/1612 (69%)] Loss: 0.522639\n",
      "Train Epoch: 1328 [1280/1612 (79%)] Loss: 0.204056\n",
      "Train Epoch: 1328 [1440/1612 (89%)] Loss: 0.295816\n",
      "Train Epoch: 1328 [1200/1612 (99%)] Loss: 0.476417\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1329 [0/1612 (0%)] Loss: 0.345787\n",
      "Train Epoch: 1329 [160/1612 (10%)] Loss: 0.197376\n",
      "Train Epoch: 1329 [320/1612 (20%)] Loss: 0.371651\n",
      "Train Epoch: 1329 [480/1612 (30%)] Loss: 0.464816\n",
      "Train Epoch: 1329 [640/1612 (40%)] Loss: 0.216595\n",
      "Train Epoch: 1329 [800/1612 (50%)] Loss: 0.447156\n",
      "Train Epoch: 1329 [960/1612 (59%)] Loss: 0.471684\n",
      "Train Epoch: 1329 [1120/1612 (69%)] Loss: 0.158492\n",
      "Train Epoch: 1329 [1280/1612 (79%)] Loss: 0.230983\n",
      "Train Epoch: 1329 [1440/1612 (89%)] Loss: 0.296351\n",
      "Train Epoch: 1329 [1200/1612 (99%)] Loss: 0.456240\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1330 [0/1612 (0%)] Loss: 0.226329\n",
      "Train Epoch: 1330 [160/1612 (10%)] Loss: 0.222423\n",
      "Train Epoch: 1330 [320/1612 (20%)] Loss: 0.215491\n",
      "Train Epoch: 1330 [480/1612 (30%)] Loss: 0.657734\n",
      "Train Epoch: 1330 [640/1612 (40%)] Loss: 0.337889\n",
      "Train Epoch: 1330 [800/1612 (50%)] Loss: 0.464584\n",
      "Train Epoch: 1330 [960/1612 (59%)] Loss: 0.264257\n",
      "Train Epoch: 1330 [1120/1612 (69%)] Loss: 0.235384\n",
      "Train Epoch: 1330 [1280/1612 (79%)] Loss: 0.216182\n",
      "Train Epoch: 1330 [1440/1612 (89%)] Loss: 0.244020\n",
      "Train Epoch: 1330 [1200/1612 (99%)] Loss: 0.338791\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1331 [0/1612 (0%)] Loss: 0.075715\n",
      "Train Epoch: 1331 [160/1612 (10%)] Loss: 0.232142\n",
      "Train Epoch: 1331 [320/1612 (20%)] Loss: 0.307213\n",
      "Train Epoch: 1331 [480/1612 (30%)] Loss: 0.239627\n",
      "Train Epoch: 1331 [640/1612 (40%)] Loss: 0.448600\n",
      "Train Epoch: 1331 [800/1612 (50%)] Loss: 0.375323\n",
      "Train Epoch: 1331 [960/1612 (59%)] Loss: 0.132521\n",
      "Train Epoch: 1331 [1120/1612 (69%)] Loss: 0.346903\n",
      "Train Epoch: 1331 [1280/1612 (79%)] Loss: 0.338150\n",
      "Train Epoch: 1331 [1440/1612 (89%)] Loss: 0.272392\n",
      "Train Epoch: 1331 [1200/1612 (99%)] Loss: 0.515888\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1332 [0/1612 (0%)] Loss: 0.219690\n",
      "Train Epoch: 1332 [160/1612 (10%)] Loss: 0.392480\n",
      "Train Epoch: 1332 [320/1612 (20%)] Loss: 0.355407\n",
      "Train Epoch: 1332 [480/1612 (30%)] Loss: 0.321867\n",
      "Train Epoch: 1332 [640/1612 (40%)] Loss: 0.646709\n",
      "Train Epoch: 1332 [800/1612 (50%)] Loss: 0.415371\n",
      "Train Epoch: 1332 [960/1612 (59%)] Loss: 0.397998\n",
      "Train Epoch: 1332 [1120/1612 (69%)] Loss: 0.211133\n",
      "Train Epoch: 1332 [1280/1612 (79%)] Loss: 0.395159\n",
      "Train Epoch: 1332 [1440/1612 (89%)] Loss: 0.217736\n",
      "Train Epoch: 1332 [1200/1612 (99%)] Loss: 0.274054\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1333 [0/1612 (0%)] Loss: 0.211995\n",
      "Train Epoch: 1333 [160/1612 (10%)] Loss: 0.196957\n",
      "Train Epoch: 1333 [320/1612 (20%)] Loss: 0.152500\n",
      "Train Epoch: 1333 [480/1612 (30%)] Loss: 0.363710\n",
      "Train Epoch: 1333 [640/1612 (40%)] Loss: 0.240724\n",
      "Train Epoch: 1333 [800/1612 (50%)] Loss: 0.310818\n",
      "Train Epoch: 1333 [960/1612 (59%)] Loss: 0.213266\n",
      "Train Epoch: 1333 [1120/1612 (69%)] Loss: 0.393368\n",
      "Train Epoch: 1333 [1280/1612 (79%)] Loss: 0.303113\n",
      "Train Epoch: 1333 [1440/1612 (89%)] Loss: 0.166253\n",
      "Train Epoch: 1333 [1200/1612 (99%)] Loss: 0.291807\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1334 [0/1612 (0%)] Loss: 0.479218\n",
      "Train Epoch: 1334 [160/1612 (10%)] Loss: 0.246202\n",
      "Train Epoch: 1334 [320/1612 (20%)] Loss: 0.679346\n",
      "Train Epoch: 1334 [480/1612 (30%)] Loss: 0.296965\n",
      "Train Epoch: 1334 [640/1612 (40%)] Loss: 0.245101\n",
      "Train Epoch: 1334 [800/1612 (50%)] Loss: 0.318970\n",
      "Train Epoch: 1334 [960/1612 (59%)] Loss: 0.210413\n",
      "Train Epoch: 1334 [1120/1612 (69%)] Loss: 0.274439\n",
      "Train Epoch: 1334 [1280/1612 (79%)] Loss: 0.242286\n",
      "Train Epoch: 1334 [1440/1612 (89%)] Loss: 0.337556\n",
      "Train Epoch: 1334 [1200/1612 (99%)] Loss: 0.302641\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1335 [0/1612 (0%)] Loss: 0.316444\n",
      "Train Epoch: 1335 [160/1612 (10%)] Loss: 0.279385\n",
      "Train Epoch: 1335 [320/1612 (20%)] Loss: 0.368417\n",
      "Train Epoch: 1335 [480/1612 (30%)] Loss: 0.398844\n",
      "Train Epoch: 1335 [640/1612 (40%)] Loss: 0.216251\n",
      "Train Epoch: 1335 [800/1612 (50%)] Loss: 0.100082\n",
      "Train Epoch: 1335 [960/1612 (59%)] Loss: 0.163463\n",
      "Train Epoch: 1335 [1120/1612 (69%)] Loss: 0.237654\n",
      "Train Epoch: 1335 [1280/1612 (79%)] Loss: 0.232393\n",
      "Train Epoch: 1335 [1440/1612 (89%)] Loss: 0.611667\n",
      "Train Epoch: 1335 [1200/1612 (99%)] Loss: 0.079832\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1336 [0/1612 (0%)] Loss: 0.245256\n",
      "Train Epoch: 1336 [160/1612 (10%)] Loss: 0.246563\n",
      "Train Epoch: 1336 [320/1612 (20%)] Loss: 0.431103\n",
      "Train Epoch: 1336 [480/1612 (30%)] Loss: 0.324741\n",
      "Train Epoch: 1336 [640/1612 (40%)] Loss: 0.313182\n",
      "Train Epoch: 1336 [800/1612 (50%)] Loss: 0.456259\n",
      "Train Epoch: 1336 [960/1612 (59%)] Loss: 0.410532\n",
      "Train Epoch: 1336 [1120/1612 (69%)] Loss: 0.233622\n",
      "Train Epoch: 1336 [1280/1612 (79%)] Loss: 0.211380\n",
      "Train Epoch: 1336 [1440/1612 (89%)] Loss: 0.207465\n",
      "Train Epoch: 1336 [1200/1612 (99%)] Loss: 0.136482\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1337 [0/1612 (0%)] Loss: 0.134401\n",
      "Train Epoch: 1337 [160/1612 (10%)] Loss: 0.393682\n",
      "Train Epoch: 1337 [320/1612 (20%)] Loss: 0.152021\n",
      "Train Epoch: 1337 [480/1612 (30%)] Loss: 0.270888\n",
      "Train Epoch: 1337 [640/1612 (40%)] Loss: 0.254502\n",
      "Train Epoch: 1337 [800/1612 (50%)] Loss: 0.483879\n",
      "Train Epoch: 1337 [960/1612 (59%)] Loss: 0.207022\n",
      "Train Epoch: 1337 [1120/1612 (69%)] Loss: 0.576794\n",
      "Train Epoch: 1337 [1280/1612 (79%)] Loss: 0.313242\n",
      "Train Epoch: 1337 [1440/1612 (89%)] Loss: 0.469167\n",
      "Train Epoch: 1337 [1200/1612 (99%)] Loss: 0.266448\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1338 [0/1612 (0%)] Loss: 0.232179\n",
      "Train Epoch: 1338 [160/1612 (10%)] Loss: 0.215061\n",
      "Train Epoch: 1338 [320/1612 (20%)] Loss: 0.225167\n",
      "Train Epoch: 1338 [480/1612 (30%)] Loss: 0.489706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1338 [640/1612 (40%)] Loss: 0.274430\n",
      "Train Epoch: 1338 [800/1612 (50%)] Loss: 0.175587\n",
      "Train Epoch: 1338 [960/1612 (59%)] Loss: 0.318154\n",
      "Train Epoch: 1338 [1120/1612 (69%)] Loss: 0.342268\n",
      "Train Epoch: 1338 [1280/1612 (79%)] Loss: 0.326283\n",
      "Train Epoch: 1338 [1440/1612 (89%)] Loss: 0.312642\n",
      "Train Epoch: 1338 [1200/1612 (99%)] Loss: 0.281508\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1339 [0/1612 (0%)] Loss: 0.274246\n",
      "Train Epoch: 1339 [160/1612 (10%)] Loss: 0.461526\n",
      "Train Epoch: 1339 [320/1612 (20%)] Loss: 0.171265\n",
      "Train Epoch: 1339 [480/1612 (30%)] Loss: 0.507080\n",
      "Train Epoch: 1339 [640/1612 (40%)] Loss: 0.299318\n",
      "Train Epoch: 1339 [800/1612 (50%)] Loss: 0.152797\n",
      "Train Epoch: 1339 [960/1612 (59%)] Loss: 0.316617\n",
      "Train Epoch: 1339 [1120/1612 (69%)] Loss: 0.262237\n",
      "Train Epoch: 1339 [1280/1612 (79%)] Loss: 0.471219\n",
      "Train Epoch: 1339 [1440/1612 (89%)] Loss: 0.168401\n",
      "Train Epoch: 1339 [1200/1612 (99%)] Loss: 0.081304\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1340 [0/1612 (0%)] Loss: 0.234826\n",
      "Train Epoch: 1340 [160/1612 (10%)] Loss: 0.188062\n",
      "Train Epoch: 1340 [320/1612 (20%)] Loss: 0.343582\n",
      "Train Epoch: 1340 [480/1612 (30%)] Loss: 0.294220\n",
      "Train Epoch: 1340 [640/1612 (40%)] Loss: 0.514835\n",
      "Train Epoch: 1340 [800/1612 (50%)] Loss: 0.404428\n",
      "Train Epoch: 1340 [960/1612 (59%)] Loss: 0.243030\n",
      "Train Epoch: 1340 [1120/1612 (69%)] Loss: 0.486158\n",
      "Train Epoch: 1340 [1280/1612 (79%)] Loss: 0.113123\n",
      "Train Epoch: 1340 [1440/1612 (89%)] Loss: 0.245508\n",
      "Train Epoch: 1340 [1200/1612 (99%)] Loss: 0.170473\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1341 [0/1612 (0%)] Loss: 0.391698\n",
      "Train Epoch: 1341 [160/1612 (10%)] Loss: 0.207398\n",
      "Train Epoch: 1341 [320/1612 (20%)] Loss: 0.245857\n",
      "Train Epoch: 1341 [480/1612 (30%)] Loss: 0.193953\n",
      "Train Epoch: 1341 [640/1612 (40%)] Loss: 0.423918\n",
      "Train Epoch: 1341 [800/1612 (50%)] Loss: 0.387781\n",
      "Train Epoch: 1341 [960/1612 (59%)] Loss: 0.339816\n",
      "Train Epoch: 1341 [1120/1612 (69%)] Loss: 0.561926\n",
      "Train Epoch: 1341 [1280/1612 (79%)] Loss: 0.154484\n",
      "Train Epoch: 1341 [1440/1612 (89%)] Loss: 0.544900\n",
      "Train Epoch: 1341 [1200/1612 (99%)] Loss: 0.124146\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1342 [0/1612 (0%)] Loss: 0.298517\n",
      "Train Epoch: 1342 [160/1612 (10%)] Loss: 0.490983\n",
      "Train Epoch: 1342 [320/1612 (20%)] Loss: 0.619689\n",
      "Train Epoch: 1342 [480/1612 (30%)] Loss: 0.282350\n",
      "Train Epoch: 1342 [640/1612 (40%)] Loss: 0.404591\n",
      "Train Epoch: 1342 [800/1612 (50%)] Loss: 0.459253\n",
      "Train Epoch: 1342 [960/1612 (59%)] Loss: 0.118827\n",
      "Train Epoch: 1342 [1120/1612 (69%)] Loss: 0.406026\n",
      "Train Epoch: 1342 [1280/1612 (79%)] Loss: 0.297533\n",
      "Train Epoch: 1342 [1440/1612 (89%)] Loss: 0.242062\n",
      "Train Epoch: 1342 [1200/1612 (99%)] Loss: 0.456707\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1343 [0/1612 (0%)] Loss: 0.164745\n",
      "Train Epoch: 1343 [160/1612 (10%)] Loss: 0.208674\n",
      "Train Epoch: 1343 [320/1612 (20%)] Loss: 0.420911\n",
      "Train Epoch: 1343 [480/1612 (30%)] Loss: 0.154209\n",
      "Train Epoch: 1343 [640/1612 (40%)] Loss: 0.422327\n",
      "Train Epoch: 1343 [800/1612 (50%)] Loss: 0.308582\n",
      "Train Epoch: 1343 [960/1612 (59%)] Loss: 0.198935\n",
      "Train Epoch: 1343 [1120/1612 (69%)] Loss: 0.306703\n",
      "Train Epoch: 1343 [1280/1612 (79%)] Loss: 0.298407\n",
      "Train Epoch: 1343 [1440/1612 (89%)] Loss: 0.155903\n",
      "Train Epoch: 1343 [1200/1612 (99%)] Loss: 0.191939\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1344 [0/1612 (0%)] Loss: 0.157064\n",
      "Train Epoch: 1344 [160/1612 (10%)] Loss: 0.258159\n",
      "Train Epoch: 1344 [320/1612 (20%)] Loss: 0.673376\n",
      "Train Epoch: 1344 [480/1612 (30%)] Loss: 0.192359\n",
      "Train Epoch: 1344 [640/1612 (40%)] Loss: 0.211338\n",
      "Train Epoch: 1344 [800/1612 (50%)] Loss: 0.343769\n",
      "Train Epoch: 1344 [960/1612 (59%)] Loss: 0.280514\n",
      "Train Epoch: 1344 [1120/1612 (69%)] Loss: 0.391931\n",
      "Train Epoch: 1344 [1280/1612 (79%)] Loss: 0.116625\n",
      "Train Epoch: 1344 [1440/1612 (89%)] Loss: 0.553337\n",
      "Train Epoch: 1344 [1200/1612 (99%)] Loss: 0.140093\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1345 [0/1612 (0%)] Loss: 0.222938\n",
      "Train Epoch: 1345 [160/1612 (10%)] Loss: 0.403128\n",
      "Train Epoch: 1345 [320/1612 (20%)] Loss: 0.226563\n",
      "Train Epoch: 1345 [480/1612 (30%)] Loss: 0.272692\n",
      "Train Epoch: 1345 [640/1612 (40%)] Loss: 0.382895\n",
      "Train Epoch: 1345 [800/1612 (50%)] Loss: 0.283625\n",
      "Train Epoch: 1345 [960/1612 (59%)] Loss: 0.633410\n",
      "Train Epoch: 1345 [1120/1612 (69%)] Loss: 0.283752\n",
      "Train Epoch: 1345 [1280/1612 (79%)] Loss: 0.442179\n",
      "Train Epoch: 1345 [1440/1612 (89%)] Loss: 0.293095\n",
      "Train Epoch: 1345 [1200/1612 (99%)] Loss: 0.373798\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1346 [0/1612 (0%)] Loss: 0.440847\n",
      "Train Epoch: 1346 [160/1612 (10%)] Loss: 0.248139\n",
      "Train Epoch: 1346 [320/1612 (20%)] Loss: 0.321800\n",
      "Train Epoch: 1346 [480/1612 (30%)] Loss: 0.378925\n",
      "Train Epoch: 1346 [640/1612 (40%)] Loss: 0.132659\n",
      "Train Epoch: 1346 [800/1612 (50%)] Loss: 0.374317\n",
      "Train Epoch: 1346 [960/1612 (59%)] Loss: 0.529628\n",
      "Train Epoch: 1346 [1120/1612 (69%)] Loss: 0.327072\n",
      "Train Epoch: 1346 [1280/1612 (79%)] Loss: 0.248736\n",
      "Train Epoch: 1346 [1440/1612 (89%)] Loss: 0.403216\n",
      "Train Epoch: 1346 [1200/1612 (99%)] Loss: 0.330454\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1347 [0/1612 (0%)] Loss: 0.213487\n",
      "Train Epoch: 1347 [160/1612 (10%)] Loss: 0.439685\n",
      "Train Epoch: 1347 [320/1612 (20%)] Loss: 0.347068\n",
      "Train Epoch: 1347 [480/1612 (30%)] Loss: 0.381310\n",
      "Train Epoch: 1347 [640/1612 (40%)] Loss: 0.117338\n",
      "Train Epoch: 1347 [800/1612 (50%)] Loss: 0.256914\n",
      "Train Epoch: 1347 [960/1612 (59%)] Loss: 0.198165\n",
      "Train Epoch: 1347 [1120/1612 (69%)] Loss: 0.395358\n",
      "Train Epoch: 1347 [1280/1612 (79%)] Loss: 0.334544\n",
      "Train Epoch: 1347 [1440/1612 (89%)] Loss: 0.161045\n",
      "Train Epoch: 1347 [1200/1612 (99%)] Loss: 0.274708\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1348 [0/1612 (0%)] Loss: 0.301634\n",
      "Train Epoch: 1348 [160/1612 (10%)] Loss: 0.169094\n",
      "Train Epoch: 1348 [320/1612 (20%)] Loss: 0.421575\n",
      "Train Epoch: 1348 [480/1612 (30%)] Loss: 0.090138\n",
      "Train Epoch: 1348 [640/1612 (40%)] Loss: 0.325028\n",
      "Train Epoch: 1348 [800/1612 (50%)] Loss: 0.172134\n",
      "Train Epoch: 1348 [960/1612 (59%)] Loss: 0.088666\n",
      "Train Epoch: 1348 [1120/1612 (69%)] Loss: 0.399340\n",
      "Train Epoch: 1348 [1280/1612 (79%)] Loss: 0.401746\n",
      "Train Epoch: 1348 [1440/1612 (89%)] Loss: 0.239344\n",
      "Train Epoch: 1348 [1200/1612 (99%)] Loss: 0.356850\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1349 [0/1612 (0%)] Loss: 0.332383\n",
      "Train Epoch: 1349 [160/1612 (10%)] Loss: 0.239220\n",
      "Train Epoch: 1349 [320/1612 (20%)] Loss: 0.148044\n",
      "Train Epoch: 1349 [480/1612 (30%)] Loss: 0.467389\n",
      "Train Epoch: 1349 [640/1612 (40%)] Loss: 0.175874\n",
      "Train Epoch: 1349 [800/1612 (50%)] Loss: 0.163610\n",
      "Train Epoch: 1349 [960/1612 (59%)] Loss: 0.311000\n",
      "Train Epoch: 1349 [1120/1612 (69%)] Loss: 0.208556\n",
      "Train Epoch: 1349 [1280/1612 (79%)] Loss: 0.255406\n",
      "Train Epoch: 1349 [1440/1612 (89%)] Loss: 0.346379\n",
      "Train Epoch: 1349 [1200/1612 (99%)] Loss: 0.259202\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1350 [0/1612 (0%)] Loss: 0.677300\n",
      "Train Epoch: 1350 [160/1612 (10%)] Loss: 0.313645\n",
      "Train Epoch: 1350 [320/1612 (20%)] Loss: 0.472472\n",
      "Train Epoch: 1350 [480/1612 (30%)] Loss: 0.215071\n",
      "Train Epoch: 1350 [640/1612 (40%)] Loss: 0.270691\n",
      "Train Epoch: 1350 [800/1612 (50%)] Loss: 0.129312\n",
      "Train Epoch: 1350 [960/1612 (59%)] Loss: 0.610594\n",
      "Train Epoch: 1350 [1120/1612 (69%)] Loss: 0.369861\n",
      "Train Epoch: 1350 [1280/1612 (79%)] Loss: 0.237255\n",
      "Train Epoch: 1350 [1440/1612 (89%)] Loss: 0.348710\n",
      "Train Epoch: 1350 [1200/1612 (99%)] Loss: 0.418641\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1351 [0/1612 (0%)] Loss: 0.258094\n",
      "Train Epoch: 1351 [160/1612 (10%)] Loss: 0.458303\n",
      "Train Epoch: 1351 [320/1612 (20%)] Loss: 0.539121\n",
      "Train Epoch: 1351 [480/1612 (30%)] Loss: 0.248778\n",
      "Train Epoch: 1351 [640/1612 (40%)] Loss: 0.160014\n",
      "Train Epoch: 1351 [800/1612 (50%)] Loss: 0.336386\n",
      "Train Epoch: 1351 [960/1612 (59%)] Loss: 0.403296\n",
      "Train Epoch: 1351 [1120/1612 (69%)] Loss: 0.412856\n",
      "Train Epoch: 1351 [1280/1612 (79%)] Loss: 0.420104\n",
      "Train Epoch: 1351 [1440/1612 (89%)] Loss: 0.080196\n",
      "Train Epoch: 1351 [1200/1612 (99%)] Loss: 0.501717\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1352 [0/1612 (0%)] Loss: 0.445871\n",
      "Train Epoch: 1352 [160/1612 (10%)] Loss: 0.144613\n",
      "Train Epoch: 1352 [320/1612 (20%)] Loss: 0.149810\n",
      "Train Epoch: 1352 [480/1612 (30%)] Loss: 0.217903\n",
      "Train Epoch: 1352 [640/1612 (40%)] Loss: 0.232886\n",
      "Train Epoch: 1352 [800/1612 (50%)] Loss: 0.261549\n",
      "Train Epoch: 1352 [960/1612 (59%)] Loss: 0.218532\n",
      "Train Epoch: 1352 [1120/1612 (69%)] Loss: 0.409055\n",
      "Train Epoch: 1352 [1280/1612 (79%)] Loss: 0.364857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1352 [1440/1612 (89%)] Loss: 0.290867\n",
      "Train Epoch: 1352 [1200/1612 (99%)] Loss: 0.520198\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1353 [0/1612 (0%)] Loss: 0.342633\n",
      "Train Epoch: 1353 [160/1612 (10%)] Loss: 0.389200\n",
      "Train Epoch: 1353 [320/1612 (20%)] Loss: 0.404732\n",
      "Train Epoch: 1353 [480/1612 (30%)] Loss: 0.085760\n",
      "Train Epoch: 1353 [640/1612 (40%)] Loss: 0.213608\n",
      "Train Epoch: 1353 [800/1612 (50%)] Loss: 0.363919\n",
      "Train Epoch: 1353 [960/1612 (59%)] Loss: 0.163174\n",
      "Train Epoch: 1353 [1120/1612 (69%)] Loss: 0.186002\n",
      "Train Epoch: 1353 [1280/1612 (79%)] Loss: 0.350306\n",
      "Train Epoch: 1353 [1440/1612 (89%)] Loss: 0.596030\n",
      "Train Epoch: 1353 [1200/1612 (99%)] Loss: 0.256578\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1354 [0/1612 (0%)] Loss: 0.277415\n",
      "Train Epoch: 1354 [160/1612 (10%)] Loss: 0.450005\n",
      "Train Epoch: 1354 [320/1612 (20%)] Loss: 0.245140\n",
      "Train Epoch: 1354 [480/1612 (30%)] Loss: 0.376491\n",
      "Train Epoch: 1354 [640/1612 (40%)] Loss: 0.227317\n",
      "Train Epoch: 1354 [800/1612 (50%)] Loss: 0.364229\n",
      "Train Epoch: 1354 [960/1612 (59%)] Loss: 0.151919\n",
      "Train Epoch: 1354 [1120/1612 (69%)] Loss: 0.186638\n",
      "Train Epoch: 1354 [1280/1612 (79%)] Loss: 0.278769\n",
      "Train Epoch: 1354 [1440/1612 (89%)] Loss: 0.247788\n",
      "Train Epoch: 1354 [1200/1612 (99%)] Loss: 0.310506\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1355 [0/1612 (0%)] Loss: 0.323964\n",
      "Train Epoch: 1355 [160/1612 (10%)] Loss: 0.190557\n",
      "Train Epoch: 1355 [320/1612 (20%)] Loss: 0.425611\n",
      "Train Epoch: 1355 [480/1612 (30%)] Loss: 0.311701\n",
      "Train Epoch: 1355 [640/1612 (40%)] Loss: 0.401413\n",
      "Train Epoch: 1355 [800/1612 (50%)] Loss: 0.155748\n",
      "Train Epoch: 1355 [960/1612 (59%)] Loss: 0.159052\n",
      "Train Epoch: 1355 [1120/1612 (69%)] Loss: 0.502654\n",
      "Train Epoch: 1355 [1280/1612 (79%)] Loss: 0.184327\n",
      "Train Epoch: 1355 [1440/1612 (89%)] Loss: 0.472295\n",
      "Train Epoch: 1355 [1200/1612 (99%)] Loss: 0.406697\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1356 [0/1612 (0%)] Loss: 0.348464\n",
      "Train Epoch: 1356 [160/1612 (10%)] Loss: 0.198466\n",
      "Train Epoch: 1356 [320/1612 (20%)] Loss: 0.098343\n",
      "Train Epoch: 1356 [480/1612 (30%)] Loss: 0.194691\n",
      "Train Epoch: 1356 [640/1612 (40%)] Loss: 0.329684\n",
      "Train Epoch: 1356 [800/1612 (50%)] Loss: 0.235809\n",
      "Train Epoch: 1356 [960/1612 (59%)] Loss: 0.336331\n",
      "Train Epoch: 1356 [1120/1612 (69%)] Loss: 0.633037\n",
      "Train Epoch: 1356 [1280/1612 (79%)] Loss: 0.273147\n",
      "Train Epoch: 1356 [1440/1612 (89%)] Loss: 0.139081\n",
      "Train Epoch: 1356 [1200/1612 (99%)] Loss: 0.172900\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1357 [0/1612 (0%)] Loss: 0.469796\n",
      "Train Epoch: 1357 [160/1612 (10%)] Loss: 0.375549\n",
      "Train Epoch: 1357 [320/1612 (20%)] Loss: 0.539467\n",
      "Train Epoch: 1357 [480/1612 (30%)] Loss: 0.495192\n",
      "Train Epoch: 1357 [640/1612 (40%)] Loss: 0.186191\n",
      "Train Epoch: 1357 [800/1612 (50%)] Loss: 0.373895\n",
      "Train Epoch: 1357 [960/1612 (59%)] Loss: 0.377655\n",
      "Train Epoch: 1357 [1120/1612 (69%)] Loss: 0.300251\n",
      "Train Epoch: 1357 [1280/1612 (79%)] Loss: 0.382457\n",
      "Train Epoch: 1357 [1440/1612 (89%)] Loss: 0.519351\n",
      "Train Epoch: 1357 [1200/1612 (99%)] Loss: 0.367153\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1358 [0/1612 (0%)] Loss: 0.135762\n",
      "Train Epoch: 1358 [160/1612 (10%)] Loss: 0.310172\n",
      "Train Epoch: 1358 [320/1612 (20%)] Loss: 0.305496\n",
      "Train Epoch: 1358 [480/1612 (30%)] Loss: 0.178257\n",
      "Train Epoch: 1358 [640/1612 (40%)] Loss: 0.368872\n",
      "Train Epoch: 1358 [800/1612 (50%)] Loss: 0.159662\n",
      "Train Epoch: 1358 [960/1612 (59%)] Loss: 0.323451\n",
      "Train Epoch: 1358 [1120/1612 (69%)] Loss: 0.164835\n",
      "Train Epoch: 1358 [1280/1612 (79%)] Loss: 0.420120\n",
      "Train Epoch: 1358 [1440/1612 (89%)] Loss: 0.384279\n",
      "Train Epoch: 1358 [1200/1612 (99%)] Loss: 0.361232\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1359 [0/1612 (0%)] Loss: 0.171161\n",
      "Train Epoch: 1359 [160/1612 (10%)] Loss: 0.324278\n",
      "Train Epoch: 1359 [320/1612 (20%)] Loss: 0.440793\n",
      "Train Epoch: 1359 [480/1612 (30%)] Loss: 0.253448\n",
      "Train Epoch: 1359 [640/1612 (40%)] Loss: 0.282939\n",
      "Train Epoch: 1359 [800/1612 (50%)] Loss: 0.251381\n",
      "Train Epoch: 1359 [960/1612 (59%)] Loss: 0.243732\n",
      "Train Epoch: 1359 [1120/1612 (69%)] Loss: 0.383819\n",
      "Train Epoch: 1359 [1280/1612 (79%)] Loss: 0.164417\n",
      "Train Epoch: 1359 [1440/1612 (89%)] Loss: 0.441789\n",
      "Train Epoch: 1359 [1200/1612 (99%)] Loss: 0.262582\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1360 [0/1612 (0%)] Loss: 0.268334\n",
      "Train Epoch: 1360 [160/1612 (10%)] Loss: 0.444381\n",
      "Train Epoch: 1360 [320/1612 (20%)] Loss: 0.486160\n",
      "Train Epoch: 1360 [480/1612 (30%)] Loss: 0.156095\n",
      "Train Epoch: 1360 [640/1612 (40%)] Loss: 0.396636\n",
      "Train Epoch: 1360 [800/1612 (50%)] Loss: 0.218096\n",
      "Train Epoch: 1360 [960/1612 (59%)] Loss: 0.375027\n",
      "Train Epoch: 1360 [1120/1612 (69%)] Loss: 0.524868\n",
      "Train Epoch: 1360 [1280/1612 (79%)] Loss: 0.316895\n",
      "Train Epoch: 1360 [1440/1612 (89%)] Loss: 0.344990\n",
      "Train Epoch: 1360 [1200/1612 (99%)] Loss: 0.455724\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1361 [0/1612 (0%)] Loss: 0.409457\n",
      "Train Epoch: 1361 [160/1612 (10%)] Loss: 0.331606\n",
      "Train Epoch: 1361 [320/1612 (20%)] Loss: 0.347262\n",
      "Train Epoch: 1361 [480/1612 (30%)] Loss: 0.443622\n",
      "Train Epoch: 1361 [640/1612 (40%)] Loss: 0.314805\n",
      "Train Epoch: 1361 [800/1612 (50%)] Loss: 0.710467\n",
      "Train Epoch: 1361 [960/1612 (59%)] Loss: 0.368933\n",
      "Train Epoch: 1361 [1120/1612 (69%)] Loss: 0.190658\n",
      "Train Epoch: 1361 [1280/1612 (79%)] Loss: 0.461018\n",
      "Train Epoch: 1361 [1440/1612 (89%)] Loss: 0.113158\n",
      "Train Epoch: 1361 [1200/1612 (99%)] Loss: 0.244832\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1362 [0/1612 (0%)] Loss: 0.433357\n",
      "Train Epoch: 1362 [160/1612 (10%)] Loss: 0.174181\n",
      "Train Epoch: 1362 [320/1612 (20%)] Loss: 0.307933\n",
      "Train Epoch: 1362 [480/1612 (30%)] Loss: 0.337420\n",
      "Train Epoch: 1362 [640/1612 (40%)] Loss: 0.243976\n",
      "Train Epoch: 1362 [800/1612 (50%)] Loss: 0.163769\n",
      "Train Epoch: 1362 [960/1612 (59%)] Loss: 0.746691\n",
      "Train Epoch: 1362 [1120/1612 (69%)] Loss: 0.406227\n",
      "Train Epoch: 1362 [1280/1612 (79%)] Loss: 0.336885\n",
      "Train Epoch: 1362 [1440/1612 (89%)] Loss: 0.291089\n",
      "Train Epoch: 1362 [1200/1612 (99%)] Loss: 0.169797\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1363 [0/1612 (0%)] Loss: 0.332649\n",
      "Train Epoch: 1363 [160/1612 (10%)] Loss: 0.433564\n",
      "Train Epoch: 1363 [320/1612 (20%)] Loss: 0.171744\n",
      "Train Epoch: 1363 [480/1612 (30%)] Loss: 0.290441\n",
      "Train Epoch: 1363 [640/1612 (40%)] Loss: 0.239227\n",
      "Train Epoch: 1363 [800/1612 (50%)] Loss: 0.265672\n",
      "Train Epoch: 1363 [960/1612 (59%)] Loss: 0.429813\n",
      "Train Epoch: 1363 [1120/1612 (69%)] Loss: 0.685104\n",
      "Train Epoch: 1363 [1280/1612 (79%)] Loss: 0.310341\n",
      "Train Epoch: 1363 [1440/1612 (89%)] Loss: 0.319986\n",
      "Train Epoch: 1363 [1200/1612 (99%)] Loss: 0.188063\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1364 [0/1612 (0%)] Loss: 0.187568\n",
      "Train Epoch: 1364 [160/1612 (10%)] Loss: 0.189858\n",
      "Train Epoch: 1364 [320/1612 (20%)] Loss: 0.233116\n",
      "Train Epoch: 1364 [480/1612 (30%)] Loss: 0.236591\n",
      "Train Epoch: 1364 [640/1612 (40%)] Loss: 0.464914\n",
      "Train Epoch: 1364 [800/1612 (50%)] Loss: 0.191007\n",
      "Train Epoch: 1364 [960/1612 (59%)] Loss: 0.337863\n",
      "Train Epoch: 1364 [1120/1612 (69%)] Loss: 0.191485\n",
      "Train Epoch: 1364 [1280/1612 (79%)] Loss: 0.391184\n",
      "Train Epoch: 1364 [1440/1612 (89%)] Loss: 0.338912\n",
      "Train Epoch: 1364 [1200/1612 (99%)] Loss: 0.267690\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1365 [0/1612 (0%)] Loss: 0.323573\n",
      "Train Epoch: 1365 [160/1612 (10%)] Loss: 0.645534\n",
      "Train Epoch: 1365 [320/1612 (20%)] Loss: 0.290288\n",
      "Train Epoch: 1365 [480/1612 (30%)] Loss: 0.353327\n",
      "Train Epoch: 1365 [640/1612 (40%)] Loss: 0.247452\n",
      "Train Epoch: 1365 [800/1612 (50%)] Loss: 0.206972\n",
      "Train Epoch: 1365 [960/1612 (59%)] Loss: 0.374569\n",
      "Train Epoch: 1365 [1120/1612 (69%)] Loss: 0.250846\n",
      "Train Epoch: 1365 [1280/1612 (79%)] Loss: 0.224180\n",
      "Train Epoch: 1365 [1440/1612 (89%)] Loss: 0.306782\n",
      "Train Epoch: 1365 [1200/1612 (99%)] Loss: 0.319648\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1366 [0/1612 (0%)] Loss: 0.352904\n",
      "Train Epoch: 1366 [160/1612 (10%)] Loss: 0.406997\n",
      "Train Epoch: 1366 [320/1612 (20%)] Loss: 0.170889\n",
      "Train Epoch: 1366 [480/1612 (30%)] Loss: 0.315546\n",
      "Train Epoch: 1366 [640/1612 (40%)] Loss: 0.259431\n",
      "Train Epoch: 1366 [800/1612 (50%)] Loss: 0.341108\n",
      "Train Epoch: 1366 [960/1612 (59%)] Loss: 0.276609\n",
      "Train Epoch: 1366 [1120/1612 (69%)] Loss: 0.286633\n",
      "Train Epoch: 1366 [1280/1612 (79%)] Loss: 0.271787\n",
      "Train Epoch: 1366 [1440/1612 (89%)] Loss: 0.390632\n",
      "Train Epoch: 1366 [1200/1612 (99%)] Loss: 0.283168\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1367 [0/1612 (0%)] Loss: 0.298472\n",
      "Train Epoch: 1367 [160/1612 (10%)] Loss: 0.383927\n",
      "Train Epoch: 1367 [320/1612 (20%)] Loss: 0.407544\n",
      "Train Epoch: 1367 [480/1612 (30%)] Loss: 0.397155\n",
      "Train Epoch: 1367 [640/1612 (40%)] Loss: 0.216033\n",
      "Train Epoch: 1367 [800/1612 (50%)] Loss: 0.249229\n",
      "Train Epoch: 1367 [960/1612 (59%)] Loss: 0.196035\n",
      "Train Epoch: 1367 [1120/1612 (69%)] Loss: 0.392062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1367 [1280/1612 (79%)] Loss: 0.255537\n",
      "Train Epoch: 1367 [1440/1612 (89%)] Loss: 0.204427\n",
      "Train Epoch: 1367 [1200/1612 (99%)] Loss: 0.497643\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1368 [0/1612 (0%)] Loss: 0.225391\n",
      "Train Epoch: 1368 [160/1612 (10%)] Loss: 0.387731\n",
      "Train Epoch: 1368 [320/1612 (20%)] Loss: 0.378566\n",
      "Train Epoch: 1368 [480/1612 (30%)] Loss: 0.249438\n",
      "Train Epoch: 1368 [640/1612 (40%)] Loss: 0.232462\n",
      "Train Epoch: 1368 [800/1612 (50%)] Loss: 0.167522\n",
      "Train Epoch: 1368 [960/1612 (59%)] Loss: 0.432589\n",
      "Train Epoch: 1368 [1120/1612 (69%)] Loss: 0.302752\n",
      "Train Epoch: 1368 [1280/1612 (79%)] Loss: 0.280027\n",
      "Train Epoch: 1368 [1440/1612 (89%)] Loss: 0.252265\n",
      "Train Epoch: 1368 [1200/1612 (99%)] Loss: 0.396539\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1369 [0/1612 (0%)] Loss: 0.317144\n",
      "Train Epoch: 1369 [160/1612 (10%)] Loss: 0.608752\n",
      "Train Epoch: 1369 [320/1612 (20%)] Loss: 0.295069\n",
      "Train Epoch: 1369 [480/1612 (30%)] Loss: 0.189610\n",
      "Train Epoch: 1369 [640/1612 (40%)] Loss: 0.335173\n",
      "Train Epoch: 1369 [800/1612 (50%)] Loss: 0.253270\n",
      "Train Epoch: 1369 [960/1612 (59%)] Loss: 0.303111\n",
      "Train Epoch: 1369 [1120/1612 (69%)] Loss: 0.306474\n",
      "Train Epoch: 1369 [1280/1612 (79%)] Loss: 0.272179\n",
      "Train Epoch: 1369 [1440/1612 (89%)] Loss: 0.560151\n",
      "Train Epoch: 1369 [1200/1612 (99%)] Loss: 0.127376\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1370 [0/1612 (0%)] Loss: 0.097402\n",
      "Train Epoch: 1370 [160/1612 (10%)] Loss: 0.266487\n",
      "Train Epoch: 1370 [320/1612 (20%)] Loss: 0.251856\n",
      "Train Epoch: 1370 [480/1612 (30%)] Loss: 0.201839\n",
      "Train Epoch: 1370 [640/1612 (40%)] Loss: 0.605322\n",
      "Train Epoch: 1370 [800/1612 (50%)] Loss: 0.297792\n",
      "Train Epoch: 1370 [960/1612 (59%)] Loss: 0.246214\n",
      "Train Epoch: 1370 [1120/1612 (69%)] Loss: 0.280512\n",
      "Train Epoch: 1370 [1280/1612 (79%)] Loss: 0.357716\n",
      "Train Epoch: 1370 [1440/1612 (89%)] Loss: 0.463655\n",
      "Train Epoch: 1370 [1200/1612 (99%)] Loss: 0.226298\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1371 [0/1612 (0%)] Loss: 0.312822\n",
      "Train Epoch: 1371 [160/1612 (10%)] Loss: 0.610824\n",
      "Train Epoch: 1371 [320/1612 (20%)] Loss: 0.266608\n",
      "Train Epoch: 1371 [480/1612 (30%)] Loss: 0.210159\n",
      "Train Epoch: 1371 [640/1612 (40%)] Loss: 0.200717\n",
      "Train Epoch: 1371 [800/1612 (50%)] Loss: 0.166579\n",
      "Train Epoch: 1371 [960/1612 (59%)] Loss: 0.194903\n",
      "Train Epoch: 1371 [1120/1612 (69%)] Loss: 0.277245\n",
      "Train Epoch: 1371 [1280/1612 (79%)] Loss: 0.230121\n",
      "Train Epoch: 1371 [1440/1612 (89%)] Loss: 0.230367\n",
      "Train Epoch: 1371 [1200/1612 (99%)] Loss: 0.370036\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1372 [0/1612 (0%)] Loss: 0.277528\n",
      "Train Epoch: 1372 [160/1612 (10%)] Loss: 0.130819\n",
      "Train Epoch: 1372 [320/1612 (20%)] Loss: 0.483323\n",
      "Train Epoch: 1372 [480/1612 (30%)] Loss: 0.259435\n",
      "Train Epoch: 1372 [640/1612 (40%)] Loss: 0.329664\n",
      "Train Epoch: 1372 [800/1612 (50%)] Loss: 0.255210\n",
      "Train Epoch: 1372 [960/1612 (59%)] Loss: 0.378172\n",
      "Train Epoch: 1372 [1120/1612 (69%)] Loss: 0.164239\n",
      "Train Epoch: 1372 [1280/1612 (79%)] Loss: 0.483425\n",
      "Train Epoch: 1372 [1440/1612 (89%)] Loss: 0.129664\n",
      "Train Epoch: 1372 [1200/1612 (99%)] Loss: 0.270884\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1373 [0/1612 (0%)] Loss: 0.303650\n",
      "Train Epoch: 1373 [160/1612 (10%)] Loss: 0.476869\n",
      "Train Epoch: 1373 [320/1612 (20%)] Loss: 0.330571\n",
      "Train Epoch: 1373 [480/1612 (30%)] Loss: 0.264275\n",
      "Train Epoch: 1373 [640/1612 (40%)] Loss: 0.230682\n",
      "Train Epoch: 1373 [800/1612 (50%)] Loss: 0.187351\n",
      "Train Epoch: 1373 [960/1612 (59%)] Loss: 0.482733\n",
      "Train Epoch: 1373 [1120/1612 (69%)] Loss: 0.168035\n",
      "Train Epoch: 1373 [1280/1612 (79%)] Loss: 0.150825\n",
      "Train Epoch: 1373 [1440/1612 (89%)] Loss: 0.104014\n",
      "Train Epoch: 1373 [1200/1612 (99%)] Loss: 0.467920\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1374 [0/1612 (0%)] Loss: 0.461123\n",
      "Train Epoch: 1374 [160/1612 (10%)] Loss: 0.365887\n",
      "Train Epoch: 1374 [320/1612 (20%)] Loss: 0.291472\n",
      "Train Epoch: 1374 [480/1612 (30%)] Loss: 0.359678\n",
      "Train Epoch: 1374 [640/1612 (40%)] Loss: 0.428660\n",
      "Train Epoch: 1374 [800/1612 (50%)] Loss: 0.499124\n",
      "Train Epoch: 1374 [960/1612 (59%)] Loss: 0.182394\n",
      "Train Epoch: 1374 [1120/1612 (69%)] Loss: 0.237245\n",
      "Train Epoch: 1374 [1280/1612 (79%)] Loss: 0.330439\n",
      "Train Epoch: 1374 [1440/1612 (89%)] Loss: 0.251541\n",
      "Train Epoch: 1374 [1200/1612 (99%)] Loss: 0.339776\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1375 [0/1612 (0%)] Loss: 0.127812\n",
      "Train Epoch: 1375 [160/1612 (10%)] Loss: 0.475402\n",
      "Train Epoch: 1375 [320/1612 (20%)] Loss: 0.214379\n",
      "Train Epoch: 1375 [480/1612 (30%)] Loss: 0.611184\n",
      "Train Epoch: 1375 [640/1612 (40%)] Loss: 0.229360\n",
      "Train Epoch: 1375 [800/1612 (50%)] Loss: 0.275277\n",
      "Train Epoch: 1375 [960/1612 (59%)] Loss: 0.382727\n",
      "Train Epoch: 1375 [1120/1612 (69%)] Loss: 0.327376\n",
      "Train Epoch: 1375 [1280/1612 (79%)] Loss: 0.194726\n",
      "Train Epoch: 1375 [1440/1612 (89%)] Loss: 0.305431\n",
      "Train Epoch: 1375 [1200/1612 (99%)] Loss: 0.059521\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1376 [0/1612 (0%)] Loss: 0.215490\n",
      "Train Epoch: 1376 [160/1612 (10%)] Loss: 0.287720\n",
      "Train Epoch: 1376 [320/1612 (20%)] Loss: 0.201318\n",
      "Train Epoch: 1376 [480/1612 (30%)] Loss: 0.356279\n",
      "Train Epoch: 1376 [640/1612 (40%)] Loss: 0.314675\n",
      "Train Epoch: 1376 [800/1612 (50%)] Loss: 0.305833\n",
      "Train Epoch: 1376 [960/1612 (59%)] Loss: 0.308909\n",
      "Train Epoch: 1376 [1120/1612 (69%)] Loss: 0.345583\n",
      "Train Epoch: 1376 [1280/1612 (79%)] Loss: 0.189545\n",
      "Train Epoch: 1376 [1440/1612 (89%)] Loss: 0.245445\n",
      "Train Epoch: 1376 [1200/1612 (99%)] Loss: 0.121837\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1377 [0/1612 (0%)] Loss: 0.254768\n",
      "Train Epoch: 1377 [160/1612 (10%)] Loss: 0.177261\n",
      "Train Epoch: 1377 [320/1612 (20%)] Loss: 0.152225\n",
      "Train Epoch: 1377 [480/1612 (30%)] Loss: 0.192625\n",
      "Train Epoch: 1377 [640/1612 (40%)] Loss: 0.286630\n",
      "Train Epoch: 1377 [800/1612 (50%)] Loss: 0.302430\n",
      "Train Epoch: 1377 [960/1612 (59%)] Loss: 0.435886\n",
      "Train Epoch: 1377 [1120/1612 (69%)] Loss: 0.325917\n",
      "Train Epoch: 1377 [1280/1612 (79%)] Loss: 0.323554\n",
      "Train Epoch: 1377 [1440/1612 (89%)] Loss: 0.417351\n",
      "Train Epoch: 1377 [1200/1612 (99%)] Loss: 0.346029\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1378 [0/1612 (0%)] Loss: 0.283952\n",
      "Train Epoch: 1378 [160/1612 (10%)] Loss: 0.205435\n",
      "Train Epoch: 1378 [320/1612 (20%)] Loss: 0.266130\n",
      "Train Epoch: 1378 [480/1612 (30%)] Loss: 0.170433\n",
      "Train Epoch: 1378 [640/1612 (40%)] Loss: 0.371223\n",
      "Train Epoch: 1378 [800/1612 (50%)] Loss: 0.164202\n",
      "Train Epoch: 1378 [960/1612 (59%)] Loss: 0.371078\n",
      "Train Epoch: 1378 [1120/1612 (69%)] Loss: 0.166054\n",
      "Train Epoch: 1378 [1280/1612 (79%)] Loss: 0.092492\n",
      "Train Epoch: 1378 [1440/1612 (89%)] Loss: 0.147303\n",
      "Train Epoch: 1378 [1200/1612 (99%)] Loss: 0.272433\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1379 [0/1612 (0%)] Loss: 0.400867\n",
      "Train Epoch: 1379 [160/1612 (10%)] Loss: 0.355085\n",
      "Train Epoch: 1379 [320/1612 (20%)] Loss: 0.297688\n",
      "Train Epoch: 1379 [480/1612 (30%)] Loss: 0.172460\n",
      "Train Epoch: 1379 [640/1612 (40%)] Loss: 0.583041\n",
      "Train Epoch: 1379 [800/1612 (50%)] Loss: 0.365134\n",
      "Train Epoch: 1379 [960/1612 (59%)] Loss: 0.327366\n",
      "Train Epoch: 1379 [1120/1612 (69%)] Loss: 0.454219\n",
      "Train Epoch: 1379 [1280/1612 (79%)] Loss: 0.327949\n",
      "Train Epoch: 1379 [1440/1612 (89%)] Loss: 0.311353\n",
      "Train Epoch: 1379 [1200/1612 (99%)] Loss: 0.354845\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1380 [0/1612 (0%)] Loss: 0.329095\n",
      "Train Epoch: 1380 [160/1612 (10%)] Loss: 0.329942\n",
      "Train Epoch: 1380 [320/1612 (20%)] Loss: 0.455973\n",
      "Train Epoch: 1380 [480/1612 (30%)] Loss: 0.405029\n",
      "Train Epoch: 1380 [640/1612 (40%)] Loss: 0.401196\n",
      "Train Epoch: 1380 [800/1612 (50%)] Loss: 0.355110\n",
      "Train Epoch: 1380 [960/1612 (59%)] Loss: 0.449260\n",
      "Train Epoch: 1380 [1120/1612 (69%)] Loss: 0.457108\n",
      "Train Epoch: 1380 [1280/1612 (79%)] Loss: 0.160345\n",
      "Train Epoch: 1380 [1440/1612 (89%)] Loss: 0.493361\n",
      "Train Epoch: 1380 [1200/1612 (99%)] Loss: 0.056589\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1381 [0/1612 (0%)] Loss: 0.415245\n",
      "Train Epoch: 1381 [160/1612 (10%)] Loss: 0.212981\n",
      "Train Epoch: 1381 [320/1612 (20%)] Loss: 0.563435\n",
      "Train Epoch: 1381 [480/1612 (30%)] Loss: 0.138764\n",
      "Train Epoch: 1381 [640/1612 (40%)] Loss: 0.190722\n",
      "Train Epoch: 1381 [800/1612 (50%)] Loss: 0.560643\n",
      "Train Epoch: 1381 [960/1612 (59%)] Loss: 0.320560\n",
      "Train Epoch: 1381 [1120/1612 (69%)] Loss: 0.370805\n",
      "Train Epoch: 1381 [1280/1612 (79%)] Loss: 0.288858\n",
      "Train Epoch: 1381 [1440/1612 (89%)] Loss: 0.405433\n",
      "Train Epoch: 1381 [1200/1612 (99%)] Loss: 0.087785\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1382 [0/1612 (0%)] Loss: 0.489381\n",
      "Train Epoch: 1382 [160/1612 (10%)] Loss: 0.404989\n",
      "Train Epoch: 1382 [320/1612 (20%)] Loss: 0.395501\n",
      "Train Epoch: 1382 [480/1612 (30%)] Loss: 0.225256\n",
      "Train Epoch: 1382 [640/1612 (40%)] Loss: 0.247795\n",
      "Train Epoch: 1382 [800/1612 (50%)] Loss: 0.464826\n",
      "Train Epoch: 1382 [960/1612 (59%)] Loss: 0.151811\n",
      "Train Epoch: 1382 [1120/1612 (69%)] Loss: 0.324314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1382 [1280/1612 (79%)] Loss: 0.210658\n",
      "Train Epoch: 1382 [1440/1612 (89%)] Loss: 0.474684\n",
      "Train Epoch: 1382 [1200/1612 (99%)] Loss: 0.208743\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1383 [0/1612 (0%)] Loss: 0.369244\n",
      "Train Epoch: 1383 [160/1612 (10%)] Loss: 0.185866\n",
      "Train Epoch: 1383 [320/1612 (20%)] Loss: 0.162259\n",
      "Train Epoch: 1383 [480/1612 (30%)] Loss: 0.264676\n",
      "Train Epoch: 1383 [640/1612 (40%)] Loss: 0.490920\n",
      "Train Epoch: 1383 [800/1612 (50%)] Loss: 0.235772\n",
      "Train Epoch: 1383 [960/1612 (59%)] Loss: 0.353313\n",
      "Train Epoch: 1383 [1120/1612 (69%)] Loss: 0.518881\n",
      "Train Epoch: 1383 [1280/1612 (79%)] Loss: 0.183987\n",
      "Train Epoch: 1383 [1440/1612 (89%)] Loss: 0.345057\n",
      "Train Epoch: 1383 [1200/1612 (99%)] Loss: 0.506788\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1384 [0/1612 (0%)] Loss: 0.171690\n",
      "Train Epoch: 1384 [160/1612 (10%)] Loss: 0.209606\n",
      "Train Epoch: 1384 [320/1612 (20%)] Loss: 0.263464\n",
      "Train Epoch: 1384 [480/1612 (30%)] Loss: 0.466988\n",
      "Train Epoch: 1384 [640/1612 (40%)] Loss: 0.330717\n",
      "Train Epoch: 1384 [800/1612 (50%)] Loss: 0.580054\n",
      "Train Epoch: 1384 [960/1612 (59%)] Loss: 0.226113\n",
      "Train Epoch: 1384 [1120/1612 (69%)] Loss: 0.470873\n",
      "Train Epoch: 1384 [1280/1612 (79%)] Loss: 0.372682\n",
      "Train Epoch: 1384 [1440/1612 (89%)] Loss: 0.389977\n",
      "Train Epoch: 1384 [1200/1612 (99%)] Loss: 0.319650\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1385 [0/1612 (0%)] Loss: 0.329330\n",
      "Train Epoch: 1385 [160/1612 (10%)] Loss: 0.100530\n",
      "Train Epoch: 1385 [320/1612 (20%)] Loss: 0.216835\n",
      "Train Epoch: 1385 [480/1612 (30%)] Loss: 0.452738\n",
      "Train Epoch: 1385 [640/1612 (40%)] Loss: 0.170190\n",
      "Train Epoch: 1385 [800/1612 (50%)] Loss: 0.149391\n",
      "Train Epoch: 1385 [960/1612 (59%)] Loss: 0.330602\n",
      "Train Epoch: 1385 [1120/1612 (69%)] Loss: 0.288586\n",
      "Train Epoch: 1385 [1280/1612 (79%)] Loss: 0.247838\n",
      "Train Epoch: 1385 [1440/1612 (89%)] Loss: 0.173335\n",
      "Train Epoch: 1385 [1200/1612 (99%)] Loss: 0.248803\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1386 [0/1612 (0%)] Loss: 0.184251\n",
      "Train Epoch: 1386 [160/1612 (10%)] Loss: 0.313621\n",
      "Train Epoch: 1386 [320/1612 (20%)] Loss: 0.205744\n",
      "Train Epoch: 1386 [480/1612 (30%)] Loss: 0.271840\n",
      "Train Epoch: 1386 [640/1612 (40%)] Loss: 0.207167\n",
      "Train Epoch: 1386 [800/1612 (50%)] Loss: 0.385632\n",
      "Train Epoch: 1386 [960/1612 (59%)] Loss: 0.163688\n",
      "Train Epoch: 1386 [1120/1612 (69%)] Loss: 0.337188\n",
      "Train Epoch: 1386 [1280/1612 (79%)] Loss: 0.268112\n",
      "Train Epoch: 1386 [1440/1612 (89%)] Loss: 0.291542\n",
      "Train Epoch: 1386 [1200/1612 (99%)] Loss: 0.650278\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1387 [0/1612 (0%)] Loss: 0.183215\n",
      "Train Epoch: 1387 [160/1612 (10%)] Loss: 0.290769\n",
      "Train Epoch: 1387 [320/1612 (20%)] Loss: 0.342283\n",
      "Train Epoch: 1387 [480/1612 (30%)] Loss: 0.260249\n",
      "Train Epoch: 1387 [640/1612 (40%)] Loss: 0.303127\n",
      "Train Epoch: 1387 [800/1612 (50%)] Loss: 0.247889\n",
      "Train Epoch: 1387 [960/1612 (59%)] Loss: 0.298446\n",
      "Train Epoch: 1387 [1120/1612 (69%)] Loss: 0.375857\n",
      "Train Epoch: 1387 [1280/1612 (79%)] Loss: 0.467287\n",
      "Train Epoch: 1387 [1440/1612 (89%)] Loss: 0.304594\n",
      "Train Epoch: 1387 [1200/1612 (99%)] Loss: 0.513028\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1388 [0/1612 (0%)] Loss: 0.259446\n",
      "Train Epoch: 1388 [160/1612 (10%)] Loss: 0.104523\n",
      "Train Epoch: 1388 [320/1612 (20%)] Loss: 0.768307\n",
      "Train Epoch: 1388 [480/1612 (30%)] Loss: 0.410997\n",
      "Train Epoch: 1388 [640/1612 (40%)] Loss: 0.199171\n",
      "Train Epoch: 1388 [800/1612 (50%)] Loss: 0.522509\n",
      "Train Epoch: 1388 [960/1612 (59%)] Loss: 0.284433\n",
      "Train Epoch: 1388 [1120/1612 (69%)] Loss: 0.124587\n",
      "Train Epoch: 1388 [1280/1612 (79%)] Loss: 0.260952\n",
      "Train Epoch: 1388 [1440/1612 (89%)] Loss: 0.664741\n",
      "Train Epoch: 1388 [1200/1612 (99%)] Loss: 0.513694\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1389 [0/1612 (0%)] Loss: 0.363129\n",
      "Train Epoch: 1389 [160/1612 (10%)] Loss: 0.283075\n",
      "Train Epoch: 1389 [320/1612 (20%)] Loss: 0.482341\n",
      "Train Epoch: 1389 [480/1612 (30%)] Loss: 0.494078\n",
      "Train Epoch: 1389 [640/1612 (40%)] Loss: 0.226862\n",
      "Train Epoch: 1389 [800/1612 (50%)] Loss: 0.127671\n",
      "Train Epoch: 1389 [960/1612 (59%)] Loss: 0.175446\n",
      "Train Epoch: 1389 [1120/1612 (69%)] Loss: 0.116780\n",
      "Train Epoch: 1389 [1280/1612 (79%)] Loss: 0.375354\n",
      "Train Epoch: 1389 [1440/1612 (89%)] Loss: 0.154084\n",
      "Train Epoch: 1389 [1200/1612 (99%)] Loss: 0.171138\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1390 [0/1612 (0%)] Loss: 0.103978\n",
      "Train Epoch: 1390 [160/1612 (10%)] Loss: 0.519116\n",
      "Train Epoch: 1390 [320/1612 (20%)] Loss: 0.309060\n",
      "Train Epoch: 1390 [480/1612 (30%)] Loss: 0.256765\n",
      "Train Epoch: 1390 [640/1612 (40%)] Loss: 0.302008\n",
      "Train Epoch: 1390 [800/1612 (50%)] Loss: 0.209124\n",
      "Train Epoch: 1390 [960/1612 (59%)] Loss: 0.257502\n",
      "Train Epoch: 1390 [1120/1612 (69%)] Loss: 0.265775\n",
      "Train Epoch: 1390 [1280/1612 (79%)] Loss: 0.443160\n",
      "Train Epoch: 1390 [1440/1612 (89%)] Loss: 0.292117\n",
      "Train Epoch: 1390 [1200/1612 (99%)] Loss: 0.430192\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1391 [0/1612 (0%)] Loss: 0.280913\n",
      "Train Epoch: 1391 [160/1612 (10%)] Loss: 0.169234\n",
      "Train Epoch: 1391 [320/1612 (20%)] Loss: 0.338027\n",
      "Train Epoch: 1391 [480/1612 (30%)] Loss: 0.181329\n",
      "Train Epoch: 1391 [640/1612 (40%)] Loss: 0.335927\n",
      "Train Epoch: 1391 [800/1612 (50%)] Loss: 0.317789\n",
      "Train Epoch: 1391 [960/1612 (59%)] Loss: 0.281914\n",
      "Train Epoch: 1391 [1120/1612 (69%)] Loss: 0.383036\n",
      "Train Epoch: 1391 [1280/1612 (79%)] Loss: 0.283438\n",
      "Train Epoch: 1391 [1440/1612 (89%)] Loss: 0.463697\n",
      "Train Epoch: 1391 [1200/1612 (99%)] Loss: 0.322466\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1392 [0/1612 (0%)] Loss: 0.390192\n",
      "Train Epoch: 1392 [160/1612 (10%)] Loss: 0.306028\n",
      "Train Epoch: 1392 [320/1612 (20%)] Loss: 0.414056\n",
      "Train Epoch: 1392 [480/1612 (30%)] Loss: 0.266734\n",
      "Train Epoch: 1392 [640/1612 (40%)] Loss: 0.230853\n",
      "Train Epoch: 1392 [800/1612 (50%)] Loss: 0.229546\n",
      "Train Epoch: 1392 [960/1612 (59%)] Loss: 0.166437\n",
      "Train Epoch: 1392 [1120/1612 (69%)] Loss: 0.219836\n",
      "Train Epoch: 1392 [1280/1612 (79%)] Loss: 0.118597\n",
      "Train Epoch: 1392 [1440/1612 (89%)] Loss: 0.282597\n",
      "Train Epoch: 1392 [1200/1612 (99%)] Loss: 0.180899\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1393 [0/1612 (0%)] Loss: 0.134158\n",
      "Train Epoch: 1393 [160/1612 (10%)] Loss: 0.463471\n",
      "Train Epoch: 1393 [320/1612 (20%)] Loss: 0.315197\n",
      "Train Epoch: 1393 [480/1612 (30%)] Loss: 0.294615\n",
      "Train Epoch: 1393 [640/1612 (40%)] Loss: 0.288249\n",
      "Train Epoch: 1393 [800/1612 (50%)] Loss: 0.498965\n",
      "Train Epoch: 1393 [960/1612 (59%)] Loss: 0.463231\n",
      "Train Epoch: 1393 [1120/1612 (69%)] Loss: 0.297084\n",
      "Train Epoch: 1393 [1280/1612 (79%)] Loss: 0.571838\n",
      "Train Epoch: 1393 [1440/1612 (89%)] Loss: 0.332034\n",
      "Train Epoch: 1393 [1200/1612 (99%)] Loss: 0.140865\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1394 [0/1612 (0%)] Loss: 0.278272\n",
      "Train Epoch: 1394 [160/1612 (10%)] Loss: 0.287465\n",
      "Train Epoch: 1394 [320/1612 (20%)] Loss: 0.211723\n",
      "Train Epoch: 1394 [480/1612 (30%)] Loss: 0.272152\n",
      "Train Epoch: 1394 [640/1612 (40%)] Loss: 0.467411\n",
      "Train Epoch: 1394 [800/1612 (50%)] Loss: 0.142644\n",
      "Train Epoch: 1394 [960/1612 (59%)] Loss: 0.285430\n",
      "Train Epoch: 1394 [1120/1612 (69%)] Loss: 0.180720\n",
      "Train Epoch: 1394 [1280/1612 (79%)] Loss: 0.380927\n",
      "Train Epoch: 1394 [1440/1612 (89%)] Loss: 0.567310\n",
      "Train Epoch: 1394 [1200/1612 (99%)] Loss: 0.307513\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1395 [0/1612 (0%)] Loss: 0.134656\n",
      "Train Epoch: 1395 [160/1612 (10%)] Loss: 0.166256\n",
      "Train Epoch: 1395 [320/1612 (20%)] Loss: 0.156442\n",
      "Train Epoch: 1395 [480/1612 (30%)] Loss: 0.201432\n",
      "Train Epoch: 1395 [640/1612 (40%)] Loss: 0.122472\n",
      "Train Epoch: 1395 [800/1612 (50%)] Loss: 0.386407\n",
      "Train Epoch: 1395 [960/1612 (59%)] Loss: 0.552661\n",
      "Train Epoch: 1395 [1120/1612 (69%)] Loss: 0.212539\n",
      "Train Epoch: 1395 [1280/1612 (79%)] Loss: 0.399673\n",
      "Train Epoch: 1395 [1440/1612 (89%)] Loss: 0.241289\n",
      "Train Epoch: 1395 [1200/1612 (99%)] Loss: 0.328627\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1396 [0/1612 (0%)] Loss: 0.193395\n",
      "Train Epoch: 1396 [160/1612 (10%)] Loss: 0.423961\n",
      "Train Epoch: 1396 [320/1612 (20%)] Loss: 0.270152\n",
      "Train Epoch: 1396 [480/1612 (30%)] Loss: 0.778510\n",
      "Train Epoch: 1396 [640/1612 (40%)] Loss: 0.392240\n",
      "Train Epoch: 1396 [800/1612 (50%)] Loss: 0.479454\n",
      "Train Epoch: 1396 [960/1612 (59%)] Loss: 0.205477\n",
      "Train Epoch: 1396 [1120/1612 (69%)] Loss: 0.206295\n",
      "Train Epoch: 1396 [1280/1612 (79%)] Loss: 0.298993\n",
      "Train Epoch: 1396 [1440/1612 (89%)] Loss: 0.376099\n",
      "Train Epoch: 1396 [1200/1612 (99%)] Loss: 0.528918\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1397 [0/1612 (0%)] Loss: 0.167409\n",
      "Train Epoch: 1397 [160/1612 (10%)] Loss: 0.146723\n",
      "Train Epoch: 1397 [320/1612 (20%)] Loss: 0.160106\n",
      "Train Epoch: 1397 [480/1612 (30%)] Loss: 0.503352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1397 [640/1612 (40%)] Loss: 0.127105\n",
      "Train Epoch: 1397 [800/1612 (50%)] Loss: 0.360305\n",
      "Train Epoch: 1397 [960/1612 (59%)] Loss: 0.133845\n",
      "Train Epoch: 1397 [1120/1612 (69%)] Loss: 0.434990\n",
      "Train Epoch: 1397 [1280/1612 (79%)] Loss: 0.274274\n",
      "Train Epoch: 1397 [1440/1612 (89%)] Loss: 0.333566\n",
      "Train Epoch: 1397 [1200/1612 (99%)] Loss: 0.256221\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1398 [0/1612 (0%)] Loss: 0.494920\n",
      "Train Epoch: 1398 [160/1612 (10%)] Loss: 0.229145\n",
      "Train Epoch: 1398 [320/1612 (20%)] Loss: 0.279624\n",
      "Train Epoch: 1398 [480/1612 (30%)] Loss: 0.169810\n",
      "Train Epoch: 1398 [640/1612 (40%)] Loss: 0.248702\n",
      "Train Epoch: 1398 [800/1612 (50%)] Loss: 0.185641\n",
      "Train Epoch: 1398 [960/1612 (59%)] Loss: 0.327570\n",
      "Train Epoch: 1398 [1120/1612 (69%)] Loss: 0.374797\n",
      "Train Epoch: 1398 [1280/1612 (79%)] Loss: 0.360608\n",
      "Train Epoch: 1398 [1440/1612 (89%)] Loss: 0.205436\n",
      "Train Epoch: 1398 [1200/1612 (99%)] Loss: 0.188870\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1399 [0/1612 (0%)] Loss: 0.145991\n",
      "Train Epoch: 1399 [160/1612 (10%)] Loss: 0.147831\n",
      "Train Epoch: 1399 [320/1612 (20%)] Loss: 0.288979\n",
      "Train Epoch: 1399 [480/1612 (30%)] Loss: 0.490402\n",
      "Train Epoch: 1399 [640/1612 (40%)] Loss: 0.261922\n",
      "Train Epoch: 1399 [800/1612 (50%)] Loss: 0.347292\n",
      "Train Epoch: 1399 [960/1612 (59%)] Loss: 0.335560\n",
      "Train Epoch: 1399 [1120/1612 (69%)] Loss: 0.293466\n",
      "Train Epoch: 1399 [1280/1612 (79%)] Loss: 0.375549\n",
      "Train Epoch: 1399 [1440/1612 (89%)] Loss: 0.129613\n",
      "Train Epoch: 1399 [1200/1612 (99%)] Loss: 0.464391\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1400 [0/1612 (0%)] Loss: 0.271821\n",
      "Train Epoch: 1400 [160/1612 (10%)] Loss: 0.504206\n",
      "Train Epoch: 1400 [320/1612 (20%)] Loss: 0.337475\n",
      "Train Epoch: 1400 [480/1612 (30%)] Loss: 0.257803\n",
      "Train Epoch: 1400 [640/1612 (40%)] Loss: 0.505872\n",
      "Train Epoch: 1400 [800/1612 (50%)] Loss: 0.194534\n",
      "Train Epoch: 1400 [960/1612 (59%)] Loss: 0.335239\n",
      "Train Epoch: 1400 [1120/1612 (69%)] Loss: 0.264754\n",
      "Train Epoch: 1400 [1280/1612 (79%)] Loss: 0.201267\n",
      "Train Epoch: 1400 [1440/1612 (89%)] Loss: 0.174463\n",
      "Train Epoch: 1400 [1200/1612 (99%)] Loss: 0.261643\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1401 [0/1612 (0%)] Loss: 0.162679\n",
      "Train Epoch: 1401 [160/1612 (10%)] Loss: 0.274171\n",
      "Train Epoch: 1401 [320/1612 (20%)] Loss: 0.208794\n",
      "Train Epoch: 1401 [480/1612 (30%)] Loss: 0.306441\n",
      "Train Epoch: 1401 [640/1612 (40%)] Loss: 0.466260\n",
      "Train Epoch: 1401 [800/1612 (50%)] Loss: 0.713092\n",
      "Train Epoch: 1401 [960/1612 (59%)] Loss: 0.556966\n",
      "Train Epoch: 1401 [1120/1612 (69%)] Loss: 0.178685\n",
      "Train Epoch: 1401 [1280/1612 (79%)] Loss: 0.538624\n",
      "Train Epoch: 1401 [1440/1612 (89%)] Loss: 0.301879\n",
      "Train Epoch: 1401 [1200/1612 (99%)] Loss: 0.138383\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1402 [0/1612 (0%)] Loss: 0.137436\n",
      "Train Epoch: 1402 [160/1612 (10%)] Loss: 0.217937\n",
      "Train Epoch: 1402 [320/1612 (20%)] Loss: 0.176451\n",
      "Train Epoch: 1402 [480/1612 (30%)] Loss: 0.313199\n",
      "Train Epoch: 1402 [640/1612 (40%)] Loss: 0.352895\n",
      "Train Epoch: 1402 [800/1612 (50%)] Loss: 0.196156\n",
      "Train Epoch: 1402 [960/1612 (59%)] Loss: 0.568429\n",
      "Train Epoch: 1402 [1120/1612 (69%)] Loss: 0.625515\n",
      "Train Epoch: 1402 [1280/1612 (79%)] Loss: 0.277785\n",
      "Train Epoch: 1402 [1440/1612 (89%)] Loss: 0.261975\n",
      "Train Epoch: 1402 [1200/1612 (99%)] Loss: 0.196482\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1403 [0/1612 (0%)] Loss: 0.180723\n",
      "Train Epoch: 1403 [160/1612 (10%)] Loss: 0.289750\n",
      "Train Epoch: 1403 [320/1612 (20%)] Loss: 0.280632\n",
      "Train Epoch: 1403 [480/1612 (30%)] Loss: 0.522088\n",
      "Train Epoch: 1403 [640/1612 (40%)] Loss: 0.203628\n",
      "Train Epoch: 1403 [800/1612 (50%)] Loss: 0.290516\n",
      "Train Epoch: 1403 [960/1612 (59%)] Loss: 0.259503\n",
      "Train Epoch: 1403 [1120/1612 (69%)] Loss: 0.198706\n",
      "Train Epoch: 1403 [1280/1612 (79%)] Loss: 0.568067\n",
      "Train Epoch: 1403 [1440/1612 (89%)] Loss: 0.082980\n",
      "Train Epoch: 1403 [1200/1612 (99%)] Loss: 0.348401\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1404 [0/1612 (0%)] Loss: 0.246789\n",
      "Train Epoch: 1404 [160/1612 (10%)] Loss: 0.428622\n",
      "Train Epoch: 1404 [320/1612 (20%)] Loss: 0.335720\n",
      "Train Epoch: 1404 [480/1612 (30%)] Loss: 0.400788\n",
      "Train Epoch: 1404 [640/1612 (40%)] Loss: 0.572808\n",
      "Train Epoch: 1404 [800/1612 (50%)] Loss: 0.270341\n",
      "Train Epoch: 1404 [960/1612 (59%)] Loss: 0.329254\n",
      "Train Epoch: 1404 [1120/1612 (69%)] Loss: 0.190395\n",
      "Train Epoch: 1404 [1280/1612 (79%)] Loss: 0.330333\n",
      "Train Epoch: 1404 [1440/1612 (89%)] Loss: 0.424897\n",
      "Train Epoch: 1404 [1200/1612 (99%)] Loss: 0.254560\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1405 [0/1612 (0%)] Loss: 0.259044\n",
      "Train Epoch: 1405 [160/1612 (10%)] Loss: 0.245497\n",
      "Train Epoch: 1405 [320/1612 (20%)] Loss: 0.254502\n",
      "Train Epoch: 1405 [480/1612 (30%)] Loss: 0.274995\n",
      "Train Epoch: 1405 [640/1612 (40%)] Loss: 0.375667\n",
      "Train Epoch: 1405 [800/1612 (50%)] Loss: 0.171829\n",
      "Train Epoch: 1405 [960/1612 (59%)] Loss: 0.230315\n",
      "Train Epoch: 1405 [1120/1612 (69%)] Loss: 0.210944\n",
      "Train Epoch: 1405 [1280/1612 (79%)] Loss: 0.295967\n",
      "Train Epoch: 1405 [1440/1612 (89%)] Loss: 0.224297\n",
      "Train Epoch: 1405 [1200/1612 (99%)] Loss: 0.114920\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1406 [0/1612 (0%)] Loss: 0.450344\n",
      "Train Epoch: 1406 [160/1612 (10%)] Loss: 0.372958\n",
      "Train Epoch: 1406 [320/1612 (20%)] Loss: 0.371856\n",
      "Train Epoch: 1406 [480/1612 (30%)] Loss: 0.438837\n",
      "Train Epoch: 1406 [640/1612 (40%)] Loss: 0.243114\n",
      "Train Epoch: 1406 [800/1612 (50%)] Loss: 0.161088\n",
      "Train Epoch: 1406 [960/1612 (59%)] Loss: 0.377175\n",
      "Train Epoch: 1406 [1120/1612 (69%)] Loss: 0.236914\n",
      "Train Epoch: 1406 [1280/1612 (79%)] Loss: 0.260020\n",
      "Train Epoch: 1406 [1440/1612 (89%)] Loss: 0.204835\n",
      "Train Epoch: 1406 [1200/1612 (99%)] Loss: 0.212437\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1407 [0/1612 (0%)] Loss: 0.428372\n",
      "Train Epoch: 1407 [160/1612 (10%)] Loss: 0.553025\n",
      "Train Epoch: 1407 [320/1612 (20%)] Loss: 0.429216\n",
      "Train Epoch: 1407 [480/1612 (30%)] Loss: 0.343653\n",
      "Train Epoch: 1407 [640/1612 (40%)] Loss: 0.233861\n",
      "Train Epoch: 1407 [800/1612 (50%)] Loss: 0.160681\n",
      "Train Epoch: 1407 [960/1612 (59%)] Loss: 0.266205\n",
      "Train Epoch: 1407 [1120/1612 (69%)] Loss: 0.387085\n",
      "Train Epoch: 1407 [1280/1612 (79%)] Loss: 0.296096\n",
      "Train Epoch: 1407 [1440/1612 (89%)] Loss: 0.112977\n",
      "Train Epoch: 1407 [1200/1612 (99%)] Loss: 0.110799\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1408 [0/1612 (0%)] Loss: 0.404547\n",
      "Train Epoch: 1408 [160/1612 (10%)] Loss: 0.354783\n",
      "Train Epoch: 1408 [320/1612 (20%)] Loss: 0.191013\n",
      "Train Epoch: 1408 [480/1612 (30%)] Loss: 0.438132\n",
      "Train Epoch: 1408 [640/1612 (40%)] Loss: 0.113455\n",
      "Train Epoch: 1408 [800/1612 (50%)] Loss: 0.195932\n",
      "Train Epoch: 1408 [960/1612 (59%)] Loss: 0.489276\n",
      "Train Epoch: 1408 [1120/1612 (69%)] Loss: 0.487813\n",
      "Train Epoch: 1408 [1280/1612 (79%)] Loss: 0.508027\n",
      "Train Epoch: 1408 [1440/1612 (89%)] Loss: 0.200094\n",
      "Train Epoch: 1408 [1200/1612 (99%)] Loss: 0.322731\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1409 [0/1612 (0%)] Loss: 0.305952\n",
      "Train Epoch: 1409 [160/1612 (10%)] Loss: 0.476494\n",
      "Train Epoch: 1409 [320/1612 (20%)] Loss: 0.342602\n",
      "Train Epoch: 1409 [480/1612 (30%)] Loss: 0.228265\n",
      "Train Epoch: 1409 [640/1612 (40%)] Loss: 0.359694\n",
      "Train Epoch: 1409 [800/1612 (50%)] Loss: 0.295238\n",
      "Train Epoch: 1409 [960/1612 (59%)] Loss: 0.192768\n",
      "Train Epoch: 1409 [1120/1612 (69%)] Loss: 0.389503\n",
      "Train Epoch: 1409 [1280/1612 (79%)] Loss: 0.268170\n",
      "Train Epoch: 1409 [1440/1612 (89%)] Loss: 0.165096\n",
      "Train Epoch: 1409 [1200/1612 (99%)] Loss: 0.287424\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1410 [0/1612 (0%)] Loss: 0.326732\n",
      "Train Epoch: 1410 [160/1612 (10%)] Loss: 0.236126\n",
      "Train Epoch: 1410 [320/1612 (20%)] Loss: 0.314718\n",
      "Train Epoch: 1410 [480/1612 (30%)] Loss: 0.335995\n",
      "Train Epoch: 1410 [640/1612 (40%)] Loss: 0.528729\n",
      "Train Epoch: 1410 [800/1612 (50%)] Loss: 0.516879\n",
      "Train Epoch: 1410 [960/1612 (59%)] Loss: 0.209645\n",
      "Train Epoch: 1410 [1120/1612 (69%)] Loss: 0.488939\n",
      "Train Epoch: 1410 [1280/1612 (79%)] Loss: 0.170137\n",
      "Train Epoch: 1410 [1440/1612 (89%)] Loss: 0.415575\n",
      "Train Epoch: 1410 [1200/1612 (99%)] Loss: 0.477620\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1411 [0/1612 (0%)] Loss: 0.188736\n",
      "Train Epoch: 1411 [160/1612 (10%)] Loss: 0.158035\n",
      "Train Epoch: 1411 [320/1612 (20%)] Loss: 0.324961\n",
      "Train Epoch: 1411 [480/1612 (30%)] Loss: 0.346090\n",
      "Train Epoch: 1411 [640/1612 (40%)] Loss: 0.146689\n",
      "Train Epoch: 1411 [800/1612 (50%)] Loss: 0.361109\n",
      "Train Epoch: 1411 [960/1612 (59%)] Loss: 0.395531\n",
      "Train Epoch: 1411 [1120/1612 (69%)] Loss: 0.229470\n",
      "Train Epoch: 1411 [1280/1612 (79%)] Loss: 0.413395\n",
      "Train Epoch: 1411 [1440/1612 (89%)] Loss: 0.175281\n",
      "Train Epoch: 1411 [1200/1612 (99%)] Loss: 0.288259\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1412 [0/1612 (0%)] Loss: 0.213694\n",
      "Train Epoch: 1412 [160/1612 (10%)] Loss: 0.230337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1412 [320/1612 (20%)] Loss: 0.232541\n",
      "Train Epoch: 1412 [480/1612 (30%)] Loss: 0.242533\n",
      "Train Epoch: 1412 [640/1612 (40%)] Loss: 0.495859\n",
      "Train Epoch: 1412 [800/1612 (50%)] Loss: 0.178074\n",
      "Train Epoch: 1412 [960/1612 (59%)] Loss: 0.369142\n",
      "Train Epoch: 1412 [1120/1612 (69%)] Loss: 0.313866\n",
      "Train Epoch: 1412 [1280/1612 (79%)] Loss: 0.334479\n",
      "Train Epoch: 1412 [1440/1612 (89%)] Loss: 0.170541\n",
      "Train Epoch: 1412 [1200/1612 (99%)] Loss: 0.400332\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1413 [0/1612 (0%)] Loss: 0.500982\n",
      "Train Epoch: 1413 [160/1612 (10%)] Loss: 0.154953\n",
      "Train Epoch: 1413 [320/1612 (20%)] Loss: 0.335608\n",
      "Train Epoch: 1413 [480/1612 (30%)] Loss: 0.252899\n",
      "Train Epoch: 1413 [640/1612 (40%)] Loss: 0.193790\n",
      "Train Epoch: 1413 [800/1612 (50%)] Loss: 0.299135\n",
      "Train Epoch: 1413 [960/1612 (59%)] Loss: 0.328593\n",
      "Train Epoch: 1413 [1120/1612 (69%)] Loss: 0.420809\n",
      "Train Epoch: 1413 [1280/1612 (79%)] Loss: 0.273826\n",
      "Train Epoch: 1413 [1440/1612 (89%)] Loss: 0.147814\n",
      "Train Epoch: 1413 [1200/1612 (99%)] Loss: 0.345965\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1414 [0/1612 (0%)] Loss: 0.158420\n",
      "Train Epoch: 1414 [160/1612 (10%)] Loss: 0.440870\n",
      "Train Epoch: 1414 [320/1612 (20%)] Loss: 0.526344\n",
      "Train Epoch: 1414 [480/1612 (30%)] Loss: 0.241366\n",
      "Train Epoch: 1414 [640/1612 (40%)] Loss: 0.337903\n",
      "Train Epoch: 1414 [800/1612 (50%)] Loss: 0.253831\n",
      "Train Epoch: 1414 [960/1612 (59%)] Loss: 0.154428\n",
      "Train Epoch: 1414 [1120/1612 (69%)] Loss: 0.307660\n",
      "Train Epoch: 1414 [1280/1612 (79%)] Loss: 0.113421\n",
      "Train Epoch: 1414 [1440/1612 (89%)] Loss: 0.402986\n",
      "Train Epoch: 1414 [1200/1612 (99%)] Loss: 0.519640\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1415 [0/1612 (0%)] Loss: 0.384616\n",
      "Train Epoch: 1415 [160/1612 (10%)] Loss: 0.320555\n",
      "Train Epoch: 1415 [320/1612 (20%)] Loss: 0.301246\n",
      "Train Epoch: 1415 [480/1612 (30%)] Loss: 0.184008\n",
      "Train Epoch: 1415 [640/1612 (40%)] Loss: 0.441594\n",
      "Train Epoch: 1415 [800/1612 (50%)] Loss: 0.197213\n",
      "Train Epoch: 1415 [960/1612 (59%)] Loss: 0.304194\n",
      "Train Epoch: 1415 [1120/1612 (69%)] Loss: 0.426599\n",
      "Train Epoch: 1415 [1280/1612 (79%)] Loss: 0.471097\n",
      "Train Epoch: 1415 [1440/1612 (89%)] Loss: 0.356795\n",
      "Train Epoch: 1415 [1200/1612 (99%)] Loss: 0.110171\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1416 [0/1612 (0%)] Loss: 0.236575\n",
      "Train Epoch: 1416 [160/1612 (10%)] Loss: 0.128993\n",
      "Train Epoch: 1416 [320/1612 (20%)] Loss: 0.315044\n",
      "Train Epoch: 1416 [480/1612 (30%)] Loss: 0.329455\n",
      "Train Epoch: 1416 [640/1612 (40%)] Loss: 0.292080\n",
      "Train Epoch: 1416 [800/1612 (50%)] Loss: 0.261086\n",
      "Train Epoch: 1416 [960/1612 (59%)] Loss: 0.194857\n",
      "Train Epoch: 1416 [1120/1612 (69%)] Loss: 0.292631\n",
      "Train Epoch: 1416 [1280/1612 (79%)] Loss: 0.343187\n",
      "Train Epoch: 1416 [1440/1612 (89%)] Loss: 0.226560\n",
      "Train Epoch: 1416 [1200/1612 (99%)] Loss: 0.270521\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1417 [0/1612 (0%)] Loss: 0.344663\n",
      "Train Epoch: 1417 [160/1612 (10%)] Loss: 0.362217\n",
      "Train Epoch: 1417 [320/1612 (20%)] Loss: 0.235885\n",
      "Train Epoch: 1417 [480/1612 (30%)] Loss: 0.188502\n",
      "Train Epoch: 1417 [640/1612 (40%)] Loss: 0.356304\n",
      "Train Epoch: 1417 [800/1612 (50%)] Loss: 0.150037\n",
      "Train Epoch: 1417 [960/1612 (59%)] Loss: 0.391888\n",
      "Train Epoch: 1417 [1120/1612 (69%)] Loss: 0.210065\n",
      "Train Epoch: 1417 [1280/1612 (79%)] Loss: 0.233998\n",
      "Train Epoch: 1417 [1440/1612 (89%)] Loss: 0.214182\n",
      "Train Epoch: 1417 [1200/1612 (99%)] Loss: 0.540288\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1418 [0/1612 (0%)] Loss: 0.245695\n",
      "Train Epoch: 1418 [160/1612 (10%)] Loss: 0.381541\n",
      "Train Epoch: 1418 [320/1612 (20%)] Loss: 0.377764\n",
      "Train Epoch: 1418 [480/1612 (30%)] Loss: 0.364760\n",
      "Train Epoch: 1418 [640/1612 (40%)] Loss: 0.101428\n",
      "Train Epoch: 1418 [800/1612 (50%)] Loss: 0.413749\n",
      "Train Epoch: 1418 [960/1612 (59%)] Loss: 0.470770\n",
      "Train Epoch: 1418 [1120/1612 (69%)] Loss: 0.418991\n",
      "Train Epoch: 1418 [1280/1612 (79%)] Loss: 0.232431\n",
      "Train Epoch: 1418 [1440/1612 (89%)] Loss: 0.361252\n",
      "Train Epoch: 1418 [1200/1612 (99%)] Loss: 0.319969\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1419 [0/1612 (0%)] Loss: 0.440192\n",
      "Train Epoch: 1419 [160/1612 (10%)] Loss: 0.260691\n",
      "Train Epoch: 1419 [320/1612 (20%)] Loss: 0.213866\n",
      "Train Epoch: 1419 [480/1612 (30%)] Loss: 0.355899\n",
      "Train Epoch: 1419 [640/1612 (40%)] Loss: 0.293076\n",
      "Train Epoch: 1419 [800/1612 (50%)] Loss: 0.143441\n",
      "Train Epoch: 1419 [960/1612 (59%)] Loss: 0.201945\n",
      "Train Epoch: 1419 [1120/1612 (69%)] Loss: 0.233682\n",
      "Train Epoch: 1419 [1280/1612 (79%)] Loss: 0.318122\n",
      "Train Epoch: 1419 [1440/1612 (89%)] Loss: 0.217050\n",
      "Train Epoch: 1419 [1200/1612 (99%)] Loss: 0.357103\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1420 [0/1612 (0%)] Loss: 0.322112\n",
      "Train Epoch: 1420 [160/1612 (10%)] Loss: 0.275568\n",
      "Train Epoch: 1420 [320/1612 (20%)] Loss: 0.158042\n",
      "Train Epoch: 1420 [480/1612 (30%)] Loss: 0.389936\n",
      "Train Epoch: 1420 [640/1612 (40%)] Loss: 0.211796\n",
      "Train Epoch: 1420 [800/1612 (50%)] Loss: 0.187835\n",
      "Train Epoch: 1420 [960/1612 (59%)] Loss: 0.316818\n",
      "Train Epoch: 1420 [1120/1612 (69%)] Loss: 0.366893\n",
      "Train Epoch: 1420 [1280/1612 (79%)] Loss: 0.395625\n",
      "Train Epoch: 1420 [1440/1612 (89%)] Loss: 0.389553\n",
      "Train Epoch: 1420 [1200/1612 (99%)] Loss: 0.096349\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1421 [0/1612 (0%)] Loss: 0.385512\n",
      "Train Epoch: 1421 [160/1612 (10%)] Loss: 0.706776\n",
      "Train Epoch: 1421 [320/1612 (20%)] Loss: 0.162265\n",
      "Train Epoch: 1421 [480/1612 (30%)] Loss: 0.389398\n",
      "Train Epoch: 1421 [640/1612 (40%)] Loss: 0.236225\n",
      "Train Epoch: 1421 [800/1612 (50%)] Loss: 0.332296\n",
      "Train Epoch: 1421 [960/1612 (59%)] Loss: 0.294841\n",
      "Train Epoch: 1421 [1120/1612 (69%)] Loss: 0.219020\n",
      "Train Epoch: 1421 [1280/1612 (79%)] Loss: 0.266986\n",
      "Train Epoch: 1421 [1440/1612 (89%)] Loss: 0.342522\n",
      "Train Epoch: 1421 [1200/1612 (99%)] Loss: 0.238045\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1422 [0/1612 (0%)] Loss: 0.405660\n",
      "Train Epoch: 1422 [160/1612 (10%)] Loss: 0.199094\n",
      "Train Epoch: 1422 [320/1612 (20%)] Loss: 0.191132\n",
      "Train Epoch: 1422 [480/1612 (30%)] Loss: 0.271699\n",
      "Train Epoch: 1422 [640/1612 (40%)] Loss: 0.311422\n",
      "Train Epoch: 1422 [800/1612 (50%)] Loss: 0.150449\n",
      "Train Epoch: 1422 [960/1612 (59%)] Loss: 0.127705\n",
      "Train Epoch: 1422 [1120/1612 (69%)] Loss: 0.205258\n",
      "Train Epoch: 1422 [1280/1612 (79%)] Loss: 0.254210\n",
      "Train Epoch: 1422 [1440/1612 (89%)] Loss: 0.367690\n",
      "Train Epoch: 1422 [1200/1612 (99%)] Loss: 0.272321\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1423 [0/1612 (0%)] Loss: 0.271993\n",
      "Train Epoch: 1423 [160/1612 (10%)] Loss: 0.288385\n",
      "Train Epoch: 1423 [320/1612 (20%)] Loss: 0.220439\n",
      "Train Epoch: 1423 [480/1612 (30%)] Loss: 0.175141\n",
      "Train Epoch: 1423 [640/1612 (40%)] Loss: 0.529265\n",
      "Train Epoch: 1423 [800/1612 (50%)] Loss: 0.216154\n",
      "Train Epoch: 1423 [960/1612 (59%)] Loss: 0.310342\n",
      "Train Epoch: 1423 [1120/1612 (69%)] Loss: 0.231197\n",
      "Train Epoch: 1423 [1280/1612 (79%)] Loss: 0.329304\n",
      "Train Epoch: 1423 [1440/1612 (89%)] Loss: 0.578912\n",
      "Train Epoch: 1423 [1200/1612 (99%)] Loss: 0.204344\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1424 [0/1612 (0%)] Loss: 0.401919\n",
      "Train Epoch: 1424 [160/1612 (10%)] Loss: 0.251482\n",
      "Train Epoch: 1424 [320/1612 (20%)] Loss: 0.218755\n",
      "Train Epoch: 1424 [480/1612 (30%)] Loss: 0.270241\n",
      "Train Epoch: 1424 [640/1612 (40%)] Loss: 0.362324\n",
      "Train Epoch: 1424 [800/1612 (50%)] Loss: 0.303110\n",
      "Train Epoch: 1424 [960/1612 (59%)] Loss: 0.317891\n",
      "Train Epoch: 1424 [1120/1612 (69%)] Loss: 0.353672\n",
      "Train Epoch: 1424 [1280/1612 (79%)] Loss: 0.288529\n",
      "Train Epoch: 1424 [1440/1612 (89%)] Loss: 0.244225\n",
      "Train Epoch: 1424 [1200/1612 (99%)] Loss: 0.205276\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1425 [0/1612 (0%)] Loss: 0.124173\n",
      "Train Epoch: 1425 [160/1612 (10%)] Loss: 0.099293\n",
      "Train Epoch: 1425 [320/1612 (20%)] Loss: 0.399994\n",
      "Train Epoch: 1425 [480/1612 (30%)] Loss: 0.591631\n",
      "Train Epoch: 1425 [640/1612 (40%)] Loss: 0.217526\n",
      "Train Epoch: 1425 [800/1612 (50%)] Loss: 0.348785\n",
      "Train Epoch: 1425 [960/1612 (59%)] Loss: 0.380350\n",
      "Train Epoch: 1425 [1120/1612 (69%)] Loss: 0.269361\n",
      "Train Epoch: 1425 [1280/1612 (79%)] Loss: 0.292141\n",
      "Train Epoch: 1425 [1440/1612 (89%)] Loss: 0.307833\n",
      "Train Epoch: 1425 [1200/1612 (99%)] Loss: 0.331387\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1426 [0/1612 (0%)] Loss: 0.204644\n",
      "Train Epoch: 1426 [160/1612 (10%)] Loss: 0.460968\n",
      "Train Epoch: 1426 [320/1612 (20%)] Loss: 0.297625\n",
      "Train Epoch: 1426 [480/1612 (30%)] Loss: 0.381506\n",
      "Train Epoch: 1426 [640/1612 (40%)] Loss: 0.278688\n",
      "Train Epoch: 1426 [800/1612 (50%)] Loss: 0.232112\n",
      "Train Epoch: 1426 [960/1612 (59%)] Loss: 0.314309\n",
      "Train Epoch: 1426 [1120/1612 (69%)] Loss: 0.087815\n",
      "Train Epoch: 1426 [1280/1612 (79%)] Loss: 0.373369\n",
      "Train Epoch: 1426 [1440/1612 (89%)] Loss: 0.140560\n",
      "Train Epoch: 1426 [1200/1612 (99%)] Loss: 0.320338\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1427 [0/1612 (0%)] Loss: 0.130115\n",
      "Train Epoch: 1427 [160/1612 (10%)] Loss: 0.225372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1427 [320/1612 (20%)] Loss: 0.379355\n",
      "Train Epoch: 1427 [480/1612 (30%)] Loss: 0.234444\n",
      "Train Epoch: 1427 [640/1612 (40%)] Loss: 0.211053\n",
      "Train Epoch: 1427 [800/1612 (50%)] Loss: 0.354670\n",
      "Train Epoch: 1427 [960/1612 (59%)] Loss: 0.355943\n",
      "Train Epoch: 1427 [1120/1612 (69%)] Loss: 0.107696\n",
      "Train Epoch: 1427 [1280/1612 (79%)] Loss: 0.404463\n",
      "Train Epoch: 1427 [1440/1612 (89%)] Loss: 0.242161\n",
      "Train Epoch: 1427 [1200/1612 (99%)] Loss: 0.247114\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1428 [0/1612 (0%)] Loss: 0.185314\n",
      "Train Epoch: 1428 [160/1612 (10%)] Loss: 0.230514\n",
      "Train Epoch: 1428 [320/1612 (20%)] Loss: 0.398592\n",
      "Train Epoch: 1428 [480/1612 (30%)] Loss: 0.395679\n",
      "Train Epoch: 1428 [640/1612 (40%)] Loss: 0.427943\n",
      "Train Epoch: 1428 [800/1612 (50%)] Loss: 0.166647\n",
      "Train Epoch: 1428 [960/1612 (59%)] Loss: 0.202286\n",
      "Train Epoch: 1428 [1120/1612 (69%)] Loss: 0.201497\n",
      "Train Epoch: 1428 [1280/1612 (79%)] Loss: 0.280185\n",
      "Train Epoch: 1428 [1440/1612 (89%)] Loss: 0.349923\n",
      "Train Epoch: 1428 [1200/1612 (99%)] Loss: 0.226169\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1429 [0/1612 (0%)] Loss: 0.126175\n",
      "Train Epoch: 1429 [160/1612 (10%)] Loss: 0.299855\n",
      "Train Epoch: 1429 [320/1612 (20%)] Loss: 0.521189\n",
      "Train Epoch: 1429 [480/1612 (30%)] Loss: 0.245901\n",
      "Train Epoch: 1429 [640/1612 (40%)] Loss: 0.515202\n",
      "Train Epoch: 1429 [800/1612 (50%)] Loss: 0.282030\n",
      "Train Epoch: 1429 [960/1612 (59%)] Loss: 0.293476\n",
      "Train Epoch: 1429 [1120/1612 (69%)] Loss: 0.257117\n",
      "Train Epoch: 1429 [1280/1612 (79%)] Loss: 0.303731\n",
      "Train Epoch: 1429 [1440/1612 (89%)] Loss: 0.345674\n",
      "Train Epoch: 1429 [1200/1612 (99%)] Loss: 0.276347\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1430 [0/1612 (0%)] Loss: 0.452685\n",
      "Train Epoch: 1430 [160/1612 (10%)] Loss: 0.360901\n",
      "Train Epoch: 1430 [320/1612 (20%)] Loss: 0.132836\n",
      "Train Epoch: 1430 [480/1612 (30%)] Loss: 0.299375\n",
      "Train Epoch: 1430 [640/1612 (40%)] Loss: 0.343221\n",
      "Train Epoch: 1430 [800/1612 (50%)] Loss: 0.537309\n",
      "Train Epoch: 1430 [960/1612 (59%)] Loss: 0.267761\n",
      "Train Epoch: 1430 [1120/1612 (69%)] Loss: 0.273722\n",
      "Train Epoch: 1430 [1280/1612 (79%)] Loss: 0.212791\n",
      "Train Epoch: 1430 [1440/1612 (89%)] Loss: 0.591905\n",
      "Train Epoch: 1430 [1200/1612 (99%)] Loss: 0.194468\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1431 [0/1612 (0%)] Loss: 0.285342\n",
      "Train Epoch: 1431 [160/1612 (10%)] Loss: 0.163135\n",
      "Train Epoch: 1431 [320/1612 (20%)] Loss: 0.367187\n",
      "Train Epoch: 1431 [480/1612 (30%)] Loss: 0.462978\n",
      "Train Epoch: 1431 [640/1612 (40%)] Loss: 0.293885\n",
      "Train Epoch: 1431 [800/1612 (50%)] Loss: 0.218750\n",
      "Train Epoch: 1431 [960/1612 (59%)] Loss: 0.454352\n",
      "Train Epoch: 1431 [1120/1612 (69%)] Loss: 0.261308\n",
      "Train Epoch: 1431 [1280/1612 (79%)] Loss: 0.276102\n",
      "Train Epoch: 1431 [1440/1612 (89%)] Loss: 0.246692\n",
      "Train Epoch: 1431 [1200/1612 (99%)] Loss: 0.258605\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1432 [0/1612 (0%)] Loss: 0.188093\n",
      "Train Epoch: 1432 [160/1612 (10%)] Loss: 0.392222\n",
      "Train Epoch: 1432 [320/1612 (20%)] Loss: 0.181921\n",
      "Train Epoch: 1432 [480/1612 (30%)] Loss: 0.198179\n",
      "Train Epoch: 1432 [640/1612 (40%)] Loss: 0.454754\n",
      "Train Epoch: 1432 [800/1612 (50%)] Loss: 0.231475\n",
      "Train Epoch: 1432 [960/1612 (59%)] Loss: 0.430298\n",
      "Train Epoch: 1432 [1120/1612 (69%)] Loss: 0.279727\n",
      "Train Epoch: 1432 [1280/1612 (79%)] Loss: 0.271937\n",
      "Train Epoch: 1432 [1440/1612 (89%)] Loss: 0.263162\n",
      "Train Epoch: 1432 [1200/1612 (99%)] Loss: 0.244190\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1433 [0/1612 (0%)] Loss: 0.432428\n",
      "Train Epoch: 1433 [160/1612 (10%)] Loss: 0.185446\n",
      "Train Epoch: 1433 [320/1612 (20%)] Loss: 0.223712\n",
      "Train Epoch: 1433 [480/1612 (30%)] Loss: 0.180266\n",
      "Train Epoch: 1433 [640/1612 (40%)] Loss: 0.337834\n",
      "Train Epoch: 1433 [800/1612 (50%)] Loss: 0.097221\n",
      "Train Epoch: 1433 [960/1612 (59%)] Loss: 0.180867\n",
      "Train Epoch: 1433 [1120/1612 (69%)] Loss: 0.348512\n",
      "Train Epoch: 1433 [1280/1612 (79%)] Loss: 0.308052\n",
      "Train Epoch: 1433 [1440/1612 (89%)] Loss: 0.329845\n",
      "Train Epoch: 1433 [1200/1612 (99%)] Loss: 0.284661\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1434 [0/1612 (0%)] Loss: 0.078632\n",
      "Train Epoch: 1434 [160/1612 (10%)] Loss: 0.367841\n",
      "Train Epoch: 1434 [320/1612 (20%)] Loss: 0.311454\n",
      "Train Epoch: 1434 [480/1612 (30%)] Loss: 0.298747\n",
      "Train Epoch: 1434 [640/1612 (40%)] Loss: 0.426539\n",
      "Train Epoch: 1434 [800/1612 (50%)] Loss: 0.270510\n",
      "Train Epoch: 1434 [960/1612 (59%)] Loss: 0.187178\n",
      "Train Epoch: 1434 [1120/1612 (69%)] Loss: 0.188676\n",
      "Train Epoch: 1434 [1280/1612 (79%)] Loss: 0.227634\n",
      "Train Epoch: 1434 [1440/1612 (89%)] Loss: 0.190955\n",
      "Train Epoch: 1434 [1200/1612 (99%)] Loss: 0.316405\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1435 [0/1612 (0%)] Loss: 0.187138\n",
      "Train Epoch: 1435 [160/1612 (10%)] Loss: 0.193852\n",
      "Train Epoch: 1435 [320/1612 (20%)] Loss: 0.221722\n",
      "Train Epoch: 1435 [480/1612 (30%)] Loss: 0.225570\n",
      "Train Epoch: 1435 [640/1612 (40%)] Loss: 0.167650\n",
      "Train Epoch: 1435 [800/1612 (50%)] Loss: 0.328446\n",
      "Train Epoch: 1435 [960/1612 (59%)] Loss: 0.169421\n",
      "Train Epoch: 1435 [1120/1612 (69%)] Loss: 0.278283\n",
      "Train Epoch: 1435 [1280/1612 (79%)] Loss: 0.261818\n",
      "Train Epoch: 1435 [1440/1612 (89%)] Loss: 0.212678\n",
      "Train Epoch: 1435 [1200/1612 (99%)] Loss: 0.412577\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1436 [0/1612 (0%)] Loss: 0.166097\n",
      "Train Epoch: 1436 [160/1612 (10%)] Loss: 0.172834\n",
      "Train Epoch: 1436 [320/1612 (20%)] Loss: 0.215309\n",
      "Train Epoch: 1436 [480/1612 (30%)] Loss: 0.478547\n",
      "Train Epoch: 1436 [640/1612 (40%)] Loss: 0.399356\n",
      "Train Epoch: 1436 [800/1612 (50%)] Loss: 0.507813\n",
      "Train Epoch: 1436 [960/1612 (59%)] Loss: 0.516846\n",
      "Train Epoch: 1436 [1120/1612 (69%)] Loss: 0.582025\n",
      "Train Epoch: 1436 [1280/1612 (79%)] Loss: 0.286628\n",
      "Train Epoch: 1436 [1440/1612 (89%)] Loss: 0.275559\n",
      "Train Epoch: 1436 [1200/1612 (99%)] Loss: 0.307665\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1437 [0/1612 (0%)] Loss: 0.204557\n",
      "Train Epoch: 1437 [160/1612 (10%)] Loss: 0.191885\n",
      "Train Epoch: 1437 [320/1612 (20%)] Loss: 0.247904\n",
      "Train Epoch: 1437 [480/1612 (30%)] Loss: 0.251197\n",
      "Train Epoch: 1437 [640/1612 (40%)] Loss: 0.302742\n",
      "Train Epoch: 1437 [800/1612 (50%)] Loss: 0.373465\n",
      "Train Epoch: 1437 [960/1612 (59%)] Loss: 0.233791\n",
      "Train Epoch: 1437 [1120/1612 (69%)] Loss: 0.610395\n",
      "Train Epoch: 1437 [1280/1612 (79%)] Loss: 0.280537\n",
      "Train Epoch: 1437 [1440/1612 (89%)] Loss: 0.368715\n",
      "Train Epoch: 1437 [1200/1612 (99%)] Loss: 0.196906\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1438 [0/1612 (0%)] Loss: 0.210549\n",
      "Train Epoch: 1438 [160/1612 (10%)] Loss: 0.245528\n",
      "Train Epoch: 1438 [320/1612 (20%)] Loss: 0.536309\n",
      "Train Epoch: 1438 [480/1612 (30%)] Loss: 0.485337\n",
      "Train Epoch: 1438 [640/1612 (40%)] Loss: 0.348881\n",
      "Train Epoch: 1438 [800/1612 (50%)] Loss: 0.370204\n",
      "Train Epoch: 1438 [960/1612 (59%)] Loss: 0.422937\n",
      "Train Epoch: 1438 [1120/1612 (69%)] Loss: 0.310602\n",
      "Train Epoch: 1438 [1280/1612 (79%)] Loss: 0.308750\n",
      "Train Epoch: 1438 [1440/1612 (89%)] Loss: 0.543456\n",
      "Train Epoch: 1438 [1200/1612 (99%)] Loss: 0.512761\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1439 [0/1612 (0%)] Loss: 0.447105\n",
      "Train Epoch: 1439 [160/1612 (10%)] Loss: 0.183616\n",
      "Train Epoch: 1439 [320/1612 (20%)] Loss: 0.133607\n",
      "Train Epoch: 1439 [480/1612 (30%)] Loss: 0.283161\n",
      "Train Epoch: 1439 [640/1612 (40%)] Loss: 0.430670\n",
      "Train Epoch: 1439 [800/1612 (50%)] Loss: 0.338703\n",
      "Train Epoch: 1439 [960/1612 (59%)] Loss: 0.351932\n",
      "Train Epoch: 1439 [1120/1612 (69%)] Loss: 0.262269\n",
      "Train Epoch: 1439 [1280/1612 (79%)] Loss: 0.225757\n",
      "Train Epoch: 1439 [1440/1612 (89%)] Loss: 0.270520\n",
      "Train Epoch: 1439 [1200/1612 (99%)] Loss: 0.754916\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1440 [0/1612 (0%)] Loss: 0.127325\n",
      "Train Epoch: 1440 [160/1612 (10%)] Loss: 0.439613\n",
      "Train Epoch: 1440 [320/1612 (20%)] Loss: 0.162000\n",
      "Train Epoch: 1440 [480/1612 (30%)] Loss: 0.382394\n",
      "Train Epoch: 1440 [640/1612 (40%)] Loss: 0.135096\n",
      "Train Epoch: 1440 [800/1612 (50%)] Loss: 0.143500\n",
      "Train Epoch: 1440 [960/1612 (59%)] Loss: 0.176352\n",
      "Train Epoch: 1440 [1120/1612 (69%)] Loss: 0.483654\n",
      "Train Epoch: 1440 [1280/1612 (79%)] Loss: 0.266532\n",
      "Train Epoch: 1440 [1440/1612 (89%)] Loss: 0.586366\n",
      "Train Epoch: 1440 [1200/1612 (99%)] Loss: 0.221476\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1441 [0/1612 (0%)] Loss: 0.351569\n",
      "Train Epoch: 1441 [160/1612 (10%)] Loss: 0.291698\n",
      "Train Epoch: 1441 [320/1612 (20%)] Loss: 0.324534\n",
      "Train Epoch: 1441 [480/1612 (30%)] Loss: 0.268989\n",
      "Train Epoch: 1441 [640/1612 (40%)] Loss: 0.322602\n",
      "Train Epoch: 1441 [800/1612 (50%)] Loss: 0.288846\n",
      "Train Epoch: 1441 [960/1612 (59%)] Loss: 0.349326\n",
      "Train Epoch: 1441 [1120/1612 (69%)] Loss: 0.221656\n",
      "Train Epoch: 1441 [1280/1612 (79%)] Loss: 0.312033\n",
      "Train Epoch: 1441 [1440/1612 (89%)] Loss: 0.260177\n",
      "Train Epoch: 1441 [1200/1612 (99%)] Loss: 0.218969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1442 [0/1612 (0%)] Loss: 0.219174\n",
      "Train Epoch: 1442 [160/1612 (10%)] Loss: 0.366488\n",
      "Train Epoch: 1442 [320/1612 (20%)] Loss: 0.461829\n",
      "Train Epoch: 1442 [480/1612 (30%)] Loss: 0.095398\n",
      "Train Epoch: 1442 [640/1612 (40%)] Loss: 0.164690\n",
      "Train Epoch: 1442 [800/1612 (50%)] Loss: 0.590253\n",
      "Train Epoch: 1442 [960/1612 (59%)] Loss: 0.389516\n",
      "Train Epoch: 1442 [1120/1612 (69%)] Loss: 0.200552\n",
      "Train Epoch: 1442 [1280/1612 (79%)] Loss: 0.482136\n",
      "Train Epoch: 1442 [1440/1612 (89%)] Loss: 0.219171\n",
      "Train Epoch: 1442 [1200/1612 (99%)] Loss: 0.194515\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1443 [0/1612 (0%)] Loss: 0.132629\n",
      "Train Epoch: 1443 [160/1612 (10%)] Loss: 0.269255\n",
      "Train Epoch: 1443 [320/1612 (20%)] Loss: 0.149705\n",
      "Train Epoch: 1443 [480/1612 (30%)] Loss: 0.123009\n",
      "Train Epoch: 1443 [640/1612 (40%)] Loss: 0.392807\n",
      "Train Epoch: 1443 [800/1612 (50%)] Loss: 0.157689\n",
      "Train Epoch: 1443 [960/1612 (59%)] Loss: 0.365323\n",
      "Train Epoch: 1443 [1120/1612 (69%)] Loss: 0.451558\n",
      "Train Epoch: 1443 [1280/1612 (79%)] Loss: 0.232288\n",
      "Train Epoch: 1443 [1440/1612 (89%)] Loss: 0.354636\n",
      "Train Epoch: 1443 [1200/1612 (99%)] Loss: 0.517153\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1444 [0/1612 (0%)] Loss: 0.452340\n",
      "Train Epoch: 1444 [160/1612 (10%)] Loss: 0.327637\n",
      "Train Epoch: 1444 [320/1612 (20%)] Loss: 0.400834\n",
      "Train Epoch: 1444 [480/1612 (30%)] Loss: 0.220533\n",
      "Train Epoch: 1444 [640/1612 (40%)] Loss: 0.424219\n",
      "Train Epoch: 1444 [800/1612 (50%)] Loss: 0.134664\n",
      "Train Epoch: 1444 [960/1612 (59%)] Loss: 0.325796\n",
      "Train Epoch: 1444 [1120/1612 (69%)] Loss: 0.225747\n",
      "Train Epoch: 1444 [1280/1612 (79%)] Loss: 0.095694\n",
      "Train Epoch: 1444 [1440/1612 (89%)] Loss: 0.212686\n",
      "Train Epoch: 1444 [1200/1612 (99%)] Loss: 0.188851\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1445 [0/1612 (0%)] Loss: 0.220182\n",
      "Train Epoch: 1445 [160/1612 (10%)] Loss: 0.369358\n",
      "Train Epoch: 1445 [320/1612 (20%)] Loss: 0.335745\n",
      "Train Epoch: 1445 [480/1612 (30%)] Loss: 0.386474\n",
      "Train Epoch: 1445 [640/1612 (40%)] Loss: 0.235023\n",
      "Train Epoch: 1445 [800/1612 (50%)] Loss: 0.271065\n",
      "Train Epoch: 1445 [960/1612 (59%)] Loss: 0.291510\n",
      "Train Epoch: 1445 [1120/1612 (69%)] Loss: 0.180167\n",
      "Train Epoch: 1445 [1280/1612 (79%)] Loss: 0.285139\n",
      "Train Epoch: 1445 [1440/1612 (89%)] Loss: 0.381060\n",
      "Train Epoch: 1445 [1200/1612 (99%)] Loss: 0.221224\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1446 [0/1612 (0%)] Loss: 0.236902\n",
      "Train Epoch: 1446 [160/1612 (10%)] Loss: 0.190026\n",
      "Train Epoch: 1446 [320/1612 (20%)] Loss: 0.356586\n",
      "Train Epoch: 1446 [480/1612 (30%)] Loss: 0.301055\n",
      "Train Epoch: 1446 [640/1612 (40%)] Loss: 0.237542\n",
      "Train Epoch: 1446 [800/1612 (50%)] Loss: 0.324289\n",
      "Train Epoch: 1446 [960/1612 (59%)] Loss: 0.405832\n",
      "Train Epoch: 1446 [1120/1612 (69%)] Loss: 0.246891\n",
      "Train Epoch: 1446 [1280/1612 (79%)] Loss: 0.258214\n",
      "Train Epoch: 1446 [1440/1612 (89%)] Loss: 0.134395\n",
      "Train Epoch: 1446 [1200/1612 (99%)] Loss: 0.330375\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1447 [0/1612 (0%)] Loss: 0.419893\n",
      "Train Epoch: 1447 [160/1612 (10%)] Loss: 0.265744\n",
      "Train Epoch: 1447 [320/1612 (20%)] Loss: 0.348004\n",
      "Train Epoch: 1447 [480/1612 (30%)] Loss: 0.363650\n",
      "Train Epoch: 1447 [640/1612 (40%)] Loss: 0.240502\n",
      "Train Epoch: 1447 [800/1612 (50%)] Loss: 0.356681\n",
      "Train Epoch: 1447 [960/1612 (59%)] Loss: 0.251159\n",
      "Train Epoch: 1447 [1120/1612 (69%)] Loss: 0.390622\n",
      "Train Epoch: 1447 [1280/1612 (79%)] Loss: 0.379361\n",
      "Train Epoch: 1447 [1440/1612 (89%)] Loss: 0.219572\n",
      "Train Epoch: 1447 [1200/1612 (99%)] Loss: 0.167102\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1448 [0/1612 (0%)] Loss: 0.146872\n",
      "Train Epoch: 1448 [160/1612 (10%)] Loss: 0.344784\n",
      "Train Epoch: 1448 [320/1612 (20%)] Loss: 0.339738\n",
      "Train Epoch: 1448 [480/1612 (30%)] Loss: 0.312037\n",
      "Train Epoch: 1448 [640/1612 (40%)] Loss: 0.119039\n",
      "Train Epoch: 1448 [800/1612 (50%)] Loss: 0.066830\n",
      "Train Epoch: 1448 [960/1612 (59%)] Loss: 0.246930\n",
      "Train Epoch: 1448 [1120/1612 (69%)] Loss: 0.324189\n",
      "Train Epoch: 1448 [1280/1612 (79%)] Loss: 0.352756\n",
      "Train Epoch: 1448 [1440/1612 (89%)] Loss: 0.142666\n",
      "Train Epoch: 1448 [1200/1612 (99%)] Loss: 0.297136\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1449 [0/1612 (0%)] Loss: 0.292170\n",
      "Train Epoch: 1449 [160/1612 (10%)] Loss: 0.288076\n",
      "Train Epoch: 1449 [320/1612 (20%)] Loss: 0.544754\n",
      "Train Epoch: 1449 [480/1612 (30%)] Loss: 0.454348\n",
      "Train Epoch: 1449 [640/1612 (40%)] Loss: 0.296575\n",
      "Train Epoch: 1449 [800/1612 (50%)] Loss: 0.430804\n",
      "Train Epoch: 1449 [960/1612 (59%)] Loss: 0.391804\n",
      "Train Epoch: 1449 [1120/1612 (69%)] Loss: 0.316055\n",
      "Train Epoch: 1449 [1280/1612 (79%)] Loss: 0.195033\n",
      "Train Epoch: 1449 [1440/1612 (89%)] Loss: 0.194889\n",
      "Train Epoch: 1449 [1200/1612 (99%)] Loss: 0.494901\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1450 [0/1612 (0%)] Loss: 0.213152\n",
      "Train Epoch: 1450 [160/1612 (10%)] Loss: 0.251235\n",
      "Train Epoch: 1450 [320/1612 (20%)] Loss: 0.197297\n",
      "Train Epoch: 1450 [480/1612 (30%)] Loss: 0.229362\n",
      "Train Epoch: 1450 [640/1612 (40%)] Loss: 0.405341\n",
      "Train Epoch: 1450 [800/1612 (50%)] Loss: 0.129226\n",
      "Train Epoch: 1450 [960/1612 (59%)] Loss: 0.291548\n",
      "Train Epoch: 1450 [1120/1612 (69%)] Loss: 0.263276\n",
      "Train Epoch: 1450 [1280/1612 (79%)] Loss: 0.234135\n",
      "Train Epoch: 1450 [1440/1612 (89%)] Loss: 0.270590\n",
      "Train Epoch: 1450 [1200/1612 (99%)] Loss: 0.251657\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1451 [0/1612 (0%)] Loss: 0.263413\n",
      "Train Epoch: 1451 [160/1612 (10%)] Loss: 0.208844\n",
      "Train Epoch: 1451 [320/1612 (20%)] Loss: 0.396499\n",
      "Train Epoch: 1451 [480/1612 (30%)] Loss: 0.418471\n",
      "Train Epoch: 1451 [640/1612 (40%)] Loss: 0.156067\n",
      "Train Epoch: 1451 [800/1612 (50%)] Loss: 0.187300\n",
      "Train Epoch: 1451 [960/1612 (59%)] Loss: 0.206577\n",
      "Train Epoch: 1451 [1120/1612 (69%)] Loss: 0.527340\n",
      "Train Epoch: 1451 [1280/1612 (79%)] Loss: 0.121577\n",
      "Train Epoch: 1451 [1440/1612 (89%)] Loss: 0.462506\n",
      "Train Epoch: 1451 [1200/1612 (99%)] Loss: 0.291480\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1452 [0/1612 (0%)] Loss: 0.214404\n",
      "Train Epoch: 1452 [160/1612 (10%)] Loss: 0.137175\n",
      "Train Epoch: 1452 [320/1612 (20%)] Loss: 0.269585\n",
      "Train Epoch: 1452 [480/1612 (30%)] Loss: 0.372029\n",
      "Train Epoch: 1452 [640/1612 (40%)] Loss: 0.412776\n",
      "Train Epoch: 1452 [800/1612 (50%)] Loss: 0.179253\n",
      "Train Epoch: 1452 [960/1612 (59%)] Loss: 0.460557\n",
      "Train Epoch: 1452 [1120/1612 (69%)] Loss: 0.219173\n",
      "Train Epoch: 1452 [1280/1612 (79%)] Loss: 0.325446\n",
      "Train Epoch: 1452 [1440/1612 (89%)] Loss: 0.132074\n",
      "Train Epoch: 1452 [1200/1612 (99%)] Loss: 0.207849\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1453 [0/1612 (0%)] Loss: 0.380880\n",
      "Train Epoch: 1453 [160/1612 (10%)] Loss: 0.350750\n",
      "Train Epoch: 1453 [320/1612 (20%)] Loss: 0.271332\n",
      "Train Epoch: 1453 [480/1612 (30%)] Loss: 0.388804\n",
      "Train Epoch: 1453 [640/1612 (40%)] Loss: 0.282523\n",
      "Train Epoch: 1453 [800/1612 (50%)] Loss: 0.078434\n",
      "Train Epoch: 1453 [960/1612 (59%)] Loss: 0.288193\n",
      "Train Epoch: 1453 [1120/1612 (69%)] Loss: 0.510532\n",
      "Train Epoch: 1453 [1280/1612 (79%)] Loss: 0.203901\n",
      "Train Epoch: 1453 [1440/1612 (89%)] Loss: 0.198600\n",
      "Train Epoch: 1453 [1200/1612 (99%)] Loss: 0.159867\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1454 [0/1612 (0%)] Loss: 0.442365\n",
      "Train Epoch: 1454 [160/1612 (10%)] Loss: 0.399280\n",
      "Train Epoch: 1454 [320/1612 (20%)] Loss: 0.377134\n",
      "Train Epoch: 1454 [480/1612 (30%)] Loss: 0.357005\n",
      "Train Epoch: 1454 [640/1612 (40%)] Loss: 0.393336\n",
      "Train Epoch: 1454 [800/1612 (50%)] Loss: 0.336019\n",
      "Train Epoch: 1454 [960/1612 (59%)] Loss: 0.129794\n",
      "Train Epoch: 1454 [1120/1612 (69%)] Loss: 0.256312\n",
      "Train Epoch: 1454 [1280/1612 (79%)] Loss: 0.284970\n",
      "Train Epoch: 1454 [1440/1612 (89%)] Loss: 0.404948\n",
      "Train Epoch: 1454 [1200/1612 (99%)] Loss: 0.309849\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1455 [0/1612 (0%)] Loss: 0.340635\n",
      "Train Epoch: 1455 [160/1612 (10%)] Loss: 0.705147\n",
      "Train Epoch: 1455 [320/1612 (20%)] Loss: 0.129070\n",
      "Train Epoch: 1455 [480/1612 (30%)] Loss: 0.353974\n",
      "Train Epoch: 1455 [640/1612 (40%)] Loss: 0.313903\n",
      "Train Epoch: 1455 [800/1612 (50%)] Loss: 0.201326\n",
      "Train Epoch: 1455 [960/1612 (59%)] Loss: 0.453040\n",
      "Train Epoch: 1455 [1120/1612 (69%)] Loss: 0.189791\n",
      "Train Epoch: 1455 [1280/1612 (79%)] Loss: 0.554148\n",
      "Train Epoch: 1455 [1440/1612 (89%)] Loss: 0.230738\n",
      "Train Epoch: 1455 [1200/1612 (99%)] Loss: 0.346961\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1456 [0/1612 (0%)] Loss: 0.111696\n",
      "Train Epoch: 1456 [160/1612 (10%)] Loss: 0.180488\n",
      "Train Epoch: 1456 [320/1612 (20%)] Loss: 0.274194\n",
      "Train Epoch: 1456 [480/1612 (30%)] Loss: 0.284296\n",
      "Train Epoch: 1456 [640/1612 (40%)] Loss: 0.161668\n",
      "Train Epoch: 1456 [800/1612 (50%)] Loss: 0.444040\n",
      "Train Epoch: 1456 [960/1612 (59%)] Loss: 0.269859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1456 [1120/1612 (69%)] Loss: 0.284255\n",
      "Train Epoch: 1456 [1280/1612 (79%)] Loss: 0.155696\n",
      "Train Epoch: 1456 [1440/1612 (89%)] Loss: 0.239464\n",
      "Train Epoch: 1456 [1200/1612 (99%)] Loss: 0.222726\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1457 [0/1612 (0%)] Loss: 0.256623\n",
      "Train Epoch: 1457 [160/1612 (10%)] Loss: 0.065950\n",
      "Train Epoch: 1457 [320/1612 (20%)] Loss: 0.347803\n",
      "Train Epoch: 1457 [480/1612 (30%)] Loss: 0.238459\n",
      "Train Epoch: 1457 [640/1612 (40%)] Loss: 0.165687\n",
      "Train Epoch: 1457 [800/1612 (50%)] Loss: 0.125447\n",
      "Train Epoch: 1457 [960/1612 (59%)] Loss: 0.284750\n",
      "Train Epoch: 1457 [1120/1612 (69%)] Loss: 0.386260\n",
      "Train Epoch: 1457 [1280/1612 (79%)] Loss: 0.365069\n",
      "Train Epoch: 1457 [1440/1612 (89%)] Loss: 0.433598\n",
      "Train Epoch: 1457 [1200/1612 (99%)] Loss: 0.142215\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1458 [0/1612 (0%)] Loss: 0.435260\n",
      "Train Epoch: 1458 [160/1612 (10%)] Loss: 0.461843\n",
      "Train Epoch: 1458 [320/1612 (20%)] Loss: 0.208474\n",
      "Train Epoch: 1458 [480/1612 (30%)] Loss: 0.313374\n",
      "Train Epoch: 1458 [640/1612 (40%)] Loss: 0.365043\n",
      "Train Epoch: 1458 [800/1612 (50%)] Loss: 0.278387\n",
      "Train Epoch: 1458 [960/1612 (59%)] Loss: 0.287956\n",
      "Train Epoch: 1458 [1120/1612 (69%)] Loss: 0.165133\n",
      "Train Epoch: 1458 [1280/1612 (79%)] Loss: 0.281241\n",
      "Train Epoch: 1458 [1440/1612 (89%)] Loss: 0.276686\n",
      "Train Epoch: 1458 [1200/1612 (99%)] Loss: 0.275073\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1459 [0/1612 (0%)] Loss: 0.268743\n",
      "Train Epoch: 1459 [160/1612 (10%)] Loss: 0.440605\n",
      "Train Epoch: 1459 [320/1612 (20%)] Loss: 0.469930\n",
      "Train Epoch: 1459 [480/1612 (30%)] Loss: 0.256517\n",
      "Train Epoch: 1459 [640/1612 (40%)] Loss: 0.286894\n",
      "Train Epoch: 1459 [800/1612 (50%)] Loss: 0.400095\n",
      "Train Epoch: 1459 [960/1612 (59%)] Loss: 0.352648\n",
      "Train Epoch: 1459 [1120/1612 (69%)] Loss: 0.397487\n",
      "Train Epoch: 1459 [1280/1612 (79%)] Loss: 0.264463\n",
      "Train Epoch: 1459 [1440/1612 (89%)] Loss: 0.352034\n",
      "Train Epoch: 1459 [1200/1612 (99%)] Loss: 0.062586\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1460 [0/1612 (0%)] Loss: 0.402925\n",
      "Train Epoch: 1460 [160/1612 (10%)] Loss: 0.530168\n",
      "Train Epoch: 1460 [320/1612 (20%)] Loss: 0.531056\n",
      "Train Epoch: 1460 [480/1612 (30%)] Loss: 0.250106\n",
      "Train Epoch: 1460 [640/1612 (40%)] Loss: 0.226232\n",
      "Train Epoch: 1460 [800/1612 (50%)] Loss: 0.231410\n",
      "Train Epoch: 1460 [960/1612 (59%)] Loss: 0.263102\n",
      "Train Epoch: 1460 [1120/1612 (69%)] Loss: 0.175708\n",
      "Train Epoch: 1460 [1280/1612 (79%)] Loss: 0.092063\n",
      "Train Epoch: 1460 [1440/1612 (89%)] Loss: 0.294752\n",
      "Train Epoch: 1460 [1200/1612 (99%)] Loss: 0.515280\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1461 [0/1612 (0%)] Loss: 0.380976\n",
      "Train Epoch: 1461 [160/1612 (10%)] Loss: 0.319386\n",
      "Train Epoch: 1461 [320/1612 (20%)] Loss: 0.360661\n",
      "Train Epoch: 1461 [480/1612 (30%)] Loss: 0.384924\n",
      "Train Epoch: 1461 [640/1612 (40%)] Loss: 0.256429\n",
      "Train Epoch: 1461 [800/1612 (50%)] Loss: 0.430210\n",
      "Train Epoch: 1461 [960/1612 (59%)] Loss: 0.225293\n",
      "Train Epoch: 1461 [1120/1612 (69%)] Loss: 0.381432\n",
      "Train Epoch: 1461 [1280/1612 (79%)] Loss: 0.205553\n",
      "Train Epoch: 1461 [1440/1612 (89%)] Loss: 0.358708\n",
      "Train Epoch: 1461 [1200/1612 (99%)] Loss: 0.677875\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1462 [0/1612 (0%)] Loss: 0.292141\n",
      "Train Epoch: 1462 [160/1612 (10%)] Loss: 0.279433\n",
      "Train Epoch: 1462 [320/1612 (20%)] Loss: 0.304546\n",
      "Train Epoch: 1462 [480/1612 (30%)] Loss: 0.203378\n",
      "Train Epoch: 1462 [640/1612 (40%)] Loss: 0.415871\n",
      "Train Epoch: 1462 [800/1612 (50%)] Loss: 0.245457\n",
      "Train Epoch: 1462 [960/1612 (59%)] Loss: 0.526380\n",
      "Train Epoch: 1462 [1120/1612 (69%)] Loss: 0.475469\n",
      "Train Epoch: 1462 [1280/1612 (79%)] Loss: 0.108525\n",
      "Train Epoch: 1462 [1440/1612 (89%)] Loss: 0.220881\n",
      "Train Epoch: 1462 [1200/1612 (99%)] Loss: 0.184571\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1463 [0/1612 (0%)] Loss: 0.324384\n",
      "Train Epoch: 1463 [160/1612 (10%)] Loss: 0.329797\n",
      "Train Epoch: 1463 [320/1612 (20%)] Loss: 0.298514\n",
      "Train Epoch: 1463 [480/1612 (30%)] Loss: 0.296927\n",
      "Train Epoch: 1463 [640/1612 (40%)] Loss: 0.233807\n",
      "Train Epoch: 1463 [800/1612 (50%)] Loss: 0.167099\n",
      "Train Epoch: 1463 [960/1612 (59%)] Loss: 0.158912\n",
      "Train Epoch: 1463 [1120/1612 (69%)] Loss: 0.450142\n",
      "Train Epoch: 1463 [1280/1612 (79%)] Loss: 0.208103\n",
      "Train Epoch: 1463 [1440/1612 (89%)] Loss: 0.410638\n",
      "Train Epoch: 1463 [1200/1612 (99%)] Loss: 0.117904\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1464 [0/1612 (0%)] Loss: 0.311257\n",
      "Train Epoch: 1464 [160/1612 (10%)] Loss: 0.270237\n",
      "Train Epoch: 1464 [320/1612 (20%)] Loss: 0.120966\n",
      "Train Epoch: 1464 [480/1612 (30%)] Loss: 0.463591\n",
      "Train Epoch: 1464 [640/1612 (40%)] Loss: 0.198339\n",
      "Train Epoch: 1464 [800/1612 (50%)] Loss: 0.248709\n",
      "Train Epoch: 1464 [960/1612 (59%)] Loss: 0.134280\n",
      "Train Epoch: 1464 [1120/1612 (69%)] Loss: 0.228442\n",
      "Train Epoch: 1464 [1280/1612 (79%)] Loss: 0.491274\n",
      "Train Epoch: 1464 [1440/1612 (89%)] Loss: 0.176776\n",
      "Train Epoch: 1464 [1200/1612 (99%)] Loss: 0.397814\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1465 [0/1612 (0%)] Loss: 0.392674\n",
      "Train Epoch: 1465 [160/1612 (10%)] Loss: 0.130541\n",
      "Train Epoch: 1465 [320/1612 (20%)] Loss: 0.316300\n",
      "Train Epoch: 1465 [480/1612 (30%)] Loss: 0.341368\n",
      "Train Epoch: 1465 [640/1612 (40%)] Loss: 0.426653\n",
      "Train Epoch: 1465 [800/1612 (50%)] Loss: 0.254716\n",
      "Train Epoch: 1465 [960/1612 (59%)] Loss: 0.365483\n",
      "Train Epoch: 1465 [1120/1612 (69%)] Loss: 0.076974\n",
      "Train Epoch: 1465 [1280/1612 (79%)] Loss: 0.237649\n",
      "Train Epoch: 1465 [1440/1612 (89%)] Loss: 0.297263\n",
      "Train Epoch: 1465 [1200/1612 (99%)] Loss: 0.335607\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1466 [0/1612 (0%)] Loss: 0.400906\n",
      "Train Epoch: 1466 [160/1612 (10%)] Loss: 0.403111\n",
      "Train Epoch: 1466 [320/1612 (20%)] Loss: 0.375601\n",
      "Train Epoch: 1466 [480/1612 (30%)] Loss: 0.351827\n",
      "Train Epoch: 1466 [640/1612 (40%)] Loss: 0.188241\n",
      "Train Epoch: 1466 [800/1612 (50%)] Loss: 0.472349\n",
      "Train Epoch: 1466 [960/1612 (59%)] Loss: 0.355399\n",
      "Train Epoch: 1466 [1120/1612 (69%)] Loss: 0.354616\n",
      "Train Epoch: 1466 [1280/1612 (79%)] Loss: 0.374288\n",
      "Train Epoch: 1466 [1440/1612 (89%)] Loss: 0.350374\n",
      "Train Epoch: 1466 [1200/1612 (99%)] Loss: 0.312872\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1467 [0/1612 (0%)] Loss: 0.515623\n",
      "Train Epoch: 1467 [160/1612 (10%)] Loss: 0.237350\n",
      "Train Epoch: 1467 [320/1612 (20%)] Loss: 0.292348\n",
      "Train Epoch: 1467 [480/1612 (30%)] Loss: 0.147618\n",
      "Train Epoch: 1467 [640/1612 (40%)] Loss: 0.424738\n",
      "Train Epoch: 1467 [800/1612 (50%)] Loss: 0.354140\n",
      "Train Epoch: 1467 [960/1612 (59%)] Loss: 0.208785\n",
      "Train Epoch: 1467 [1120/1612 (69%)] Loss: 0.254331\n",
      "Train Epoch: 1467 [1280/1612 (79%)] Loss: 0.698951\n",
      "Train Epoch: 1467 [1440/1612 (89%)] Loss: 0.195018\n",
      "Train Epoch: 1467 [1200/1612 (99%)] Loss: 0.284525\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1468 [0/1612 (0%)] Loss: 0.348686\n",
      "Train Epoch: 1468 [160/1612 (10%)] Loss: 0.131872\n",
      "Train Epoch: 1468 [320/1612 (20%)] Loss: 0.216472\n",
      "Train Epoch: 1468 [480/1612 (30%)] Loss: 0.359572\n",
      "Train Epoch: 1468 [640/1612 (40%)] Loss: 0.197666\n",
      "Train Epoch: 1468 [800/1612 (50%)] Loss: 0.224960\n",
      "Train Epoch: 1468 [960/1612 (59%)] Loss: 0.408082\n",
      "Train Epoch: 1468 [1120/1612 (69%)] Loss: 0.385790\n",
      "Train Epoch: 1468 [1280/1612 (79%)] Loss: 0.159254\n",
      "Train Epoch: 1468 [1440/1612 (89%)] Loss: 0.193694\n",
      "Train Epoch: 1468 [1200/1612 (99%)] Loss: 0.296898\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1469 [0/1612 (0%)] Loss: 0.299668\n",
      "Train Epoch: 1469 [160/1612 (10%)] Loss: 0.334440\n",
      "Train Epoch: 1469 [320/1612 (20%)] Loss: 0.116764\n",
      "Train Epoch: 1469 [480/1612 (30%)] Loss: 0.284064\n",
      "Train Epoch: 1469 [640/1612 (40%)] Loss: 0.277612\n",
      "Train Epoch: 1469 [800/1612 (50%)] Loss: 0.327430\n",
      "Train Epoch: 1469 [960/1612 (59%)] Loss: 0.263332\n",
      "Train Epoch: 1469 [1120/1612 (69%)] Loss: 0.208750\n",
      "Train Epoch: 1469 [1280/1612 (79%)] Loss: 0.203081\n",
      "Train Epoch: 1469 [1440/1612 (89%)] Loss: 0.302193\n",
      "Train Epoch: 1469 [1200/1612 (99%)] Loss: 0.304478\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1470 [0/1612 (0%)] Loss: 0.415950\n",
      "Train Epoch: 1470 [160/1612 (10%)] Loss: 0.300353\n",
      "Train Epoch: 1470 [320/1612 (20%)] Loss: 0.269349\n",
      "Train Epoch: 1470 [480/1612 (30%)] Loss: 0.242456\n",
      "Train Epoch: 1470 [640/1612 (40%)] Loss: 0.269038\n",
      "Train Epoch: 1470 [800/1612 (50%)] Loss: 0.327493\n",
      "Train Epoch: 1470 [960/1612 (59%)] Loss: 0.282181\n",
      "Train Epoch: 1470 [1120/1612 (69%)] Loss: 0.487086\n",
      "Train Epoch: 1470 [1280/1612 (79%)] Loss: 0.133203\n",
      "Train Epoch: 1470 [1440/1612 (89%)] Loss: 0.223593\n",
      "Train Epoch: 1470 [1200/1612 (99%)] Loss: 0.344208\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1471 [0/1612 (0%)] Loss: 0.432888\n",
      "Train Epoch: 1471 [160/1612 (10%)] Loss: 0.465126\n",
      "Train Epoch: 1471 [320/1612 (20%)] Loss: 0.184762\n",
      "Train Epoch: 1471 [480/1612 (30%)] Loss: 0.236284\n",
      "Train Epoch: 1471 [640/1612 (40%)] Loss: 0.356515\n",
      "Train Epoch: 1471 [800/1612 (50%)] Loss: 0.393618\n",
      "Train Epoch: 1471 [960/1612 (59%)] Loss: 0.278409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1471 [1120/1612 (69%)] Loss: 0.257189\n",
      "Train Epoch: 1471 [1280/1612 (79%)] Loss: 0.321112\n",
      "Train Epoch: 1471 [1440/1612 (89%)] Loss: 0.396934\n",
      "Train Epoch: 1471 [1200/1612 (99%)] Loss: 0.437976\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1472 [0/1612 (0%)] Loss: 0.126559\n",
      "Train Epoch: 1472 [160/1612 (10%)] Loss: 0.232454\n",
      "Train Epoch: 1472 [320/1612 (20%)] Loss: 0.162187\n",
      "Train Epoch: 1472 [480/1612 (30%)] Loss: 0.452650\n",
      "Train Epoch: 1472 [640/1612 (40%)] Loss: 0.281908\n",
      "Train Epoch: 1472 [800/1612 (50%)] Loss: 0.292063\n",
      "Train Epoch: 1472 [960/1612 (59%)] Loss: 0.230237\n",
      "Train Epoch: 1472 [1120/1612 (69%)] Loss: 0.235755\n",
      "Train Epoch: 1472 [1280/1612 (79%)] Loss: 0.328120\n",
      "Train Epoch: 1472 [1440/1612 (89%)] Loss: 0.432374\n",
      "Train Epoch: 1472 [1200/1612 (99%)] Loss: 0.069649\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1473 [0/1612 (0%)] Loss: 0.185938\n",
      "Train Epoch: 1473 [160/1612 (10%)] Loss: 0.415104\n",
      "Train Epoch: 1473 [320/1612 (20%)] Loss: 0.299957\n",
      "Train Epoch: 1473 [480/1612 (30%)] Loss: 0.275932\n",
      "Train Epoch: 1473 [640/1612 (40%)] Loss: 0.543474\n",
      "Train Epoch: 1473 [800/1612 (50%)] Loss: 0.304969\n",
      "Train Epoch: 1473 [960/1612 (59%)] Loss: 0.247137\n",
      "Train Epoch: 1473 [1120/1612 (69%)] Loss: 0.179891\n",
      "Train Epoch: 1473 [1280/1612 (79%)] Loss: 0.312301\n",
      "Train Epoch: 1473 [1440/1612 (89%)] Loss: 0.411441\n",
      "Train Epoch: 1473 [1200/1612 (99%)] Loss: 0.181923\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1474 [0/1612 (0%)] Loss: 0.301680\n",
      "Train Epoch: 1474 [160/1612 (10%)] Loss: 0.322752\n",
      "Train Epoch: 1474 [320/1612 (20%)] Loss: 0.154489\n",
      "Train Epoch: 1474 [480/1612 (30%)] Loss: 0.302519\n",
      "Train Epoch: 1474 [640/1612 (40%)] Loss: 0.320391\n",
      "Train Epoch: 1474 [800/1612 (50%)] Loss: 0.263663\n",
      "Train Epoch: 1474 [960/1612 (59%)] Loss: 0.123295\n",
      "Train Epoch: 1474 [1120/1612 (69%)] Loss: 0.358896\n",
      "Train Epoch: 1474 [1280/1612 (79%)] Loss: 0.314455\n",
      "Train Epoch: 1474 [1440/1612 (89%)] Loss: 0.367850\n",
      "Train Epoch: 1474 [1200/1612 (99%)] Loss: 0.222162\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1475 [0/1612 (0%)] Loss: 0.407359\n",
      "Train Epoch: 1475 [160/1612 (10%)] Loss: 0.344543\n",
      "Train Epoch: 1475 [320/1612 (20%)] Loss: 0.188268\n",
      "Train Epoch: 1475 [480/1612 (30%)] Loss: 0.652726\n",
      "Train Epoch: 1475 [640/1612 (40%)] Loss: 0.256440\n",
      "Train Epoch: 1475 [800/1612 (50%)] Loss: 0.268129\n",
      "Train Epoch: 1475 [960/1612 (59%)] Loss: 0.147795\n",
      "Train Epoch: 1475 [1120/1612 (69%)] Loss: 0.172878\n",
      "Train Epoch: 1475 [1280/1612 (79%)] Loss: 0.431202\n",
      "Train Epoch: 1475 [1440/1612 (89%)] Loss: 0.505184\n",
      "Train Epoch: 1475 [1200/1612 (99%)] Loss: 0.482749\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1476 [0/1612 (0%)] Loss: 0.301111\n",
      "Train Epoch: 1476 [160/1612 (10%)] Loss: 0.330970\n",
      "Train Epoch: 1476 [320/1612 (20%)] Loss: 0.441986\n",
      "Train Epoch: 1476 [480/1612 (30%)] Loss: 0.463978\n",
      "Train Epoch: 1476 [640/1612 (40%)] Loss: 0.230756\n",
      "Train Epoch: 1476 [800/1612 (50%)] Loss: 0.169297\n",
      "Train Epoch: 1476 [960/1612 (59%)] Loss: 0.332518\n",
      "Train Epoch: 1476 [1120/1612 (69%)] Loss: 0.162757\n",
      "Train Epoch: 1476 [1280/1612 (79%)] Loss: 0.191304\n",
      "Train Epoch: 1476 [1440/1612 (89%)] Loss: 0.271354\n",
      "Train Epoch: 1476 [1200/1612 (99%)] Loss: 0.377435\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1477 [0/1612 (0%)] Loss: 0.135593\n",
      "Train Epoch: 1477 [160/1612 (10%)] Loss: 0.535375\n",
      "Train Epoch: 1477 [320/1612 (20%)] Loss: 0.187363\n",
      "Train Epoch: 1477 [480/1612 (30%)] Loss: 0.439644\n",
      "Train Epoch: 1477 [640/1612 (40%)] Loss: 0.196167\n",
      "Train Epoch: 1477 [800/1612 (50%)] Loss: 0.220412\n",
      "Train Epoch: 1477 [960/1612 (59%)] Loss: 0.220131\n",
      "Train Epoch: 1477 [1120/1612 (69%)] Loss: 0.515811\n",
      "Train Epoch: 1477 [1280/1612 (79%)] Loss: 0.248467\n",
      "Train Epoch: 1477 [1440/1612 (89%)] Loss: 0.329442\n",
      "Train Epoch: 1477 [1200/1612 (99%)] Loss: 0.263276\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1478 [0/1612 (0%)] Loss: 0.096406\n",
      "Train Epoch: 1478 [160/1612 (10%)] Loss: 0.325451\n",
      "Train Epoch: 1478 [320/1612 (20%)] Loss: 0.329166\n",
      "Train Epoch: 1478 [480/1612 (30%)] Loss: 0.442791\n",
      "Train Epoch: 1478 [640/1612 (40%)] Loss: 0.323261\n",
      "Train Epoch: 1478 [800/1612 (50%)] Loss: 0.269298\n",
      "Train Epoch: 1478 [960/1612 (59%)] Loss: 0.167077\n",
      "Train Epoch: 1478 [1120/1612 (69%)] Loss: 0.046069\n",
      "Train Epoch: 1478 [1280/1612 (79%)] Loss: 0.165198\n",
      "Train Epoch: 1478 [1440/1612 (89%)] Loss: 0.338590\n",
      "Train Epoch: 1478 [1200/1612 (99%)] Loss: 0.742306\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1479 [0/1612 (0%)] Loss: 0.489014\n",
      "Train Epoch: 1479 [160/1612 (10%)] Loss: 0.200409\n",
      "Train Epoch: 1479 [320/1612 (20%)] Loss: 0.398744\n",
      "Train Epoch: 1479 [480/1612 (30%)] Loss: 0.311736\n",
      "Train Epoch: 1479 [640/1612 (40%)] Loss: 0.334563\n",
      "Train Epoch: 1479 [800/1612 (50%)] Loss: 0.277012\n",
      "Train Epoch: 1479 [960/1612 (59%)] Loss: 0.292402\n",
      "Train Epoch: 1479 [1120/1612 (69%)] Loss: 0.392355\n",
      "Train Epoch: 1479 [1280/1612 (79%)] Loss: 0.307988\n",
      "Train Epoch: 1479 [1440/1612 (89%)] Loss: 0.326131\n",
      "Train Epoch: 1479 [1200/1612 (99%)] Loss: 0.192681\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1480 [0/1612 (0%)] Loss: 0.254688\n",
      "Train Epoch: 1480 [160/1612 (10%)] Loss: 0.227073\n",
      "Train Epoch: 1480 [320/1612 (20%)] Loss: 0.137072\n",
      "Train Epoch: 1480 [480/1612 (30%)] Loss: 0.189042\n",
      "Train Epoch: 1480 [640/1612 (40%)] Loss: 0.360040\n",
      "Train Epoch: 1480 [800/1612 (50%)] Loss: 0.236299\n",
      "Train Epoch: 1480 [960/1612 (59%)] Loss: 0.430495\n",
      "Train Epoch: 1480 [1120/1612 (69%)] Loss: 0.150028\n",
      "Train Epoch: 1480 [1280/1612 (79%)] Loss: 0.672441\n",
      "Train Epoch: 1480 [1440/1612 (89%)] Loss: 0.234006\n",
      "Train Epoch: 1480 [1200/1612 (99%)] Loss: 0.307888\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1481 [0/1612 (0%)] Loss: 0.215455\n",
      "Train Epoch: 1481 [160/1612 (10%)] Loss: 0.300053\n",
      "Train Epoch: 1481 [320/1612 (20%)] Loss: 0.234699\n",
      "Train Epoch: 1481 [480/1612 (30%)] Loss: 0.316131\n",
      "Train Epoch: 1481 [640/1612 (40%)] Loss: 0.235652\n",
      "Train Epoch: 1481 [800/1612 (50%)] Loss: 0.415163\n",
      "Train Epoch: 1481 [960/1612 (59%)] Loss: 0.265861\n",
      "Train Epoch: 1481 [1120/1612 (69%)] Loss: 0.475035\n",
      "Train Epoch: 1481 [1280/1612 (79%)] Loss: 0.361657\n",
      "Train Epoch: 1481 [1440/1612 (89%)] Loss: 0.456698\n",
      "Train Epoch: 1481 [1200/1612 (99%)] Loss: 0.390990\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1482 [0/1612 (0%)] Loss: 0.215513\n",
      "Train Epoch: 1482 [160/1612 (10%)] Loss: 0.158785\n",
      "Train Epoch: 1482 [320/1612 (20%)] Loss: 0.391089\n",
      "Train Epoch: 1482 [480/1612 (30%)] Loss: 0.481588\n",
      "Train Epoch: 1482 [640/1612 (40%)] Loss: 0.209777\n",
      "Train Epoch: 1482 [800/1612 (50%)] Loss: 0.337875\n",
      "Train Epoch: 1482 [960/1612 (59%)] Loss: 0.218759\n",
      "Train Epoch: 1482 [1120/1612 (69%)] Loss: 0.198950\n",
      "Train Epoch: 1482 [1280/1612 (79%)] Loss: 0.544811\n",
      "Train Epoch: 1482 [1440/1612 (89%)] Loss: 0.377121\n",
      "Train Epoch: 1482 [1200/1612 (99%)] Loss: 0.099509\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1483 [0/1612 (0%)] Loss: 0.287878\n",
      "Train Epoch: 1483 [160/1612 (10%)] Loss: 0.349430\n",
      "Train Epoch: 1483 [320/1612 (20%)] Loss: 0.154482\n",
      "Train Epoch: 1483 [480/1612 (30%)] Loss: 0.351873\n",
      "Train Epoch: 1483 [640/1612 (40%)] Loss: 0.330976\n",
      "Train Epoch: 1483 [800/1612 (50%)] Loss: 0.250864\n",
      "Train Epoch: 1483 [960/1612 (59%)] Loss: 0.270407\n",
      "Train Epoch: 1483 [1120/1612 (69%)] Loss: 0.193292\n",
      "Train Epoch: 1483 [1280/1612 (79%)] Loss: 0.417546\n",
      "Train Epoch: 1483 [1440/1612 (89%)] Loss: 0.315019\n",
      "Train Epoch: 1483 [1200/1612 (99%)] Loss: 0.569498\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1484 [0/1612 (0%)] Loss: 0.321559\n",
      "Train Epoch: 1484 [160/1612 (10%)] Loss: 0.523770\n",
      "Train Epoch: 1484 [320/1612 (20%)] Loss: 0.411136\n",
      "Train Epoch: 1484 [480/1612 (30%)] Loss: 0.579769\n",
      "Train Epoch: 1484 [640/1612 (40%)] Loss: 0.297174\n",
      "Train Epoch: 1484 [800/1612 (50%)] Loss: 0.507715\n",
      "Train Epoch: 1484 [960/1612 (59%)] Loss: 0.220987\n",
      "Train Epoch: 1484 [1120/1612 (69%)] Loss: 0.323286\n",
      "Train Epoch: 1484 [1280/1612 (79%)] Loss: 0.376609\n",
      "Train Epoch: 1484 [1440/1612 (89%)] Loss: 0.376223\n",
      "Train Epoch: 1484 [1200/1612 (99%)] Loss: 0.306309\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1485 [0/1612 (0%)] Loss: 0.215263\n",
      "Train Epoch: 1485 [160/1612 (10%)] Loss: 0.303917\n",
      "Train Epoch: 1485 [320/1612 (20%)] Loss: 0.386940\n",
      "Train Epoch: 1485 [480/1612 (30%)] Loss: 0.160609\n",
      "Train Epoch: 1485 [640/1612 (40%)] Loss: 0.559484\n",
      "Train Epoch: 1485 [800/1612 (50%)] Loss: 0.390672\n",
      "Train Epoch: 1485 [960/1612 (59%)] Loss: 0.357373\n",
      "Train Epoch: 1485 [1120/1612 (69%)] Loss: 0.274987\n",
      "Train Epoch: 1485 [1280/1612 (79%)] Loss: 0.296563\n",
      "Train Epoch: 1485 [1440/1612 (89%)] Loss: 0.269983\n",
      "Train Epoch: 1485 [1200/1612 (99%)] Loss: 0.306675\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1486 [0/1612 (0%)] Loss: 0.216947\n",
      "Train Epoch: 1486 [160/1612 (10%)] Loss: 0.213302\n",
      "Train Epoch: 1486 [320/1612 (20%)] Loss: 0.309783\n",
      "Train Epoch: 1486 [480/1612 (30%)] Loss: 0.195992\n",
      "Train Epoch: 1486 [640/1612 (40%)] Loss: 0.377153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1486 [800/1612 (50%)] Loss: 0.161268\n",
      "Train Epoch: 1486 [960/1612 (59%)] Loss: 0.464979\n",
      "Train Epoch: 1486 [1120/1612 (69%)] Loss: 0.349936\n",
      "Train Epoch: 1486 [1280/1612 (79%)] Loss: 0.261788\n",
      "Train Epoch: 1486 [1440/1612 (89%)] Loss: 0.359546\n",
      "Train Epoch: 1486 [1200/1612 (99%)] Loss: 0.308350\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1487 [0/1612 (0%)] Loss: 0.162300\n",
      "Train Epoch: 1487 [160/1612 (10%)] Loss: 0.177974\n",
      "Train Epoch: 1487 [320/1612 (20%)] Loss: 0.243054\n",
      "Train Epoch: 1487 [480/1612 (30%)] Loss: 0.144730\n",
      "Train Epoch: 1487 [640/1612 (40%)] Loss: 0.118241\n",
      "Train Epoch: 1487 [800/1612 (50%)] Loss: 0.225786\n",
      "Train Epoch: 1487 [960/1612 (59%)] Loss: 0.410526\n",
      "Train Epoch: 1487 [1120/1612 (69%)] Loss: 0.192472\n",
      "Train Epoch: 1487 [1280/1612 (79%)] Loss: 0.433865\n",
      "Train Epoch: 1487 [1440/1612 (89%)] Loss: 0.215149\n",
      "Train Epoch: 1487 [1200/1612 (99%)] Loss: 0.331838\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1488 [0/1612 (0%)] Loss: 0.292564\n",
      "Train Epoch: 1488 [160/1612 (10%)] Loss: 0.218857\n",
      "Train Epoch: 1488 [320/1612 (20%)] Loss: 0.153992\n",
      "Train Epoch: 1488 [480/1612 (30%)] Loss: 0.192674\n",
      "Train Epoch: 1488 [640/1612 (40%)] Loss: 0.117190\n",
      "Train Epoch: 1488 [800/1612 (50%)] Loss: 0.450704\n",
      "Train Epoch: 1488 [960/1612 (59%)] Loss: 0.300267\n",
      "Train Epoch: 1488 [1120/1612 (69%)] Loss: 0.530538\n",
      "Train Epoch: 1488 [1280/1612 (79%)] Loss: 0.354326\n",
      "Train Epoch: 1488 [1440/1612 (89%)] Loss: 0.305740\n",
      "Train Epoch: 1488 [1200/1612 (99%)] Loss: 0.292861\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1489 [0/1612 (0%)] Loss: 0.400622\n",
      "Train Epoch: 1489 [160/1612 (10%)] Loss: 0.165196\n",
      "Train Epoch: 1489 [320/1612 (20%)] Loss: 0.208983\n",
      "Train Epoch: 1489 [480/1612 (30%)] Loss: 0.363871\n",
      "Train Epoch: 1489 [640/1612 (40%)] Loss: 0.492684\n",
      "Train Epoch: 1489 [800/1612 (50%)] Loss: 0.335299\n",
      "Train Epoch: 1489 [960/1612 (59%)] Loss: 0.252386\n",
      "Train Epoch: 1489 [1120/1612 (69%)] Loss: 0.285316\n",
      "Train Epoch: 1489 [1280/1612 (79%)] Loss: 0.186998\n",
      "Train Epoch: 1489 [1440/1612 (89%)] Loss: 0.197183\n",
      "Train Epoch: 1489 [1200/1612 (99%)] Loss: 0.238537\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1490 [0/1612 (0%)] Loss: 0.224555\n",
      "Train Epoch: 1490 [160/1612 (10%)] Loss: 0.216575\n",
      "Train Epoch: 1490 [320/1612 (20%)] Loss: 0.363789\n",
      "Train Epoch: 1490 [480/1612 (30%)] Loss: 0.232824\n",
      "Train Epoch: 1490 [640/1612 (40%)] Loss: 0.332892\n",
      "Train Epoch: 1490 [800/1612 (50%)] Loss: 0.149561\n",
      "Train Epoch: 1490 [960/1612 (59%)] Loss: 0.306444\n",
      "Train Epoch: 1490 [1120/1612 (69%)] Loss: 0.323370\n",
      "Train Epoch: 1490 [1280/1612 (79%)] Loss: 0.444528\n",
      "Train Epoch: 1490 [1440/1612 (89%)] Loss: 0.557090\n",
      "Train Epoch: 1490 [1200/1612 (99%)] Loss: 0.500296\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1491 [0/1612 (0%)] Loss: 0.353379\n",
      "Train Epoch: 1491 [160/1612 (10%)] Loss: 0.417930\n",
      "Train Epoch: 1491 [320/1612 (20%)] Loss: 0.247408\n",
      "Train Epoch: 1491 [480/1612 (30%)] Loss: 0.225748\n",
      "Train Epoch: 1491 [640/1612 (40%)] Loss: 0.307730\n",
      "Train Epoch: 1491 [800/1612 (50%)] Loss: 0.259538\n",
      "Train Epoch: 1491 [960/1612 (59%)] Loss: 0.326126\n",
      "Train Epoch: 1491 [1120/1612 (69%)] Loss: 0.281508\n",
      "Train Epoch: 1491 [1280/1612 (79%)] Loss: 0.214598\n",
      "Train Epoch: 1491 [1440/1612 (89%)] Loss: 0.567944\n",
      "Train Epoch: 1491 [1200/1612 (99%)] Loss: 0.530425\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1492 [0/1612 (0%)] Loss: 0.217705\n",
      "Train Epoch: 1492 [160/1612 (10%)] Loss: 0.146161\n",
      "Train Epoch: 1492 [320/1612 (20%)] Loss: 0.421386\n",
      "Train Epoch: 1492 [480/1612 (30%)] Loss: 0.223430\n",
      "Train Epoch: 1492 [640/1612 (40%)] Loss: 0.301909\n",
      "Train Epoch: 1492 [800/1612 (50%)] Loss: 0.274162\n",
      "Train Epoch: 1492 [960/1612 (59%)] Loss: 0.135659\n",
      "Train Epoch: 1492 [1120/1612 (69%)] Loss: 0.247067\n",
      "Train Epoch: 1492 [1280/1612 (79%)] Loss: 0.391236\n",
      "Train Epoch: 1492 [1440/1612 (89%)] Loss: 0.305133\n",
      "Train Epoch: 1492 [1200/1612 (99%)] Loss: 0.443567\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1493 [0/1612 (0%)] Loss: 0.320282\n",
      "Train Epoch: 1493 [160/1612 (10%)] Loss: 0.173875\n",
      "Train Epoch: 1493 [320/1612 (20%)] Loss: 0.087539\n",
      "Train Epoch: 1493 [480/1612 (30%)] Loss: 0.192779\n",
      "Train Epoch: 1493 [640/1612 (40%)] Loss: 0.365009\n",
      "Train Epoch: 1493 [800/1612 (50%)] Loss: 0.528474\n",
      "Train Epoch: 1493 [960/1612 (59%)] Loss: 0.149113\n",
      "Train Epoch: 1493 [1120/1612 (69%)] Loss: 0.169439\n",
      "Train Epoch: 1493 [1280/1612 (79%)] Loss: 0.203014\n",
      "Train Epoch: 1493 [1440/1612 (89%)] Loss: 0.379173\n",
      "Train Epoch: 1493 [1200/1612 (99%)] Loss: 0.055039\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1494 [0/1612 (0%)] Loss: 0.264876\n",
      "Train Epoch: 1494 [160/1612 (10%)] Loss: 0.493800\n",
      "Train Epoch: 1494 [320/1612 (20%)] Loss: 0.457151\n",
      "Train Epoch: 1494 [480/1612 (30%)] Loss: 0.350468\n",
      "Train Epoch: 1494 [640/1612 (40%)] Loss: 0.228452\n",
      "Train Epoch: 1494 [800/1612 (50%)] Loss: 0.360295\n",
      "Train Epoch: 1494 [960/1612 (59%)] Loss: 0.357675\n",
      "Train Epoch: 1494 [1120/1612 (69%)] Loss: 0.181920\n",
      "Train Epoch: 1494 [1280/1612 (79%)] Loss: 0.378358\n",
      "Train Epoch: 1494 [1440/1612 (89%)] Loss: 0.320877\n",
      "Train Epoch: 1494 [1200/1612 (99%)] Loss: 0.387653\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1495 [0/1612 (0%)] Loss: 0.428243\n",
      "Train Epoch: 1495 [160/1612 (10%)] Loss: 0.422983\n",
      "Train Epoch: 1495 [320/1612 (20%)] Loss: 0.150480\n",
      "Train Epoch: 1495 [480/1612 (30%)] Loss: 0.380961\n",
      "Train Epoch: 1495 [640/1612 (40%)] Loss: 0.197347\n",
      "Train Epoch: 1495 [800/1612 (50%)] Loss: 0.256419\n",
      "Train Epoch: 1495 [960/1612 (59%)] Loss: 0.095467\n",
      "Train Epoch: 1495 [1120/1612 (69%)] Loss: 0.174682\n",
      "Train Epoch: 1495 [1280/1612 (79%)] Loss: 0.242680\n",
      "Train Epoch: 1495 [1440/1612 (89%)] Loss: 0.368902\n",
      "Train Epoch: 1495 [1200/1612 (99%)] Loss: 0.595293\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1496 [0/1612 (0%)] Loss: 0.295609\n",
      "Train Epoch: 1496 [160/1612 (10%)] Loss: 0.317446\n",
      "Train Epoch: 1496 [320/1612 (20%)] Loss: 0.313038\n",
      "Train Epoch: 1496 [480/1612 (30%)] Loss: 0.387805\n",
      "Train Epoch: 1496 [640/1612 (40%)] Loss: 0.383795\n",
      "Train Epoch: 1496 [800/1612 (50%)] Loss: 0.190443\n",
      "Train Epoch: 1496 [960/1612 (59%)] Loss: 0.456181\n",
      "Train Epoch: 1496 [1120/1612 (69%)] Loss: 0.463768\n",
      "Train Epoch: 1496 [1280/1612 (79%)] Loss: 0.456210\n",
      "Train Epoch: 1496 [1440/1612 (89%)] Loss: 0.500293\n",
      "Train Epoch: 1496 [1200/1612 (99%)] Loss: 0.421860\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1497 [0/1612 (0%)] Loss: 0.209054\n",
      "Train Epoch: 1497 [160/1612 (10%)] Loss: 0.434289\n",
      "Train Epoch: 1497 [320/1612 (20%)] Loss: 0.259735\n",
      "Train Epoch: 1497 [480/1612 (30%)] Loss: 0.276520\n",
      "Train Epoch: 1497 [640/1612 (40%)] Loss: 0.284117\n",
      "Train Epoch: 1497 [800/1612 (50%)] Loss: 0.234583\n",
      "Train Epoch: 1497 [960/1612 (59%)] Loss: 0.175417\n",
      "Train Epoch: 1497 [1120/1612 (69%)] Loss: 0.221678\n",
      "Train Epoch: 1497 [1280/1612 (79%)] Loss: 0.317312\n",
      "Train Epoch: 1497 [1440/1612 (89%)] Loss: 0.323432\n",
      "Train Epoch: 1497 [1200/1612 (99%)] Loss: 0.361416\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1498 [0/1612 (0%)] Loss: 0.540473\n",
      "Train Epoch: 1498 [160/1612 (10%)] Loss: 0.377262\n",
      "Train Epoch: 1498 [320/1612 (20%)] Loss: 0.111423\n",
      "Train Epoch: 1498 [480/1612 (30%)] Loss: 0.145702\n",
      "Train Epoch: 1498 [640/1612 (40%)] Loss: 0.226879\n",
      "Train Epoch: 1498 [800/1612 (50%)] Loss: 0.149864\n",
      "Train Epoch: 1498 [960/1612 (59%)] Loss: 0.348473\n",
      "Train Epoch: 1498 [1120/1612 (69%)] Loss: 0.176876\n",
      "Train Epoch: 1498 [1280/1612 (79%)] Loss: 0.241453\n",
      "Train Epoch: 1498 [1440/1612 (89%)] Loss: 0.210442\n",
      "Train Epoch: 1498 [1200/1612 (99%)] Loss: 0.285541\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1499 [0/1612 (0%)] Loss: 0.200960\n",
      "Train Epoch: 1499 [160/1612 (10%)] Loss: 0.272715\n",
      "Train Epoch: 1499 [320/1612 (20%)] Loss: 0.333819\n",
      "Train Epoch: 1499 [480/1612 (30%)] Loss: 0.259186\n",
      "Train Epoch: 1499 [640/1612 (40%)] Loss: 0.300569\n",
      "Train Epoch: 1499 [800/1612 (50%)] Loss: 0.232617\n",
      "Train Epoch: 1499 [960/1612 (59%)] Loss: 0.131108\n",
      "Train Epoch: 1499 [1120/1612 (69%)] Loss: 0.185594\n",
      "Train Epoch: 1499 [1280/1612 (79%)] Loss: 0.408644\n",
      "Train Epoch: 1499 [1440/1612 (89%)] Loss: 0.186084\n",
      "Train Epoch: 1499 [1200/1612 (99%)] Loss: 0.335388\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1500 [0/1612 (0%)] Loss: 0.222754\n",
      "Train Epoch: 1500 [160/1612 (10%)] Loss: 0.287145\n",
      "Train Epoch: 1500 [320/1612 (20%)] Loss: 0.378639\n",
      "Train Epoch: 1500 [480/1612 (30%)] Loss: 0.339031\n",
      "Train Epoch: 1500 [640/1612 (40%)] Loss: 0.335480\n",
      "Train Epoch: 1500 [800/1612 (50%)] Loss: 0.233493\n",
      "Train Epoch: 1500 [960/1612 (59%)] Loss: 0.243505\n",
      "Train Epoch: 1500 [1120/1612 (69%)] Loss: 0.261098\n",
      "Train Epoch: 1500 [1280/1612 (79%)] Loss: 0.387501\n",
      "Train Epoch: 1500 [1440/1612 (89%)] Loss: 0.265802\n",
      "Train Epoch: 1500 [1200/1612 (99%)] Loss: 0.379773\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1501 [0/1612 (0%)] Loss: 0.167228\n",
      "Train Epoch: 1501 [160/1612 (10%)] Loss: 0.214128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1501 [320/1612 (20%)] Loss: 0.125422\n",
      "Train Epoch: 1501 [480/1612 (30%)] Loss: 0.332208\n",
      "Train Epoch: 1501 [640/1612 (40%)] Loss: 0.202159\n",
      "Train Epoch: 1501 [800/1612 (50%)] Loss: 0.481232\n",
      "Train Epoch: 1501 [960/1612 (59%)] Loss: 0.237886\n",
      "Train Epoch: 1501 [1120/1612 (69%)] Loss: 0.412014\n",
      "Train Epoch: 1501 [1280/1612 (79%)] Loss: 0.257720\n",
      "Train Epoch: 1501 [1440/1612 (89%)] Loss: 0.189129\n",
      "Train Epoch: 1501 [1200/1612 (99%)] Loss: 0.598691\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1502 [0/1612 (0%)] Loss: 0.223245\n",
      "Train Epoch: 1502 [160/1612 (10%)] Loss: 0.320594\n",
      "Train Epoch: 1502 [320/1612 (20%)] Loss: 0.364713\n",
      "Train Epoch: 1502 [480/1612 (30%)] Loss: 0.281189\n",
      "Train Epoch: 1502 [640/1612 (40%)] Loss: 0.211432\n",
      "Train Epoch: 1502 [800/1612 (50%)] Loss: 0.260470\n",
      "Train Epoch: 1502 [960/1612 (59%)] Loss: 0.210605\n",
      "Train Epoch: 1502 [1120/1612 (69%)] Loss: 0.149696\n",
      "Train Epoch: 1502 [1280/1612 (79%)] Loss: 0.173702\n",
      "Train Epoch: 1502 [1440/1612 (89%)] Loss: 0.362999\n",
      "Train Epoch: 1502 [1200/1612 (99%)] Loss: 0.202313\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1503 [0/1612 (0%)] Loss: 0.337971\n",
      "Train Epoch: 1503 [160/1612 (10%)] Loss: 0.177255\n",
      "Train Epoch: 1503 [320/1612 (20%)] Loss: 0.261017\n",
      "Train Epoch: 1503 [480/1612 (30%)] Loss: 0.433120\n",
      "Train Epoch: 1503 [640/1612 (40%)] Loss: 0.235408\n",
      "Train Epoch: 1503 [800/1612 (50%)] Loss: 0.269458\n",
      "Train Epoch: 1503 [960/1612 (59%)] Loss: 0.386221\n",
      "Train Epoch: 1503 [1120/1612 (69%)] Loss: 0.292633\n",
      "Train Epoch: 1503 [1280/1612 (79%)] Loss: 0.400951\n",
      "Train Epoch: 1503 [1440/1612 (89%)] Loss: 0.383372\n",
      "Train Epoch: 1503 [1200/1612 (99%)] Loss: 0.355600\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1504 [0/1612 (0%)] Loss: 0.486833\n",
      "Train Epoch: 1504 [160/1612 (10%)] Loss: 0.155294\n",
      "Train Epoch: 1504 [320/1612 (20%)] Loss: 0.203676\n",
      "Train Epoch: 1504 [480/1612 (30%)] Loss: 0.109532\n",
      "Train Epoch: 1504 [640/1612 (40%)] Loss: 0.196863\n",
      "Train Epoch: 1504 [800/1612 (50%)] Loss: 0.172307\n",
      "Train Epoch: 1504 [960/1612 (59%)] Loss: 0.178928\n",
      "Train Epoch: 1504 [1120/1612 (69%)] Loss: 0.213471\n",
      "Train Epoch: 1504 [1280/1612 (79%)] Loss: 0.182191\n",
      "Train Epoch: 1504 [1440/1612 (89%)] Loss: 0.265298\n",
      "Train Epoch: 1504 [1200/1612 (99%)] Loss: 0.540296\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1505 [0/1612 (0%)] Loss: 0.393862\n",
      "Train Epoch: 1505 [160/1612 (10%)] Loss: 0.334289\n",
      "Train Epoch: 1505 [320/1612 (20%)] Loss: 0.341244\n",
      "Train Epoch: 1505 [480/1612 (30%)] Loss: 0.306176\n",
      "Train Epoch: 1505 [640/1612 (40%)] Loss: 0.096828\n",
      "Train Epoch: 1505 [800/1612 (50%)] Loss: 0.296923\n",
      "Train Epoch: 1505 [960/1612 (59%)] Loss: 0.354123\n",
      "Train Epoch: 1505 [1120/1612 (69%)] Loss: 0.293607\n",
      "Train Epoch: 1505 [1280/1612 (79%)] Loss: 0.527162\n",
      "Train Epoch: 1505 [1440/1612 (89%)] Loss: 0.636899\n",
      "Train Epoch: 1505 [1200/1612 (99%)] Loss: 0.308939\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1506 [0/1612 (0%)] Loss: 0.171341\n",
      "Train Epoch: 1506 [160/1612 (10%)] Loss: 0.350518\n",
      "Train Epoch: 1506 [320/1612 (20%)] Loss: 0.203716\n",
      "Train Epoch: 1506 [480/1612 (30%)] Loss: 0.399264\n",
      "Train Epoch: 1506 [640/1612 (40%)] Loss: 0.313331\n",
      "Train Epoch: 1506 [800/1612 (50%)] Loss: 0.322536\n",
      "Train Epoch: 1506 [960/1612 (59%)] Loss: 0.294401\n",
      "Train Epoch: 1506 [1120/1612 (69%)] Loss: 0.235538\n",
      "Train Epoch: 1506 [1280/1612 (79%)] Loss: 0.424898\n",
      "Train Epoch: 1506 [1440/1612 (89%)] Loss: 0.438172\n",
      "Train Epoch: 1506 [1200/1612 (99%)] Loss: 0.544912\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1507 [0/1612 (0%)] Loss: 0.104335\n",
      "Train Epoch: 1507 [160/1612 (10%)] Loss: 0.507855\n",
      "Train Epoch: 1507 [320/1612 (20%)] Loss: 0.391596\n",
      "Train Epoch: 1507 [480/1612 (30%)] Loss: 0.463721\n",
      "Train Epoch: 1507 [640/1612 (40%)] Loss: 0.168518\n",
      "Train Epoch: 1507 [800/1612 (50%)] Loss: 0.362437\n",
      "Train Epoch: 1507 [960/1612 (59%)] Loss: 0.365745\n",
      "Train Epoch: 1507 [1120/1612 (69%)] Loss: 0.205660\n",
      "Train Epoch: 1507 [1280/1612 (79%)] Loss: 0.126079\n",
      "Train Epoch: 1507 [1440/1612 (89%)] Loss: 0.222964\n",
      "Train Epoch: 1507 [1200/1612 (99%)] Loss: 0.269500\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1508 [0/1612 (0%)] Loss: 0.118039\n",
      "Train Epoch: 1508 [160/1612 (10%)] Loss: 0.486507\n",
      "Train Epoch: 1508 [320/1612 (20%)] Loss: 0.218778\n",
      "Train Epoch: 1508 [480/1612 (30%)] Loss: 0.306266\n",
      "Train Epoch: 1508 [640/1612 (40%)] Loss: 0.229299\n",
      "Train Epoch: 1508 [800/1612 (50%)] Loss: 0.208499\n",
      "Train Epoch: 1508 [960/1612 (59%)] Loss: 0.272318\n",
      "Train Epoch: 1508 [1120/1612 (69%)] Loss: 0.137536\n",
      "Train Epoch: 1508 [1280/1612 (79%)] Loss: 0.438562\n",
      "Train Epoch: 1508 [1440/1612 (89%)] Loss: 0.413704\n",
      "Train Epoch: 1508 [1200/1612 (99%)] Loss: 0.225026\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1509 [0/1612 (0%)] Loss: 0.359421\n",
      "Train Epoch: 1509 [160/1612 (10%)] Loss: 0.308323\n",
      "Train Epoch: 1509 [320/1612 (20%)] Loss: 0.106428\n",
      "Train Epoch: 1509 [480/1612 (30%)] Loss: 0.477110\n",
      "Train Epoch: 1509 [640/1612 (40%)] Loss: 0.283256\n",
      "Train Epoch: 1509 [800/1612 (50%)] Loss: 0.404962\n",
      "Train Epoch: 1509 [960/1612 (59%)] Loss: 0.502055\n",
      "Train Epoch: 1509 [1120/1612 (69%)] Loss: 0.311063\n",
      "Train Epoch: 1509 [1280/1612 (79%)] Loss: 0.110688\n",
      "Train Epoch: 1509 [1440/1612 (89%)] Loss: 0.266490\n",
      "Train Epoch: 1509 [1200/1612 (99%)] Loss: 0.331047\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1510 [0/1612 (0%)] Loss: 0.112842\n",
      "Train Epoch: 1510 [160/1612 (10%)] Loss: 0.291230\n",
      "Train Epoch: 1510 [320/1612 (20%)] Loss: 0.129882\n",
      "Train Epoch: 1510 [480/1612 (30%)] Loss: 0.205112\n",
      "Train Epoch: 1510 [640/1612 (40%)] Loss: 0.491157\n",
      "Train Epoch: 1510 [800/1612 (50%)] Loss: 0.249594\n",
      "Train Epoch: 1510 [960/1612 (59%)] Loss: 0.193511\n",
      "Train Epoch: 1510 [1120/1612 (69%)] Loss: 0.355437\n",
      "Train Epoch: 1510 [1280/1612 (79%)] Loss: 0.347209\n",
      "Train Epoch: 1510 [1440/1612 (89%)] Loss: 0.399936\n",
      "Train Epoch: 1510 [1200/1612 (99%)] Loss: 0.280875\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1511 [0/1612 (0%)] Loss: 0.209316\n",
      "Train Epoch: 1511 [160/1612 (10%)] Loss: 0.123138\n",
      "Train Epoch: 1511 [320/1612 (20%)] Loss: 0.383288\n",
      "Train Epoch: 1511 [480/1612 (30%)] Loss: 0.220225\n",
      "Train Epoch: 1511 [640/1612 (40%)] Loss: 0.280180\n",
      "Train Epoch: 1511 [800/1612 (50%)] Loss: 0.484838\n",
      "Train Epoch: 1511 [960/1612 (59%)] Loss: 0.284287\n",
      "Train Epoch: 1511 [1120/1612 (69%)] Loss: 0.631728\n",
      "Train Epoch: 1511 [1280/1612 (79%)] Loss: 0.129784\n",
      "Train Epoch: 1511 [1440/1612 (89%)] Loss: 0.213944\n",
      "Train Epoch: 1511 [1200/1612 (99%)] Loss: 0.374664\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1512 [0/1612 (0%)] Loss: 0.404046\n",
      "Train Epoch: 1512 [160/1612 (10%)] Loss: 0.268132\n",
      "Train Epoch: 1512 [320/1612 (20%)] Loss: 0.248148\n",
      "Train Epoch: 1512 [480/1612 (30%)] Loss: 0.246595\n",
      "Train Epoch: 1512 [640/1612 (40%)] Loss: 0.729596\n",
      "Train Epoch: 1512 [800/1612 (50%)] Loss: 0.229159\n",
      "Train Epoch: 1512 [960/1612 (59%)] Loss: 0.342918\n",
      "Train Epoch: 1512 [1120/1612 (69%)] Loss: 0.257279\n",
      "Train Epoch: 1512 [1280/1612 (79%)] Loss: 0.215678\n",
      "Train Epoch: 1512 [1440/1612 (89%)] Loss: 0.237636\n",
      "Train Epoch: 1512 [1200/1612 (99%)] Loss: 0.349955\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1513 [0/1612 (0%)] Loss: 0.352429\n",
      "Train Epoch: 1513 [160/1612 (10%)] Loss: 0.343067\n",
      "Train Epoch: 1513 [320/1612 (20%)] Loss: 0.282319\n",
      "Train Epoch: 1513 [480/1612 (30%)] Loss: 0.284100\n",
      "Train Epoch: 1513 [640/1612 (40%)] Loss: 0.276692\n",
      "Train Epoch: 1513 [800/1612 (50%)] Loss: 0.187819\n",
      "Train Epoch: 1513 [960/1612 (59%)] Loss: 0.181981\n",
      "Train Epoch: 1513 [1120/1612 (69%)] Loss: 0.425409\n",
      "Train Epoch: 1513 [1280/1612 (79%)] Loss: 0.337091\n",
      "Train Epoch: 1513 [1440/1612 (89%)] Loss: 0.318877\n",
      "Train Epoch: 1513 [1200/1612 (99%)] Loss: 0.174946\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1514 [0/1612 (0%)] Loss: 0.105387\n",
      "Train Epoch: 1514 [160/1612 (10%)] Loss: 0.132760\n",
      "Train Epoch: 1514 [320/1612 (20%)] Loss: 0.173237\n",
      "Train Epoch: 1514 [480/1612 (30%)] Loss: 0.477241\n",
      "Train Epoch: 1514 [640/1612 (40%)] Loss: 0.227685\n",
      "Train Epoch: 1514 [800/1612 (50%)] Loss: 0.242496\n",
      "Train Epoch: 1514 [960/1612 (59%)] Loss: 0.257225\n",
      "Train Epoch: 1514 [1120/1612 (69%)] Loss: 0.256368\n",
      "Train Epoch: 1514 [1280/1612 (79%)] Loss: 0.290940\n",
      "Train Epoch: 1514 [1440/1612 (89%)] Loss: 0.200409\n",
      "Train Epoch: 1514 [1200/1612 (99%)] Loss: 0.183745\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1515 [0/1612 (0%)] Loss: 0.352564\n",
      "Train Epoch: 1515 [160/1612 (10%)] Loss: 0.182588\n",
      "Train Epoch: 1515 [320/1612 (20%)] Loss: 0.553434\n",
      "Train Epoch: 1515 [480/1612 (30%)] Loss: 0.279684\n",
      "Train Epoch: 1515 [640/1612 (40%)] Loss: 0.243392\n",
      "Train Epoch: 1515 [800/1612 (50%)] Loss: 0.228121\n",
      "Train Epoch: 1515 [960/1612 (59%)] Loss: 0.443100\n",
      "Train Epoch: 1515 [1120/1612 (69%)] Loss: 0.320490\n",
      "Train Epoch: 1515 [1280/1612 (79%)] Loss: 0.218582\n",
      "Train Epoch: 1515 [1440/1612 (89%)] Loss: 0.315415\n",
      "Train Epoch: 1515 [1200/1612 (99%)] Loss: 0.294406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1516 [0/1612 (0%)] Loss: 0.197870\n",
      "Train Epoch: 1516 [160/1612 (10%)] Loss: 0.296344\n",
      "Train Epoch: 1516 [320/1612 (20%)] Loss: 0.514717\n",
      "Train Epoch: 1516 [480/1612 (30%)] Loss: 0.324085\n",
      "Train Epoch: 1516 [640/1612 (40%)] Loss: 0.396207\n",
      "Train Epoch: 1516 [800/1612 (50%)] Loss: 0.255172\n",
      "Train Epoch: 1516 [960/1612 (59%)] Loss: 0.136613\n",
      "Train Epoch: 1516 [1120/1612 (69%)] Loss: 0.134553\n",
      "Train Epoch: 1516 [1280/1612 (79%)] Loss: 0.219434\n",
      "Train Epoch: 1516 [1440/1612 (89%)] Loss: 0.248129\n",
      "Train Epoch: 1516 [1200/1612 (99%)] Loss: 0.392401\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1517 [0/1612 (0%)] Loss: 0.310734\n",
      "Train Epoch: 1517 [160/1612 (10%)] Loss: 0.592946\n",
      "Train Epoch: 1517 [320/1612 (20%)] Loss: 0.347742\n",
      "Train Epoch: 1517 [480/1612 (30%)] Loss: 0.391059\n",
      "Train Epoch: 1517 [640/1612 (40%)] Loss: 0.408033\n",
      "Train Epoch: 1517 [800/1612 (50%)] Loss: 0.272132\n",
      "Train Epoch: 1517 [960/1612 (59%)] Loss: 0.399691\n",
      "Train Epoch: 1517 [1120/1612 (69%)] Loss: 0.313001\n",
      "Train Epoch: 1517 [1280/1612 (79%)] Loss: 0.294619\n",
      "Train Epoch: 1517 [1440/1612 (89%)] Loss: 0.329633\n",
      "Train Epoch: 1517 [1200/1612 (99%)] Loss: 0.263876\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1518 [0/1612 (0%)] Loss: 0.505666\n",
      "Train Epoch: 1518 [160/1612 (10%)] Loss: 0.405735\n",
      "Train Epoch: 1518 [320/1612 (20%)] Loss: 0.336377\n",
      "Train Epoch: 1518 [480/1612 (30%)] Loss: 0.342750\n",
      "Train Epoch: 1518 [640/1612 (40%)] Loss: 0.299207\n",
      "Train Epoch: 1518 [800/1612 (50%)] Loss: 0.227255\n",
      "Train Epoch: 1518 [960/1612 (59%)] Loss: 0.450089\n",
      "Train Epoch: 1518 [1120/1612 (69%)] Loss: 0.246905\n",
      "Train Epoch: 1518 [1280/1612 (79%)] Loss: 0.084581\n",
      "Train Epoch: 1518 [1440/1612 (89%)] Loss: 0.281517\n",
      "Train Epoch: 1518 [1200/1612 (99%)] Loss: 0.233989\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1519 [0/1612 (0%)] Loss: 0.259802\n",
      "Train Epoch: 1519 [160/1612 (10%)] Loss: 0.460083\n",
      "Train Epoch: 1519 [320/1612 (20%)] Loss: 0.282889\n",
      "Train Epoch: 1519 [480/1612 (30%)] Loss: 0.170232\n",
      "Train Epoch: 1519 [640/1612 (40%)] Loss: 0.464571\n",
      "Train Epoch: 1519 [800/1612 (50%)] Loss: 0.482917\n",
      "Train Epoch: 1519 [960/1612 (59%)] Loss: 0.284701\n",
      "Train Epoch: 1519 [1120/1612 (69%)] Loss: 0.380378\n",
      "Train Epoch: 1519 [1280/1612 (79%)] Loss: 0.387609\n",
      "Train Epoch: 1519 [1440/1612 (89%)] Loss: 0.253019\n",
      "Train Epoch: 1519 [1200/1612 (99%)] Loss: 0.213098\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1520 [0/1612 (0%)] Loss: 0.215961\n",
      "Train Epoch: 1520 [160/1612 (10%)] Loss: 0.266633\n",
      "Train Epoch: 1520 [320/1612 (20%)] Loss: 0.378412\n",
      "Train Epoch: 1520 [480/1612 (30%)] Loss: 0.317228\n",
      "Train Epoch: 1520 [640/1612 (40%)] Loss: 0.282574\n",
      "Train Epoch: 1520 [800/1612 (50%)] Loss: 0.254247\n",
      "Train Epoch: 1520 [960/1612 (59%)] Loss: 0.369094\n",
      "Train Epoch: 1520 [1120/1612 (69%)] Loss: 0.339547\n",
      "Train Epoch: 1520 [1280/1612 (79%)] Loss: 0.357526\n",
      "Train Epoch: 1520 [1440/1612 (89%)] Loss: 0.458453\n",
      "Train Epoch: 1520 [1200/1612 (99%)] Loss: 0.074479\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1521 [0/1612 (0%)] Loss: 0.383870\n",
      "Train Epoch: 1521 [160/1612 (10%)] Loss: 0.279424\n",
      "Train Epoch: 1521 [320/1612 (20%)] Loss: 0.385615\n",
      "Train Epoch: 1521 [480/1612 (30%)] Loss: 0.317568\n",
      "Train Epoch: 1521 [640/1612 (40%)] Loss: 0.142527\n",
      "Train Epoch: 1521 [800/1612 (50%)] Loss: 0.500925\n",
      "Train Epoch: 1521 [960/1612 (59%)] Loss: 0.314701\n",
      "Train Epoch: 1521 [1120/1612 (69%)] Loss: 0.158681\n",
      "Train Epoch: 1521 [1280/1612 (79%)] Loss: 0.310221\n",
      "Train Epoch: 1521 [1440/1612 (89%)] Loss: 0.258207\n",
      "Train Epoch: 1521 [1200/1612 (99%)] Loss: 0.455894\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1522 [0/1612 (0%)] Loss: 0.360529\n",
      "Train Epoch: 1522 [160/1612 (10%)] Loss: 0.252834\n",
      "Train Epoch: 1522 [320/1612 (20%)] Loss: 0.384527\n",
      "Train Epoch: 1522 [480/1612 (30%)] Loss: 0.330121\n",
      "Train Epoch: 1522 [640/1612 (40%)] Loss: 0.315164\n",
      "Train Epoch: 1522 [800/1612 (50%)] Loss: 0.404165\n",
      "Train Epoch: 1522 [960/1612 (59%)] Loss: 0.500246\n",
      "Train Epoch: 1522 [1120/1612 (69%)] Loss: 0.243264\n",
      "Train Epoch: 1522 [1280/1612 (79%)] Loss: 0.195188\n",
      "Train Epoch: 1522 [1440/1612 (89%)] Loss: 0.186474\n",
      "Train Epoch: 1522 [1200/1612 (99%)] Loss: 0.269548\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1523 [0/1612 (0%)] Loss: 0.211051\n",
      "Train Epoch: 1523 [160/1612 (10%)] Loss: 0.234126\n",
      "Train Epoch: 1523 [320/1612 (20%)] Loss: 0.246935\n",
      "Train Epoch: 1523 [480/1612 (30%)] Loss: 0.512574\n",
      "Train Epoch: 1523 [640/1612 (40%)] Loss: 0.297513\n",
      "Train Epoch: 1523 [800/1612 (50%)] Loss: 0.359951\n",
      "Train Epoch: 1523 [960/1612 (59%)] Loss: 0.194859\n",
      "Train Epoch: 1523 [1120/1612 (69%)] Loss: 0.306617\n",
      "Train Epoch: 1523 [1280/1612 (79%)] Loss: 0.562157\n",
      "Train Epoch: 1523 [1440/1612 (89%)] Loss: 0.186413\n",
      "Train Epoch: 1523 [1200/1612 (99%)] Loss: 0.384198\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1524 [0/1612 (0%)] Loss: 0.452745\n",
      "Train Epoch: 1524 [160/1612 (10%)] Loss: 0.383808\n",
      "Train Epoch: 1524 [320/1612 (20%)] Loss: 0.253112\n",
      "Train Epoch: 1524 [480/1612 (30%)] Loss: 0.440253\n",
      "Train Epoch: 1524 [640/1612 (40%)] Loss: 0.190452\n",
      "Train Epoch: 1524 [800/1612 (50%)] Loss: 0.439442\n",
      "Train Epoch: 1524 [960/1612 (59%)] Loss: 0.245175\n",
      "Train Epoch: 1524 [1120/1612 (69%)] Loss: 0.226825\n",
      "Train Epoch: 1524 [1280/1612 (79%)] Loss: 0.454141\n",
      "Train Epoch: 1524 [1440/1612 (89%)] Loss: 0.352846\n",
      "Train Epoch: 1524 [1200/1612 (99%)] Loss: 0.298694\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1525 [0/1612 (0%)] Loss: 0.273592\n",
      "Train Epoch: 1525 [160/1612 (10%)] Loss: 0.100542\n",
      "Train Epoch: 1525 [320/1612 (20%)] Loss: 0.162550\n",
      "Train Epoch: 1525 [480/1612 (30%)] Loss: 0.263781\n",
      "Train Epoch: 1525 [640/1612 (40%)] Loss: 0.254446\n",
      "Train Epoch: 1525 [800/1612 (50%)] Loss: 0.453449\n",
      "Train Epoch: 1525 [960/1612 (59%)] Loss: 0.279218\n",
      "Train Epoch: 1525 [1120/1612 (69%)] Loss: 0.367935\n",
      "Train Epoch: 1525 [1280/1612 (79%)] Loss: 0.193166\n",
      "Train Epoch: 1525 [1440/1612 (89%)] Loss: 0.442734\n",
      "Train Epoch: 1525 [1200/1612 (99%)] Loss: 0.238697\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1526 [0/1612 (0%)] Loss: 0.165507\n",
      "Train Epoch: 1526 [160/1612 (10%)] Loss: 0.133671\n",
      "Train Epoch: 1526 [320/1612 (20%)] Loss: 0.176608\n",
      "Train Epoch: 1526 [480/1612 (30%)] Loss: 0.279396\n",
      "Train Epoch: 1526 [640/1612 (40%)] Loss: 0.442023\n",
      "Train Epoch: 1526 [800/1612 (50%)] Loss: 0.077091\n",
      "Train Epoch: 1526 [960/1612 (59%)] Loss: 0.183634\n",
      "Train Epoch: 1526 [1120/1612 (69%)] Loss: 0.202523\n",
      "Train Epoch: 1526 [1280/1612 (79%)] Loss: 0.187088\n",
      "Train Epoch: 1526 [1440/1612 (89%)] Loss: 0.321744\n",
      "Train Epoch: 1526 [1200/1612 (99%)] Loss: 0.089780\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1527 [0/1612 (0%)] Loss: 0.392713\n",
      "Train Epoch: 1527 [160/1612 (10%)] Loss: 0.083973\n",
      "Train Epoch: 1527 [320/1612 (20%)] Loss: 0.155603\n",
      "Train Epoch: 1527 [480/1612 (30%)] Loss: 0.229931\n",
      "Train Epoch: 1527 [640/1612 (40%)] Loss: 0.360371\n",
      "Train Epoch: 1527 [800/1612 (50%)] Loss: 0.163614\n",
      "Train Epoch: 1527 [960/1612 (59%)] Loss: 0.335244\n",
      "Train Epoch: 1527 [1120/1612 (69%)] Loss: 0.214590\n",
      "Train Epoch: 1527 [1280/1612 (79%)] Loss: 0.406908\n",
      "Train Epoch: 1527 [1440/1612 (89%)] Loss: 0.299025\n",
      "Train Epoch: 1527 [1200/1612 (99%)] Loss: 0.511258\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1528 [0/1612 (0%)] Loss: 0.181637\n",
      "Train Epoch: 1528 [160/1612 (10%)] Loss: 0.469596\n",
      "Train Epoch: 1528 [320/1612 (20%)] Loss: 0.347272\n",
      "Train Epoch: 1528 [480/1612 (30%)] Loss: 0.489403\n",
      "Train Epoch: 1528 [640/1612 (40%)] Loss: 0.513221\n",
      "Train Epoch: 1528 [800/1612 (50%)] Loss: 0.112097\n",
      "Train Epoch: 1528 [960/1612 (59%)] Loss: 0.192433\n",
      "Train Epoch: 1528 [1120/1612 (69%)] Loss: 0.203145\n",
      "Train Epoch: 1528 [1280/1612 (79%)] Loss: 0.373476\n",
      "Train Epoch: 1528 [1440/1612 (89%)] Loss: 0.223479\n",
      "Train Epoch: 1528 [1200/1612 (99%)] Loss: 0.340112\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1529 [0/1612 (0%)] Loss: 0.219727\n",
      "Train Epoch: 1529 [160/1612 (10%)] Loss: 0.202180\n",
      "Train Epoch: 1529 [320/1612 (20%)] Loss: 0.337180\n",
      "Train Epoch: 1529 [480/1612 (30%)] Loss: 0.290920\n",
      "Train Epoch: 1529 [640/1612 (40%)] Loss: 0.209025\n",
      "Train Epoch: 1529 [800/1612 (50%)] Loss: 0.272069\n",
      "Train Epoch: 1529 [960/1612 (59%)] Loss: 0.484243\n",
      "Train Epoch: 1529 [1120/1612 (69%)] Loss: 0.429719\n",
      "Train Epoch: 1529 [1280/1612 (79%)] Loss: 0.266352\n",
      "Train Epoch: 1529 [1440/1612 (89%)] Loss: 0.452883\n",
      "Train Epoch: 1529 [1200/1612 (99%)] Loss: 0.278643\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1530 [0/1612 (0%)] Loss: 0.270023\n",
      "Train Epoch: 1530 [160/1612 (10%)] Loss: 0.462524\n",
      "Train Epoch: 1530 [320/1612 (20%)] Loss: 0.220116\n",
      "Train Epoch: 1530 [480/1612 (30%)] Loss: 0.436903\n",
      "Train Epoch: 1530 [640/1612 (40%)] Loss: 0.284079\n",
      "Train Epoch: 1530 [800/1612 (50%)] Loss: 0.231748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1530 [960/1612 (59%)] Loss: 0.212698\n",
      "Train Epoch: 1530 [1120/1612 (69%)] Loss: 0.299140\n",
      "Train Epoch: 1530 [1280/1612 (79%)] Loss: 0.302549\n",
      "Train Epoch: 1530 [1440/1612 (89%)] Loss: 0.281971\n",
      "Train Epoch: 1530 [1200/1612 (99%)] Loss: 0.430413\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1531 [0/1612 (0%)] Loss: 0.498662\n",
      "Train Epoch: 1531 [160/1612 (10%)] Loss: 0.186076\n",
      "Train Epoch: 1531 [320/1612 (20%)] Loss: 0.308857\n",
      "Train Epoch: 1531 [480/1612 (30%)] Loss: 0.366974\n",
      "Train Epoch: 1531 [640/1612 (40%)] Loss: 0.286658\n",
      "Train Epoch: 1531 [800/1612 (50%)] Loss: 0.474496\n",
      "Train Epoch: 1531 [960/1612 (59%)] Loss: 0.357159\n",
      "Train Epoch: 1531 [1120/1612 (69%)] Loss: 0.231513\n",
      "Train Epoch: 1531 [1280/1612 (79%)] Loss: 0.298948\n",
      "Train Epoch: 1531 [1440/1612 (89%)] Loss: 0.297602\n",
      "Train Epoch: 1531 [1200/1612 (99%)] Loss: 0.307073\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1532 [0/1612 (0%)] Loss: 0.493627\n",
      "Train Epoch: 1532 [160/1612 (10%)] Loss: 0.537627\n",
      "Train Epoch: 1532 [320/1612 (20%)] Loss: 0.266069\n",
      "Train Epoch: 1532 [480/1612 (30%)] Loss: 0.312841\n",
      "Train Epoch: 1532 [640/1612 (40%)] Loss: 0.255465\n",
      "Train Epoch: 1532 [800/1612 (50%)] Loss: 0.348088\n",
      "Train Epoch: 1532 [960/1612 (59%)] Loss: 0.159937\n",
      "Train Epoch: 1532 [1120/1612 (69%)] Loss: 0.828314\n",
      "Train Epoch: 1532 [1280/1612 (79%)] Loss: 0.222432\n",
      "Train Epoch: 1532 [1440/1612 (89%)] Loss: 0.244268\n",
      "Train Epoch: 1532 [1200/1612 (99%)] Loss: 0.328541\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1533 [0/1612 (0%)] Loss: 0.490507\n",
      "Train Epoch: 1533 [160/1612 (10%)] Loss: 0.277951\n",
      "Train Epoch: 1533 [320/1612 (20%)] Loss: 0.199402\n",
      "Train Epoch: 1533 [480/1612 (30%)] Loss: 0.201981\n",
      "Train Epoch: 1533 [640/1612 (40%)] Loss: 0.408966\n",
      "Train Epoch: 1533 [800/1612 (50%)] Loss: 0.373901\n",
      "Train Epoch: 1533 [960/1612 (59%)] Loss: 0.214267\n",
      "Train Epoch: 1533 [1120/1612 (69%)] Loss: 0.431508\n",
      "Train Epoch: 1533 [1280/1612 (79%)] Loss: 0.268206\n",
      "Train Epoch: 1533 [1440/1612 (89%)] Loss: 0.273853\n",
      "Train Epoch: 1533 [1200/1612 (99%)] Loss: 0.404428\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1534 [0/1612 (0%)] Loss: 0.703219\n",
      "Train Epoch: 1534 [160/1612 (10%)] Loss: 0.429905\n",
      "Train Epoch: 1534 [320/1612 (20%)] Loss: 0.338618\n",
      "Train Epoch: 1534 [480/1612 (30%)] Loss: 0.126803\n",
      "Train Epoch: 1534 [640/1612 (40%)] Loss: 0.455635\n",
      "Train Epoch: 1534 [800/1612 (50%)] Loss: 0.315318\n",
      "Train Epoch: 1534 [960/1612 (59%)] Loss: 0.225801\n",
      "Train Epoch: 1534 [1120/1612 (69%)] Loss: 0.225902\n",
      "Train Epoch: 1534 [1280/1612 (79%)] Loss: 0.172812\n",
      "Train Epoch: 1534 [1440/1612 (89%)] Loss: 0.200017\n",
      "Train Epoch: 1534 [1200/1612 (99%)] Loss: 0.623197\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1535 [0/1612 (0%)] Loss: 0.246730\n",
      "Train Epoch: 1535 [160/1612 (10%)] Loss: 0.282262\n",
      "Train Epoch: 1535 [320/1612 (20%)] Loss: 0.332028\n",
      "Train Epoch: 1535 [480/1612 (30%)] Loss: 0.504664\n",
      "Train Epoch: 1535 [640/1612 (40%)] Loss: 0.441150\n",
      "Train Epoch: 1535 [800/1612 (50%)] Loss: 0.309207\n",
      "Train Epoch: 1535 [960/1612 (59%)] Loss: 0.249956\n",
      "Train Epoch: 1535 [1120/1612 (69%)] Loss: 0.181665\n",
      "Train Epoch: 1535 [1280/1612 (79%)] Loss: 0.258807\n",
      "Train Epoch: 1535 [1440/1612 (89%)] Loss: 0.299081\n",
      "Train Epoch: 1535 [1200/1612 (99%)] Loss: 0.329681\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1536 [0/1612 (0%)] Loss: 0.306921\n",
      "Train Epoch: 1536 [160/1612 (10%)] Loss: 0.170428\n",
      "Train Epoch: 1536 [320/1612 (20%)] Loss: 0.451933\n",
      "Train Epoch: 1536 [480/1612 (30%)] Loss: 0.220981\n",
      "Train Epoch: 1536 [640/1612 (40%)] Loss: 0.161298\n",
      "Train Epoch: 1536 [800/1612 (50%)] Loss: 0.198503\n",
      "Train Epoch: 1536 [960/1612 (59%)] Loss: 0.357235\n",
      "Train Epoch: 1536 [1120/1612 (69%)] Loss: 0.489942\n",
      "Train Epoch: 1536 [1280/1612 (79%)] Loss: 0.200131\n",
      "Train Epoch: 1536 [1440/1612 (89%)] Loss: 0.309697\n",
      "Train Epoch: 1536 [1200/1612 (99%)] Loss: 0.256454\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1537 [0/1612 (0%)] Loss: 0.337597\n",
      "Train Epoch: 1537 [160/1612 (10%)] Loss: 0.277164\n",
      "Train Epoch: 1537 [320/1612 (20%)] Loss: 0.165660\n",
      "Train Epoch: 1537 [480/1612 (30%)] Loss: 0.419370\n",
      "Train Epoch: 1537 [640/1612 (40%)] Loss: 0.212627\n",
      "Train Epoch: 1537 [800/1612 (50%)] Loss: 0.264373\n",
      "Train Epoch: 1537 [960/1612 (59%)] Loss: 0.369603\n",
      "Train Epoch: 1537 [1120/1612 (69%)] Loss: 0.295223\n",
      "Train Epoch: 1537 [1280/1612 (79%)] Loss: 0.325192\n",
      "Train Epoch: 1537 [1440/1612 (89%)] Loss: 0.241791\n",
      "Train Epoch: 1537 [1200/1612 (99%)] Loss: 0.192462\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1538 [0/1612 (0%)] Loss: 0.423459\n",
      "Train Epoch: 1538 [160/1612 (10%)] Loss: 0.257605\n",
      "Train Epoch: 1538 [320/1612 (20%)] Loss: 0.267680\n",
      "Train Epoch: 1538 [480/1612 (30%)] Loss: 0.400592\n",
      "Train Epoch: 1538 [640/1612 (40%)] Loss: 0.189698\n",
      "Train Epoch: 1538 [800/1612 (50%)] Loss: 0.340709\n",
      "Train Epoch: 1538 [960/1612 (59%)] Loss: 0.141829\n",
      "Train Epoch: 1538 [1120/1612 (69%)] Loss: 0.148080\n",
      "Train Epoch: 1538 [1280/1612 (79%)] Loss: 0.268801\n",
      "Train Epoch: 1538 [1440/1612 (89%)] Loss: 0.351012\n",
      "Train Epoch: 1538 [1200/1612 (99%)] Loss: 0.289312\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1539 [0/1612 (0%)] Loss: 0.258180\n",
      "Train Epoch: 1539 [160/1612 (10%)] Loss: 0.289244\n",
      "Train Epoch: 1539 [320/1612 (20%)] Loss: 0.240846\n",
      "Train Epoch: 1539 [480/1612 (30%)] Loss: 0.304304\n",
      "Train Epoch: 1539 [640/1612 (40%)] Loss: 0.340286\n",
      "Train Epoch: 1539 [800/1612 (50%)] Loss: 0.126975\n",
      "Train Epoch: 1539 [960/1612 (59%)] Loss: 0.225146\n",
      "Train Epoch: 1539 [1120/1612 (69%)] Loss: 0.309965\n",
      "Train Epoch: 1539 [1280/1612 (79%)] Loss: 0.482135\n",
      "Train Epoch: 1539 [1440/1612 (89%)] Loss: 0.229249\n",
      "Train Epoch: 1539 [1200/1612 (99%)] Loss: 0.195073\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1540 [0/1612 (0%)] Loss: 0.412390\n",
      "Train Epoch: 1540 [160/1612 (10%)] Loss: 0.400496\n",
      "Train Epoch: 1540 [320/1612 (20%)] Loss: 0.231499\n",
      "Train Epoch: 1540 [480/1612 (30%)] Loss: 0.280364\n",
      "Train Epoch: 1540 [640/1612 (40%)] Loss: 0.206054\n",
      "Train Epoch: 1540 [800/1612 (50%)] Loss: 0.262196\n",
      "Train Epoch: 1540 [960/1612 (59%)] Loss: 0.153900\n",
      "Train Epoch: 1540 [1120/1612 (69%)] Loss: 0.230142\n",
      "Train Epoch: 1540 [1280/1612 (79%)] Loss: 0.413353\n",
      "Train Epoch: 1540 [1440/1612 (89%)] Loss: 0.502889\n",
      "Train Epoch: 1540 [1200/1612 (99%)] Loss: 0.355685\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1541 [0/1612 (0%)] Loss: 0.162024\n",
      "Train Epoch: 1541 [160/1612 (10%)] Loss: 0.353474\n",
      "Train Epoch: 1541 [320/1612 (20%)] Loss: 0.178123\n",
      "Train Epoch: 1541 [480/1612 (30%)] Loss: 0.251144\n",
      "Train Epoch: 1541 [640/1612 (40%)] Loss: 0.427543\n",
      "Train Epoch: 1541 [800/1612 (50%)] Loss: 0.247373\n",
      "Train Epoch: 1541 [960/1612 (59%)] Loss: 0.403519\n",
      "Train Epoch: 1541 [1120/1612 (69%)] Loss: 0.438046\n",
      "Train Epoch: 1541 [1280/1612 (79%)] Loss: 0.253506\n",
      "Train Epoch: 1541 [1440/1612 (89%)] Loss: 0.201876\n",
      "Train Epoch: 1541 [1200/1612 (99%)] Loss: 0.666131\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1542 [0/1612 (0%)] Loss: 0.295849\n",
      "Train Epoch: 1542 [160/1612 (10%)] Loss: 0.260740\n",
      "Train Epoch: 1542 [320/1612 (20%)] Loss: 0.199552\n",
      "Train Epoch: 1542 [480/1612 (30%)] Loss: 0.164828\n",
      "Train Epoch: 1542 [640/1612 (40%)] Loss: 0.434703\n",
      "Train Epoch: 1542 [800/1612 (50%)] Loss: 0.260877\n",
      "Train Epoch: 1542 [960/1612 (59%)] Loss: 0.432334\n",
      "Train Epoch: 1542 [1120/1612 (69%)] Loss: 0.193943\n",
      "Train Epoch: 1542 [1280/1612 (79%)] Loss: 0.262357\n",
      "Train Epoch: 1542 [1440/1612 (89%)] Loss: 0.289552\n",
      "Train Epoch: 1542 [1200/1612 (99%)] Loss: 0.298737\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1543 [0/1612 (0%)] Loss: 0.225220\n",
      "Train Epoch: 1543 [160/1612 (10%)] Loss: 0.271441\n",
      "Train Epoch: 1543 [320/1612 (20%)] Loss: 0.181290\n",
      "Train Epoch: 1543 [480/1612 (30%)] Loss: 0.264274\n",
      "Train Epoch: 1543 [640/1612 (40%)] Loss: 0.306925\n",
      "Train Epoch: 1543 [800/1612 (50%)] Loss: 0.322087\n",
      "Train Epoch: 1543 [960/1612 (59%)] Loss: 0.421607\n",
      "Train Epoch: 1543 [1120/1612 (69%)] Loss: 0.267945\n",
      "Train Epoch: 1543 [1280/1612 (79%)] Loss: 0.090648\n",
      "Train Epoch: 1543 [1440/1612 (89%)] Loss: 0.367988\n",
      "Train Epoch: 1543 [1200/1612 (99%)] Loss: 0.149220\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1544 [0/1612 (0%)] Loss: 0.159368\n",
      "Train Epoch: 1544 [160/1612 (10%)] Loss: 0.284355\n",
      "Train Epoch: 1544 [320/1612 (20%)] Loss: 0.163659\n",
      "Train Epoch: 1544 [480/1612 (30%)] Loss: 0.372760\n",
      "Train Epoch: 1544 [640/1612 (40%)] Loss: 0.219305\n",
      "Train Epoch: 1544 [800/1612 (50%)] Loss: 0.505264\n",
      "Train Epoch: 1544 [960/1612 (59%)] Loss: 0.340503\n",
      "Train Epoch: 1544 [1120/1612 (69%)] Loss: 0.323246\n",
      "Train Epoch: 1544 [1280/1612 (79%)] Loss: 0.197536\n",
      "Train Epoch: 1544 [1440/1612 (89%)] Loss: 0.285612\n",
      "Train Epoch: 1544 [1200/1612 (99%)] Loss: 0.272442\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1545 [0/1612 (0%)] Loss: 0.119768\n",
      "Train Epoch: 1545 [160/1612 (10%)] Loss: 0.369374\n",
      "Train Epoch: 1545 [320/1612 (20%)] Loss: 0.396214\n",
      "Train Epoch: 1545 [480/1612 (30%)] Loss: 0.161814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1545 [640/1612 (40%)] Loss: 0.349142\n",
      "Train Epoch: 1545 [800/1612 (50%)] Loss: 0.253161\n",
      "Train Epoch: 1545 [960/1612 (59%)] Loss: 0.235389\n",
      "Train Epoch: 1545 [1120/1612 (69%)] Loss: 0.214975\n",
      "Train Epoch: 1545 [1280/1612 (79%)] Loss: 0.418744\n",
      "Train Epoch: 1545 [1440/1612 (89%)] Loss: 0.232874\n",
      "Train Epoch: 1545 [1200/1612 (99%)] Loss: 0.239880\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1546 [0/1612 (0%)] Loss: 0.134080\n",
      "Train Epoch: 1546 [160/1612 (10%)] Loss: 0.270435\n",
      "Train Epoch: 1546 [320/1612 (20%)] Loss: 0.276083\n",
      "Train Epoch: 1546 [480/1612 (30%)] Loss: 0.392860\n",
      "Train Epoch: 1546 [640/1612 (40%)] Loss: 0.436345\n",
      "Train Epoch: 1546 [800/1612 (50%)] Loss: 0.454486\n",
      "Train Epoch: 1546 [960/1612 (59%)] Loss: 0.264891\n",
      "Train Epoch: 1546 [1120/1612 (69%)] Loss: 0.426156\n",
      "Train Epoch: 1546 [1280/1612 (79%)] Loss: 0.244490\n",
      "Train Epoch: 1546 [1440/1612 (89%)] Loss: 0.171405\n",
      "Train Epoch: 1546 [1200/1612 (99%)] Loss: 0.261779\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1547 [0/1612 (0%)] Loss: 0.318681\n",
      "Train Epoch: 1547 [160/1612 (10%)] Loss: 0.216071\n",
      "Train Epoch: 1547 [320/1612 (20%)] Loss: 0.367738\n",
      "Train Epoch: 1547 [480/1612 (30%)] Loss: 0.293990\n",
      "Train Epoch: 1547 [640/1612 (40%)] Loss: 0.183948\n",
      "Train Epoch: 1547 [800/1612 (50%)] Loss: 0.289856\n",
      "Train Epoch: 1547 [960/1612 (59%)] Loss: 0.302259\n",
      "Train Epoch: 1547 [1120/1612 (69%)] Loss: 0.149992\n",
      "Train Epoch: 1547 [1280/1612 (79%)] Loss: 0.254330\n",
      "Train Epoch: 1547 [1440/1612 (89%)] Loss: 0.122063\n",
      "Train Epoch: 1547 [1200/1612 (99%)] Loss: 0.468673\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1548 [0/1612 (0%)] Loss: 0.389089\n",
      "Train Epoch: 1548 [160/1612 (10%)] Loss: 0.217837\n",
      "Train Epoch: 1548 [320/1612 (20%)] Loss: 0.297806\n",
      "Train Epoch: 1548 [480/1612 (30%)] Loss: 0.094170\n",
      "Train Epoch: 1548 [640/1612 (40%)] Loss: 0.396964\n",
      "Train Epoch: 1548 [800/1612 (50%)] Loss: 0.300404\n",
      "Train Epoch: 1548 [960/1612 (59%)] Loss: 0.084475\n",
      "Train Epoch: 1548 [1120/1612 (69%)] Loss: 0.203621\n",
      "Train Epoch: 1548 [1280/1612 (79%)] Loss: 0.265058\n",
      "Train Epoch: 1548 [1440/1612 (89%)] Loss: 0.268874\n",
      "Train Epoch: 1548 [1200/1612 (99%)] Loss: 0.321326\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1549 [0/1612 (0%)] Loss: 0.236090\n",
      "Train Epoch: 1549 [160/1612 (10%)] Loss: 0.233590\n",
      "Train Epoch: 1549 [320/1612 (20%)] Loss: 0.345584\n",
      "Train Epoch: 1549 [480/1612 (30%)] Loss: 0.207182\n",
      "Train Epoch: 1549 [640/1612 (40%)] Loss: 0.178382\n",
      "Train Epoch: 1549 [800/1612 (50%)] Loss: 0.609540\n",
      "Train Epoch: 1549 [960/1612 (59%)] Loss: 0.186204\n",
      "Train Epoch: 1549 [1120/1612 (69%)] Loss: 0.455084\n",
      "Train Epoch: 1549 [1280/1612 (79%)] Loss: 0.354431\n",
      "Train Epoch: 1549 [1440/1612 (89%)] Loss: 0.375011\n",
      "Train Epoch: 1549 [1200/1612 (99%)] Loss: 0.223195\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1550 [0/1612 (0%)] Loss: 0.320996\n",
      "Train Epoch: 1550 [160/1612 (10%)] Loss: 0.239953\n",
      "Train Epoch: 1550 [320/1612 (20%)] Loss: 0.284130\n",
      "Train Epoch: 1550 [480/1612 (30%)] Loss: 0.195309\n",
      "Train Epoch: 1550 [640/1612 (40%)] Loss: 0.487260\n",
      "Train Epoch: 1550 [800/1612 (50%)] Loss: 0.322440\n",
      "Train Epoch: 1550 [960/1612 (59%)] Loss: 0.193553\n",
      "Train Epoch: 1550 [1120/1612 (69%)] Loss: 0.257332\n",
      "Train Epoch: 1550 [1280/1612 (79%)] Loss: 0.211286\n",
      "Train Epoch: 1550 [1440/1612 (89%)] Loss: 0.233000\n",
      "Train Epoch: 1550 [1200/1612 (99%)] Loss: 0.521511\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1551 [0/1612 (0%)] Loss: 0.298485\n",
      "Train Epoch: 1551 [160/1612 (10%)] Loss: 0.442772\n",
      "Train Epoch: 1551 [320/1612 (20%)] Loss: 0.302039\n",
      "Train Epoch: 1551 [480/1612 (30%)] Loss: 0.317782\n",
      "Train Epoch: 1551 [640/1612 (40%)] Loss: 0.353897\n",
      "Train Epoch: 1551 [800/1612 (50%)] Loss: 0.247568\n",
      "Train Epoch: 1551 [960/1612 (59%)] Loss: 0.288404\n",
      "Train Epoch: 1551 [1120/1612 (69%)] Loss: 0.235801\n",
      "Train Epoch: 1551 [1280/1612 (79%)] Loss: 0.544500\n",
      "Train Epoch: 1551 [1440/1612 (89%)] Loss: 0.218670\n",
      "Train Epoch: 1551 [1200/1612 (99%)] Loss: 0.361202\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1552 [0/1612 (0%)] Loss: 0.283067\n",
      "Train Epoch: 1552 [160/1612 (10%)] Loss: 0.084809\n",
      "Train Epoch: 1552 [320/1612 (20%)] Loss: 0.449135\n",
      "Train Epoch: 1552 [480/1612 (30%)] Loss: 0.273338\n",
      "Train Epoch: 1552 [640/1612 (40%)] Loss: 0.287889\n",
      "Train Epoch: 1552 [800/1612 (50%)] Loss: 0.416333\n",
      "Train Epoch: 1552 [960/1612 (59%)] Loss: 0.177005\n",
      "Train Epoch: 1552 [1120/1612 (69%)] Loss: 0.350263\n",
      "Train Epoch: 1552 [1280/1612 (79%)] Loss: 0.312442\n",
      "Train Epoch: 1552 [1440/1612 (89%)] Loss: 0.269842\n",
      "Train Epoch: 1552 [1200/1612 (99%)] Loss: 0.275554\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1553 [0/1612 (0%)] Loss: 0.265670\n",
      "Train Epoch: 1553 [160/1612 (10%)] Loss: 0.153174\n",
      "Train Epoch: 1553 [320/1612 (20%)] Loss: 0.384716\n",
      "Train Epoch: 1553 [480/1612 (30%)] Loss: 0.262961\n",
      "Train Epoch: 1553 [640/1612 (40%)] Loss: 0.300538\n",
      "Train Epoch: 1553 [800/1612 (50%)] Loss: 0.254666\n",
      "Train Epoch: 1553 [960/1612 (59%)] Loss: 0.331860\n",
      "Train Epoch: 1553 [1120/1612 (69%)] Loss: 0.372368\n",
      "Train Epoch: 1553 [1280/1612 (79%)] Loss: 0.376844\n",
      "Train Epoch: 1553 [1440/1612 (89%)] Loss: 0.241204\n",
      "Train Epoch: 1553 [1200/1612 (99%)] Loss: 0.252412\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1554 [0/1612 (0%)] Loss: 0.384161\n",
      "Train Epoch: 1554 [160/1612 (10%)] Loss: 0.416422\n",
      "Train Epoch: 1554 [320/1612 (20%)] Loss: 0.297861\n",
      "Train Epoch: 1554 [480/1612 (30%)] Loss: 0.318124\n",
      "Train Epoch: 1554 [640/1612 (40%)] Loss: 0.158668\n",
      "Train Epoch: 1554 [800/1612 (50%)] Loss: 0.293463\n",
      "Train Epoch: 1554 [960/1612 (59%)] Loss: 0.403463\n",
      "Train Epoch: 1554 [1120/1612 (69%)] Loss: 0.284904\n",
      "Train Epoch: 1554 [1280/1612 (79%)] Loss: 0.375540\n",
      "Train Epoch: 1554 [1440/1612 (89%)] Loss: 0.207341\n",
      "Train Epoch: 1554 [1200/1612 (99%)] Loss: 0.636022\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1555 [0/1612 (0%)] Loss: 0.106646\n",
      "Train Epoch: 1555 [160/1612 (10%)] Loss: 0.411413\n",
      "Train Epoch: 1555 [320/1612 (20%)] Loss: 0.252766\n",
      "Train Epoch: 1555 [480/1612 (30%)] Loss: 0.164174\n",
      "Train Epoch: 1555 [640/1612 (40%)] Loss: 0.263416\n",
      "Train Epoch: 1555 [800/1612 (50%)] Loss: 0.259693\n",
      "Train Epoch: 1555 [960/1612 (59%)] Loss: 0.211605\n",
      "Train Epoch: 1555 [1120/1612 (69%)] Loss: 0.255784\n",
      "Train Epoch: 1555 [1280/1612 (79%)] Loss: 0.562497\n",
      "Train Epoch: 1555 [1440/1612 (89%)] Loss: 0.311626\n",
      "Train Epoch: 1555 [1200/1612 (99%)] Loss: 0.226069\n",
      "\n",
      "Test set: Average loss: 0.0295, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1556 [0/1612 (0%)] Loss: 0.260740\n",
      "Train Epoch: 1556 [160/1612 (10%)] Loss: 0.227625\n",
      "Train Epoch: 1556 [320/1612 (20%)] Loss: 0.459250\n",
      "Train Epoch: 1556 [480/1612 (30%)] Loss: 0.281484\n",
      "Train Epoch: 1556 [640/1612 (40%)] Loss: 0.141845\n",
      "Train Epoch: 1556 [800/1612 (50%)] Loss: 0.416530\n",
      "Train Epoch: 1556 [960/1612 (59%)] Loss: 0.332721\n",
      "Train Epoch: 1556 [1120/1612 (69%)] Loss: 0.352544\n",
      "Train Epoch: 1556 [1280/1612 (79%)] Loss: 0.287377\n",
      "Train Epoch: 1556 [1440/1612 (89%)] Loss: 0.290107\n",
      "Train Epoch: 1556 [1200/1612 (99%)] Loss: 0.351717\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1557 [0/1612 (0%)] Loss: 0.372432\n",
      "Train Epoch: 1557 [160/1612 (10%)] Loss: 0.366833\n",
      "Train Epoch: 1557 [320/1612 (20%)] Loss: 0.381675\n",
      "Train Epoch: 1557 [480/1612 (30%)] Loss: 0.316331\n",
      "Train Epoch: 1557 [640/1612 (40%)] Loss: 0.360531\n",
      "Train Epoch: 1557 [800/1612 (50%)] Loss: 0.295778\n",
      "Train Epoch: 1557 [960/1612 (59%)] Loss: 0.126600\n",
      "Train Epoch: 1557 [1120/1612 (69%)] Loss: 0.351185\n",
      "Train Epoch: 1557 [1280/1612 (79%)] Loss: 0.249767\n",
      "Train Epoch: 1557 [1440/1612 (89%)] Loss: 0.147532\n",
      "Train Epoch: 1557 [1200/1612 (99%)] Loss: 0.107943\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1558 [0/1612 (0%)] Loss: 0.311423\n",
      "Train Epoch: 1558 [160/1612 (10%)] Loss: 0.236355\n",
      "Train Epoch: 1558 [320/1612 (20%)] Loss: 0.041202\n",
      "Train Epoch: 1558 [480/1612 (30%)] Loss: 0.434313\n",
      "Train Epoch: 1558 [640/1612 (40%)] Loss: 0.613729\n",
      "Train Epoch: 1558 [800/1612 (50%)] Loss: 0.380627\n",
      "Train Epoch: 1558 [960/1612 (59%)] Loss: 0.132622\n",
      "Train Epoch: 1558 [1120/1612 (69%)] Loss: 0.137290\n",
      "Train Epoch: 1558 [1280/1612 (79%)] Loss: 0.340181\n",
      "Train Epoch: 1558 [1440/1612 (89%)] Loss: 0.406422\n",
      "Train Epoch: 1558 [1200/1612 (99%)] Loss: 0.300630\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1559 [0/1612 (0%)] Loss: 0.367877\n",
      "Train Epoch: 1559 [160/1612 (10%)] Loss: 0.250539\n",
      "Train Epoch: 1559 [320/1612 (20%)] Loss: 0.121422\n",
      "Train Epoch: 1559 [480/1612 (30%)] Loss: 0.366821\n",
      "Train Epoch: 1559 [640/1612 (40%)] Loss: 0.233248\n",
      "Train Epoch: 1559 [800/1612 (50%)] Loss: 0.141668\n",
      "Train Epoch: 1559 [960/1612 (59%)] Loss: 0.092488\n",
      "Train Epoch: 1559 [1120/1612 (69%)] Loss: 0.298259\n",
      "Train Epoch: 1559 [1280/1612 (79%)] Loss: 0.308269\n",
      "Train Epoch: 1559 [1440/1612 (89%)] Loss: 0.256968\n",
      "Train Epoch: 1559 [1200/1612 (99%)] Loss: 0.366055\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1560 [0/1612 (0%)] Loss: 0.135225\n",
      "Train Epoch: 1560 [160/1612 (10%)] Loss: 0.214870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1560 [320/1612 (20%)] Loss: 0.287836\n",
      "Train Epoch: 1560 [480/1612 (30%)] Loss: 0.364562\n",
      "Train Epoch: 1560 [640/1612 (40%)] Loss: 0.173653\n",
      "Train Epoch: 1560 [800/1612 (50%)] Loss: 0.488892\n",
      "Train Epoch: 1560 [960/1612 (59%)] Loss: 0.641153\n",
      "Train Epoch: 1560 [1120/1612 (69%)] Loss: 0.410399\n",
      "Train Epoch: 1560 [1280/1612 (79%)] Loss: 0.338383\n",
      "Train Epoch: 1560 [1440/1612 (89%)] Loss: 0.311054\n",
      "Train Epoch: 1560 [1200/1612 (99%)] Loss: 0.317793\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1561 [0/1612 (0%)] Loss: 0.295168\n",
      "Train Epoch: 1561 [160/1612 (10%)] Loss: 0.228680\n",
      "Train Epoch: 1561 [320/1612 (20%)] Loss: 0.310001\n",
      "Train Epoch: 1561 [480/1612 (30%)] Loss: 0.487261\n",
      "Train Epoch: 1561 [640/1612 (40%)] Loss: 0.273308\n",
      "Train Epoch: 1561 [800/1612 (50%)] Loss: 0.276140\n",
      "Train Epoch: 1561 [960/1612 (59%)] Loss: 0.267650\n",
      "Train Epoch: 1561 [1120/1612 (69%)] Loss: 0.183122\n",
      "Train Epoch: 1561 [1280/1612 (79%)] Loss: 0.217870\n",
      "Train Epoch: 1561 [1440/1612 (89%)] Loss: 0.517897\n",
      "Train Epoch: 1561 [1200/1612 (99%)] Loss: 0.545991\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1562 [0/1612 (0%)] Loss: 0.272941\n",
      "Train Epoch: 1562 [160/1612 (10%)] Loss: 0.253580\n",
      "Train Epoch: 1562 [320/1612 (20%)] Loss: 0.410965\n",
      "Train Epoch: 1562 [480/1612 (30%)] Loss: 0.219644\n",
      "Train Epoch: 1562 [640/1612 (40%)] Loss: 0.361945\n",
      "Train Epoch: 1562 [800/1612 (50%)] Loss: 0.318732\n",
      "Train Epoch: 1562 [960/1612 (59%)] Loss: 0.370789\n",
      "Train Epoch: 1562 [1120/1612 (69%)] Loss: 0.284273\n",
      "Train Epoch: 1562 [1280/1612 (79%)] Loss: 0.098459\n",
      "Train Epoch: 1562 [1440/1612 (89%)] Loss: 0.285165\n",
      "Train Epoch: 1562 [1200/1612 (99%)] Loss: 0.174012\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1563 [0/1612 (0%)] Loss: 0.224286\n",
      "Train Epoch: 1563 [160/1612 (10%)] Loss: 0.301787\n",
      "Train Epoch: 1563 [320/1612 (20%)] Loss: 0.247300\n",
      "Train Epoch: 1563 [480/1612 (30%)] Loss: 0.259905\n",
      "Train Epoch: 1563 [640/1612 (40%)] Loss: 0.189777\n",
      "Train Epoch: 1563 [800/1612 (50%)] Loss: 0.269233\n",
      "Train Epoch: 1563 [960/1612 (59%)] Loss: 0.110379\n",
      "Train Epoch: 1563 [1120/1612 (69%)] Loss: 0.461771\n",
      "Train Epoch: 1563 [1280/1612 (79%)] Loss: 0.270014\n",
      "Train Epoch: 1563 [1440/1612 (89%)] Loss: 0.265639\n",
      "Train Epoch: 1563 [1200/1612 (99%)] Loss: 0.244120\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1564 [0/1612 (0%)] Loss: 0.430108\n",
      "Train Epoch: 1564 [160/1612 (10%)] Loss: 0.222530\n",
      "Train Epoch: 1564 [320/1612 (20%)] Loss: 0.362620\n",
      "Train Epoch: 1564 [480/1612 (30%)] Loss: 0.098740\n",
      "Train Epoch: 1564 [640/1612 (40%)] Loss: 0.262518\n",
      "Train Epoch: 1564 [800/1612 (50%)] Loss: 0.234297\n",
      "Train Epoch: 1564 [960/1612 (59%)] Loss: 0.361141\n",
      "Train Epoch: 1564 [1120/1612 (69%)] Loss: 0.133776\n",
      "Train Epoch: 1564 [1280/1612 (79%)] Loss: 0.293581\n",
      "Train Epoch: 1564 [1440/1612 (89%)] Loss: 0.305297\n",
      "Train Epoch: 1564 [1200/1612 (99%)] Loss: 0.417176\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1565 [0/1612 (0%)] Loss: 0.263448\n",
      "Train Epoch: 1565 [160/1612 (10%)] Loss: 0.353884\n",
      "Train Epoch: 1565 [320/1612 (20%)] Loss: 0.155863\n",
      "Train Epoch: 1565 [480/1612 (30%)] Loss: 0.269398\n",
      "Train Epoch: 1565 [640/1612 (40%)] Loss: 0.285318\n",
      "Train Epoch: 1565 [800/1612 (50%)] Loss: 0.510409\n",
      "Train Epoch: 1565 [960/1612 (59%)] Loss: 0.142154\n",
      "Train Epoch: 1565 [1120/1612 (69%)] Loss: 0.810754\n",
      "Train Epoch: 1565 [1280/1612 (79%)] Loss: 0.381104\n",
      "Train Epoch: 1565 [1440/1612 (89%)] Loss: 0.341514\n",
      "Train Epoch: 1565 [1200/1612 (99%)] Loss: 0.323338\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1566 [0/1612 (0%)] Loss: 0.237935\n",
      "Train Epoch: 1566 [160/1612 (10%)] Loss: 0.432696\n",
      "Train Epoch: 1566 [320/1612 (20%)] Loss: 0.464476\n",
      "Train Epoch: 1566 [480/1612 (30%)] Loss: 0.219652\n",
      "Train Epoch: 1566 [640/1612 (40%)] Loss: 0.437594\n",
      "Train Epoch: 1566 [800/1612 (50%)] Loss: 0.526301\n",
      "Train Epoch: 1566 [960/1612 (59%)] Loss: 0.185152\n",
      "Train Epoch: 1566 [1120/1612 (69%)] Loss: 0.318437\n",
      "Train Epoch: 1566 [1280/1612 (79%)] Loss: 0.370099\n",
      "Train Epoch: 1566 [1440/1612 (89%)] Loss: 0.196467\n",
      "Train Epoch: 1566 [1200/1612 (99%)] Loss: 0.648691\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1567 [0/1612 (0%)] Loss: 0.173284\n",
      "Train Epoch: 1567 [160/1612 (10%)] Loss: 0.355300\n",
      "Train Epoch: 1567 [320/1612 (20%)] Loss: 0.284414\n",
      "Train Epoch: 1567 [480/1612 (30%)] Loss: 0.247553\n",
      "Train Epoch: 1567 [640/1612 (40%)] Loss: 0.242610\n",
      "Train Epoch: 1567 [800/1612 (50%)] Loss: 0.206289\n",
      "Train Epoch: 1567 [960/1612 (59%)] Loss: 0.085232\n",
      "Train Epoch: 1567 [1120/1612 (69%)] Loss: 0.370967\n",
      "Train Epoch: 1567 [1280/1612 (79%)] Loss: 0.139520\n",
      "Train Epoch: 1567 [1440/1612 (89%)] Loss: 0.153084\n",
      "Train Epoch: 1567 [1200/1612 (99%)] Loss: 0.159628\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1568 [0/1612 (0%)] Loss: 0.279518\n",
      "Train Epoch: 1568 [160/1612 (10%)] Loss: 0.156812\n",
      "Train Epoch: 1568 [320/1612 (20%)] Loss: 0.270661\n",
      "Train Epoch: 1568 [480/1612 (30%)] Loss: 0.299599\n",
      "Train Epoch: 1568 [640/1612 (40%)] Loss: 0.187258\n",
      "Train Epoch: 1568 [800/1612 (50%)] Loss: 0.181421\n",
      "Train Epoch: 1568 [960/1612 (59%)] Loss: 0.145069\n",
      "Train Epoch: 1568 [1120/1612 (69%)] Loss: 0.210424\n",
      "Train Epoch: 1568 [1280/1612 (79%)] Loss: 0.141267\n",
      "Train Epoch: 1568 [1440/1612 (89%)] Loss: 0.119446\n",
      "Train Epoch: 1568 [1200/1612 (99%)] Loss: 0.317301\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1569 [0/1612 (0%)] Loss: 0.071908\n",
      "Train Epoch: 1569 [160/1612 (10%)] Loss: 0.307010\n",
      "Train Epoch: 1569 [320/1612 (20%)] Loss: 0.316233\n",
      "Train Epoch: 1569 [480/1612 (30%)] Loss: 0.283790\n",
      "Train Epoch: 1569 [640/1612 (40%)] Loss: 0.235046\n",
      "Train Epoch: 1569 [800/1612 (50%)] Loss: 0.366079\n",
      "Train Epoch: 1569 [960/1612 (59%)] Loss: 0.242681\n",
      "Train Epoch: 1569 [1120/1612 (69%)] Loss: 0.338370\n",
      "Train Epoch: 1569 [1280/1612 (79%)] Loss: 0.333755\n",
      "Train Epoch: 1569 [1440/1612 (89%)] Loss: 0.268149\n",
      "Train Epoch: 1569 [1200/1612 (99%)] Loss: 0.299123\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1570 [0/1612 (0%)] Loss: 0.310951\n",
      "Train Epoch: 1570 [160/1612 (10%)] Loss: 0.424749\n",
      "Train Epoch: 1570 [320/1612 (20%)] Loss: 0.327599\n",
      "Train Epoch: 1570 [480/1612 (30%)] Loss: 0.423764\n",
      "Train Epoch: 1570 [640/1612 (40%)] Loss: 0.280977\n",
      "Train Epoch: 1570 [800/1612 (50%)] Loss: 0.512287\n",
      "Train Epoch: 1570 [960/1612 (59%)] Loss: 0.313932\n",
      "Train Epoch: 1570 [1120/1612 (69%)] Loss: 0.237389\n",
      "Train Epoch: 1570 [1280/1612 (79%)] Loss: 0.238588\n",
      "Train Epoch: 1570 [1440/1612 (89%)] Loss: 0.275351\n",
      "Train Epoch: 1570 [1200/1612 (99%)] Loss: 0.446411\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1571 [0/1612 (0%)] Loss: 0.453072\n",
      "Train Epoch: 1571 [160/1612 (10%)] Loss: 0.219594\n",
      "Train Epoch: 1571 [320/1612 (20%)] Loss: 0.315519\n",
      "Train Epoch: 1571 [480/1612 (30%)] Loss: 0.550778\n",
      "Train Epoch: 1571 [640/1612 (40%)] Loss: 0.081150\n",
      "Train Epoch: 1571 [800/1612 (50%)] Loss: 0.345251\n",
      "Train Epoch: 1571 [960/1612 (59%)] Loss: 0.280263\n",
      "Train Epoch: 1571 [1120/1612 (69%)] Loss: 0.295272\n",
      "Train Epoch: 1571 [1280/1612 (79%)] Loss: 0.241766\n",
      "Train Epoch: 1571 [1440/1612 (89%)] Loss: 0.229065\n",
      "Train Epoch: 1571 [1200/1612 (99%)] Loss: 0.317999\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1572 [0/1612 (0%)] Loss: 0.276259\n",
      "Train Epoch: 1572 [160/1612 (10%)] Loss: 0.356589\n",
      "Train Epoch: 1572 [320/1612 (20%)] Loss: 0.304918\n",
      "Train Epoch: 1572 [480/1612 (30%)] Loss: 0.306626\n",
      "Train Epoch: 1572 [640/1612 (40%)] Loss: 0.195117\n",
      "Train Epoch: 1572 [800/1612 (50%)] Loss: 0.192068\n",
      "Train Epoch: 1572 [960/1612 (59%)] Loss: 0.369783\n",
      "Train Epoch: 1572 [1120/1612 (69%)] Loss: 0.310965\n",
      "Train Epoch: 1572 [1280/1612 (79%)] Loss: 0.204718\n",
      "Train Epoch: 1572 [1440/1612 (89%)] Loss: 0.547943\n",
      "Train Epoch: 1572 [1200/1612 (99%)] Loss: 0.184344\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1573 [0/1612 (0%)] Loss: 0.308219\n",
      "Train Epoch: 1573 [160/1612 (10%)] Loss: 0.389458\n",
      "Train Epoch: 1573 [320/1612 (20%)] Loss: 0.198760\n",
      "Train Epoch: 1573 [480/1612 (30%)] Loss: 0.302559\n",
      "Train Epoch: 1573 [640/1612 (40%)] Loss: 0.199018\n",
      "Train Epoch: 1573 [800/1612 (50%)] Loss: 0.366396\n",
      "Train Epoch: 1573 [960/1612 (59%)] Loss: 0.109780\n",
      "Train Epoch: 1573 [1120/1612 (69%)] Loss: 0.079404\n",
      "Train Epoch: 1573 [1280/1612 (79%)] Loss: 0.144710\n",
      "Train Epoch: 1573 [1440/1612 (89%)] Loss: 0.138236\n",
      "Train Epoch: 1573 [1200/1612 (99%)] Loss: 0.206588\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1574 [0/1612 (0%)] Loss: 0.245103\n",
      "Train Epoch: 1574 [160/1612 (10%)] Loss: 0.338567\n",
      "Train Epoch: 1574 [320/1612 (20%)] Loss: 0.245828\n",
      "Train Epoch: 1574 [480/1612 (30%)] Loss: 0.240375\n",
      "Train Epoch: 1574 [640/1612 (40%)] Loss: 0.119201\n",
      "Train Epoch: 1574 [800/1612 (50%)] Loss: 0.352979\n",
      "Train Epoch: 1574 [960/1612 (59%)] Loss: 0.295359\n",
      "Train Epoch: 1574 [1120/1612 (69%)] Loss: 0.117361\n",
      "Train Epoch: 1574 [1280/1612 (79%)] Loss: 0.307916\n",
      "Train Epoch: 1574 [1440/1612 (89%)] Loss: 0.336750\n",
      "Train Epoch: 1574 [1200/1612 (99%)] Loss: 0.620689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1575 [0/1612 (0%)] Loss: 0.455351\n",
      "Train Epoch: 1575 [160/1612 (10%)] Loss: 0.448026\n",
      "Train Epoch: 1575 [320/1612 (20%)] Loss: 0.228274\n",
      "Train Epoch: 1575 [480/1612 (30%)] Loss: 0.226819\n",
      "Train Epoch: 1575 [640/1612 (40%)] Loss: 0.489842\n",
      "Train Epoch: 1575 [800/1612 (50%)] Loss: 0.430776\n",
      "Train Epoch: 1575 [960/1612 (59%)] Loss: 0.306615\n",
      "Train Epoch: 1575 [1120/1612 (69%)] Loss: 0.319579\n",
      "Train Epoch: 1575 [1280/1612 (79%)] Loss: 0.271172\n",
      "Train Epoch: 1575 [1440/1612 (89%)] Loss: 0.405265\n",
      "Train Epoch: 1575 [1200/1612 (99%)] Loss: 0.269413\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1576 [0/1612 (0%)] Loss: 0.160246\n",
      "Train Epoch: 1576 [160/1612 (10%)] Loss: 0.228063\n",
      "Train Epoch: 1576 [320/1612 (20%)] Loss: 0.084930\n",
      "Train Epoch: 1576 [480/1612 (30%)] Loss: 0.187281\n",
      "Train Epoch: 1576 [640/1612 (40%)] Loss: 0.374881\n",
      "Train Epoch: 1576 [800/1612 (50%)] Loss: 0.470099\n",
      "Train Epoch: 1576 [960/1612 (59%)] Loss: 0.265795\n",
      "Train Epoch: 1576 [1120/1612 (69%)] Loss: 0.298262\n",
      "Train Epoch: 1576 [1280/1612 (79%)] Loss: 0.387116\n",
      "Train Epoch: 1576 [1440/1612 (89%)] Loss: 0.213986\n",
      "Train Epoch: 1576 [1200/1612 (99%)] Loss: 0.342951\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1577 [0/1612 (0%)] Loss: 0.224977\n",
      "Train Epoch: 1577 [160/1612 (10%)] Loss: 0.307018\n",
      "Train Epoch: 1577 [320/1612 (20%)] Loss: 0.156851\n",
      "Train Epoch: 1577 [480/1612 (30%)] Loss: 0.313683\n",
      "Train Epoch: 1577 [640/1612 (40%)] Loss: 0.263071\n",
      "Train Epoch: 1577 [800/1612 (50%)] Loss: 0.175928\n",
      "Train Epoch: 1577 [960/1612 (59%)] Loss: 0.135954\n",
      "Train Epoch: 1577 [1120/1612 (69%)] Loss: 0.556194\n",
      "Train Epoch: 1577 [1280/1612 (79%)] Loss: 0.267995\n",
      "Train Epoch: 1577 [1440/1612 (89%)] Loss: 0.395472\n",
      "Train Epoch: 1577 [1200/1612 (99%)] Loss: 0.460584\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1578 [0/1612 (0%)] Loss: 0.316329\n",
      "Train Epoch: 1578 [160/1612 (10%)] Loss: 0.294915\n",
      "Train Epoch: 1578 [320/1612 (20%)] Loss: 0.227269\n",
      "Train Epoch: 1578 [480/1612 (30%)] Loss: 0.121501\n",
      "Train Epoch: 1578 [640/1612 (40%)] Loss: 0.419252\n",
      "Train Epoch: 1578 [800/1612 (50%)] Loss: 0.149146\n",
      "Train Epoch: 1578 [960/1612 (59%)] Loss: 0.297552\n",
      "Train Epoch: 1578 [1120/1612 (69%)] Loss: 0.290690\n",
      "Train Epoch: 1578 [1280/1612 (79%)] Loss: 0.310708\n",
      "Train Epoch: 1578 [1440/1612 (89%)] Loss: 0.276815\n",
      "Train Epoch: 1578 [1200/1612 (99%)] Loss: 0.400559\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1579 [0/1612 (0%)] Loss: 0.219517\n",
      "Train Epoch: 1579 [160/1612 (10%)] Loss: 0.263472\n",
      "Train Epoch: 1579 [320/1612 (20%)] Loss: 0.173089\n",
      "Train Epoch: 1579 [480/1612 (30%)] Loss: 0.200166\n",
      "Train Epoch: 1579 [640/1612 (40%)] Loss: 0.478008\n",
      "Train Epoch: 1579 [800/1612 (50%)] Loss: 0.290455\n",
      "Train Epoch: 1579 [960/1612 (59%)] Loss: 0.396369\n",
      "Train Epoch: 1579 [1120/1612 (69%)] Loss: 0.336033\n",
      "Train Epoch: 1579 [1280/1612 (79%)] Loss: 0.249516\n",
      "Train Epoch: 1579 [1440/1612 (89%)] Loss: 0.490113\n",
      "Train Epoch: 1579 [1200/1612 (99%)] Loss: 0.408589\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1580 [0/1612 (0%)] Loss: 0.346150\n",
      "Train Epoch: 1580 [160/1612 (10%)] Loss: 0.437652\n",
      "Train Epoch: 1580 [320/1612 (20%)] Loss: 0.282850\n",
      "Train Epoch: 1580 [480/1612 (30%)] Loss: 0.395851\n",
      "Train Epoch: 1580 [640/1612 (40%)] Loss: 0.533888\n",
      "Train Epoch: 1580 [800/1612 (50%)] Loss: 0.248492\n",
      "Train Epoch: 1580 [960/1612 (59%)] Loss: 0.215094\n",
      "Train Epoch: 1580 [1120/1612 (69%)] Loss: 0.265315\n",
      "Train Epoch: 1580 [1280/1612 (79%)] Loss: 0.305977\n",
      "Train Epoch: 1580 [1440/1612 (89%)] Loss: 0.243138\n",
      "Train Epoch: 1580 [1200/1612 (99%)] Loss: 0.125979\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1581 [0/1612 (0%)] Loss: 0.453078\n",
      "Train Epoch: 1581 [160/1612 (10%)] Loss: 0.207655\n",
      "Train Epoch: 1581 [320/1612 (20%)] Loss: 0.122031\n",
      "Train Epoch: 1581 [480/1612 (30%)] Loss: 0.313452\n",
      "Train Epoch: 1581 [640/1612 (40%)] Loss: 0.148929\n",
      "Train Epoch: 1581 [800/1612 (50%)] Loss: 0.122838\n",
      "Train Epoch: 1581 [960/1612 (59%)] Loss: 0.349606\n",
      "Train Epoch: 1581 [1120/1612 (69%)] Loss: 0.473778\n",
      "Train Epoch: 1581 [1280/1612 (79%)] Loss: 0.235427\n",
      "Train Epoch: 1581 [1440/1612 (89%)] Loss: 0.466465\n",
      "Train Epoch: 1581 [1200/1612 (99%)] Loss: 0.423006\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1582 [0/1612 (0%)] Loss: 0.147226\n",
      "Train Epoch: 1582 [160/1612 (10%)] Loss: 0.183059\n",
      "Train Epoch: 1582 [320/1612 (20%)] Loss: 0.395866\n",
      "Train Epoch: 1582 [480/1612 (30%)] Loss: 0.132475\n",
      "Train Epoch: 1582 [640/1612 (40%)] Loss: 0.193132\n",
      "Train Epoch: 1582 [800/1612 (50%)] Loss: 0.213591\n",
      "Train Epoch: 1582 [960/1612 (59%)] Loss: 0.320754\n",
      "Train Epoch: 1582 [1120/1612 (69%)] Loss: 0.303443\n",
      "Train Epoch: 1582 [1280/1612 (79%)] Loss: 0.524771\n",
      "Train Epoch: 1582 [1440/1612 (89%)] Loss: 0.351277\n",
      "Train Epoch: 1582 [1200/1612 (99%)] Loss: 0.474757\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1583 [0/1612 (0%)] Loss: 0.288753\n",
      "Train Epoch: 1583 [160/1612 (10%)] Loss: 0.249544\n",
      "Train Epoch: 1583 [320/1612 (20%)] Loss: 0.401085\n",
      "Train Epoch: 1583 [480/1612 (30%)] Loss: 0.271642\n",
      "Train Epoch: 1583 [640/1612 (40%)] Loss: 0.378369\n",
      "Train Epoch: 1583 [800/1612 (50%)] Loss: 0.489371\n",
      "Train Epoch: 1583 [960/1612 (59%)] Loss: 0.274539\n",
      "Train Epoch: 1583 [1120/1612 (69%)] Loss: 0.258394\n",
      "Train Epoch: 1583 [1280/1612 (79%)] Loss: 0.282768\n",
      "Train Epoch: 1583 [1440/1612 (89%)] Loss: 0.390697\n",
      "Train Epoch: 1583 [1200/1612 (99%)] Loss: 0.254967\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1584 [0/1612 (0%)] Loss: 0.195904\n",
      "Train Epoch: 1584 [160/1612 (10%)] Loss: 0.204388\n",
      "Train Epoch: 1584 [320/1612 (20%)] Loss: 0.083325\n",
      "Train Epoch: 1584 [480/1612 (30%)] Loss: 0.179874\n",
      "Train Epoch: 1584 [640/1612 (40%)] Loss: 0.317055\n",
      "Train Epoch: 1584 [800/1612 (50%)] Loss: 0.302189\n",
      "Train Epoch: 1584 [960/1612 (59%)] Loss: 0.245666\n",
      "Train Epoch: 1584 [1120/1612 (69%)] Loss: 0.211373\n",
      "Train Epoch: 1584 [1280/1612 (79%)] Loss: 0.207485\n",
      "Train Epoch: 1584 [1440/1612 (89%)] Loss: 0.256731\n",
      "Train Epoch: 1584 [1200/1612 (99%)] Loss: 0.347609\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1585 [0/1612 (0%)] Loss: 0.151922\n",
      "Train Epoch: 1585 [160/1612 (10%)] Loss: 0.303819\n",
      "Train Epoch: 1585 [320/1612 (20%)] Loss: 0.425364\n",
      "Train Epoch: 1585 [480/1612 (30%)] Loss: 0.422778\n",
      "Train Epoch: 1585 [640/1612 (40%)] Loss: 0.264130\n",
      "Train Epoch: 1585 [800/1612 (50%)] Loss: 0.423436\n",
      "Train Epoch: 1585 [960/1612 (59%)] Loss: 0.343908\n",
      "Train Epoch: 1585 [1120/1612 (69%)] Loss: 0.109731\n",
      "Train Epoch: 1585 [1280/1612 (79%)] Loss: 0.375010\n",
      "Train Epoch: 1585 [1440/1612 (89%)] Loss: 0.480670\n",
      "Train Epoch: 1585 [1200/1612 (99%)] Loss: 0.398463\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1586 [0/1612 (0%)] Loss: 0.333890\n",
      "Train Epoch: 1586 [160/1612 (10%)] Loss: 0.437263\n",
      "Train Epoch: 1586 [320/1612 (20%)] Loss: 0.343163\n",
      "Train Epoch: 1586 [480/1612 (30%)] Loss: 0.269343\n",
      "Train Epoch: 1586 [640/1612 (40%)] Loss: 0.205014\n",
      "Train Epoch: 1586 [800/1612 (50%)] Loss: 0.204207\n",
      "Train Epoch: 1586 [960/1612 (59%)] Loss: 0.235450\n",
      "Train Epoch: 1586 [1120/1612 (69%)] Loss: 0.284825\n",
      "Train Epoch: 1586 [1280/1612 (79%)] Loss: 0.327192\n",
      "Train Epoch: 1586 [1440/1612 (89%)] Loss: 0.247676\n",
      "Train Epoch: 1586 [1200/1612 (99%)] Loss: 0.295105\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1587 [0/1612 (0%)] Loss: 0.632441\n",
      "Train Epoch: 1587 [160/1612 (10%)] Loss: 0.224725\n",
      "Train Epoch: 1587 [320/1612 (20%)] Loss: 0.110130\n",
      "Train Epoch: 1587 [480/1612 (30%)] Loss: 0.326033\n",
      "Train Epoch: 1587 [640/1612 (40%)] Loss: 0.257611\n",
      "Train Epoch: 1587 [800/1612 (50%)] Loss: 0.220628\n",
      "Train Epoch: 1587 [960/1612 (59%)] Loss: 0.362316\n",
      "Train Epoch: 1587 [1120/1612 (69%)] Loss: 0.295447\n",
      "Train Epoch: 1587 [1280/1612 (79%)] Loss: 0.364576\n",
      "Train Epoch: 1587 [1440/1612 (89%)] Loss: 0.166820\n",
      "Train Epoch: 1587 [1200/1612 (99%)] Loss: 0.288779\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1588 [0/1612 (0%)] Loss: 0.127620\n",
      "Train Epoch: 1588 [160/1612 (10%)] Loss: 0.106082\n",
      "Train Epoch: 1588 [320/1612 (20%)] Loss: 0.354828\n",
      "Train Epoch: 1588 [480/1612 (30%)] Loss: 0.344561\n",
      "Train Epoch: 1588 [640/1612 (40%)] Loss: 0.260265\n",
      "Train Epoch: 1588 [800/1612 (50%)] Loss: 0.100317\n",
      "Train Epoch: 1588 [960/1612 (59%)] Loss: 0.482047\n",
      "Train Epoch: 1588 [1120/1612 (69%)] Loss: 0.482663\n",
      "Train Epoch: 1588 [1280/1612 (79%)] Loss: 0.300968\n",
      "Train Epoch: 1588 [1440/1612 (89%)] Loss: 0.231284\n",
      "Train Epoch: 1588 [1200/1612 (99%)] Loss: 0.170391\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1589 [0/1612 (0%)] Loss: 0.222824\n",
      "Train Epoch: 1589 [160/1612 (10%)] Loss: 0.333064\n",
      "Train Epoch: 1589 [320/1612 (20%)] Loss: 0.453641\n",
      "Train Epoch: 1589 [480/1612 (30%)] Loss: 0.322193\n",
      "Train Epoch: 1589 [640/1612 (40%)] Loss: 0.199321\n",
      "Train Epoch: 1589 [800/1612 (50%)] Loss: 0.356664\n",
      "Train Epoch: 1589 [960/1612 (59%)] Loss: 0.574760\n",
      "Train Epoch: 1589 [1120/1612 (69%)] Loss: 0.252430\n",
      "Train Epoch: 1589 [1280/1612 (79%)] Loss: 0.211392\n",
      "Train Epoch: 1589 [1440/1612 (89%)] Loss: 0.146707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1589 [1200/1612 (99%)] Loss: 0.231333\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1590 [0/1612 (0%)] Loss: 0.417919\n",
      "Train Epoch: 1590 [160/1612 (10%)] Loss: 0.282388\n",
      "Train Epoch: 1590 [320/1612 (20%)] Loss: 0.182377\n",
      "Train Epoch: 1590 [480/1612 (30%)] Loss: 0.215536\n",
      "Train Epoch: 1590 [640/1612 (40%)] Loss: 0.452719\n",
      "Train Epoch: 1590 [800/1612 (50%)] Loss: 0.084751\n",
      "Train Epoch: 1590 [960/1612 (59%)] Loss: 0.302509\n",
      "Train Epoch: 1590 [1120/1612 (69%)] Loss: 0.279068\n",
      "Train Epoch: 1590 [1280/1612 (79%)] Loss: 0.199482\n",
      "Train Epoch: 1590 [1440/1612 (89%)] Loss: 0.234993\n",
      "Train Epoch: 1590 [1200/1612 (99%)] Loss: 0.269868\n",
      "\n",
      "Test set: Average loss: 0.0316, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1591 [0/1612 (0%)] Loss: 0.235372\n",
      "Train Epoch: 1591 [160/1612 (10%)] Loss: 0.266528\n",
      "Train Epoch: 1591 [320/1612 (20%)] Loss: 0.233091\n",
      "Train Epoch: 1591 [480/1612 (30%)] Loss: 0.412531\n",
      "Train Epoch: 1591 [640/1612 (40%)] Loss: 0.194969\n",
      "Train Epoch: 1591 [800/1612 (50%)] Loss: 0.413003\n",
      "Train Epoch: 1591 [960/1612 (59%)] Loss: 0.379398\n",
      "Train Epoch: 1591 [1120/1612 (69%)] Loss: 0.376051\n",
      "Train Epoch: 1591 [1280/1612 (79%)] Loss: 0.244720\n",
      "Train Epoch: 1591 [1440/1612 (89%)] Loss: 0.164590\n",
      "Train Epoch: 1591 [1200/1612 (99%)] Loss: 0.638963\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1592 [0/1612 (0%)] Loss: 0.511275\n",
      "Train Epoch: 1592 [160/1612 (10%)] Loss: 0.600644\n",
      "Train Epoch: 1592 [320/1612 (20%)] Loss: 0.127061\n",
      "Train Epoch: 1592 [480/1612 (30%)] Loss: 0.253223\n",
      "Train Epoch: 1592 [640/1612 (40%)] Loss: 0.249407\n",
      "Train Epoch: 1592 [800/1612 (50%)] Loss: 0.263820\n",
      "Train Epoch: 1592 [960/1612 (59%)] Loss: 0.476667\n",
      "Train Epoch: 1592 [1120/1612 (69%)] Loss: 0.369468\n",
      "Train Epoch: 1592 [1280/1612 (79%)] Loss: 0.275343\n",
      "Train Epoch: 1592 [1440/1612 (89%)] Loss: 0.247598\n",
      "Train Epoch: 1592 [1200/1612 (99%)] Loss: 0.317491\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1593 [0/1612 (0%)] Loss: 0.297302\n",
      "Train Epoch: 1593 [160/1612 (10%)] Loss: 0.596005\n",
      "Train Epoch: 1593 [320/1612 (20%)] Loss: 0.132123\n",
      "Train Epoch: 1593 [480/1612 (30%)] Loss: 0.424860\n",
      "Train Epoch: 1593 [640/1612 (40%)] Loss: 0.460828\n",
      "Train Epoch: 1593 [800/1612 (50%)] Loss: 0.361753\n",
      "Train Epoch: 1593 [960/1612 (59%)] Loss: 0.345051\n",
      "Train Epoch: 1593 [1120/1612 (69%)] Loss: 0.354123\n",
      "Train Epoch: 1593 [1280/1612 (79%)] Loss: 0.256353\n",
      "Train Epoch: 1593 [1440/1612 (89%)] Loss: 0.275330\n",
      "Train Epoch: 1593 [1200/1612 (99%)] Loss: 0.252877\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1594 [0/1612 (0%)] Loss: 0.223936\n",
      "Train Epoch: 1594 [160/1612 (10%)] Loss: 0.309923\n",
      "Train Epoch: 1594 [320/1612 (20%)] Loss: 0.217830\n",
      "Train Epoch: 1594 [480/1612 (30%)] Loss: 0.267650\n",
      "Train Epoch: 1594 [640/1612 (40%)] Loss: 0.284777\n",
      "Train Epoch: 1594 [800/1612 (50%)] Loss: 0.376964\n",
      "Train Epoch: 1594 [960/1612 (59%)] Loss: 0.175136\n",
      "Train Epoch: 1594 [1120/1612 (69%)] Loss: 0.168342\n",
      "Train Epoch: 1594 [1280/1612 (79%)] Loss: 0.198374\n",
      "Train Epoch: 1594 [1440/1612 (89%)] Loss: 0.165720\n",
      "Train Epoch: 1594 [1200/1612 (99%)] Loss: 0.247692\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1595 [0/1612 (0%)] Loss: 0.315186\n",
      "Train Epoch: 1595 [160/1612 (10%)] Loss: 0.110774\n",
      "Train Epoch: 1595 [320/1612 (20%)] Loss: 0.210154\n",
      "Train Epoch: 1595 [480/1612 (30%)] Loss: 0.220276\n",
      "Train Epoch: 1595 [640/1612 (40%)] Loss: 0.450312\n",
      "Train Epoch: 1595 [800/1612 (50%)] Loss: 0.856998\n",
      "Train Epoch: 1595 [960/1612 (59%)] Loss: 0.291250\n",
      "Train Epoch: 1595 [1120/1612 (69%)] Loss: 0.263877\n",
      "Train Epoch: 1595 [1280/1612 (79%)] Loss: 0.182034\n",
      "Train Epoch: 1595 [1440/1612 (89%)] Loss: 0.298782\n",
      "Train Epoch: 1595 [1200/1612 (99%)] Loss: 0.271597\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1596 [0/1612 (0%)] Loss: 0.305402\n",
      "Train Epoch: 1596 [160/1612 (10%)] Loss: 0.240299\n",
      "Train Epoch: 1596 [320/1612 (20%)] Loss: 0.317647\n",
      "Train Epoch: 1596 [480/1612 (30%)] Loss: 0.266601\n",
      "Train Epoch: 1596 [640/1612 (40%)] Loss: 0.417840\n",
      "Train Epoch: 1596 [800/1612 (50%)] Loss: 0.393387\n",
      "Train Epoch: 1596 [960/1612 (59%)] Loss: 0.092090\n",
      "Train Epoch: 1596 [1120/1612 (69%)] Loss: 0.444322\n",
      "Train Epoch: 1596 [1280/1612 (79%)] Loss: 0.214113\n",
      "Train Epoch: 1596 [1440/1612 (89%)] Loss: 0.217515\n",
      "Train Epoch: 1596 [1200/1612 (99%)] Loss: 0.316102\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1597 [0/1612 (0%)] Loss: 0.250441\n",
      "Train Epoch: 1597 [160/1612 (10%)] Loss: 0.204700\n",
      "Train Epoch: 1597 [320/1612 (20%)] Loss: 0.301409\n",
      "Train Epoch: 1597 [480/1612 (30%)] Loss: 0.322119\n",
      "Train Epoch: 1597 [640/1612 (40%)] Loss: 0.305734\n",
      "Train Epoch: 1597 [800/1612 (50%)] Loss: 0.351071\n",
      "Train Epoch: 1597 [960/1612 (59%)] Loss: 0.354553\n",
      "Train Epoch: 1597 [1120/1612 (69%)] Loss: 0.289642\n",
      "Train Epoch: 1597 [1280/1612 (79%)] Loss: 0.113230\n",
      "Train Epoch: 1597 [1440/1612 (89%)] Loss: 0.309106\n",
      "Train Epoch: 1597 [1200/1612 (99%)] Loss: 0.364474\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1598 [0/1612 (0%)] Loss: 0.299510\n",
      "Train Epoch: 1598 [160/1612 (10%)] Loss: 0.390718\n",
      "Train Epoch: 1598 [320/1612 (20%)] Loss: 0.323117\n",
      "Train Epoch: 1598 [480/1612 (30%)] Loss: 0.280897\n",
      "Train Epoch: 1598 [640/1612 (40%)] Loss: 0.247361\n",
      "Train Epoch: 1598 [800/1612 (50%)] Loss: 0.204774\n",
      "Train Epoch: 1598 [960/1612 (59%)] Loss: 0.339214\n",
      "Train Epoch: 1598 [1120/1612 (69%)] Loss: 0.714835\n",
      "Train Epoch: 1598 [1280/1612 (79%)] Loss: 0.251451\n",
      "Train Epoch: 1598 [1440/1612 (89%)] Loss: 0.240874\n",
      "Train Epoch: 1598 [1200/1612 (99%)] Loss: 0.610591\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1599 [0/1612 (0%)] Loss: 0.275679\n",
      "Train Epoch: 1599 [160/1612 (10%)] Loss: 0.276030\n",
      "Train Epoch: 1599 [320/1612 (20%)] Loss: 0.209679\n",
      "Train Epoch: 1599 [480/1612 (30%)] Loss: 0.357958\n",
      "Train Epoch: 1599 [640/1612 (40%)] Loss: 0.370964\n",
      "Train Epoch: 1599 [800/1612 (50%)] Loss: 0.174127\n",
      "Train Epoch: 1599 [960/1612 (59%)] Loss: 0.302480\n",
      "Train Epoch: 1599 [1120/1612 (69%)] Loss: 0.129591\n",
      "Train Epoch: 1599 [1280/1612 (79%)] Loss: 0.349226\n",
      "Train Epoch: 1599 [1440/1612 (89%)] Loss: 0.261914\n",
      "Train Epoch: 1599 [1200/1612 (99%)] Loss: 0.355726\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1600 [0/1612 (0%)] Loss: 0.299515\n",
      "Train Epoch: 1600 [160/1612 (10%)] Loss: 0.333532\n",
      "Train Epoch: 1600 [320/1612 (20%)] Loss: 0.169772\n",
      "Train Epoch: 1600 [480/1612 (30%)] Loss: 0.387592\n",
      "Train Epoch: 1600 [640/1612 (40%)] Loss: 0.298787\n",
      "Train Epoch: 1600 [800/1612 (50%)] Loss: 0.141861\n",
      "Train Epoch: 1600 [960/1612 (59%)] Loss: 0.394225\n",
      "Train Epoch: 1600 [1120/1612 (69%)] Loss: 0.307622\n",
      "Train Epoch: 1600 [1280/1612 (79%)] Loss: 0.377909\n",
      "Train Epoch: 1600 [1440/1612 (89%)] Loss: 0.147610\n",
      "Train Epoch: 1600 [1200/1612 (99%)] Loss: 0.673522\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1601 [0/1612 (0%)] Loss: 0.369406\n",
      "Train Epoch: 1601 [160/1612 (10%)] Loss: 0.413553\n",
      "Train Epoch: 1601 [320/1612 (20%)] Loss: 0.234632\n",
      "Train Epoch: 1601 [480/1612 (30%)] Loss: 0.117766\n",
      "Train Epoch: 1601 [640/1612 (40%)] Loss: 0.514080\n",
      "Train Epoch: 1601 [800/1612 (50%)] Loss: 0.220666\n",
      "Train Epoch: 1601 [960/1612 (59%)] Loss: 0.437818\n",
      "Train Epoch: 1601 [1120/1612 (69%)] Loss: 0.225560\n",
      "Train Epoch: 1601 [1280/1612 (79%)] Loss: 0.420906\n",
      "Train Epoch: 1601 [1440/1612 (89%)] Loss: 0.402502\n",
      "Train Epoch: 1601 [1200/1612 (99%)] Loss: 0.372026\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1602 [0/1612 (0%)] Loss: 0.298563\n",
      "Train Epoch: 1602 [160/1612 (10%)] Loss: 0.249058\n",
      "Train Epoch: 1602 [320/1612 (20%)] Loss: 0.517327\n",
      "Train Epoch: 1602 [480/1612 (30%)] Loss: 0.180675\n",
      "Train Epoch: 1602 [640/1612 (40%)] Loss: 0.249861\n",
      "Train Epoch: 1602 [800/1612 (50%)] Loss: 0.376128\n",
      "Train Epoch: 1602 [960/1612 (59%)] Loss: 0.253593\n",
      "Train Epoch: 1602 [1120/1612 (69%)] Loss: 0.241129\n",
      "Train Epoch: 1602 [1280/1612 (79%)] Loss: 0.379009\n",
      "Train Epoch: 1602 [1440/1612 (89%)] Loss: 0.319167\n",
      "Train Epoch: 1602 [1200/1612 (99%)] Loss: 0.292270\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1603 [0/1612 (0%)] Loss: 0.140376\n",
      "Train Epoch: 1603 [160/1612 (10%)] Loss: 0.118094\n",
      "Train Epoch: 1603 [320/1612 (20%)] Loss: 0.266737\n",
      "Train Epoch: 1603 [480/1612 (30%)] Loss: 0.148800\n",
      "Train Epoch: 1603 [640/1612 (40%)] Loss: 0.327243\n",
      "Train Epoch: 1603 [800/1612 (50%)] Loss: 0.564514\n",
      "Train Epoch: 1603 [960/1612 (59%)] Loss: 0.139640\n",
      "Train Epoch: 1603 [1120/1612 (69%)] Loss: 0.421726\n",
      "Train Epoch: 1603 [1280/1612 (79%)] Loss: 0.271273\n",
      "Train Epoch: 1603 [1440/1612 (89%)] Loss: 0.142962\n",
      "Train Epoch: 1603 [1200/1612 (99%)] Loss: 0.413469\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1604 [0/1612 (0%)] Loss: 0.254874\n",
      "Train Epoch: 1604 [160/1612 (10%)] Loss: 0.427288\n",
      "Train Epoch: 1604 [320/1612 (20%)] Loss: 0.243197\n",
      "Train Epoch: 1604 [480/1612 (30%)] Loss: 0.264795\n",
      "Train Epoch: 1604 [640/1612 (40%)] Loss: 0.342618\n",
      "Train Epoch: 1604 [800/1612 (50%)] Loss: 0.447109\n",
      "Train Epoch: 1604 [960/1612 (59%)] Loss: 0.227588\n",
      "Train Epoch: 1604 [1120/1612 (69%)] Loss: 0.241802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1604 [1280/1612 (79%)] Loss: 0.255744\n",
      "Train Epoch: 1604 [1440/1612 (89%)] Loss: 0.289901\n",
      "Train Epoch: 1604 [1200/1612 (99%)] Loss: 0.189618\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1605 [0/1612 (0%)] Loss: 0.428945\n",
      "Train Epoch: 1605 [160/1612 (10%)] Loss: 0.120351\n",
      "Train Epoch: 1605 [320/1612 (20%)] Loss: 0.308483\n",
      "Train Epoch: 1605 [480/1612 (30%)] Loss: 0.171450\n",
      "Train Epoch: 1605 [640/1612 (40%)] Loss: 0.193475\n",
      "Train Epoch: 1605 [800/1612 (50%)] Loss: 0.243477\n",
      "Train Epoch: 1605 [960/1612 (59%)] Loss: 0.395008\n",
      "Train Epoch: 1605 [1120/1612 (69%)] Loss: 0.295240\n",
      "Train Epoch: 1605 [1280/1612 (79%)] Loss: 0.123993\n",
      "Train Epoch: 1605 [1440/1612 (89%)] Loss: 0.154903\n",
      "Train Epoch: 1605 [1200/1612 (99%)] Loss: 0.339250\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1606 [0/1612 (0%)] Loss: 0.573964\n",
      "Train Epoch: 1606 [160/1612 (10%)] Loss: 0.265441\n",
      "Train Epoch: 1606 [320/1612 (20%)] Loss: 0.150338\n",
      "Train Epoch: 1606 [480/1612 (30%)] Loss: 0.299578\n",
      "Train Epoch: 1606 [640/1612 (40%)] Loss: 0.667029\n",
      "Train Epoch: 1606 [800/1612 (50%)] Loss: 0.148204\n",
      "Train Epoch: 1606 [960/1612 (59%)] Loss: 0.415840\n",
      "Train Epoch: 1606 [1120/1612 (69%)] Loss: 0.181729\n",
      "Train Epoch: 1606 [1280/1612 (79%)] Loss: 0.330336\n",
      "Train Epoch: 1606 [1440/1612 (89%)] Loss: 0.432072\n",
      "Train Epoch: 1606 [1200/1612 (99%)] Loss: 0.190967\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1607 [0/1612 (0%)] Loss: 0.127887\n",
      "Train Epoch: 1607 [160/1612 (10%)] Loss: 0.433313\n",
      "Train Epoch: 1607 [320/1612 (20%)] Loss: 0.218746\n",
      "Train Epoch: 1607 [480/1612 (30%)] Loss: 0.211688\n",
      "Train Epoch: 1607 [640/1612 (40%)] Loss: 0.324353\n",
      "Train Epoch: 1607 [800/1612 (50%)] Loss: 0.139103\n",
      "Train Epoch: 1607 [960/1612 (59%)] Loss: 0.225736\n",
      "Train Epoch: 1607 [1120/1612 (69%)] Loss: 0.423953\n",
      "Train Epoch: 1607 [1280/1612 (79%)] Loss: 0.408320\n",
      "Train Epoch: 1607 [1440/1612 (89%)] Loss: 0.267981\n",
      "Train Epoch: 1607 [1200/1612 (99%)] Loss: 0.089059\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1608 [0/1612 (0%)] Loss: 0.195658\n",
      "Train Epoch: 1608 [160/1612 (10%)] Loss: 0.277257\n",
      "Train Epoch: 1608 [320/1612 (20%)] Loss: 0.262172\n",
      "Train Epoch: 1608 [480/1612 (30%)] Loss: 0.293177\n",
      "Train Epoch: 1608 [640/1612 (40%)] Loss: 0.211023\n",
      "Train Epoch: 1608 [800/1612 (50%)] Loss: 0.190316\n",
      "Train Epoch: 1608 [960/1612 (59%)] Loss: 0.298538\n",
      "Train Epoch: 1608 [1120/1612 (69%)] Loss: 0.636651\n",
      "Train Epoch: 1608 [1280/1612 (79%)] Loss: 0.101119\n",
      "Train Epoch: 1608 [1440/1612 (89%)] Loss: 0.375191\n",
      "Train Epoch: 1608 [1200/1612 (99%)] Loss: 0.156286\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1609 [0/1612 (0%)] Loss: 0.175374\n",
      "Train Epoch: 1609 [160/1612 (10%)] Loss: 0.201037\n",
      "Train Epoch: 1609 [320/1612 (20%)] Loss: 0.584116\n",
      "Train Epoch: 1609 [480/1612 (30%)] Loss: 0.246208\n",
      "Train Epoch: 1609 [640/1612 (40%)] Loss: 0.375448\n",
      "Train Epoch: 1609 [800/1612 (50%)] Loss: 0.272419\n",
      "Train Epoch: 1609 [960/1612 (59%)] Loss: 0.187346\n",
      "Train Epoch: 1609 [1120/1612 (69%)] Loss: 0.630470\n",
      "Train Epoch: 1609 [1280/1612 (79%)] Loss: 0.368780\n",
      "Train Epoch: 1609 [1440/1612 (89%)] Loss: 0.123414\n",
      "Train Epoch: 1609 [1200/1612 (99%)] Loss: 0.101603\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1610 [0/1612 (0%)] Loss: 0.238765\n",
      "Train Epoch: 1610 [160/1612 (10%)] Loss: 0.535078\n",
      "Train Epoch: 1610 [320/1612 (20%)] Loss: 0.529730\n",
      "Train Epoch: 1610 [480/1612 (30%)] Loss: 0.261286\n",
      "Train Epoch: 1610 [640/1612 (40%)] Loss: 0.373518\n",
      "Train Epoch: 1610 [800/1612 (50%)] Loss: 0.354448\n",
      "Train Epoch: 1610 [960/1612 (59%)] Loss: 0.310032\n",
      "Train Epoch: 1610 [1120/1612 (69%)] Loss: 0.332527\n",
      "Train Epoch: 1610 [1280/1612 (79%)] Loss: 0.270160\n",
      "Train Epoch: 1610 [1440/1612 (89%)] Loss: 0.320646\n",
      "Train Epoch: 1610 [1200/1612 (99%)] Loss: 0.724014\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1611 [0/1612 (0%)] Loss: 0.361028\n",
      "Train Epoch: 1611 [160/1612 (10%)] Loss: 0.383755\n",
      "Train Epoch: 1611 [320/1612 (20%)] Loss: 0.518135\n",
      "Train Epoch: 1611 [480/1612 (30%)] Loss: 0.100622\n",
      "Train Epoch: 1611 [640/1612 (40%)] Loss: 0.163335\n",
      "Train Epoch: 1611 [800/1612 (50%)] Loss: 0.162277\n",
      "Train Epoch: 1611 [960/1612 (59%)] Loss: 0.303622\n",
      "Train Epoch: 1611 [1120/1612 (69%)] Loss: 0.194281\n",
      "Train Epoch: 1611 [1280/1612 (79%)] Loss: 0.525126\n",
      "Train Epoch: 1611 [1440/1612 (89%)] Loss: 0.323577\n",
      "Train Epoch: 1611 [1200/1612 (99%)] Loss: 0.465819\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1612 [0/1612 (0%)] Loss: 0.468384\n",
      "Train Epoch: 1612 [160/1612 (10%)] Loss: 0.367650\n",
      "Train Epoch: 1612 [320/1612 (20%)] Loss: 0.384340\n",
      "Train Epoch: 1612 [480/1612 (30%)] Loss: 0.383446\n",
      "Train Epoch: 1612 [640/1612 (40%)] Loss: 0.474053\n",
      "Train Epoch: 1612 [800/1612 (50%)] Loss: 0.243217\n",
      "Train Epoch: 1612 [960/1612 (59%)] Loss: 0.188108\n",
      "Train Epoch: 1612 [1120/1612 (69%)] Loss: 0.211040\n",
      "Train Epoch: 1612 [1280/1612 (79%)] Loss: 0.356029\n",
      "Train Epoch: 1612 [1440/1612 (89%)] Loss: 0.281438\n",
      "Train Epoch: 1612 [1200/1612 (99%)] Loss: 0.251056\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1613 [0/1612 (0%)] Loss: 0.077028\n",
      "Train Epoch: 1613 [160/1612 (10%)] Loss: 0.158557\n",
      "Train Epoch: 1613 [320/1612 (20%)] Loss: 0.313179\n",
      "Train Epoch: 1613 [480/1612 (30%)] Loss: 0.484470\n",
      "Train Epoch: 1613 [640/1612 (40%)] Loss: 0.235003\n",
      "Train Epoch: 1613 [800/1612 (50%)] Loss: 0.134772\n",
      "Train Epoch: 1613 [960/1612 (59%)] Loss: 0.494050\n",
      "Train Epoch: 1613 [1120/1612 (69%)] Loss: 0.198254\n",
      "Train Epoch: 1613 [1280/1612 (79%)] Loss: 0.343308\n",
      "Train Epoch: 1613 [1440/1612 (89%)] Loss: 0.425000\n",
      "Train Epoch: 1613 [1200/1612 (99%)] Loss: 0.342432\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1614 [0/1612 (0%)] Loss: 0.391001\n",
      "Train Epoch: 1614 [160/1612 (10%)] Loss: 0.230055\n",
      "Train Epoch: 1614 [320/1612 (20%)] Loss: 0.215298\n",
      "Train Epoch: 1614 [480/1612 (30%)] Loss: 0.178680\n",
      "Train Epoch: 1614 [640/1612 (40%)] Loss: 0.358505\n",
      "Train Epoch: 1614 [800/1612 (50%)] Loss: 0.233884\n",
      "Train Epoch: 1614 [960/1612 (59%)] Loss: 0.330082\n",
      "Train Epoch: 1614 [1120/1612 (69%)] Loss: 0.479528\n",
      "Train Epoch: 1614 [1280/1612 (79%)] Loss: 0.311581\n",
      "Train Epoch: 1614 [1440/1612 (89%)] Loss: 0.273504\n",
      "Train Epoch: 1614 [1200/1612 (99%)] Loss: 0.324727\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1615 [0/1612 (0%)] Loss: 0.059831\n",
      "Train Epoch: 1615 [160/1612 (10%)] Loss: 0.324459\n",
      "Train Epoch: 1615 [320/1612 (20%)] Loss: 0.290398\n",
      "Train Epoch: 1615 [480/1612 (30%)] Loss: 0.370342\n",
      "Train Epoch: 1615 [640/1612 (40%)] Loss: 0.360574\n",
      "Train Epoch: 1615 [800/1612 (50%)] Loss: 0.354098\n",
      "Train Epoch: 1615 [960/1612 (59%)] Loss: 0.349603\n",
      "Train Epoch: 1615 [1120/1612 (69%)] Loss: 0.238707\n",
      "Train Epoch: 1615 [1280/1612 (79%)] Loss: 0.426858\n",
      "Train Epoch: 1615 [1440/1612 (89%)] Loss: 0.339748\n",
      "Train Epoch: 1615 [1200/1612 (99%)] Loss: 0.102000\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1616 [0/1612 (0%)] Loss: 0.279167\n",
      "Train Epoch: 1616 [160/1612 (10%)] Loss: 0.272141\n",
      "Train Epoch: 1616 [320/1612 (20%)] Loss: 0.367576\n",
      "Train Epoch: 1616 [480/1612 (30%)] Loss: 0.342449\n",
      "Train Epoch: 1616 [640/1612 (40%)] Loss: 0.248504\n",
      "Train Epoch: 1616 [800/1612 (50%)] Loss: 0.379543\n",
      "Train Epoch: 1616 [960/1612 (59%)] Loss: 0.559005\n",
      "Train Epoch: 1616 [1120/1612 (69%)] Loss: 0.223222\n",
      "Train Epoch: 1616 [1280/1612 (79%)] Loss: 0.125252\n",
      "Train Epoch: 1616 [1440/1612 (89%)] Loss: 0.266401\n",
      "Train Epoch: 1616 [1200/1612 (99%)] Loss: 0.186066\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1617 [0/1612 (0%)] Loss: 0.131866\n",
      "Train Epoch: 1617 [160/1612 (10%)] Loss: 0.333319\n",
      "Train Epoch: 1617 [320/1612 (20%)] Loss: 0.206341\n",
      "Train Epoch: 1617 [480/1612 (30%)] Loss: 0.364663\n",
      "Train Epoch: 1617 [640/1612 (40%)] Loss: 0.374354\n",
      "Train Epoch: 1617 [800/1612 (50%)] Loss: 0.411374\n",
      "Train Epoch: 1617 [960/1612 (59%)] Loss: 0.195764\n",
      "Train Epoch: 1617 [1120/1612 (69%)] Loss: 0.185499\n",
      "Train Epoch: 1617 [1280/1612 (79%)] Loss: 0.228725\n",
      "Train Epoch: 1617 [1440/1612 (89%)] Loss: 0.409208\n",
      "Train Epoch: 1617 [1200/1612 (99%)] Loss: 0.258991\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1618 [0/1612 (0%)] Loss: 0.479056\n",
      "Train Epoch: 1618 [160/1612 (10%)] Loss: 0.205133\n",
      "Train Epoch: 1618 [320/1612 (20%)] Loss: 0.339654\n",
      "Train Epoch: 1618 [480/1612 (30%)] Loss: 0.263307\n",
      "Train Epoch: 1618 [640/1612 (40%)] Loss: 0.290987\n",
      "Train Epoch: 1618 [800/1612 (50%)] Loss: 0.241538\n",
      "Train Epoch: 1618 [960/1612 (59%)] Loss: 0.138664\n",
      "Train Epoch: 1618 [1120/1612 (69%)] Loss: 0.300679\n",
      "Train Epoch: 1618 [1280/1612 (79%)] Loss: 0.226207\n",
      "Train Epoch: 1618 [1440/1612 (89%)] Loss: 0.252936\n",
      "Train Epoch: 1618 [1200/1612 (99%)] Loss: 0.297000\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1619 [0/1612 (0%)] Loss: 0.498337\n",
      "Train Epoch: 1619 [160/1612 (10%)] Loss: 0.116665\n",
      "Train Epoch: 1619 [320/1612 (20%)] Loss: 0.281298\n",
      "Train Epoch: 1619 [480/1612 (30%)] Loss: 0.403791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1619 [640/1612 (40%)] Loss: 0.110856\n",
      "Train Epoch: 1619 [800/1612 (50%)] Loss: 0.147874\n",
      "Train Epoch: 1619 [960/1612 (59%)] Loss: 0.358861\n",
      "Train Epoch: 1619 [1120/1612 (69%)] Loss: 0.237315\n",
      "Train Epoch: 1619 [1280/1612 (79%)] Loss: 0.207703\n",
      "Train Epoch: 1619 [1440/1612 (89%)] Loss: 0.521872\n",
      "Train Epoch: 1619 [1200/1612 (99%)] Loss: 0.576466\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1620 [0/1612 (0%)] Loss: 0.167487\n",
      "Train Epoch: 1620 [160/1612 (10%)] Loss: 0.249125\n",
      "Train Epoch: 1620 [320/1612 (20%)] Loss: 0.150428\n",
      "Train Epoch: 1620 [480/1612 (30%)] Loss: 0.203345\n",
      "Train Epoch: 1620 [640/1612 (40%)] Loss: 0.357081\n",
      "Train Epoch: 1620 [800/1612 (50%)] Loss: 0.190748\n",
      "Train Epoch: 1620 [960/1612 (59%)] Loss: 0.119080\n",
      "Train Epoch: 1620 [1120/1612 (69%)] Loss: 0.441599\n",
      "Train Epoch: 1620 [1280/1612 (79%)] Loss: 0.286707\n",
      "Train Epoch: 1620 [1440/1612 (89%)] Loss: 0.187459\n",
      "Train Epoch: 1620 [1200/1612 (99%)] Loss: 0.542174\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1621 [0/1612 (0%)] Loss: 0.302198\n",
      "Train Epoch: 1621 [160/1612 (10%)] Loss: 0.308832\n",
      "Train Epoch: 1621 [320/1612 (20%)] Loss: 0.186248\n",
      "Train Epoch: 1621 [480/1612 (30%)] Loss: 0.350978\n",
      "Train Epoch: 1621 [640/1612 (40%)] Loss: 0.229114\n",
      "Train Epoch: 1621 [800/1612 (50%)] Loss: 0.198246\n",
      "Train Epoch: 1621 [960/1612 (59%)] Loss: 0.192964\n",
      "Train Epoch: 1621 [1120/1612 (69%)] Loss: 0.130766\n",
      "Train Epoch: 1621 [1280/1612 (79%)] Loss: 0.324072\n",
      "Train Epoch: 1621 [1440/1612 (89%)] Loss: 0.223176\n",
      "Train Epoch: 1621 [1200/1612 (99%)] Loss: 0.196194\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1622 [0/1612 (0%)] Loss: 0.303868\n",
      "Train Epoch: 1622 [160/1612 (10%)] Loss: 0.446284\n",
      "Train Epoch: 1622 [320/1612 (20%)] Loss: 0.337600\n",
      "Train Epoch: 1622 [480/1612 (30%)] Loss: 0.184815\n",
      "Train Epoch: 1622 [640/1612 (40%)] Loss: 0.323228\n",
      "Train Epoch: 1622 [800/1612 (50%)] Loss: 0.623412\n",
      "Train Epoch: 1622 [960/1612 (59%)] Loss: 0.393958\n",
      "Train Epoch: 1622 [1120/1612 (69%)] Loss: 0.473845\n",
      "Train Epoch: 1622 [1280/1612 (79%)] Loss: 0.376983\n",
      "Train Epoch: 1622 [1440/1612 (89%)] Loss: 0.275483\n",
      "Train Epoch: 1622 [1200/1612 (99%)] Loss: 0.259446\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1623 [0/1612 (0%)] Loss: 0.301723\n",
      "Train Epoch: 1623 [160/1612 (10%)] Loss: 0.281328\n",
      "Train Epoch: 1623 [320/1612 (20%)] Loss: 0.429325\n",
      "Train Epoch: 1623 [480/1612 (30%)] Loss: 0.132318\n",
      "Train Epoch: 1623 [640/1612 (40%)] Loss: 0.474741\n",
      "Train Epoch: 1623 [800/1612 (50%)] Loss: 0.097692\n",
      "Train Epoch: 1623 [960/1612 (59%)] Loss: 0.476407\n",
      "Train Epoch: 1623 [1120/1612 (69%)] Loss: 0.260649\n",
      "Train Epoch: 1623 [1280/1612 (79%)] Loss: 0.266792\n",
      "Train Epoch: 1623 [1440/1612 (89%)] Loss: 0.295044\n",
      "Train Epoch: 1623 [1200/1612 (99%)] Loss: 0.252013\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1624 [0/1612 (0%)] Loss: 0.187313\n",
      "Train Epoch: 1624 [160/1612 (10%)] Loss: 0.203554\n",
      "Train Epoch: 1624 [320/1612 (20%)] Loss: 0.138388\n",
      "Train Epoch: 1624 [480/1612 (30%)] Loss: 0.284630\n",
      "Train Epoch: 1624 [640/1612 (40%)] Loss: 0.215907\n",
      "Train Epoch: 1624 [800/1612 (50%)] Loss: 0.205484\n",
      "Train Epoch: 1624 [960/1612 (59%)] Loss: 0.279307\n",
      "Train Epoch: 1624 [1120/1612 (69%)] Loss: 0.037463\n",
      "Train Epoch: 1624 [1280/1612 (79%)] Loss: 0.338721\n",
      "Train Epoch: 1624 [1440/1612 (89%)] Loss: 0.108679\n",
      "Train Epoch: 1624 [1200/1612 (99%)] Loss: 0.271518\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1625 [0/1612 (0%)] Loss: 0.463097\n",
      "Train Epoch: 1625 [160/1612 (10%)] Loss: 0.158651\n",
      "Train Epoch: 1625 [320/1612 (20%)] Loss: 0.237583\n",
      "Train Epoch: 1625 [480/1612 (30%)] Loss: 0.486781\n",
      "Train Epoch: 1625 [640/1612 (40%)] Loss: 0.342435\n",
      "Train Epoch: 1625 [800/1612 (50%)] Loss: 0.301793\n",
      "Train Epoch: 1625 [960/1612 (59%)] Loss: 0.381417\n",
      "Train Epoch: 1625 [1120/1612 (69%)] Loss: 0.372114\n",
      "Train Epoch: 1625 [1280/1612 (79%)] Loss: 0.230335\n",
      "Train Epoch: 1625 [1440/1612 (89%)] Loss: 0.321859\n",
      "Train Epoch: 1625 [1200/1612 (99%)] Loss: 0.408930\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1626 [0/1612 (0%)] Loss: 0.187277\n",
      "Train Epoch: 1626 [160/1612 (10%)] Loss: 0.176886\n",
      "Train Epoch: 1626 [320/1612 (20%)] Loss: 0.504269\n",
      "Train Epoch: 1626 [480/1612 (30%)] Loss: 0.367154\n",
      "Train Epoch: 1626 [640/1612 (40%)] Loss: 0.194953\n",
      "Train Epoch: 1626 [800/1612 (50%)] Loss: 0.297952\n",
      "Train Epoch: 1626 [960/1612 (59%)] Loss: 0.427445\n",
      "Train Epoch: 1626 [1120/1612 (69%)] Loss: 0.268136\n",
      "Train Epoch: 1626 [1280/1612 (79%)] Loss: 0.310443\n",
      "Train Epoch: 1626 [1440/1612 (89%)] Loss: 0.216787\n",
      "Train Epoch: 1626 [1200/1612 (99%)] Loss: 0.379336\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1627 [0/1612 (0%)] Loss: 0.235405\n",
      "Train Epoch: 1627 [160/1612 (10%)] Loss: 0.369622\n",
      "Train Epoch: 1627 [320/1612 (20%)] Loss: 0.286758\n",
      "Train Epoch: 1627 [480/1612 (30%)] Loss: 0.060811\n",
      "Train Epoch: 1627 [640/1612 (40%)] Loss: 0.393128\n",
      "Train Epoch: 1627 [800/1612 (50%)] Loss: 0.313903\n",
      "Train Epoch: 1627 [960/1612 (59%)] Loss: 0.385671\n",
      "Train Epoch: 1627 [1120/1612 (69%)] Loss: 0.445827\n",
      "Train Epoch: 1627 [1280/1612 (79%)] Loss: 0.153736\n",
      "Train Epoch: 1627 [1440/1612 (89%)] Loss: 0.183640\n",
      "Train Epoch: 1627 [1200/1612 (99%)] Loss: 0.184383\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1628 [0/1612 (0%)] Loss: 0.108554\n",
      "Train Epoch: 1628 [160/1612 (10%)] Loss: 0.226164\n",
      "Train Epoch: 1628 [320/1612 (20%)] Loss: 0.297178\n",
      "Train Epoch: 1628 [480/1612 (30%)] Loss: 0.237046\n",
      "Train Epoch: 1628 [640/1612 (40%)] Loss: 0.519527\n",
      "Train Epoch: 1628 [800/1612 (50%)] Loss: 0.187013\n",
      "Train Epoch: 1628 [960/1612 (59%)] Loss: 0.386864\n",
      "Train Epoch: 1628 [1120/1612 (69%)] Loss: 0.341673\n",
      "Train Epoch: 1628 [1280/1612 (79%)] Loss: 0.251117\n",
      "Train Epoch: 1628 [1440/1612 (89%)] Loss: 0.246672\n",
      "Train Epoch: 1628 [1200/1612 (99%)] Loss: 0.494381\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1629 [0/1612 (0%)] Loss: 0.400179\n",
      "Train Epoch: 1629 [160/1612 (10%)] Loss: 0.228518\n",
      "Train Epoch: 1629 [320/1612 (20%)] Loss: 0.099427\n",
      "Train Epoch: 1629 [480/1612 (30%)] Loss: 0.305640\n",
      "Train Epoch: 1629 [640/1612 (40%)] Loss: 0.240807\n",
      "Train Epoch: 1629 [800/1612 (50%)] Loss: 0.338835\n",
      "Train Epoch: 1629 [960/1612 (59%)] Loss: 0.081813\n",
      "Train Epoch: 1629 [1120/1612 (69%)] Loss: 0.216185\n",
      "Train Epoch: 1629 [1280/1612 (79%)] Loss: 0.187090\n",
      "Train Epoch: 1629 [1440/1612 (89%)] Loss: 0.140501\n",
      "Train Epoch: 1629 [1200/1612 (99%)] Loss: 0.274360\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1630 [0/1612 (0%)] Loss: 0.316603\n",
      "Train Epoch: 1630 [160/1612 (10%)] Loss: 0.448033\n",
      "Train Epoch: 1630 [320/1612 (20%)] Loss: 0.408737\n",
      "Train Epoch: 1630 [480/1612 (30%)] Loss: 0.380918\n",
      "Train Epoch: 1630 [640/1612 (40%)] Loss: 0.202034\n",
      "Train Epoch: 1630 [800/1612 (50%)] Loss: 0.194270\n",
      "Train Epoch: 1630 [960/1612 (59%)] Loss: 0.335787\n",
      "Train Epoch: 1630 [1120/1612 (69%)] Loss: 0.124618\n",
      "Train Epoch: 1630 [1280/1612 (79%)] Loss: 0.501930\n",
      "Train Epoch: 1630 [1440/1612 (89%)] Loss: 0.101960\n",
      "Train Epoch: 1630 [1200/1612 (99%)] Loss: 0.390502\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1631 [0/1612 (0%)] Loss: 0.111259\n",
      "Train Epoch: 1631 [160/1612 (10%)] Loss: 0.415251\n",
      "Train Epoch: 1631 [320/1612 (20%)] Loss: 0.294143\n",
      "Train Epoch: 1631 [480/1612 (30%)] Loss: 0.208006\n",
      "Train Epoch: 1631 [640/1612 (40%)] Loss: 0.295498\n",
      "Train Epoch: 1631 [800/1612 (50%)] Loss: 0.159453\n",
      "Train Epoch: 1631 [960/1612 (59%)] Loss: 0.229499\n",
      "Train Epoch: 1631 [1120/1612 (69%)] Loss: 0.280428\n",
      "Train Epoch: 1631 [1280/1612 (79%)] Loss: 0.288245\n",
      "Train Epoch: 1631 [1440/1612 (89%)] Loss: 0.189074\n",
      "Train Epoch: 1631 [1200/1612 (99%)] Loss: 0.368364\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1632 [0/1612 (0%)] Loss: 0.290562\n",
      "Train Epoch: 1632 [160/1612 (10%)] Loss: 0.240587\n",
      "Train Epoch: 1632 [320/1612 (20%)] Loss: 0.310325\n",
      "Train Epoch: 1632 [480/1612 (30%)] Loss: 0.245811\n",
      "Train Epoch: 1632 [640/1612 (40%)] Loss: 0.432654\n",
      "Train Epoch: 1632 [800/1612 (50%)] Loss: 0.194657\n",
      "Train Epoch: 1632 [960/1612 (59%)] Loss: 0.260831\n",
      "Train Epoch: 1632 [1120/1612 (69%)] Loss: 0.180283\n",
      "Train Epoch: 1632 [1280/1612 (79%)] Loss: 0.142955\n",
      "Train Epoch: 1632 [1440/1612 (89%)] Loss: 0.398689\n",
      "Train Epoch: 1632 [1200/1612 (99%)] Loss: 0.179657\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1633 [0/1612 (0%)] Loss: 0.095751\n",
      "Train Epoch: 1633 [160/1612 (10%)] Loss: 0.226066\n",
      "Train Epoch: 1633 [320/1612 (20%)] Loss: 0.415091\n",
      "Train Epoch: 1633 [480/1612 (30%)] Loss: 0.226631\n",
      "Train Epoch: 1633 [640/1612 (40%)] Loss: 0.223242\n",
      "Train Epoch: 1633 [800/1612 (50%)] Loss: 0.297753\n",
      "Train Epoch: 1633 [960/1612 (59%)] Loss: 0.353560\n",
      "Train Epoch: 1633 [1120/1612 (69%)] Loss: 0.398506\n",
      "Train Epoch: 1633 [1280/1612 (79%)] Loss: 0.245774\n",
      "Train Epoch: 1633 [1440/1612 (89%)] Loss: 0.246201\n",
      "Train Epoch: 1633 [1200/1612 (99%)] Loss: 0.253784\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1634 [0/1612 (0%)] Loss: 0.484045\n",
      "Train Epoch: 1634 [160/1612 (10%)] Loss: 0.294641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1634 [320/1612 (20%)] Loss: 0.225681\n",
      "Train Epoch: 1634 [480/1612 (30%)] Loss: 0.332301\n",
      "Train Epoch: 1634 [640/1612 (40%)] Loss: 0.283587\n",
      "Train Epoch: 1634 [800/1612 (50%)] Loss: 0.284080\n",
      "Train Epoch: 1634 [960/1612 (59%)] Loss: 0.326126\n",
      "Train Epoch: 1634 [1120/1612 (69%)] Loss: 0.474107\n",
      "Train Epoch: 1634 [1280/1612 (79%)] Loss: 0.170735\n",
      "Train Epoch: 1634 [1440/1612 (89%)] Loss: 0.423394\n",
      "Train Epoch: 1634 [1200/1612 (99%)] Loss: 0.162564\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1635 [0/1612 (0%)] Loss: 0.282075\n",
      "Train Epoch: 1635 [160/1612 (10%)] Loss: 0.364028\n",
      "Train Epoch: 1635 [320/1612 (20%)] Loss: 0.194537\n",
      "Train Epoch: 1635 [480/1612 (30%)] Loss: 0.174945\n",
      "Train Epoch: 1635 [640/1612 (40%)] Loss: 0.180757\n",
      "Train Epoch: 1635 [800/1612 (50%)] Loss: 0.353376\n",
      "Train Epoch: 1635 [960/1612 (59%)] Loss: 0.377876\n",
      "Train Epoch: 1635 [1120/1612 (69%)] Loss: 0.263438\n",
      "Train Epoch: 1635 [1280/1612 (79%)] Loss: 0.111918\n",
      "Train Epoch: 1635 [1440/1612 (89%)] Loss: 0.353300\n",
      "Train Epoch: 1635 [1200/1612 (99%)] Loss: 0.272027\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1636 [0/1612 (0%)] Loss: 0.341938\n",
      "Train Epoch: 1636 [160/1612 (10%)] Loss: 0.233054\n",
      "Train Epoch: 1636 [320/1612 (20%)] Loss: 0.119306\n",
      "Train Epoch: 1636 [480/1612 (30%)] Loss: 0.322599\n",
      "Train Epoch: 1636 [640/1612 (40%)] Loss: 0.203308\n",
      "Train Epoch: 1636 [800/1612 (50%)] Loss: 0.658559\n",
      "Train Epoch: 1636 [960/1612 (59%)] Loss: 0.185098\n",
      "Train Epoch: 1636 [1120/1612 (69%)] Loss: 0.235580\n",
      "Train Epoch: 1636 [1280/1612 (79%)] Loss: 0.357517\n",
      "Train Epoch: 1636 [1440/1612 (89%)] Loss: 0.310655\n",
      "Train Epoch: 1636 [1200/1612 (99%)] Loss: 0.185360\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1637 [0/1612 (0%)] Loss: 0.179257\n",
      "Train Epoch: 1637 [160/1612 (10%)] Loss: 0.306446\n",
      "Train Epoch: 1637 [320/1612 (20%)] Loss: 0.123473\n",
      "Train Epoch: 1637 [480/1612 (30%)] Loss: 0.198195\n",
      "Train Epoch: 1637 [640/1612 (40%)] Loss: 0.214113\n",
      "Train Epoch: 1637 [800/1612 (50%)] Loss: 0.299384\n",
      "Train Epoch: 1637 [960/1612 (59%)] Loss: 0.278090\n",
      "Train Epoch: 1637 [1120/1612 (69%)] Loss: 0.346744\n",
      "Train Epoch: 1637 [1280/1612 (79%)] Loss: 0.312505\n",
      "Train Epoch: 1637 [1440/1612 (89%)] Loss: 0.432386\n",
      "Train Epoch: 1637 [1200/1612 (99%)] Loss: 0.231074\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1638 [0/1612 (0%)] Loss: 0.245504\n",
      "Train Epoch: 1638 [160/1612 (10%)] Loss: 0.088941\n",
      "Train Epoch: 1638 [320/1612 (20%)] Loss: 0.335823\n",
      "Train Epoch: 1638 [480/1612 (30%)] Loss: 0.609164\n",
      "Train Epoch: 1638 [640/1612 (40%)] Loss: 0.273943\n",
      "Train Epoch: 1638 [800/1612 (50%)] Loss: 0.379206\n",
      "Train Epoch: 1638 [960/1612 (59%)] Loss: 0.275949\n",
      "Train Epoch: 1638 [1120/1612 (69%)] Loss: 0.383702\n",
      "Train Epoch: 1638 [1280/1612 (79%)] Loss: 0.176800\n",
      "Train Epoch: 1638 [1440/1612 (89%)] Loss: 0.498373\n",
      "Train Epoch: 1638 [1200/1612 (99%)] Loss: 0.386546\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1639 [0/1612 (0%)] Loss: 0.441332\n",
      "Train Epoch: 1639 [160/1612 (10%)] Loss: 0.140737\n",
      "Train Epoch: 1639 [320/1612 (20%)] Loss: 0.337476\n",
      "Train Epoch: 1639 [480/1612 (30%)] Loss: 0.326936\n",
      "Train Epoch: 1639 [640/1612 (40%)] Loss: 0.350906\n",
      "Train Epoch: 1639 [800/1612 (50%)] Loss: 0.342222\n",
      "Train Epoch: 1639 [960/1612 (59%)] Loss: 0.311685\n",
      "Train Epoch: 1639 [1120/1612 (69%)] Loss: 0.182333\n",
      "Train Epoch: 1639 [1280/1612 (79%)] Loss: 0.312068\n",
      "Train Epoch: 1639 [1440/1612 (89%)] Loss: 0.353562\n",
      "Train Epoch: 1639 [1200/1612 (99%)] Loss: 0.178075\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1640 [0/1612 (0%)] Loss: 0.361178\n",
      "Train Epoch: 1640 [160/1612 (10%)] Loss: 0.238804\n",
      "Train Epoch: 1640 [320/1612 (20%)] Loss: 0.369124\n",
      "Train Epoch: 1640 [480/1612 (30%)] Loss: 0.209720\n",
      "Train Epoch: 1640 [640/1612 (40%)] Loss: 0.215588\n",
      "Train Epoch: 1640 [800/1612 (50%)] Loss: 0.320828\n",
      "Train Epoch: 1640 [960/1612 (59%)] Loss: 0.289887\n",
      "Train Epoch: 1640 [1120/1612 (69%)] Loss: 0.157267\n",
      "Train Epoch: 1640 [1280/1612 (79%)] Loss: 0.169539\n",
      "Train Epoch: 1640 [1440/1612 (89%)] Loss: 0.363695\n",
      "Train Epoch: 1640 [1200/1612 (99%)] Loss: 0.133195\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1641 [0/1612 (0%)] Loss: 0.164065\n",
      "Train Epoch: 1641 [160/1612 (10%)] Loss: 0.339325\n",
      "Train Epoch: 1641 [320/1612 (20%)] Loss: 0.555569\n",
      "Train Epoch: 1641 [480/1612 (30%)] Loss: 0.180103\n",
      "Train Epoch: 1641 [640/1612 (40%)] Loss: 0.379334\n",
      "Train Epoch: 1641 [800/1612 (50%)] Loss: 0.193925\n",
      "Train Epoch: 1641 [960/1612 (59%)] Loss: 0.420907\n",
      "Train Epoch: 1641 [1120/1612 (69%)] Loss: 0.181962\n",
      "Train Epoch: 1641 [1280/1612 (79%)] Loss: 0.152211\n",
      "Train Epoch: 1641 [1440/1612 (89%)] Loss: 0.185652\n",
      "Train Epoch: 1641 [1200/1612 (99%)] Loss: 0.350500\n",
      "\n",
      "Test set: Average loss: 0.0318, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1642 [0/1612 (0%)] Loss: 0.220196\n",
      "Train Epoch: 1642 [160/1612 (10%)] Loss: 0.149343\n",
      "Train Epoch: 1642 [320/1612 (20%)] Loss: 0.142396\n",
      "Train Epoch: 1642 [480/1612 (30%)] Loss: 0.145244\n",
      "Train Epoch: 1642 [640/1612 (40%)] Loss: 0.301780\n",
      "Train Epoch: 1642 [800/1612 (50%)] Loss: 0.389045\n",
      "Train Epoch: 1642 [960/1612 (59%)] Loss: 0.550610\n",
      "Train Epoch: 1642 [1120/1612 (69%)] Loss: 0.315464\n",
      "Train Epoch: 1642 [1280/1612 (79%)] Loss: 0.303648\n",
      "Train Epoch: 1642 [1440/1612 (89%)] Loss: 0.174805\n",
      "Train Epoch: 1642 [1200/1612 (99%)] Loss: 0.338443\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1643 [0/1612 (0%)] Loss: 0.123148\n",
      "Train Epoch: 1643 [160/1612 (10%)] Loss: 0.227662\n",
      "Train Epoch: 1643 [320/1612 (20%)] Loss: 0.363773\n",
      "Train Epoch: 1643 [480/1612 (30%)] Loss: 0.167911\n",
      "Train Epoch: 1643 [640/1612 (40%)] Loss: 0.214904\n",
      "Train Epoch: 1643 [800/1612 (50%)] Loss: 0.096219\n",
      "Train Epoch: 1643 [960/1612 (59%)] Loss: 0.407820\n",
      "Train Epoch: 1643 [1120/1612 (69%)] Loss: 0.282091\n",
      "Train Epoch: 1643 [1280/1612 (79%)] Loss: 0.382169\n",
      "Train Epoch: 1643 [1440/1612 (89%)] Loss: 0.328274\n",
      "Train Epoch: 1643 [1200/1612 (99%)] Loss: 0.252866\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1644 [0/1612 (0%)] Loss: 0.092733\n",
      "Train Epoch: 1644 [160/1612 (10%)] Loss: 0.456485\n",
      "Train Epoch: 1644 [320/1612 (20%)] Loss: 0.094328\n",
      "Train Epoch: 1644 [480/1612 (30%)] Loss: 0.331028\n",
      "Train Epoch: 1644 [640/1612 (40%)] Loss: 0.222726\n",
      "Train Epoch: 1644 [800/1612 (50%)] Loss: 0.466086\n",
      "Train Epoch: 1644 [960/1612 (59%)] Loss: 0.396545\n",
      "Train Epoch: 1644 [1120/1612 (69%)] Loss: 0.255904\n",
      "Train Epoch: 1644 [1280/1612 (79%)] Loss: 0.391761\n",
      "Train Epoch: 1644 [1440/1612 (89%)] Loss: 0.285451\n",
      "Train Epoch: 1644 [1200/1612 (99%)] Loss: 0.338367\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1645 [0/1612 (0%)] Loss: 0.367804\n",
      "Train Epoch: 1645 [160/1612 (10%)] Loss: 0.292285\n",
      "Train Epoch: 1645 [320/1612 (20%)] Loss: 0.181655\n",
      "Train Epoch: 1645 [480/1612 (30%)] Loss: 0.191079\n",
      "Train Epoch: 1645 [640/1612 (40%)] Loss: 0.224657\n",
      "Train Epoch: 1645 [800/1612 (50%)] Loss: 0.405557\n",
      "Train Epoch: 1645 [960/1612 (59%)] Loss: 0.087104\n",
      "Train Epoch: 1645 [1120/1612 (69%)] Loss: 0.411976\n",
      "Train Epoch: 1645 [1280/1612 (79%)] Loss: 0.165125\n",
      "Train Epoch: 1645 [1440/1612 (89%)] Loss: 0.423309\n",
      "Train Epoch: 1645 [1200/1612 (99%)] Loss: 0.240886\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1646 [0/1612 (0%)] Loss: 0.312411\n",
      "Train Epoch: 1646 [160/1612 (10%)] Loss: 0.199830\n",
      "Train Epoch: 1646 [320/1612 (20%)] Loss: 0.306186\n",
      "Train Epoch: 1646 [480/1612 (30%)] Loss: 0.175622\n",
      "Train Epoch: 1646 [640/1612 (40%)] Loss: 0.484708\n",
      "Train Epoch: 1646 [800/1612 (50%)] Loss: 0.157724\n",
      "Train Epoch: 1646 [960/1612 (59%)] Loss: 0.201159\n",
      "Train Epoch: 1646 [1120/1612 (69%)] Loss: 0.436800\n",
      "Train Epoch: 1646 [1280/1612 (79%)] Loss: 0.307624\n",
      "Train Epoch: 1646 [1440/1612 (89%)] Loss: 0.267240\n",
      "Train Epoch: 1646 [1200/1612 (99%)] Loss: 0.316409\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1647 [0/1612 (0%)] Loss: 0.230586\n",
      "Train Epoch: 1647 [160/1612 (10%)] Loss: 0.554781\n",
      "Train Epoch: 1647 [320/1612 (20%)] Loss: 0.366866\n",
      "Train Epoch: 1647 [480/1612 (30%)] Loss: 0.443953\n",
      "Train Epoch: 1647 [640/1612 (40%)] Loss: 0.278736\n",
      "Train Epoch: 1647 [800/1612 (50%)] Loss: 0.441889\n",
      "Train Epoch: 1647 [960/1612 (59%)] Loss: 0.373277\n",
      "Train Epoch: 1647 [1120/1612 (69%)] Loss: 0.203947\n",
      "Train Epoch: 1647 [1280/1612 (79%)] Loss: 0.441989\n",
      "Train Epoch: 1647 [1440/1612 (89%)] Loss: 0.212148\n",
      "Train Epoch: 1647 [1200/1612 (99%)] Loss: 0.558928\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1648 [0/1612 (0%)] Loss: 0.247228\n",
      "Train Epoch: 1648 [160/1612 (10%)] Loss: 0.501469\n",
      "Train Epoch: 1648 [320/1612 (20%)] Loss: 0.354861\n",
      "Train Epoch: 1648 [480/1612 (30%)] Loss: 0.357175\n",
      "Train Epoch: 1648 [640/1612 (40%)] Loss: 0.067908\n",
      "Train Epoch: 1648 [800/1612 (50%)] Loss: 0.307204\n",
      "Train Epoch: 1648 [960/1612 (59%)] Loss: 0.159778\n",
      "Train Epoch: 1648 [1120/1612 (69%)] Loss: 0.174359\n",
      "Train Epoch: 1648 [1280/1612 (79%)] Loss: 0.371824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1648 [1440/1612 (89%)] Loss: 0.188644\n",
      "Train Epoch: 1648 [1200/1612 (99%)] Loss: 0.089529\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1649 [0/1612 (0%)] Loss: 0.185174\n",
      "Train Epoch: 1649 [160/1612 (10%)] Loss: 0.185484\n",
      "Train Epoch: 1649 [320/1612 (20%)] Loss: 0.267191\n",
      "Train Epoch: 1649 [480/1612 (30%)] Loss: 0.236451\n",
      "Train Epoch: 1649 [640/1612 (40%)] Loss: 0.377161\n",
      "Train Epoch: 1649 [800/1612 (50%)] Loss: 0.228689\n",
      "Train Epoch: 1649 [960/1612 (59%)] Loss: 0.323815\n",
      "Train Epoch: 1649 [1120/1612 (69%)] Loss: 0.332574\n",
      "Train Epoch: 1649 [1280/1612 (79%)] Loss: 0.459363\n",
      "Train Epoch: 1649 [1440/1612 (89%)] Loss: 0.479088\n",
      "Train Epoch: 1649 [1200/1612 (99%)] Loss: 0.268340\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1650 [0/1612 (0%)] Loss: 0.169503\n",
      "Train Epoch: 1650 [160/1612 (10%)] Loss: 0.256494\n",
      "Train Epoch: 1650 [320/1612 (20%)] Loss: 0.153647\n",
      "Train Epoch: 1650 [480/1612 (30%)] Loss: 0.318635\n",
      "Train Epoch: 1650 [640/1612 (40%)] Loss: 0.258041\n",
      "Train Epoch: 1650 [800/1612 (50%)] Loss: 0.318905\n",
      "Train Epoch: 1650 [960/1612 (59%)] Loss: 0.782693\n",
      "Train Epoch: 1650 [1120/1612 (69%)] Loss: 0.283566\n",
      "Train Epoch: 1650 [1280/1612 (79%)] Loss: 0.286924\n",
      "Train Epoch: 1650 [1440/1612 (89%)] Loss: 0.240018\n",
      "Train Epoch: 1650 [1200/1612 (99%)] Loss: 0.147468\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1651 [0/1612 (0%)] Loss: 0.713910\n",
      "Train Epoch: 1651 [160/1612 (10%)] Loss: 0.301460\n",
      "Train Epoch: 1651 [320/1612 (20%)] Loss: 0.643867\n",
      "Train Epoch: 1651 [480/1612 (30%)] Loss: 0.240184\n",
      "Train Epoch: 1651 [640/1612 (40%)] Loss: 0.392483\n",
      "Train Epoch: 1651 [800/1612 (50%)] Loss: 0.172124\n",
      "Train Epoch: 1651 [960/1612 (59%)] Loss: 0.133002\n",
      "Train Epoch: 1651 [1120/1612 (69%)] Loss: 0.266625\n",
      "Train Epoch: 1651 [1280/1612 (79%)] Loss: 0.162423\n",
      "Train Epoch: 1651 [1440/1612 (89%)] Loss: 0.264649\n",
      "Train Epoch: 1651 [1200/1612 (99%)] Loss: 0.306347\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1652 [0/1612 (0%)] Loss: 0.345414\n",
      "Train Epoch: 1652 [160/1612 (10%)] Loss: 0.089810\n",
      "Train Epoch: 1652 [320/1612 (20%)] Loss: 0.368920\n",
      "Train Epoch: 1652 [480/1612 (30%)] Loss: 0.236869\n",
      "Train Epoch: 1652 [640/1612 (40%)] Loss: 0.334795\n",
      "Train Epoch: 1652 [800/1612 (50%)] Loss: 0.223438\n",
      "Train Epoch: 1652 [960/1612 (59%)] Loss: 0.412184\n",
      "Train Epoch: 1652 [1120/1612 (69%)] Loss: 0.504497\n",
      "Train Epoch: 1652 [1280/1612 (79%)] Loss: 0.301521\n",
      "Train Epoch: 1652 [1440/1612 (89%)] Loss: 0.247136\n",
      "Train Epoch: 1652 [1200/1612 (99%)] Loss: 0.288809\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1653 [0/1612 (0%)] Loss: 0.339577\n",
      "Train Epoch: 1653 [160/1612 (10%)] Loss: 0.155292\n",
      "Train Epoch: 1653 [320/1612 (20%)] Loss: 0.354636\n",
      "Train Epoch: 1653 [480/1612 (30%)] Loss: 0.403545\n",
      "Train Epoch: 1653 [640/1612 (40%)] Loss: 0.323158\n",
      "Train Epoch: 1653 [800/1612 (50%)] Loss: 0.297348\n",
      "Train Epoch: 1653 [960/1612 (59%)] Loss: 0.234042\n",
      "Train Epoch: 1653 [1120/1612 (69%)] Loss: 0.472117\n",
      "Train Epoch: 1653 [1280/1612 (79%)] Loss: 0.202410\n",
      "Train Epoch: 1653 [1440/1612 (89%)] Loss: 0.206577\n",
      "Train Epoch: 1653 [1200/1612 (99%)] Loss: 0.249663\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1654 [0/1612 (0%)] Loss: 0.481495\n",
      "Train Epoch: 1654 [160/1612 (10%)] Loss: 0.378911\n",
      "Train Epoch: 1654 [320/1612 (20%)] Loss: 0.107707\n",
      "Train Epoch: 1654 [480/1612 (30%)] Loss: 0.245577\n",
      "Train Epoch: 1654 [640/1612 (40%)] Loss: 0.220174\n",
      "Train Epoch: 1654 [800/1612 (50%)] Loss: 0.068724\n",
      "Train Epoch: 1654 [960/1612 (59%)] Loss: 0.343336\n",
      "Train Epoch: 1654 [1120/1612 (69%)] Loss: 0.226836\n",
      "Train Epoch: 1654 [1280/1612 (79%)] Loss: 0.174115\n",
      "Train Epoch: 1654 [1440/1612 (89%)] Loss: 0.340238\n",
      "Train Epoch: 1654 [1200/1612 (99%)] Loss: 0.287289\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1655 [0/1612 (0%)] Loss: 0.322041\n",
      "Train Epoch: 1655 [160/1612 (10%)] Loss: 0.296002\n",
      "Train Epoch: 1655 [320/1612 (20%)] Loss: 0.274705\n",
      "Train Epoch: 1655 [480/1612 (30%)] Loss: 0.191930\n",
      "Train Epoch: 1655 [640/1612 (40%)] Loss: 0.407184\n",
      "Train Epoch: 1655 [800/1612 (50%)] Loss: 0.250160\n",
      "Train Epoch: 1655 [960/1612 (59%)] Loss: 0.452547\n",
      "Train Epoch: 1655 [1120/1612 (69%)] Loss: 0.355479\n",
      "Train Epoch: 1655 [1280/1612 (79%)] Loss: 0.236659\n",
      "Train Epoch: 1655 [1440/1612 (89%)] Loss: 0.321130\n",
      "Train Epoch: 1655 [1200/1612 (99%)] Loss: 0.619005\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1656 [0/1612 (0%)] Loss: 0.210934\n",
      "Train Epoch: 1656 [160/1612 (10%)] Loss: 0.296474\n",
      "Train Epoch: 1656 [320/1612 (20%)] Loss: 0.234870\n",
      "Train Epoch: 1656 [480/1612 (30%)] Loss: 0.271382\n",
      "Train Epoch: 1656 [640/1612 (40%)] Loss: 0.339899\n",
      "Train Epoch: 1656 [800/1612 (50%)] Loss: 0.157544\n",
      "Train Epoch: 1656 [960/1612 (59%)] Loss: 0.434073\n",
      "Train Epoch: 1656 [1120/1612 (69%)] Loss: 0.172707\n",
      "Train Epoch: 1656 [1280/1612 (79%)] Loss: 0.286566\n",
      "Train Epoch: 1656 [1440/1612 (89%)] Loss: 0.246680\n",
      "Train Epoch: 1656 [1200/1612 (99%)] Loss: 0.816315\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1657 [0/1612 (0%)] Loss: 0.408055\n",
      "Train Epoch: 1657 [160/1612 (10%)] Loss: 0.413721\n",
      "Train Epoch: 1657 [320/1612 (20%)] Loss: 0.195180\n",
      "Train Epoch: 1657 [480/1612 (30%)] Loss: 0.421093\n",
      "Train Epoch: 1657 [640/1612 (40%)] Loss: 0.372355\n",
      "Train Epoch: 1657 [800/1612 (50%)] Loss: 0.341396\n",
      "Train Epoch: 1657 [960/1612 (59%)] Loss: 0.083372\n",
      "Train Epoch: 1657 [1120/1612 (69%)] Loss: 0.194432\n",
      "Train Epoch: 1657 [1280/1612 (79%)] Loss: 0.507457\n",
      "Train Epoch: 1657 [1440/1612 (89%)] Loss: 0.143940\n",
      "Train Epoch: 1657 [1200/1612 (99%)] Loss: 0.120585\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1658 [0/1612 (0%)] Loss: 0.389815\n",
      "Train Epoch: 1658 [160/1612 (10%)] Loss: 0.355131\n",
      "Train Epoch: 1658 [320/1612 (20%)] Loss: 0.346201\n",
      "Train Epoch: 1658 [480/1612 (30%)] Loss: 0.418794\n",
      "Train Epoch: 1658 [640/1612 (40%)] Loss: 0.279501\n",
      "Train Epoch: 1658 [800/1612 (50%)] Loss: 0.197599\n",
      "Train Epoch: 1658 [960/1612 (59%)] Loss: 0.178791\n",
      "Train Epoch: 1658 [1120/1612 (69%)] Loss: 0.245128\n",
      "Train Epoch: 1658 [1280/1612 (79%)] Loss: 0.238845\n",
      "Train Epoch: 1658 [1440/1612 (89%)] Loss: 0.313562\n",
      "Train Epoch: 1658 [1200/1612 (99%)] Loss: 0.255932\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1659 [0/1612 (0%)] Loss: 0.167646\n",
      "Train Epoch: 1659 [160/1612 (10%)] Loss: 0.387934\n",
      "Train Epoch: 1659 [320/1612 (20%)] Loss: 0.670092\n",
      "Train Epoch: 1659 [480/1612 (30%)] Loss: 0.199935\n",
      "Train Epoch: 1659 [640/1612 (40%)] Loss: 0.328139\n",
      "Train Epoch: 1659 [800/1612 (50%)] Loss: 0.491801\n",
      "Train Epoch: 1659 [960/1612 (59%)] Loss: 0.402787\n",
      "Train Epoch: 1659 [1120/1612 (69%)] Loss: 0.469140\n",
      "Train Epoch: 1659 [1280/1612 (79%)] Loss: 0.251241\n",
      "Train Epoch: 1659 [1440/1612 (89%)] Loss: 0.359835\n",
      "Train Epoch: 1659 [1200/1612 (99%)] Loss: 0.476194\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1660 [0/1612 (0%)] Loss: 0.446000\n",
      "Train Epoch: 1660 [160/1612 (10%)] Loss: 0.361672\n",
      "Train Epoch: 1660 [320/1612 (20%)] Loss: 0.093174\n",
      "Train Epoch: 1660 [480/1612 (30%)] Loss: 0.203090\n",
      "Train Epoch: 1660 [640/1612 (40%)] Loss: 0.140852\n",
      "Train Epoch: 1660 [800/1612 (50%)] Loss: 0.378373\n",
      "Train Epoch: 1660 [960/1612 (59%)] Loss: 0.135219\n",
      "Train Epoch: 1660 [1120/1612 (69%)] Loss: 0.240774\n",
      "Train Epoch: 1660 [1280/1612 (79%)] Loss: 0.167145\n",
      "Train Epoch: 1660 [1440/1612 (89%)] Loss: 0.236299\n",
      "Train Epoch: 1660 [1200/1612 (99%)] Loss: 0.326905\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1661 [0/1612 (0%)] Loss: 0.180282\n",
      "Train Epoch: 1661 [160/1612 (10%)] Loss: 0.402696\n",
      "Train Epoch: 1661 [320/1612 (20%)] Loss: 0.179329\n",
      "Train Epoch: 1661 [480/1612 (30%)] Loss: 0.308883\n",
      "Train Epoch: 1661 [640/1612 (40%)] Loss: 0.133490\n",
      "Train Epoch: 1661 [800/1612 (50%)] Loss: 0.214318\n",
      "Train Epoch: 1661 [960/1612 (59%)] Loss: 0.327748\n",
      "Train Epoch: 1661 [1120/1612 (69%)] Loss: 0.274291\n",
      "Train Epoch: 1661 [1280/1612 (79%)] Loss: 0.327058\n",
      "Train Epoch: 1661 [1440/1612 (89%)] Loss: 0.240637\n",
      "Train Epoch: 1661 [1200/1612 (99%)] Loss: 0.436805\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1662 [0/1612 (0%)] Loss: 0.234976\n",
      "Train Epoch: 1662 [160/1612 (10%)] Loss: 0.203768\n",
      "Train Epoch: 1662 [320/1612 (20%)] Loss: 0.328200\n",
      "Train Epoch: 1662 [480/1612 (30%)] Loss: 0.304611\n",
      "Train Epoch: 1662 [640/1612 (40%)] Loss: 0.424341\n",
      "Train Epoch: 1662 [800/1612 (50%)] Loss: 0.330129\n",
      "Train Epoch: 1662 [960/1612 (59%)] Loss: 0.413424\n",
      "Train Epoch: 1662 [1120/1612 (69%)] Loss: 0.331699\n",
      "Train Epoch: 1662 [1280/1612 (79%)] Loss: 0.309781\n",
      "Train Epoch: 1662 [1440/1612 (89%)] Loss: 0.198758\n",
      "Train Epoch: 1662 [1200/1612 (99%)] Loss: 0.593903\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1663 [0/1612 (0%)] Loss: 0.152838\n",
      "Train Epoch: 1663 [160/1612 (10%)] Loss: 0.153213\n",
      "Train Epoch: 1663 [320/1612 (20%)] Loss: 0.240575\n",
      "Train Epoch: 1663 [480/1612 (30%)] Loss: 0.167333\n",
      "Train Epoch: 1663 [640/1612 (40%)] Loss: 0.169353\n",
      "Train Epoch: 1663 [800/1612 (50%)] Loss: 0.337295\n",
      "Train Epoch: 1663 [960/1612 (59%)] Loss: 0.549339\n",
      "Train Epoch: 1663 [1120/1612 (69%)] Loss: 0.305931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1663 [1280/1612 (79%)] Loss: 0.127652\n",
      "Train Epoch: 1663 [1440/1612 (89%)] Loss: 0.262307\n",
      "Train Epoch: 1663 [1200/1612 (99%)] Loss: 0.219493\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1664 [0/1612 (0%)] Loss: 0.187042\n",
      "Train Epoch: 1664 [160/1612 (10%)] Loss: 0.240296\n",
      "Train Epoch: 1664 [320/1612 (20%)] Loss: 0.188799\n",
      "Train Epoch: 1664 [480/1612 (30%)] Loss: 0.447204\n",
      "Train Epoch: 1664 [640/1612 (40%)] Loss: 0.196837\n",
      "Train Epoch: 1664 [800/1612 (50%)] Loss: 0.336976\n",
      "Train Epoch: 1664 [960/1612 (59%)] Loss: 0.202144\n",
      "Train Epoch: 1664 [1120/1612 (69%)] Loss: 0.254628\n",
      "Train Epoch: 1664 [1280/1612 (79%)] Loss: 0.293391\n",
      "Train Epoch: 1664 [1440/1612 (89%)] Loss: 0.333579\n",
      "Train Epoch: 1664 [1200/1612 (99%)] Loss: 0.438448\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1665 [0/1612 (0%)] Loss: 0.532291\n",
      "Train Epoch: 1665 [160/1612 (10%)] Loss: 0.233513\n",
      "Train Epoch: 1665 [320/1612 (20%)] Loss: 0.120611\n",
      "Train Epoch: 1665 [480/1612 (30%)] Loss: 0.228484\n",
      "Train Epoch: 1665 [640/1612 (40%)] Loss: 0.279945\n",
      "Train Epoch: 1665 [800/1612 (50%)] Loss: 0.302274\n",
      "Train Epoch: 1665 [960/1612 (59%)] Loss: 0.517094\n",
      "Train Epoch: 1665 [1120/1612 (69%)] Loss: 0.601064\n",
      "Train Epoch: 1665 [1280/1612 (79%)] Loss: 0.384806\n",
      "Train Epoch: 1665 [1440/1612 (89%)] Loss: 0.103985\n",
      "Train Epoch: 1665 [1200/1612 (99%)] Loss: 0.440534\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1666 [0/1612 (0%)] Loss: 0.408790\n",
      "Train Epoch: 1666 [160/1612 (10%)] Loss: 0.288056\n",
      "Train Epoch: 1666 [320/1612 (20%)] Loss: 0.386283\n",
      "Train Epoch: 1666 [480/1612 (30%)] Loss: 0.312254\n",
      "Train Epoch: 1666 [640/1612 (40%)] Loss: 0.411524\n",
      "Train Epoch: 1666 [800/1612 (50%)] Loss: 0.307186\n",
      "Train Epoch: 1666 [960/1612 (59%)] Loss: 0.305354\n",
      "Train Epoch: 1666 [1120/1612 (69%)] Loss: 0.285630\n",
      "Train Epoch: 1666 [1280/1612 (79%)] Loss: 0.117532\n",
      "Train Epoch: 1666 [1440/1612 (89%)] Loss: 0.562865\n",
      "Train Epoch: 1666 [1200/1612 (99%)] Loss: 0.415711\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1667 [0/1612 (0%)] Loss: 0.336245\n",
      "Train Epoch: 1667 [160/1612 (10%)] Loss: 0.733812\n",
      "Train Epoch: 1667 [320/1612 (20%)] Loss: 0.235704\n",
      "Train Epoch: 1667 [480/1612 (30%)] Loss: 0.381665\n",
      "Train Epoch: 1667 [640/1612 (40%)] Loss: 0.208957\n",
      "Train Epoch: 1667 [800/1612 (50%)] Loss: 0.434301\n",
      "Train Epoch: 1667 [960/1612 (59%)] Loss: 0.250053\n",
      "Train Epoch: 1667 [1120/1612 (69%)] Loss: 0.572888\n",
      "Train Epoch: 1667 [1280/1612 (79%)] Loss: 0.244200\n",
      "Train Epoch: 1667 [1440/1612 (89%)] Loss: 0.291808\n",
      "Train Epoch: 1667 [1200/1612 (99%)] Loss: 0.411606\n",
      "\n",
      "Test set: Average loss: 0.0295, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1668 [0/1612 (0%)] Loss: 0.313317\n",
      "Train Epoch: 1668 [160/1612 (10%)] Loss: 0.274923\n",
      "Train Epoch: 1668 [320/1612 (20%)] Loss: 0.346577\n",
      "Train Epoch: 1668 [480/1612 (30%)] Loss: 0.189417\n",
      "Train Epoch: 1668 [640/1612 (40%)] Loss: 0.288317\n",
      "Train Epoch: 1668 [800/1612 (50%)] Loss: 0.413994\n",
      "Train Epoch: 1668 [960/1612 (59%)] Loss: 0.515475\n",
      "Train Epoch: 1668 [1120/1612 (69%)] Loss: 0.566667\n",
      "Train Epoch: 1668 [1280/1612 (79%)] Loss: 0.281229\n",
      "Train Epoch: 1668 [1440/1612 (89%)] Loss: 0.188225\n",
      "Train Epoch: 1668 [1200/1612 (99%)] Loss: 0.196377\n",
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1669 [0/1612 (0%)] Loss: 0.275452\n",
      "Train Epoch: 1669 [160/1612 (10%)] Loss: 0.195658\n",
      "Train Epoch: 1669 [320/1612 (20%)] Loss: 0.862942\n",
      "Train Epoch: 1669 [480/1612 (30%)] Loss: 0.396927\n",
      "Train Epoch: 1669 [640/1612 (40%)] Loss: 0.208367\n",
      "Train Epoch: 1669 [800/1612 (50%)] Loss: 0.195203\n",
      "Train Epoch: 1669 [960/1612 (59%)] Loss: 0.270485\n",
      "Train Epoch: 1669 [1120/1612 (69%)] Loss: 0.195512\n",
      "Train Epoch: 1669 [1280/1612 (79%)] Loss: 0.486350\n",
      "Train Epoch: 1669 [1440/1612 (89%)] Loss: 0.453518\n",
      "Train Epoch: 1669 [1200/1612 (99%)] Loss: 0.407001\n",
      "\n",
      "Test set: Average loss: 0.0330, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1670 [0/1612 (0%)] Loss: 0.248616\n",
      "Train Epoch: 1670 [160/1612 (10%)] Loss: 0.282505\n",
      "Train Epoch: 1670 [320/1612 (20%)] Loss: 0.428077\n",
      "Train Epoch: 1670 [480/1612 (30%)] Loss: 0.276834\n",
      "Train Epoch: 1670 [640/1612 (40%)] Loss: 0.538386\n",
      "Train Epoch: 1670 [800/1612 (50%)] Loss: 0.523060\n",
      "Train Epoch: 1670 [960/1612 (59%)] Loss: 0.153402\n",
      "Train Epoch: 1670 [1120/1612 (69%)] Loss: 0.467666\n",
      "Train Epoch: 1670 [1280/1612 (79%)] Loss: 0.133382\n",
      "Train Epoch: 1670 [1440/1612 (89%)] Loss: 0.186030\n",
      "Train Epoch: 1670 [1200/1612 (99%)] Loss: 0.427075\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1671 [0/1612 (0%)] Loss: 0.398183\n",
      "Train Epoch: 1671 [160/1612 (10%)] Loss: 0.319991\n",
      "Train Epoch: 1671 [320/1612 (20%)] Loss: 0.313177\n",
      "Train Epoch: 1671 [480/1612 (30%)] Loss: 0.251171\n",
      "Train Epoch: 1671 [640/1612 (40%)] Loss: 0.241780\n",
      "Train Epoch: 1671 [800/1612 (50%)] Loss: 0.325373\n",
      "Train Epoch: 1671 [960/1612 (59%)] Loss: 0.163826\n",
      "Train Epoch: 1671 [1120/1612 (69%)] Loss: 0.204332\n",
      "Train Epoch: 1671 [1280/1612 (79%)] Loss: 0.167435\n",
      "Train Epoch: 1671 [1440/1612 (89%)] Loss: 0.344986\n",
      "Train Epoch: 1671 [1200/1612 (99%)] Loss: 0.224508\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1672 [0/1612 (0%)] Loss: 0.265980\n",
      "Train Epoch: 1672 [160/1612 (10%)] Loss: 0.199127\n",
      "Train Epoch: 1672 [320/1612 (20%)] Loss: 0.383587\n",
      "Train Epoch: 1672 [480/1612 (30%)] Loss: 0.505907\n",
      "Train Epoch: 1672 [640/1612 (40%)] Loss: 0.194722\n",
      "Train Epoch: 1672 [800/1612 (50%)] Loss: 0.088887\n",
      "Train Epoch: 1672 [960/1612 (59%)] Loss: 0.075679\n",
      "Train Epoch: 1672 [1120/1612 (69%)] Loss: 0.550296\n",
      "Train Epoch: 1672 [1280/1612 (79%)] Loss: 0.468284\n",
      "Train Epoch: 1672 [1440/1612 (89%)] Loss: 0.161088\n",
      "Train Epoch: 1672 [1200/1612 (99%)] Loss: 0.396614\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1673 [0/1612 (0%)] Loss: 0.353780\n",
      "Train Epoch: 1673 [160/1612 (10%)] Loss: 0.614058\n",
      "Train Epoch: 1673 [320/1612 (20%)] Loss: 0.261209\n",
      "Train Epoch: 1673 [480/1612 (30%)] Loss: 0.121052\n",
      "Train Epoch: 1673 [640/1612 (40%)] Loss: 0.290688\n",
      "Train Epoch: 1673 [800/1612 (50%)] Loss: 0.247414\n",
      "Train Epoch: 1673 [960/1612 (59%)] Loss: 0.233423\n",
      "Train Epoch: 1673 [1120/1612 (69%)] Loss: 0.261940\n",
      "Train Epoch: 1673 [1280/1612 (79%)] Loss: 0.244838\n",
      "Train Epoch: 1673 [1440/1612 (89%)] Loss: 0.307725\n",
      "Train Epoch: 1673 [1200/1612 (99%)] Loss: 0.231504\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1674 [0/1612 (0%)] Loss: 0.323449\n",
      "Train Epoch: 1674 [160/1612 (10%)] Loss: 0.390441\n",
      "Train Epoch: 1674 [320/1612 (20%)] Loss: 0.362983\n",
      "Train Epoch: 1674 [480/1612 (30%)] Loss: 0.065177\n",
      "Train Epoch: 1674 [640/1612 (40%)] Loss: 0.278815\n",
      "Train Epoch: 1674 [800/1612 (50%)] Loss: 0.344018\n",
      "Train Epoch: 1674 [960/1612 (59%)] Loss: 0.203457\n",
      "Train Epoch: 1674 [1120/1612 (69%)] Loss: 0.314206\n",
      "Train Epoch: 1674 [1280/1612 (79%)] Loss: 0.498138\n",
      "Train Epoch: 1674 [1440/1612 (89%)] Loss: 0.182322\n",
      "Train Epoch: 1674 [1200/1612 (99%)] Loss: 0.165475\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1675 [0/1612 (0%)] Loss: 0.432325\n",
      "Train Epoch: 1675 [160/1612 (10%)] Loss: 0.223073\n",
      "Train Epoch: 1675 [320/1612 (20%)] Loss: 0.255201\n",
      "Train Epoch: 1675 [480/1612 (30%)] Loss: 0.238100\n",
      "Train Epoch: 1675 [640/1612 (40%)] Loss: 0.327637\n",
      "Train Epoch: 1675 [800/1612 (50%)] Loss: 0.176096\n",
      "Train Epoch: 1675 [960/1612 (59%)] Loss: 0.224795\n",
      "Train Epoch: 1675 [1120/1612 (69%)] Loss: 0.312846\n",
      "Train Epoch: 1675 [1280/1612 (79%)] Loss: 0.221299\n",
      "Train Epoch: 1675 [1440/1612 (89%)] Loss: 0.281748\n",
      "Train Epoch: 1675 [1200/1612 (99%)] Loss: 0.332294\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1676 [0/1612 (0%)] Loss: 0.281807\n",
      "Train Epoch: 1676 [160/1612 (10%)] Loss: 0.238439\n",
      "Train Epoch: 1676 [320/1612 (20%)] Loss: 0.311539\n",
      "Train Epoch: 1676 [480/1612 (30%)] Loss: 0.132356\n",
      "Train Epoch: 1676 [640/1612 (40%)] Loss: 0.555551\n",
      "Train Epoch: 1676 [800/1612 (50%)] Loss: 0.459878\n",
      "Train Epoch: 1676 [960/1612 (59%)] Loss: 0.085558\n",
      "Train Epoch: 1676 [1120/1612 (69%)] Loss: 0.251604\n",
      "Train Epoch: 1676 [1280/1612 (79%)] Loss: 0.245826\n",
      "Train Epoch: 1676 [1440/1612 (89%)] Loss: 0.566222\n",
      "Train Epoch: 1676 [1200/1612 (99%)] Loss: 0.291955\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1677 [0/1612 (0%)] Loss: 0.196432\n",
      "Train Epoch: 1677 [160/1612 (10%)] Loss: 0.282295\n",
      "Train Epoch: 1677 [320/1612 (20%)] Loss: 0.113782\n",
      "Train Epoch: 1677 [480/1612 (30%)] Loss: 0.195197\n",
      "Train Epoch: 1677 [640/1612 (40%)] Loss: 0.479814\n",
      "Train Epoch: 1677 [800/1612 (50%)] Loss: 0.239487\n",
      "Train Epoch: 1677 [960/1612 (59%)] Loss: 0.353898\n",
      "Train Epoch: 1677 [1120/1612 (69%)] Loss: 0.175972\n",
      "Train Epoch: 1677 [1280/1612 (79%)] Loss: 0.344343\n",
      "Train Epoch: 1677 [1440/1612 (89%)] Loss: 0.528699\n",
      "Train Epoch: 1677 [1200/1612 (99%)] Loss: 0.365297\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1678 [0/1612 (0%)] Loss: 0.260398\n",
      "Train Epoch: 1678 [160/1612 (10%)] Loss: 0.081260\n",
      "Train Epoch: 1678 [320/1612 (20%)] Loss: 0.235280\n",
      "Train Epoch: 1678 [480/1612 (30%)] Loss: 0.237003\n",
      "Train Epoch: 1678 [640/1612 (40%)] Loss: 0.562878\n",
      "Train Epoch: 1678 [800/1612 (50%)] Loss: 0.255018\n",
      "Train Epoch: 1678 [960/1612 (59%)] Loss: 0.300001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1678 [1120/1612 (69%)] Loss: 0.070562\n",
      "Train Epoch: 1678 [1280/1612 (79%)] Loss: 0.326226\n",
      "Train Epoch: 1678 [1440/1612 (89%)] Loss: 0.201528\n",
      "Train Epoch: 1678 [1200/1612 (99%)] Loss: 0.395514\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1679 [0/1612 (0%)] Loss: 0.267987\n",
      "Train Epoch: 1679 [160/1612 (10%)] Loss: 0.330304\n",
      "Train Epoch: 1679 [320/1612 (20%)] Loss: 0.252256\n",
      "Train Epoch: 1679 [480/1612 (30%)] Loss: 0.269476\n",
      "Train Epoch: 1679 [640/1612 (40%)] Loss: 0.227618\n",
      "Train Epoch: 1679 [800/1612 (50%)] Loss: 0.168250\n",
      "Train Epoch: 1679 [960/1612 (59%)] Loss: 0.242546\n",
      "Train Epoch: 1679 [1120/1612 (69%)] Loss: 0.338564\n",
      "Train Epoch: 1679 [1280/1612 (79%)] Loss: 0.310746\n",
      "Train Epoch: 1679 [1440/1612 (89%)] Loss: 0.154505\n",
      "Train Epoch: 1679 [1200/1612 (99%)] Loss: 0.188743\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1680 [0/1612 (0%)] Loss: 0.314495\n",
      "Train Epoch: 1680 [160/1612 (10%)] Loss: 0.296181\n",
      "Train Epoch: 1680 [320/1612 (20%)] Loss: 0.226261\n",
      "Train Epoch: 1680 [480/1612 (30%)] Loss: 0.478395\n",
      "Train Epoch: 1680 [640/1612 (40%)] Loss: 0.283425\n",
      "Train Epoch: 1680 [800/1612 (50%)] Loss: 0.407967\n",
      "Train Epoch: 1680 [960/1612 (59%)] Loss: 0.273707\n",
      "Train Epoch: 1680 [1120/1612 (69%)] Loss: 0.346262\n",
      "Train Epoch: 1680 [1280/1612 (79%)] Loss: 0.246048\n",
      "Train Epoch: 1680 [1440/1612 (89%)] Loss: 0.271202\n",
      "Train Epoch: 1680 [1200/1612 (99%)] Loss: 0.307125\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1681 [0/1612 (0%)] Loss: 0.397543\n",
      "Train Epoch: 1681 [160/1612 (10%)] Loss: 0.474299\n",
      "Train Epoch: 1681 [320/1612 (20%)] Loss: 0.349084\n",
      "Train Epoch: 1681 [480/1612 (30%)] Loss: 0.266018\n",
      "Train Epoch: 1681 [640/1612 (40%)] Loss: 0.459907\n",
      "Train Epoch: 1681 [800/1612 (50%)] Loss: 0.278085\n",
      "Train Epoch: 1681 [960/1612 (59%)] Loss: 0.181811\n",
      "Train Epoch: 1681 [1120/1612 (69%)] Loss: 0.398563\n",
      "Train Epoch: 1681 [1280/1612 (79%)] Loss: 0.257532\n",
      "Train Epoch: 1681 [1440/1612 (89%)] Loss: 0.439510\n",
      "Train Epoch: 1681 [1200/1612 (99%)] Loss: 0.174481\n",
      "\n",
      "Test set: Average loss: 0.0252, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1682 [0/1612 (0%)] Loss: 0.187636\n",
      "Train Epoch: 1682 [160/1612 (10%)] Loss: 0.301373\n",
      "Train Epoch: 1682 [320/1612 (20%)] Loss: 0.365043\n",
      "Train Epoch: 1682 [480/1612 (30%)] Loss: 0.411977\n",
      "Train Epoch: 1682 [640/1612 (40%)] Loss: 0.251726\n",
      "Train Epoch: 1682 [800/1612 (50%)] Loss: 0.259665\n",
      "Train Epoch: 1682 [960/1612 (59%)] Loss: 0.254901\n",
      "Train Epoch: 1682 [1120/1612 (69%)] Loss: 0.296163\n",
      "Train Epoch: 1682 [1280/1612 (79%)] Loss: 0.426110\n",
      "Train Epoch: 1682 [1440/1612 (89%)] Loss: 0.482116\n",
      "Train Epoch: 1682 [1200/1612 (99%)] Loss: 0.476054\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1683 [0/1612 (0%)] Loss: 0.245855\n",
      "Train Epoch: 1683 [160/1612 (10%)] Loss: 0.295639\n",
      "Train Epoch: 1683 [320/1612 (20%)] Loss: 0.289361\n",
      "Train Epoch: 1683 [480/1612 (30%)] Loss: 0.114296\n",
      "Train Epoch: 1683 [640/1612 (40%)] Loss: 0.260198\n",
      "Train Epoch: 1683 [800/1612 (50%)] Loss: 0.576149\n",
      "Train Epoch: 1683 [960/1612 (59%)] Loss: 0.511442\n",
      "Train Epoch: 1683 [1120/1612 (69%)] Loss: 0.162300\n",
      "Train Epoch: 1683 [1280/1612 (79%)] Loss: 0.407508\n",
      "Train Epoch: 1683 [1440/1612 (89%)] Loss: 0.202753\n",
      "Train Epoch: 1683 [1200/1612 (99%)] Loss: 0.416331\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1684 [0/1612 (0%)] Loss: 0.105953\n",
      "Train Epoch: 1684 [160/1612 (10%)] Loss: 0.398242\n",
      "Train Epoch: 1684 [320/1612 (20%)] Loss: 0.389974\n",
      "Train Epoch: 1684 [480/1612 (30%)] Loss: 0.359480\n",
      "Train Epoch: 1684 [640/1612 (40%)] Loss: 0.306499\n",
      "Train Epoch: 1684 [800/1612 (50%)] Loss: 0.667065\n",
      "Train Epoch: 1684 [960/1612 (59%)] Loss: 0.339832\n",
      "Train Epoch: 1684 [1120/1612 (69%)] Loss: 0.149138\n",
      "Train Epoch: 1684 [1280/1612 (79%)] Loss: 0.436813\n",
      "Train Epoch: 1684 [1440/1612 (89%)] Loss: 0.428464\n",
      "Train Epoch: 1684 [1200/1612 (99%)] Loss: 0.326454\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1685 [0/1612 (0%)] Loss: 0.454051\n",
      "Train Epoch: 1685 [160/1612 (10%)] Loss: 0.305950\n",
      "Train Epoch: 1685 [320/1612 (20%)] Loss: 0.293796\n",
      "Train Epoch: 1685 [480/1612 (30%)] Loss: 0.116028\n",
      "Train Epoch: 1685 [640/1612 (40%)] Loss: 0.437436\n",
      "Train Epoch: 1685 [800/1612 (50%)] Loss: 0.336027\n",
      "Train Epoch: 1685 [960/1612 (59%)] Loss: 0.249736\n",
      "Train Epoch: 1685 [1120/1612 (69%)] Loss: 0.176831\n",
      "Train Epoch: 1685 [1280/1612 (79%)] Loss: 0.115739\n",
      "Train Epoch: 1685 [1440/1612 (89%)] Loss: 0.397121\n",
      "Train Epoch: 1685 [1200/1612 (99%)] Loss: 0.159399\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1686 [0/1612 (0%)] Loss: 0.573328\n",
      "Train Epoch: 1686 [160/1612 (10%)] Loss: 0.404165\n",
      "Train Epoch: 1686 [320/1612 (20%)] Loss: 0.256701\n",
      "Train Epoch: 1686 [480/1612 (30%)] Loss: 0.196776\n",
      "Train Epoch: 1686 [640/1612 (40%)] Loss: 0.062834\n",
      "Train Epoch: 1686 [800/1612 (50%)] Loss: 0.320029\n",
      "Train Epoch: 1686 [960/1612 (59%)] Loss: 0.248380\n",
      "Train Epoch: 1686 [1120/1612 (69%)] Loss: 0.368001\n",
      "Train Epoch: 1686 [1280/1612 (79%)] Loss: 0.279542\n",
      "Train Epoch: 1686 [1440/1612 (89%)] Loss: 0.261227\n",
      "Train Epoch: 1686 [1200/1612 (99%)] Loss: 0.221129\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1687 [0/1612 (0%)] Loss: 0.499925\n",
      "Train Epoch: 1687 [160/1612 (10%)] Loss: 0.176773\n",
      "Train Epoch: 1687 [320/1612 (20%)] Loss: 0.231793\n",
      "Train Epoch: 1687 [480/1612 (30%)] Loss: 0.449604\n",
      "Train Epoch: 1687 [640/1612 (40%)] Loss: 0.178971\n",
      "Train Epoch: 1687 [800/1612 (50%)] Loss: 0.290497\n",
      "Train Epoch: 1687 [960/1612 (59%)] Loss: 0.204034\n",
      "Train Epoch: 1687 [1120/1612 (69%)] Loss: 0.118777\n",
      "Train Epoch: 1687 [1280/1612 (79%)] Loss: 0.284075\n",
      "Train Epoch: 1687 [1440/1612 (89%)] Loss: 0.476542\n",
      "Train Epoch: 1687 [1200/1612 (99%)] Loss: 0.297096\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1688 [0/1612 (0%)] Loss: 0.199216\n",
      "Train Epoch: 1688 [160/1612 (10%)] Loss: 0.095065\n",
      "Train Epoch: 1688 [320/1612 (20%)] Loss: 0.130330\n",
      "Train Epoch: 1688 [480/1612 (30%)] Loss: 0.298623\n",
      "Train Epoch: 1688 [640/1612 (40%)] Loss: 0.228395\n",
      "Train Epoch: 1688 [800/1612 (50%)] Loss: 0.168920\n",
      "Train Epoch: 1688 [960/1612 (59%)] Loss: 0.277085\n",
      "Train Epoch: 1688 [1120/1612 (69%)] Loss: 0.304191\n",
      "Train Epoch: 1688 [1280/1612 (79%)] Loss: 0.322530\n",
      "Train Epoch: 1688 [1440/1612 (89%)] Loss: 0.245767\n",
      "Train Epoch: 1688 [1200/1612 (99%)] Loss: 0.448253\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1689 [0/1612 (0%)] Loss: 0.110357\n",
      "Train Epoch: 1689 [160/1612 (10%)] Loss: 0.235178\n",
      "Train Epoch: 1689 [320/1612 (20%)] Loss: 0.379801\n",
      "Train Epoch: 1689 [480/1612 (30%)] Loss: 0.197958\n",
      "Train Epoch: 1689 [640/1612 (40%)] Loss: 0.357616\n",
      "Train Epoch: 1689 [800/1612 (50%)] Loss: 0.360296\n",
      "Train Epoch: 1689 [960/1612 (59%)] Loss: 0.293223\n",
      "Train Epoch: 1689 [1120/1612 (69%)] Loss: 0.254988\n",
      "Train Epoch: 1689 [1280/1612 (79%)] Loss: 0.229761\n",
      "Train Epoch: 1689 [1440/1612 (89%)] Loss: 0.434227\n",
      "Train Epoch: 1689 [1200/1612 (99%)] Loss: 0.376187\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1690 [0/1612 (0%)] Loss: 0.282249\n",
      "Train Epoch: 1690 [160/1612 (10%)] Loss: 0.254829\n",
      "Train Epoch: 1690 [320/1612 (20%)] Loss: 0.589798\n",
      "Train Epoch: 1690 [480/1612 (30%)] Loss: 0.165726\n",
      "Train Epoch: 1690 [640/1612 (40%)] Loss: 0.417953\n",
      "Train Epoch: 1690 [800/1612 (50%)] Loss: 0.369136\n",
      "Train Epoch: 1690 [960/1612 (59%)] Loss: 0.157098\n",
      "Train Epoch: 1690 [1120/1612 (69%)] Loss: 0.163010\n",
      "Train Epoch: 1690 [1280/1612 (79%)] Loss: 0.295266\n",
      "Train Epoch: 1690 [1440/1612 (89%)] Loss: 0.188528\n",
      "Train Epoch: 1690 [1200/1612 (99%)] Loss: 0.196965\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1691 [0/1612 (0%)] Loss: 0.134333\n",
      "Train Epoch: 1691 [160/1612 (10%)] Loss: 0.434583\n",
      "Train Epoch: 1691 [320/1612 (20%)] Loss: 0.190598\n",
      "Train Epoch: 1691 [480/1612 (30%)] Loss: 0.192295\n",
      "Train Epoch: 1691 [640/1612 (40%)] Loss: 0.359114\n",
      "Train Epoch: 1691 [800/1612 (50%)] Loss: 0.180167\n",
      "Train Epoch: 1691 [960/1612 (59%)] Loss: 0.170892\n",
      "Train Epoch: 1691 [1120/1612 (69%)] Loss: 0.207607\n",
      "Train Epoch: 1691 [1280/1612 (79%)] Loss: 0.351380\n",
      "Train Epoch: 1691 [1440/1612 (89%)] Loss: 0.480072\n",
      "Train Epoch: 1691 [1200/1612 (99%)] Loss: 0.337338\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1692 [0/1612 (0%)] Loss: 0.180042\n",
      "Train Epoch: 1692 [160/1612 (10%)] Loss: 0.453634\n",
      "Train Epoch: 1692 [320/1612 (20%)] Loss: 0.058667\n",
      "Train Epoch: 1692 [480/1612 (30%)] Loss: 0.306277\n",
      "Train Epoch: 1692 [640/1612 (40%)] Loss: 0.046564\n",
      "Train Epoch: 1692 [800/1612 (50%)] Loss: 0.504126\n",
      "Train Epoch: 1692 [960/1612 (59%)] Loss: 0.323938\n",
      "Train Epoch: 1692 [1120/1612 (69%)] Loss: 0.212812\n",
      "Train Epoch: 1692 [1280/1612 (79%)] Loss: 0.515457\n",
      "Train Epoch: 1692 [1440/1612 (89%)] Loss: 0.318807\n",
      "Train Epoch: 1692 [1200/1612 (99%)] Loss: 0.255356\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1693 [0/1612 (0%)] Loss: 0.261647\n",
      "Train Epoch: 1693 [160/1612 (10%)] Loss: 0.249379\n",
      "Train Epoch: 1693 [320/1612 (20%)] Loss: 0.231710\n",
      "Train Epoch: 1693 [480/1612 (30%)] Loss: 0.178737\n",
      "Train Epoch: 1693 [640/1612 (40%)] Loss: 0.193665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1693 [800/1612 (50%)] Loss: 0.282474\n",
      "Train Epoch: 1693 [960/1612 (59%)] Loss: 0.260712\n",
      "Train Epoch: 1693 [1120/1612 (69%)] Loss: 0.326660\n",
      "Train Epoch: 1693 [1280/1612 (79%)] Loss: 0.516034\n",
      "Train Epoch: 1693 [1440/1612 (89%)] Loss: 0.350319\n",
      "Train Epoch: 1693 [1200/1612 (99%)] Loss: 0.438102\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1694 [0/1612 (0%)] Loss: 0.194044\n",
      "Train Epoch: 1694 [160/1612 (10%)] Loss: 0.571712\n",
      "Train Epoch: 1694 [320/1612 (20%)] Loss: 0.266033\n",
      "Train Epoch: 1694 [480/1612 (30%)] Loss: 0.134077\n",
      "Train Epoch: 1694 [640/1612 (40%)] Loss: 0.368864\n",
      "Train Epoch: 1694 [800/1612 (50%)] Loss: 0.112034\n",
      "Train Epoch: 1694 [960/1612 (59%)] Loss: 0.421842\n",
      "Train Epoch: 1694 [1120/1612 (69%)] Loss: 0.327867\n",
      "Train Epoch: 1694 [1280/1612 (79%)] Loss: 0.189054\n",
      "Train Epoch: 1694 [1440/1612 (89%)] Loss: 0.238326\n",
      "Train Epoch: 1694 [1200/1612 (99%)] Loss: 0.150442\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1695 [0/1612 (0%)] Loss: 0.272927\n",
      "Train Epoch: 1695 [160/1612 (10%)] Loss: 0.297991\n",
      "Train Epoch: 1695 [320/1612 (20%)] Loss: 0.176322\n",
      "Train Epoch: 1695 [480/1612 (30%)] Loss: 0.605916\n",
      "Train Epoch: 1695 [640/1612 (40%)] Loss: 0.402367\n",
      "Train Epoch: 1695 [800/1612 (50%)] Loss: 0.279217\n",
      "Train Epoch: 1695 [960/1612 (59%)] Loss: 0.269198\n",
      "Train Epoch: 1695 [1120/1612 (69%)] Loss: 0.193784\n",
      "Train Epoch: 1695 [1280/1612 (79%)] Loss: 0.184001\n",
      "Train Epoch: 1695 [1440/1612 (89%)] Loss: 0.188600\n",
      "Train Epoch: 1695 [1200/1612 (99%)] Loss: 0.235887\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1696 [0/1612 (0%)] Loss: 0.132069\n",
      "Train Epoch: 1696 [160/1612 (10%)] Loss: 0.109953\n",
      "Train Epoch: 1696 [320/1612 (20%)] Loss: 0.408203\n",
      "Train Epoch: 1696 [480/1612 (30%)] Loss: 0.297584\n",
      "Train Epoch: 1696 [640/1612 (40%)] Loss: 0.302383\n",
      "Train Epoch: 1696 [800/1612 (50%)] Loss: 0.192207\n",
      "Train Epoch: 1696 [960/1612 (59%)] Loss: 0.308627\n",
      "Train Epoch: 1696 [1120/1612 (69%)] Loss: 0.286148\n",
      "Train Epoch: 1696 [1280/1612 (79%)] Loss: 0.341138\n",
      "Train Epoch: 1696 [1440/1612 (89%)] Loss: 0.395551\n",
      "Train Epoch: 1696 [1200/1612 (99%)] Loss: 0.212504\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1697 [0/1612 (0%)] Loss: 0.554135\n",
      "Train Epoch: 1697 [160/1612 (10%)] Loss: 0.112010\n",
      "Train Epoch: 1697 [320/1612 (20%)] Loss: 0.232137\n",
      "Train Epoch: 1697 [480/1612 (30%)] Loss: 0.201115\n",
      "Train Epoch: 1697 [640/1612 (40%)] Loss: 0.211763\n",
      "Train Epoch: 1697 [800/1612 (50%)] Loss: 0.240746\n",
      "Train Epoch: 1697 [960/1612 (59%)] Loss: 0.296933\n",
      "Train Epoch: 1697 [1120/1612 (69%)] Loss: 0.259584\n",
      "Train Epoch: 1697 [1280/1612 (79%)] Loss: 0.308745\n",
      "Train Epoch: 1697 [1440/1612 (89%)] Loss: 0.535157\n",
      "Train Epoch: 1697 [1200/1612 (99%)] Loss: 0.339069\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1698 [0/1612 (0%)] Loss: 0.332046\n",
      "Train Epoch: 1698 [160/1612 (10%)] Loss: 0.217647\n",
      "Train Epoch: 1698 [320/1612 (20%)] Loss: 0.327980\n",
      "Train Epoch: 1698 [480/1612 (30%)] Loss: 0.185319\n",
      "Train Epoch: 1698 [640/1612 (40%)] Loss: 0.326705\n",
      "Train Epoch: 1698 [800/1612 (50%)] Loss: 0.242698\n",
      "Train Epoch: 1698 [960/1612 (59%)] Loss: 0.170715\n",
      "Train Epoch: 1698 [1120/1612 (69%)] Loss: 0.380956\n",
      "Train Epoch: 1698 [1280/1612 (79%)] Loss: 0.378544\n",
      "Train Epoch: 1698 [1440/1612 (89%)] Loss: 0.328859\n",
      "Train Epoch: 1698 [1200/1612 (99%)] Loss: 0.367055\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1699 [0/1612 (0%)] Loss: 0.422060\n",
      "Train Epoch: 1699 [160/1612 (10%)] Loss: 0.183970\n",
      "Train Epoch: 1699 [320/1612 (20%)] Loss: 0.486591\n",
      "Train Epoch: 1699 [480/1612 (30%)] Loss: 0.151605\n",
      "Train Epoch: 1699 [640/1612 (40%)] Loss: 0.300331\n",
      "Train Epoch: 1699 [800/1612 (50%)] Loss: 0.286399\n",
      "Train Epoch: 1699 [960/1612 (59%)] Loss: 0.157998\n",
      "Train Epoch: 1699 [1120/1612 (69%)] Loss: 0.317261\n",
      "Train Epoch: 1699 [1280/1612 (79%)] Loss: 0.215699\n",
      "Train Epoch: 1699 [1440/1612 (89%)] Loss: 0.286454\n",
      "Train Epoch: 1699 [1200/1612 (99%)] Loss: 0.490155\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1700 [0/1612 (0%)] Loss: 0.124045\n",
      "Train Epoch: 1700 [160/1612 (10%)] Loss: 0.385174\n",
      "Train Epoch: 1700 [320/1612 (20%)] Loss: 0.443026\n",
      "Train Epoch: 1700 [480/1612 (30%)] Loss: 0.281417\n",
      "Train Epoch: 1700 [640/1612 (40%)] Loss: 0.214458\n",
      "Train Epoch: 1700 [800/1612 (50%)] Loss: 0.508610\n",
      "Train Epoch: 1700 [960/1612 (59%)] Loss: 0.255908\n",
      "Train Epoch: 1700 [1120/1612 (69%)] Loss: 0.351895\n",
      "Train Epoch: 1700 [1280/1612 (79%)] Loss: 0.174348\n",
      "Train Epoch: 1700 [1440/1612 (89%)] Loss: 0.365278\n",
      "Train Epoch: 1700 [1200/1612 (99%)] Loss: 0.284550\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1701 [0/1612 (0%)] Loss: 0.241454\n",
      "Train Epoch: 1701 [160/1612 (10%)] Loss: 0.439074\n",
      "Train Epoch: 1701 [320/1612 (20%)] Loss: 0.223263\n",
      "Train Epoch: 1701 [480/1612 (30%)] Loss: 0.161363\n",
      "Train Epoch: 1701 [640/1612 (40%)] Loss: 0.293899\n",
      "Train Epoch: 1701 [800/1612 (50%)] Loss: 0.361999\n",
      "Train Epoch: 1701 [960/1612 (59%)] Loss: 0.364319\n",
      "Train Epoch: 1701 [1120/1612 (69%)] Loss: 0.259199\n",
      "Train Epoch: 1701 [1280/1612 (79%)] Loss: 0.520296\n",
      "Train Epoch: 1701 [1440/1612 (89%)] Loss: 0.400746\n",
      "Train Epoch: 1701 [1200/1612 (99%)] Loss: 0.208859\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1702 [0/1612 (0%)] Loss: 0.312519\n",
      "Train Epoch: 1702 [160/1612 (10%)] Loss: 0.188615\n",
      "Train Epoch: 1702 [320/1612 (20%)] Loss: 0.593694\n",
      "Train Epoch: 1702 [480/1612 (30%)] Loss: 0.440060\n",
      "Train Epoch: 1702 [640/1612 (40%)] Loss: 0.219729\n",
      "Train Epoch: 1702 [800/1612 (50%)] Loss: 0.260803\n",
      "Train Epoch: 1702 [960/1612 (59%)] Loss: 0.334424\n",
      "Train Epoch: 1702 [1120/1612 (69%)] Loss: 0.278870\n",
      "Train Epoch: 1702 [1280/1612 (79%)] Loss: 0.323315\n",
      "Train Epoch: 1702 [1440/1612 (89%)] Loss: 0.544635\n",
      "Train Epoch: 1702 [1200/1612 (99%)] Loss: 0.413416\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1703 [0/1612 (0%)] Loss: 0.281191\n",
      "Train Epoch: 1703 [160/1612 (10%)] Loss: 0.464661\n",
      "Train Epoch: 1703 [320/1612 (20%)] Loss: 0.480024\n",
      "Train Epoch: 1703 [480/1612 (30%)] Loss: 0.090316\n",
      "Train Epoch: 1703 [640/1612 (40%)] Loss: 0.543986\n",
      "Train Epoch: 1703 [800/1612 (50%)] Loss: 0.268088\n",
      "Train Epoch: 1703 [960/1612 (59%)] Loss: 0.343664\n",
      "Train Epoch: 1703 [1120/1612 (69%)] Loss: 0.342215\n",
      "Train Epoch: 1703 [1280/1612 (79%)] Loss: 0.417205\n",
      "Train Epoch: 1703 [1440/1612 (89%)] Loss: 0.521546\n",
      "Train Epoch: 1703 [1200/1612 (99%)] Loss: 0.651845\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1704 [0/1612 (0%)] Loss: 0.256366\n",
      "Train Epoch: 1704 [160/1612 (10%)] Loss: 0.347325\n",
      "Train Epoch: 1704 [320/1612 (20%)] Loss: 0.205829\n",
      "Train Epoch: 1704 [480/1612 (30%)] Loss: 0.336375\n",
      "Train Epoch: 1704 [640/1612 (40%)] Loss: 0.436839\n",
      "Train Epoch: 1704 [800/1612 (50%)] Loss: 0.381829\n",
      "Train Epoch: 1704 [960/1612 (59%)] Loss: 0.361758\n",
      "Train Epoch: 1704 [1120/1612 (69%)] Loss: 0.322284\n",
      "Train Epoch: 1704 [1280/1612 (79%)] Loss: 0.265683\n",
      "Train Epoch: 1704 [1440/1612 (89%)] Loss: 0.451262\n",
      "Train Epoch: 1704 [1200/1612 (99%)] Loss: 0.306791\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1705 [0/1612 (0%)] Loss: 0.416002\n",
      "Train Epoch: 1705 [160/1612 (10%)] Loss: 0.256516\n",
      "Train Epoch: 1705 [320/1612 (20%)] Loss: 0.351946\n",
      "Train Epoch: 1705 [480/1612 (30%)] Loss: 0.198611\n",
      "Train Epoch: 1705 [640/1612 (40%)] Loss: 0.325753\n",
      "Train Epoch: 1705 [800/1612 (50%)] Loss: 0.153797\n",
      "Train Epoch: 1705 [960/1612 (59%)] Loss: 0.452071\n",
      "Train Epoch: 1705 [1120/1612 (69%)] Loss: 0.479102\n",
      "Train Epoch: 1705 [1280/1612 (79%)] Loss: 0.518920\n",
      "Train Epoch: 1705 [1440/1612 (89%)] Loss: 0.253064\n",
      "Train Epoch: 1705 [1200/1612 (99%)] Loss: 0.244371\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1706 [0/1612 (0%)] Loss: 0.392495\n",
      "Train Epoch: 1706 [160/1612 (10%)] Loss: 0.098073\n",
      "Train Epoch: 1706 [320/1612 (20%)] Loss: 0.262779\n",
      "Train Epoch: 1706 [480/1612 (30%)] Loss: 0.110358\n",
      "Train Epoch: 1706 [640/1612 (40%)] Loss: 0.302401\n",
      "Train Epoch: 1706 [800/1612 (50%)] Loss: 0.135065\n",
      "Train Epoch: 1706 [960/1612 (59%)] Loss: 0.416695\n",
      "Train Epoch: 1706 [1120/1612 (69%)] Loss: 0.371067\n",
      "Train Epoch: 1706 [1280/1612 (79%)] Loss: 0.466272\n",
      "Train Epoch: 1706 [1440/1612 (89%)] Loss: 0.364460\n",
      "Train Epoch: 1706 [1200/1612 (99%)] Loss: 0.222065\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1707 [0/1612 (0%)] Loss: 0.260587\n",
      "Train Epoch: 1707 [160/1612 (10%)] Loss: 0.131496\n",
      "Train Epoch: 1707 [320/1612 (20%)] Loss: 0.178929\n",
      "Train Epoch: 1707 [480/1612 (30%)] Loss: 0.297347\n",
      "Train Epoch: 1707 [640/1612 (40%)] Loss: 0.349676\n",
      "Train Epoch: 1707 [800/1612 (50%)] Loss: 0.210232\n",
      "Train Epoch: 1707 [960/1612 (59%)] Loss: 0.332163\n",
      "Train Epoch: 1707 [1120/1612 (69%)] Loss: 0.148093\n",
      "Train Epoch: 1707 [1280/1612 (79%)] Loss: 0.435584\n",
      "Train Epoch: 1707 [1440/1612 (89%)] Loss: 0.349153\n",
      "Train Epoch: 1707 [1200/1612 (99%)] Loss: 0.449590\n",
      "\n",
      "Test set: Average loss: 0.0295, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1708 [0/1612 (0%)] Loss: 0.256845\n",
      "Train Epoch: 1708 [160/1612 (10%)] Loss: 0.224924\n",
      "Train Epoch: 1708 [320/1612 (20%)] Loss: 0.308204\n",
      "Train Epoch: 1708 [480/1612 (30%)] Loss: 0.189178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1708 [640/1612 (40%)] Loss: 0.360611\n",
      "Train Epoch: 1708 [800/1612 (50%)] Loss: 0.166994\n",
      "Train Epoch: 1708 [960/1612 (59%)] Loss: 0.342698\n",
      "Train Epoch: 1708 [1120/1612 (69%)] Loss: 0.302121\n",
      "Train Epoch: 1708 [1280/1612 (79%)] Loss: 0.284066\n",
      "Train Epoch: 1708 [1440/1612 (89%)] Loss: 0.248578\n",
      "Train Epoch: 1708 [1200/1612 (99%)] Loss: 0.525231\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1709 [0/1612 (0%)] Loss: 0.161841\n",
      "Train Epoch: 1709 [160/1612 (10%)] Loss: 0.264244\n",
      "Train Epoch: 1709 [320/1612 (20%)] Loss: 0.268079\n",
      "Train Epoch: 1709 [480/1612 (30%)] Loss: 0.220302\n",
      "Train Epoch: 1709 [640/1612 (40%)] Loss: 0.427217\n",
      "Train Epoch: 1709 [800/1612 (50%)] Loss: 0.209036\n",
      "Train Epoch: 1709 [960/1612 (59%)] Loss: 0.263787\n",
      "Train Epoch: 1709 [1120/1612 (69%)] Loss: 0.240650\n",
      "Train Epoch: 1709 [1280/1612 (79%)] Loss: 0.471323\n",
      "Train Epoch: 1709 [1440/1612 (89%)] Loss: 0.153850\n",
      "Train Epoch: 1709 [1200/1612 (99%)] Loss: 0.385471\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1710 [0/1612 (0%)] Loss: 0.263906\n",
      "Train Epoch: 1710 [160/1612 (10%)] Loss: 0.196902\n",
      "Train Epoch: 1710 [320/1612 (20%)] Loss: 0.135562\n",
      "Train Epoch: 1710 [480/1612 (30%)] Loss: 0.396915\n",
      "Train Epoch: 1710 [640/1612 (40%)] Loss: 0.220899\n",
      "Train Epoch: 1710 [800/1612 (50%)] Loss: 0.237819\n",
      "Train Epoch: 1710 [960/1612 (59%)] Loss: 0.332570\n",
      "Train Epoch: 1710 [1120/1612 (69%)] Loss: 0.257121\n",
      "Train Epoch: 1710 [1280/1612 (79%)] Loss: 0.396432\n",
      "Train Epoch: 1710 [1440/1612 (89%)] Loss: 0.362294\n",
      "Train Epoch: 1710 [1200/1612 (99%)] Loss: 0.193834\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1711 [0/1612 (0%)] Loss: 0.316852\n",
      "Train Epoch: 1711 [160/1612 (10%)] Loss: 0.367524\n",
      "Train Epoch: 1711 [320/1612 (20%)] Loss: 0.270962\n",
      "Train Epoch: 1711 [480/1612 (30%)] Loss: 0.222693\n",
      "Train Epoch: 1711 [640/1612 (40%)] Loss: 0.309227\n",
      "Train Epoch: 1711 [800/1612 (50%)] Loss: 0.262134\n",
      "Train Epoch: 1711 [960/1612 (59%)] Loss: 0.409458\n",
      "Train Epoch: 1711 [1120/1612 (69%)] Loss: 0.237836\n",
      "Train Epoch: 1711 [1280/1612 (79%)] Loss: 0.166140\n",
      "Train Epoch: 1711 [1440/1612 (89%)] Loss: 0.204946\n",
      "Train Epoch: 1711 [1200/1612 (99%)] Loss: 0.272785\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1712 [0/1612 (0%)] Loss: 0.256786\n",
      "Train Epoch: 1712 [160/1612 (10%)] Loss: 0.345981\n",
      "Train Epoch: 1712 [320/1612 (20%)] Loss: 0.342185\n",
      "Train Epoch: 1712 [480/1612 (30%)] Loss: 0.358026\n",
      "Train Epoch: 1712 [640/1612 (40%)] Loss: 0.372206\n",
      "Train Epoch: 1712 [800/1612 (50%)] Loss: 0.161688\n",
      "Train Epoch: 1712 [960/1612 (59%)] Loss: 0.432770\n",
      "Train Epoch: 1712 [1120/1612 (69%)] Loss: 0.350528\n",
      "Train Epoch: 1712 [1280/1612 (79%)] Loss: 0.269649\n",
      "Train Epoch: 1712 [1440/1612 (89%)] Loss: 0.310438\n",
      "Train Epoch: 1712 [1200/1612 (99%)] Loss: 0.175036\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1713 [0/1612 (0%)] Loss: 0.138027\n",
      "Train Epoch: 1713 [160/1612 (10%)] Loss: 0.239693\n",
      "Train Epoch: 1713 [320/1612 (20%)] Loss: 0.244393\n",
      "Train Epoch: 1713 [480/1612 (30%)] Loss: 0.170975\n",
      "Train Epoch: 1713 [640/1612 (40%)] Loss: 0.348470\n",
      "Train Epoch: 1713 [800/1612 (50%)] Loss: 0.235772\n",
      "Train Epoch: 1713 [960/1612 (59%)] Loss: 0.302659\n",
      "Train Epoch: 1713 [1120/1612 (69%)] Loss: 0.255154\n",
      "Train Epoch: 1713 [1280/1612 (79%)] Loss: 0.169056\n",
      "Train Epoch: 1713 [1440/1612 (89%)] Loss: 0.215068\n",
      "Train Epoch: 1713 [1200/1612 (99%)] Loss: 0.356450\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1714 [0/1612 (0%)] Loss: 0.197367\n",
      "Train Epoch: 1714 [160/1612 (10%)] Loss: 0.108035\n",
      "Train Epoch: 1714 [320/1612 (20%)] Loss: 0.290565\n",
      "Train Epoch: 1714 [480/1612 (30%)] Loss: 0.413021\n",
      "Train Epoch: 1714 [640/1612 (40%)] Loss: 0.224182\n",
      "Train Epoch: 1714 [800/1612 (50%)] Loss: 0.524205\n",
      "Train Epoch: 1714 [960/1612 (59%)] Loss: 0.379892\n",
      "Train Epoch: 1714 [1120/1612 (69%)] Loss: 0.315734\n",
      "Train Epoch: 1714 [1280/1612 (79%)] Loss: 0.175116\n",
      "Train Epoch: 1714 [1440/1612 (89%)] Loss: 0.473338\n",
      "Train Epoch: 1714 [1200/1612 (99%)] Loss: 0.197641\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1715 [0/1612 (0%)] Loss: 0.398593\n",
      "Train Epoch: 1715 [160/1612 (10%)] Loss: 0.238176\n",
      "Train Epoch: 1715 [320/1612 (20%)] Loss: 0.385436\n",
      "Train Epoch: 1715 [480/1612 (30%)] Loss: 0.237021\n",
      "Train Epoch: 1715 [640/1612 (40%)] Loss: 0.362710\n",
      "Train Epoch: 1715 [800/1612 (50%)] Loss: 0.384822\n",
      "Train Epoch: 1715 [960/1612 (59%)] Loss: 0.325075\n",
      "Train Epoch: 1715 [1120/1612 (69%)] Loss: 0.219100\n",
      "Train Epoch: 1715 [1280/1612 (79%)] Loss: 0.225754\n",
      "Train Epoch: 1715 [1440/1612 (89%)] Loss: 0.410514\n",
      "Train Epoch: 1715 [1200/1612 (99%)] Loss: 0.222483\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1716 [0/1612 (0%)] Loss: 0.153995\n",
      "Train Epoch: 1716 [160/1612 (10%)] Loss: 0.467848\n",
      "Train Epoch: 1716 [320/1612 (20%)] Loss: 0.424397\n",
      "Train Epoch: 1716 [480/1612 (30%)] Loss: 0.350513\n",
      "Train Epoch: 1716 [640/1612 (40%)] Loss: 0.194235\n",
      "Train Epoch: 1716 [800/1612 (50%)] Loss: 0.253867\n",
      "Train Epoch: 1716 [960/1612 (59%)] Loss: 0.663859\n",
      "Train Epoch: 1716 [1120/1612 (69%)] Loss: 0.164030\n",
      "Train Epoch: 1716 [1280/1612 (79%)] Loss: 0.271410\n",
      "Train Epoch: 1716 [1440/1612 (89%)] Loss: 0.122034\n",
      "Train Epoch: 1716 [1200/1612 (99%)] Loss: 0.125961\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1717 [0/1612 (0%)] Loss: 0.314189\n",
      "Train Epoch: 1717 [160/1612 (10%)] Loss: 0.364261\n",
      "Train Epoch: 1717 [320/1612 (20%)] Loss: 0.243231\n",
      "Train Epoch: 1717 [480/1612 (30%)] Loss: 0.410620\n",
      "Train Epoch: 1717 [640/1612 (40%)] Loss: 0.317176\n",
      "Train Epoch: 1717 [800/1612 (50%)] Loss: 0.273986\n",
      "Train Epoch: 1717 [960/1612 (59%)] Loss: 0.092676\n",
      "Train Epoch: 1717 [1120/1612 (69%)] Loss: 0.164413\n",
      "Train Epoch: 1717 [1280/1612 (79%)] Loss: 0.155676\n",
      "Train Epoch: 1717 [1440/1612 (89%)] Loss: 0.251815\n",
      "Train Epoch: 1717 [1200/1612 (99%)] Loss: 0.557037\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1718 [0/1612 (0%)] Loss: 0.594941\n",
      "Train Epoch: 1718 [160/1612 (10%)] Loss: 0.642390\n",
      "Train Epoch: 1718 [320/1612 (20%)] Loss: 0.391395\n",
      "Train Epoch: 1718 [480/1612 (30%)] Loss: 0.402432\n",
      "Train Epoch: 1718 [640/1612 (40%)] Loss: 0.416707\n",
      "Train Epoch: 1718 [800/1612 (50%)] Loss: 0.252530\n",
      "Train Epoch: 1718 [960/1612 (59%)] Loss: 0.235314\n",
      "Train Epoch: 1718 [1120/1612 (69%)] Loss: 0.339372\n",
      "Train Epoch: 1718 [1280/1612 (79%)] Loss: 0.151209\n",
      "Train Epoch: 1718 [1440/1612 (89%)] Loss: 0.340231\n",
      "Train Epoch: 1718 [1200/1612 (99%)] Loss: 0.135645\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1719 [0/1612 (0%)] Loss: 0.236958\n",
      "Train Epoch: 1719 [160/1612 (10%)] Loss: 0.175180\n",
      "Train Epoch: 1719 [320/1612 (20%)] Loss: 0.166808\n",
      "Train Epoch: 1719 [480/1612 (30%)] Loss: 0.251336\n",
      "Train Epoch: 1719 [640/1612 (40%)] Loss: 0.608430\n",
      "Train Epoch: 1719 [800/1612 (50%)] Loss: 0.251993\n",
      "Train Epoch: 1719 [960/1612 (59%)] Loss: 0.457905\n",
      "Train Epoch: 1719 [1120/1612 (69%)] Loss: 0.218860\n",
      "Train Epoch: 1719 [1280/1612 (79%)] Loss: 0.313235\n",
      "Train Epoch: 1719 [1440/1612 (89%)] Loss: 0.490224\n",
      "Train Epoch: 1719 [1200/1612 (99%)] Loss: 0.241305\n",
      "\n",
      "Test set: Average loss: 0.0283, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1720 [0/1612 (0%)] Loss: 0.170670\n",
      "Train Epoch: 1720 [160/1612 (10%)] Loss: 0.330223\n",
      "Train Epoch: 1720 [320/1612 (20%)] Loss: 0.311623\n",
      "Train Epoch: 1720 [480/1612 (30%)] Loss: 0.108083\n",
      "Train Epoch: 1720 [640/1612 (40%)] Loss: 0.174039\n",
      "Train Epoch: 1720 [800/1612 (50%)] Loss: 0.191053\n",
      "Train Epoch: 1720 [960/1612 (59%)] Loss: 0.168229\n",
      "Train Epoch: 1720 [1120/1612 (69%)] Loss: 0.352856\n",
      "Train Epoch: 1720 [1280/1612 (79%)] Loss: 0.286257\n",
      "Train Epoch: 1720 [1440/1612 (89%)] Loss: 0.512071\n",
      "Train Epoch: 1720 [1200/1612 (99%)] Loss: 0.393003\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1721 [0/1612 (0%)] Loss: 0.203585\n",
      "Train Epoch: 1721 [160/1612 (10%)] Loss: 0.351514\n",
      "Train Epoch: 1721 [320/1612 (20%)] Loss: 0.439468\n",
      "Train Epoch: 1721 [480/1612 (30%)] Loss: 0.219067\n",
      "Train Epoch: 1721 [640/1612 (40%)] Loss: 0.552941\n",
      "Train Epoch: 1721 [800/1612 (50%)] Loss: 0.388033\n",
      "Train Epoch: 1721 [960/1612 (59%)] Loss: 0.259416\n",
      "Train Epoch: 1721 [1120/1612 (69%)] Loss: 0.294722\n",
      "Train Epoch: 1721 [1280/1612 (79%)] Loss: 0.302843\n",
      "Train Epoch: 1721 [1440/1612 (89%)] Loss: 0.259209\n",
      "Train Epoch: 1721 [1200/1612 (99%)] Loss: 0.237712\n",
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1722 [0/1612 (0%)] Loss: 0.327869\n",
      "Train Epoch: 1722 [160/1612 (10%)] Loss: 0.251341\n",
      "Train Epoch: 1722 [320/1612 (20%)] Loss: 0.488363\n",
      "Train Epoch: 1722 [480/1612 (30%)] Loss: 0.175686\n",
      "Train Epoch: 1722 [640/1612 (40%)] Loss: 0.305331\n",
      "Train Epoch: 1722 [800/1612 (50%)] Loss: 0.201441\n",
      "Train Epoch: 1722 [960/1612 (59%)] Loss: 0.268502\n",
      "Train Epoch: 1722 [1120/1612 (69%)] Loss: 0.378043\n",
      "Train Epoch: 1722 [1280/1612 (79%)] Loss: 0.214031\n",
      "Train Epoch: 1722 [1440/1612 (89%)] Loss: 0.140102\n",
      "Train Epoch: 1722 [1200/1612 (99%)] Loss: 0.232476\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1723 [0/1612 (0%)] Loss: 0.126642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1723 [160/1612 (10%)] Loss: 0.245633\n",
      "Train Epoch: 1723 [320/1612 (20%)] Loss: 0.288133\n",
      "Train Epoch: 1723 [480/1612 (30%)] Loss: 0.059315\n",
      "Train Epoch: 1723 [640/1612 (40%)] Loss: 0.432914\n",
      "Train Epoch: 1723 [800/1612 (50%)] Loss: 0.303695\n",
      "Train Epoch: 1723 [960/1612 (59%)] Loss: 0.228102\n",
      "Train Epoch: 1723 [1120/1612 (69%)] Loss: 0.414650\n",
      "Train Epoch: 1723 [1280/1612 (79%)] Loss: 0.269341\n",
      "Train Epoch: 1723 [1440/1612 (89%)] Loss: 0.207472\n",
      "Train Epoch: 1723 [1200/1612 (99%)] Loss: 0.260657\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1724 [0/1612 (0%)] Loss: 0.321478\n",
      "Train Epoch: 1724 [160/1612 (10%)] Loss: 0.366094\n",
      "Train Epoch: 1724 [320/1612 (20%)] Loss: 0.377064\n",
      "Train Epoch: 1724 [480/1612 (30%)] Loss: 0.515576\n",
      "Train Epoch: 1724 [640/1612 (40%)] Loss: 0.067712\n",
      "Train Epoch: 1724 [800/1612 (50%)] Loss: 0.243824\n",
      "Train Epoch: 1724 [960/1612 (59%)] Loss: 0.449356\n",
      "Train Epoch: 1724 [1120/1612 (69%)] Loss: 0.247946\n",
      "Train Epoch: 1724 [1280/1612 (79%)] Loss: 0.267696\n",
      "Train Epoch: 1724 [1440/1612 (89%)] Loss: 0.259085\n",
      "Train Epoch: 1724 [1200/1612 (99%)] Loss: 0.413192\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1725 [0/1612 (0%)] Loss: 0.292999\n",
      "Train Epoch: 1725 [160/1612 (10%)] Loss: 0.269093\n",
      "Train Epoch: 1725 [320/1612 (20%)] Loss: 0.306872\n",
      "Train Epoch: 1725 [480/1612 (30%)] Loss: 0.631084\n",
      "Train Epoch: 1725 [640/1612 (40%)] Loss: 0.375639\n",
      "Train Epoch: 1725 [800/1612 (50%)] Loss: 0.254026\n",
      "Train Epoch: 1725 [960/1612 (59%)] Loss: 0.437210\n",
      "Train Epoch: 1725 [1120/1612 (69%)] Loss: 0.364655\n",
      "Train Epoch: 1725 [1280/1612 (79%)] Loss: 0.319895\n",
      "Train Epoch: 1725 [1440/1612 (89%)] Loss: 0.313224\n",
      "Train Epoch: 1725 [1200/1612 (99%)] Loss: 0.138699\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1726 [0/1612 (0%)] Loss: 0.300416\n",
      "Train Epoch: 1726 [160/1612 (10%)] Loss: 0.330047\n",
      "Train Epoch: 1726 [320/1612 (20%)] Loss: 0.301984\n",
      "Train Epoch: 1726 [480/1612 (30%)] Loss: 0.153927\n",
      "Train Epoch: 1726 [640/1612 (40%)] Loss: 0.317852\n",
      "Train Epoch: 1726 [800/1612 (50%)] Loss: 0.319482\n",
      "Train Epoch: 1726 [960/1612 (59%)] Loss: 0.104550\n",
      "Train Epoch: 1726 [1120/1612 (69%)] Loss: 0.340801\n",
      "Train Epoch: 1726 [1280/1612 (79%)] Loss: 0.334200\n",
      "Train Epoch: 1726 [1440/1612 (89%)] Loss: 0.281008\n",
      "Train Epoch: 1726 [1200/1612 (99%)] Loss: 0.195810\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1727 [0/1612 (0%)] Loss: 0.227764\n",
      "Train Epoch: 1727 [160/1612 (10%)] Loss: 0.113823\n",
      "Train Epoch: 1727 [320/1612 (20%)] Loss: 0.216857\n",
      "Train Epoch: 1727 [480/1612 (30%)] Loss: 0.239085\n",
      "Train Epoch: 1727 [640/1612 (40%)] Loss: 0.240752\n",
      "Train Epoch: 1727 [800/1612 (50%)] Loss: 0.199276\n",
      "Train Epoch: 1727 [960/1612 (59%)] Loss: 0.442609\n",
      "Train Epoch: 1727 [1120/1612 (69%)] Loss: 0.240580\n",
      "Train Epoch: 1727 [1280/1612 (79%)] Loss: 0.317564\n",
      "Train Epoch: 1727 [1440/1612 (89%)] Loss: 0.110226\n",
      "Train Epoch: 1727 [1200/1612 (99%)] Loss: 0.288974\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1728 [0/1612 (0%)] Loss: 0.236677\n",
      "Train Epoch: 1728 [160/1612 (10%)] Loss: 0.298088\n",
      "Train Epoch: 1728 [320/1612 (20%)] Loss: 0.258611\n",
      "Train Epoch: 1728 [480/1612 (30%)] Loss: 0.368879\n",
      "Train Epoch: 1728 [640/1612 (40%)] Loss: 0.287139\n",
      "Train Epoch: 1728 [800/1612 (50%)] Loss: 0.238363\n",
      "Train Epoch: 1728 [960/1612 (59%)] Loss: 0.431869\n",
      "Train Epoch: 1728 [1120/1612 (69%)] Loss: 0.170630\n",
      "Train Epoch: 1728 [1280/1612 (79%)] Loss: 0.356610\n",
      "Train Epoch: 1728 [1440/1612 (89%)] Loss: 0.055950\n",
      "Train Epoch: 1728 [1200/1612 (99%)] Loss: 0.455845\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1729 [0/1612 (0%)] Loss: 0.204743\n",
      "Train Epoch: 1729 [160/1612 (10%)] Loss: 0.343350\n",
      "Train Epoch: 1729 [320/1612 (20%)] Loss: 0.156694\n",
      "Train Epoch: 1729 [480/1612 (30%)] Loss: 0.253304\n",
      "Train Epoch: 1729 [640/1612 (40%)] Loss: 0.249039\n",
      "Train Epoch: 1729 [800/1612 (50%)] Loss: 0.212627\n",
      "Train Epoch: 1729 [960/1612 (59%)] Loss: 0.261466\n",
      "Train Epoch: 1729 [1120/1612 (69%)] Loss: 0.408066\n",
      "Train Epoch: 1729 [1280/1612 (79%)] Loss: 0.068561\n",
      "Train Epoch: 1729 [1440/1612 (89%)] Loss: 0.261401\n",
      "Train Epoch: 1729 [1200/1612 (99%)] Loss: 0.379293\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1730 [0/1612 (0%)] Loss: 0.285547\n",
      "Train Epoch: 1730 [160/1612 (10%)] Loss: 0.384322\n",
      "Train Epoch: 1730 [320/1612 (20%)] Loss: 0.206475\n",
      "Train Epoch: 1730 [480/1612 (30%)] Loss: 0.401284\n",
      "Train Epoch: 1730 [640/1612 (40%)] Loss: 0.451483\n",
      "Train Epoch: 1730 [800/1612 (50%)] Loss: 0.144405\n",
      "Train Epoch: 1730 [960/1612 (59%)] Loss: 0.690280\n",
      "Train Epoch: 1730 [1120/1612 (69%)] Loss: 0.460594\n",
      "Train Epoch: 1730 [1280/1612 (79%)] Loss: 0.222038\n",
      "Train Epoch: 1730 [1440/1612 (89%)] Loss: 0.215185\n",
      "Train Epoch: 1730 [1200/1612 (99%)] Loss: 0.579677\n",
      "\n",
      "Test set: Average loss: 0.0338, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1731 [0/1612 (0%)] Loss: 0.223301\n",
      "Train Epoch: 1731 [160/1612 (10%)] Loss: 0.185111\n",
      "Train Epoch: 1731 [320/1612 (20%)] Loss: 0.269290\n",
      "Train Epoch: 1731 [480/1612 (30%)] Loss: 0.197736\n",
      "Train Epoch: 1731 [640/1612 (40%)] Loss: 0.156870\n",
      "Train Epoch: 1731 [800/1612 (50%)] Loss: 0.334459\n",
      "Train Epoch: 1731 [960/1612 (59%)] Loss: 0.600564\n",
      "Train Epoch: 1731 [1120/1612 (69%)] Loss: 0.346715\n",
      "Train Epoch: 1731 [1280/1612 (79%)] Loss: 0.320092\n",
      "Train Epoch: 1731 [1440/1612 (89%)] Loss: 0.263270\n",
      "Train Epoch: 1731 [1200/1612 (99%)] Loss: 0.375921\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1732 [0/1612 (0%)] Loss: 0.352653\n",
      "Train Epoch: 1732 [160/1612 (10%)] Loss: 0.183611\n",
      "Train Epoch: 1732 [320/1612 (20%)] Loss: 0.430356\n",
      "Train Epoch: 1732 [480/1612 (30%)] Loss: 0.294256\n",
      "Train Epoch: 1732 [640/1612 (40%)] Loss: 0.246712\n",
      "Train Epoch: 1732 [800/1612 (50%)] Loss: 0.226803\n",
      "Train Epoch: 1732 [960/1612 (59%)] Loss: 0.299804\n",
      "Train Epoch: 1732 [1120/1612 (69%)] Loss: 0.268293\n",
      "Train Epoch: 1732 [1280/1612 (79%)] Loss: 0.469945\n",
      "Train Epoch: 1732 [1440/1612 (89%)] Loss: 0.448238\n",
      "Train Epoch: 1732 [1200/1612 (99%)] Loss: 0.186138\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1733 [0/1612 (0%)] Loss: 0.237029\n",
      "Train Epoch: 1733 [160/1612 (10%)] Loss: 0.432854\n",
      "Train Epoch: 1733 [320/1612 (20%)] Loss: 0.400662\n",
      "Train Epoch: 1733 [480/1612 (30%)] Loss: 0.172548\n",
      "Train Epoch: 1733 [640/1612 (40%)] Loss: 0.267034\n",
      "Train Epoch: 1733 [800/1612 (50%)] Loss: 0.405744\n",
      "Train Epoch: 1733 [960/1612 (59%)] Loss: 0.369932\n",
      "Train Epoch: 1733 [1120/1612 (69%)] Loss: 0.560390\n",
      "Train Epoch: 1733 [1280/1612 (79%)] Loss: 0.395268\n",
      "Train Epoch: 1733 [1440/1612 (89%)] Loss: 0.361698\n",
      "Train Epoch: 1733 [1200/1612 (99%)] Loss: 0.106699\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1734 [0/1612 (0%)] Loss: 0.186897\n",
      "Train Epoch: 1734 [160/1612 (10%)] Loss: 0.338607\n",
      "Train Epoch: 1734 [320/1612 (20%)] Loss: 0.298083\n",
      "Train Epoch: 1734 [480/1612 (30%)] Loss: 0.212452\n",
      "Train Epoch: 1734 [640/1612 (40%)] Loss: 0.208197\n",
      "Train Epoch: 1734 [800/1612 (50%)] Loss: 0.135638\n",
      "Train Epoch: 1734 [960/1612 (59%)] Loss: 0.489821\n",
      "Train Epoch: 1734 [1120/1612 (69%)] Loss: 0.298284\n",
      "Train Epoch: 1734 [1280/1612 (79%)] Loss: 0.302848\n",
      "Train Epoch: 1734 [1440/1612 (89%)] Loss: 0.097702\n",
      "Train Epoch: 1734 [1200/1612 (99%)] Loss: 0.330964\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1735 [0/1612 (0%)] Loss: 0.582334\n",
      "Train Epoch: 1735 [160/1612 (10%)] Loss: 0.076799\n",
      "Train Epoch: 1735 [320/1612 (20%)] Loss: 0.321028\n",
      "Train Epoch: 1735 [480/1612 (30%)] Loss: 0.275729\n",
      "Train Epoch: 1735 [640/1612 (40%)] Loss: 0.355214\n",
      "Train Epoch: 1735 [800/1612 (50%)] Loss: 0.264891\n",
      "Train Epoch: 1735 [960/1612 (59%)] Loss: 0.419570\n",
      "Train Epoch: 1735 [1120/1612 (69%)] Loss: 0.331978\n",
      "Train Epoch: 1735 [1280/1612 (79%)] Loss: 0.180441\n",
      "Train Epoch: 1735 [1440/1612 (89%)] Loss: 0.378917\n",
      "Train Epoch: 1735 [1200/1612 (99%)] Loss: 0.344786\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1736 [0/1612 (0%)] Loss: 0.428854\n",
      "Train Epoch: 1736 [160/1612 (10%)] Loss: 0.365986\n",
      "Train Epoch: 1736 [320/1612 (20%)] Loss: 0.168372\n",
      "Train Epoch: 1736 [480/1612 (30%)] Loss: 0.150236\n",
      "Train Epoch: 1736 [640/1612 (40%)] Loss: 0.233865\n",
      "Train Epoch: 1736 [800/1612 (50%)] Loss: 0.351800\n",
      "Train Epoch: 1736 [960/1612 (59%)] Loss: 0.306400\n",
      "Train Epoch: 1736 [1120/1612 (69%)] Loss: 0.155861\n",
      "Train Epoch: 1736 [1280/1612 (79%)] Loss: 0.433327\n",
      "Train Epoch: 1736 [1440/1612 (89%)] Loss: 0.285256\n",
      "Train Epoch: 1736 [1200/1612 (99%)] Loss: 0.160623\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1737 [0/1612 (0%)] Loss: 0.287777\n",
      "Train Epoch: 1737 [160/1612 (10%)] Loss: 0.292993\n",
      "Train Epoch: 1737 [320/1612 (20%)] Loss: 0.262980\n",
      "Train Epoch: 1737 [480/1612 (30%)] Loss: 0.160801\n",
      "Train Epoch: 1737 [640/1612 (40%)] Loss: 0.268157\n",
      "Train Epoch: 1737 [800/1612 (50%)] Loss: 0.478707\n",
      "Train Epoch: 1737 [960/1612 (59%)] Loss: 0.350016\n",
      "Train Epoch: 1737 [1120/1612 (69%)] Loss: 0.284168\n",
      "Train Epoch: 1737 [1280/1612 (79%)] Loss: 0.275818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1737 [1440/1612 (89%)] Loss: 0.160490\n",
      "Train Epoch: 1737 [1200/1612 (99%)] Loss: 0.240559\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1738 [0/1612 (0%)] Loss: 0.542200\n",
      "Train Epoch: 1738 [160/1612 (10%)] Loss: 0.205906\n",
      "Train Epoch: 1738 [320/1612 (20%)] Loss: 0.332108\n",
      "Train Epoch: 1738 [480/1612 (30%)] Loss: 0.224949\n",
      "Train Epoch: 1738 [640/1612 (40%)] Loss: 0.386523\n",
      "Train Epoch: 1738 [800/1612 (50%)] Loss: 0.279148\n",
      "Train Epoch: 1738 [960/1612 (59%)] Loss: 0.373277\n",
      "Train Epoch: 1738 [1120/1612 (69%)] Loss: 0.148847\n",
      "Train Epoch: 1738 [1280/1612 (79%)] Loss: 0.252051\n",
      "Train Epoch: 1738 [1440/1612 (89%)] Loss: 0.367290\n",
      "Train Epoch: 1738 [1200/1612 (99%)] Loss: 0.504330\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1739 [0/1612 (0%)] Loss: 0.426185\n",
      "Train Epoch: 1739 [160/1612 (10%)] Loss: 0.304936\n",
      "Train Epoch: 1739 [320/1612 (20%)] Loss: 0.347803\n",
      "Train Epoch: 1739 [480/1612 (30%)] Loss: 0.327138\n",
      "Train Epoch: 1739 [640/1612 (40%)] Loss: 0.358414\n",
      "Train Epoch: 1739 [800/1612 (50%)] Loss: 0.337881\n",
      "Train Epoch: 1739 [960/1612 (59%)] Loss: 0.375210\n",
      "Train Epoch: 1739 [1120/1612 (69%)] Loss: 0.239121\n",
      "Train Epoch: 1739 [1280/1612 (79%)] Loss: 0.289523\n",
      "Train Epoch: 1739 [1440/1612 (89%)] Loss: 0.258417\n",
      "Train Epoch: 1739 [1200/1612 (99%)] Loss: 0.219157\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1740 [0/1612 (0%)] Loss: 0.132165\n",
      "Train Epoch: 1740 [160/1612 (10%)] Loss: 0.195728\n",
      "Train Epoch: 1740 [320/1612 (20%)] Loss: 0.164308\n",
      "Train Epoch: 1740 [480/1612 (30%)] Loss: 0.408154\n",
      "Train Epoch: 1740 [640/1612 (40%)] Loss: 0.392599\n",
      "Train Epoch: 1740 [800/1612 (50%)] Loss: 0.332961\n",
      "Train Epoch: 1740 [960/1612 (59%)] Loss: 0.407305\n",
      "Train Epoch: 1740 [1120/1612 (69%)] Loss: 0.159682\n",
      "Train Epoch: 1740 [1280/1612 (79%)] Loss: 0.402251\n",
      "Train Epoch: 1740 [1440/1612 (89%)] Loss: 0.266077\n",
      "Train Epoch: 1740 [1200/1612 (99%)] Loss: 0.317299\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1741 [0/1612 (0%)] Loss: 0.532972\n",
      "Train Epoch: 1741 [160/1612 (10%)] Loss: 0.209339\n",
      "Train Epoch: 1741 [320/1612 (20%)] Loss: 0.351863\n",
      "Train Epoch: 1741 [480/1612 (30%)] Loss: 0.284132\n",
      "Train Epoch: 1741 [640/1612 (40%)] Loss: 0.179356\n",
      "Train Epoch: 1741 [800/1612 (50%)] Loss: 0.523823\n",
      "Train Epoch: 1741 [960/1612 (59%)] Loss: 0.396865\n",
      "Train Epoch: 1741 [1120/1612 (69%)] Loss: 0.292548\n",
      "Train Epoch: 1741 [1280/1612 (79%)] Loss: 0.461845\n",
      "Train Epoch: 1741 [1440/1612 (89%)] Loss: 0.332746\n",
      "Train Epoch: 1741 [1200/1612 (99%)] Loss: 0.507406\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1742 [0/1612 (0%)] Loss: 0.272844\n",
      "Train Epoch: 1742 [160/1612 (10%)] Loss: 0.219530\n",
      "Train Epoch: 1742 [320/1612 (20%)] Loss: 0.241374\n",
      "Train Epoch: 1742 [480/1612 (30%)] Loss: 0.376939\n",
      "Train Epoch: 1742 [640/1612 (40%)] Loss: 0.293557\n",
      "Train Epoch: 1742 [800/1612 (50%)] Loss: 0.396109\n",
      "Train Epoch: 1742 [960/1612 (59%)] Loss: 0.312120\n",
      "Train Epoch: 1742 [1120/1612 (69%)] Loss: 0.404571\n",
      "Train Epoch: 1742 [1280/1612 (79%)] Loss: 0.401060\n",
      "Train Epoch: 1742 [1440/1612 (89%)] Loss: 0.238582\n",
      "Train Epoch: 1742 [1200/1612 (99%)] Loss: 0.363672\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1743 [0/1612 (0%)] Loss: 0.225699\n",
      "Train Epoch: 1743 [160/1612 (10%)] Loss: 0.220953\n",
      "Train Epoch: 1743 [320/1612 (20%)] Loss: 0.143230\n",
      "Train Epoch: 1743 [480/1612 (30%)] Loss: 0.303441\n",
      "Train Epoch: 1743 [640/1612 (40%)] Loss: 0.263500\n",
      "Train Epoch: 1743 [800/1612 (50%)] Loss: 0.329082\n",
      "Train Epoch: 1743 [960/1612 (59%)] Loss: 0.260962\n",
      "Train Epoch: 1743 [1120/1612 (69%)] Loss: 0.312336\n",
      "Train Epoch: 1743 [1280/1612 (79%)] Loss: 0.106553\n",
      "Train Epoch: 1743 [1440/1612 (89%)] Loss: 0.321228\n",
      "Train Epoch: 1743 [1200/1612 (99%)] Loss: 0.465372\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1744 [0/1612 (0%)] Loss: 0.237482\n",
      "Train Epoch: 1744 [160/1612 (10%)] Loss: 0.353880\n",
      "Train Epoch: 1744 [320/1612 (20%)] Loss: 0.287210\n",
      "Train Epoch: 1744 [480/1612 (30%)] Loss: 0.386994\n",
      "Train Epoch: 1744 [640/1612 (40%)] Loss: 0.315904\n",
      "Train Epoch: 1744 [800/1612 (50%)] Loss: 0.538851\n",
      "Train Epoch: 1744 [960/1612 (59%)] Loss: 0.212080\n",
      "Train Epoch: 1744 [1120/1612 (69%)] Loss: 0.246697\n",
      "Train Epoch: 1744 [1280/1612 (79%)] Loss: 0.331593\n",
      "Train Epoch: 1744 [1440/1612 (89%)] Loss: 0.106135\n",
      "Train Epoch: 1744 [1200/1612 (99%)] Loss: 0.118186\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1745 [0/1612 (0%)] Loss: 0.212198\n",
      "Train Epoch: 1745 [160/1612 (10%)] Loss: 0.276332\n",
      "Train Epoch: 1745 [320/1612 (20%)] Loss: 0.439219\n",
      "Train Epoch: 1745 [480/1612 (30%)] Loss: 0.158774\n",
      "Train Epoch: 1745 [640/1612 (40%)] Loss: 0.390701\n",
      "Train Epoch: 1745 [800/1612 (50%)] Loss: 0.206562\n",
      "Train Epoch: 1745 [960/1612 (59%)] Loss: 0.460319\n",
      "Train Epoch: 1745 [1120/1612 (69%)] Loss: 0.159452\n",
      "Train Epoch: 1745 [1280/1612 (79%)] Loss: 0.191883\n",
      "Train Epoch: 1745 [1440/1612 (89%)] Loss: 0.179259\n",
      "Train Epoch: 1745 [1200/1612 (99%)] Loss: 0.272805\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1746 [0/1612 (0%)] Loss: 0.077713\n",
      "Train Epoch: 1746 [160/1612 (10%)] Loss: 0.338575\n",
      "Train Epoch: 1746 [320/1612 (20%)] Loss: 0.104706\n",
      "Train Epoch: 1746 [480/1612 (30%)] Loss: 0.461539\n",
      "Train Epoch: 1746 [640/1612 (40%)] Loss: 0.133878\n",
      "Train Epoch: 1746 [800/1612 (50%)] Loss: 0.137938\n",
      "Train Epoch: 1746 [960/1612 (59%)] Loss: 0.214188\n",
      "Train Epoch: 1746 [1120/1612 (69%)] Loss: 0.150263\n",
      "Train Epoch: 1746 [1280/1612 (79%)] Loss: 0.325487\n",
      "Train Epoch: 1746 [1440/1612 (89%)] Loss: 0.235547\n",
      "Train Epoch: 1746 [1200/1612 (99%)] Loss: 0.336480\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1747 [0/1612 (0%)] Loss: 0.304363\n",
      "Train Epoch: 1747 [160/1612 (10%)] Loss: 0.205261\n",
      "Train Epoch: 1747 [320/1612 (20%)] Loss: 0.200740\n",
      "Train Epoch: 1747 [480/1612 (30%)] Loss: 0.201930\n",
      "Train Epoch: 1747 [640/1612 (40%)] Loss: 0.456120\n",
      "Train Epoch: 1747 [800/1612 (50%)] Loss: 0.375230\n",
      "Train Epoch: 1747 [960/1612 (59%)] Loss: 0.228858\n",
      "Train Epoch: 1747 [1120/1612 (69%)] Loss: 0.405366\n",
      "Train Epoch: 1747 [1280/1612 (79%)] Loss: 0.438739\n",
      "Train Epoch: 1747 [1440/1612 (89%)] Loss: 0.281741\n",
      "Train Epoch: 1747 [1200/1612 (99%)] Loss: 0.165387\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1748 [0/1612 (0%)] Loss: 0.217799\n",
      "Train Epoch: 1748 [160/1612 (10%)] Loss: 0.235017\n",
      "Train Epoch: 1748 [320/1612 (20%)] Loss: 0.300638\n",
      "Train Epoch: 1748 [480/1612 (30%)] Loss: 0.330329\n",
      "Train Epoch: 1748 [640/1612 (40%)] Loss: 0.164572\n",
      "Train Epoch: 1748 [800/1612 (50%)] Loss: 0.353256\n",
      "Train Epoch: 1748 [960/1612 (59%)] Loss: 0.252283\n",
      "Train Epoch: 1748 [1120/1612 (69%)] Loss: 0.217328\n",
      "Train Epoch: 1748 [1280/1612 (79%)] Loss: 0.205335\n",
      "Train Epoch: 1748 [1440/1612 (89%)] Loss: 0.376855\n",
      "Train Epoch: 1748 [1200/1612 (99%)] Loss: 0.747880\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1749 [0/1612 (0%)] Loss: 0.343107\n",
      "Train Epoch: 1749 [160/1612 (10%)] Loss: 0.244135\n",
      "Train Epoch: 1749 [320/1612 (20%)] Loss: 0.213138\n",
      "Train Epoch: 1749 [480/1612 (30%)] Loss: 0.285763\n",
      "Train Epoch: 1749 [640/1612 (40%)] Loss: 0.286225\n",
      "Train Epoch: 1749 [800/1612 (50%)] Loss: 0.299661\n",
      "Train Epoch: 1749 [960/1612 (59%)] Loss: 0.411465\n",
      "Train Epoch: 1749 [1120/1612 (69%)] Loss: 0.219303\n",
      "Train Epoch: 1749 [1280/1612 (79%)] Loss: 0.359748\n",
      "Train Epoch: 1749 [1440/1612 (89%)] Loss: 0.316519\n",
      "Train Epoch: 1749 [1200/1612 (99%)] Loss: 0.179286\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1750 [0/1612 (0%)] Loss: 0.237898\n",
      "Train Epoch: 1750 [160/1612 (10%)] Loss: 0.141193\n",
      "Train Epoch: 1750 [320/1612 (20%)] Loss: 0.363490\n",
      "Train Epoch: 1750 [480/1612 (30%)] Loss: 0.277997\n",
      "Train Epoch: 1750 [640/1612 (40%)] Loss: 0.601521\n",
      "Train Epoch: 1750 [800/1612 (50%)] Loss: 0.339026\n",
      "Train Epoch: 1750 [960/1612 (59%)] Loss: 0.364481\n",
      "Train Epoch: 1750 [1120/1612 (69%)] Loss: 0.366075\n",
      "Train Epoch: 1750 [1280/1612 (79%)] Loss: 0.411013\n",
      "Train Epoch: 1750 [1440/1612 (89%)] Loss: 0.165479\n",
      "Train Epoch: 1750 [1200/1612 (99%)] Loss: 0.252146\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1751 [0/1612 (0%)] Loss: 0.210189\n",
      "Train Epoch: 1751 [160/1612 (10%)] Loss: 0.192149\n",
      "Train Epoch: 1751 [320/1612 (20%)] Loss: 0.189608\n",
      "Train Epoch: 1751 [480/1612 (30%)] Loss: 0.414186\n",
      "Train Epoch: 1751 [640/1612 (40%)] Loss: 0.354968\n",
      "Train Epoch: 1751 [800/1612 (50%)] Loss: 0.250455\n",
      "Train Epoch: 1751 [960/1612 (59%)] Loss: 0.443619\n",
      "Train Epoch: 1751 [1120/1612 (69%)] Loss: 0.369152\n",
      "Train Epoch: 1751 [1280/1612 (79%)] Loss: 0.292172\n",
      "Train Epoch: 1751 [1440/1612 (89%)] Loss: 0.434931\n",
      "Train Epoch: 1751 [1200/1612 (99%)] Loss: 0.213843\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1752 [0/1612 (0%)] Loss: 0.164165\n",
      "Train Epoch: 1752 [160/1612 (10%)] Loss: 0.335431\n",
      "Train Epoch: 1752 [320/1612 (20%)] Loss: 0.216754\n",
      "Train Epoch: 1752 [480/1612 (30%)] Loss: 0.206146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1752 [640/1612 (40%)] Loss: 0.447661\n",
      "Train Epoch: 1752 [800/1612 (50%)] Loss: 0.173146\n",
      "Train Epoch: 1752 [960/1612 (59%)] Loss: 0.355327\n",
      "Train Epoch: 1752 [1120/1612 (69%)] Loss: 0.333171\n",
      "Train Epoch: 1752 [1280/1612 (79%)] Loss: 0.363020\n",
      "Train Epoch: 1752 [1440/1612 (89%)] Loss: 0.390974\n",
      "Train Epoch: 1752 [1200/1612 (99%)] Loss: 0.289111\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1753 [0/1612 (0%)] Loss: 0.231118\n",
      "Train Epoch: 1753 [160/1612 (10%)] Loss: 0.355750\n",
      "Train Epoch: 1753 [320/1612 (20%)] Loss: 0.309095\n",
      "Train Epoch: 1753 [480/1612 (30%)] Loss: 0.376987\n",
      "Train Epoch: 1753 [640/1612 (40%)] Loss: 0.282955\n",
      "Train Epoch: 1753 [800/1612 (50%)] Loss: 0.166185\n",
      "Train Epoch: 1753 [960/1612 (59%)] Loss: 0.358557\n",
      "Train Epoch: 1753 [1120/1612 (69%)] Loss: 0.382486\n",
      "Train Epoch: 1753 [1280/1612 (79%)] Loss: 0.297289\n",
      "Train Epoch: 1753 [1440/1612 (89%)] Loss: 0.275701\n",
      "Train Epoch: 1753 [1200/1612 (99%)] Loss: 0.321177\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1754 [0/1612 (0%)] Loss: 0.428404\n",
      "Train Epoch: 1754 [160/1612 (10%)] Loss: 0.132590\n",
      "Train Epoch: 1754 [320/1612 (20%)] Loss: 0.267994\n",
      "Train Epoch: 1754 [480/1612 (30%)] Loss: 0.293719\n",
      "Train Epoch: 1754 [640/1612 (40%)] Loss: 0.208567\n",
      "Train Epoch: 1754 [800/1612 (50%)] Loss: 0.218487\n",
      "Train Epoch: 1754 [960/1612 (59%)] Loss: 0.271577\n",
      "Train Epoch: 1754 [1120/1612 (69%)] Loss: 0.317724\n",
      "Train Epoch: 1754 [1280/1612 (79%)] Loss: 0.330459\n",
      "Train Epoch: 1754 [1440/1612 (89%)] Loss: 0.435132\n",
      "Train Epoch: 1754 [1200/1612 (99%)] Loss: 0.244260\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1755 [0/1612 (0%)] Loss: 0.198953\n",
      "Train Epoch: 1755 [160/1612 (10%)] Loss: 0.198047\n",
      "Train Epoch: 1755 [320/1612 (20%)] Loss: 0.177321\n",
      "Train Epoch: 1755 [480/1612 (30%)] Loss: 0.216185\n",
      "Train Epoch: 1755 [640/1612 (40%)] Loss: 0.467817\n",
      "Train Epoch: 1755 [800/1612 (50%)] Loss: 0.322702\n",
      "Train Epoch: 1755 [960/1612 (59%)] Loss: 0.425616\n",
      "Train Epoch: 1755 [1120/1612 (69%)] Loss: 0.314227\n",
      "Train Epoch: 1755 [1280/1612 (79%)] Loss: 0.293890\n",
      "Train Epoch: 1755 [1440/1612 (89%)] Loss: 0.367536\n",
      "Train Epoch: 1755 [1200/1612 (99%)] Loss: 0.256484\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1756 [0/1612 (0%)] Loss: 0.336298\n",
      "Train Epoch: 1756 [160/1612 (10%)] Loss: 0.137806\n",
      "Train Epoch: 1756 [320/1612 (20%)] Loss: 0.429912\n",
      "Train Epoch: 1756 [480/1612 (30%)] Loss: 0.369994\n",
      "Train Epoch: 1756 [640/1612 (40%)] Loss: 0.168427\n",
      "Train Epoch: 1756 [800/1612 (50%)] Loss: 0.153396\n",
      "Train Epoch: 1756 [960/1612 (59%)] Loss: 0.382164\n",
      "Train Epoch: 1756 [1120/1612 (69%)] Loss: 0.416685\n",
      "Train Epoch: 1756 [1280/1612 (79%)] Loss: 0.226032\n",
      "Train Epoch: 1756 [1440/1612 (89%)] Loss: 0.185636\n",
      "Train Epoch: 1756 [1200/1612 (99%)] Loss: 0.381999\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1757 [0/1612 (0%)] Loss: 0.201880\n",
      "Train Epoch: 1757 [160/1612 (10%)] Loss: 0.273414\n",
      "Train Epoch: 1757 [320/1612 (20%)] Loss: 0.411707\n",
      "Train Epoch: 1757 [480/1612 (30%)] Loss: 0.252111\n",
      "Train Epoch: 1757 [640/1612 (40%)] Loss: 0.374736\n",
      "Train Epoch: 1757 [800/1612 (50%)] Loss: 0.317675\n",
      "Train Epoch: 1757 [960/1612 (59%)] Loss: 0.091821\n",
      "Train Epoch: 1757 [1120/1612 (69%)] Loss: 0.347313\n",
      "Train Epoch: 1757 [1280/1612 (79%)] Loss: 0.214782\n",
      "Train Epoch: 1757 [1440/1612 (89%)] Loss: 0.177629\n",
      "Train Epoch: 1757 [1200/1612 (99%)] Loss: 0.174614\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1758 [0/1612 (0%)] Loss: 0.505707\n",
      "Train Epoch: 1758 [160/1612 (10%)] Loss: 0.587247\n",
      "Train Epoch: 1758 [320/1612 (20%)] Loss: 0.270540\n",
      "Train Epoch: 1758 [480/1612 (30%)] Loss: 0.238431\n",
      "Train Epoch: 1758 [640/1612 (40%)] Loss: 0.205285\n",
      "Train Epoch: 1758 [800/1612 (50%)] Loss: 0.211778\n",
      "Train Epoch: 1758 [960/1612 (59%)] Loss: 0.452247\n",
      "Train Epoch: 1758 [1120/1612 (69%)] Loss: 0.216062\n",
      "Train Epoch: 1758 [1280/1612 (79%)] Loss: 0.135496\n",
      "Train Epoch: 1758 [1440/1612 (89%)] Loss: 0.417476\n",
      "Train Epoch: 1758 [1200/1612 (99%)] Loss: 0.259648\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1759 [0/1612 (0%)] Loss: 0.240552\n",
      "Train Epoch: 1759 [160/1612 (10%)] Loss: 0.335334\n",
      "Train Epoch: 1759 [320/1612 (20%)] Loss: 0.427264\n",
      "Train Epoch: 1759 [480/1612 (30%)] Loss: 0.271735\n",
      "Train Epoch: 1759 [640/1612 (40%)] Loss: 0.177339\n",
      "Train Epoch: 1759 [800/1612 (50%)] Loss: 0.364211\n",
      "Train Epoch: 1759 [960/1612 (59%)] Loss: 0.083267\n",
      "Train Epoch: 1759 [1120/1612 (69%)] Loss: 0.283861\n",
      "Train Epoch: 1759 [1280/1612 (79%)] Loss: 0.327003\n",
      "Train Epoch: 1759 [1440/1612 (89%)] Loss: 0.424777\n",
      "Train Epoch: 1759 [1200/1612 (99%)] Loss: 0.385987\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1760 [0/1612 (0%)] Loss: 0.213274\n",
      "Train Epoch: 1760 [160/1612 (10%)] Loss: 0.360525\n",
      "Train Epoch: 1760 [320/1612 (20%)] Loss: 0.238451\n",
      "Train Epoch: 1760 [480/1612 (30%)] Loss: 0.164683\n",
      "Train Epoch: 1760 [640/1612 (40%)] Loss: 0.329011\n",
      "Train Epoch: 1760 [800/1612 (50%)] Loss: 0.504223\n",
      "Train Epoch: 1760 [960/1612 (59%)] Loss: 0.205374\n",
      "Train Epoch: 1760 [1120/1612 (69%)] Loss: 0.285855\n",
      "Train Epoch: 1760 [1280/1612 (79%)] Loss: 0.281694\n",
      "Train Epoch: 1760 [1440/1612 (89%)] Loss: 0.275174\n",
      "Train Epoch: 1760 [1200/1612 (99%)] Loss: 0.315633\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1761 [0/1612 (0%)] Loss: 0.330210\n",
      "Train Epoch: 1761 [160/1612 (10%)] Loss: 0.173649\n",
      "Train Epoch: 1761 [320/1612 (20%)] Loss: 0.442156\n",
      "Train Epoch: 1761 [480/1612 (30%)] Loss: 0.209579\n",
      "Train Epoch: 1761 [640/1612 (40%)] Loss: 0.545623\n",
      "Train Epoch: 1761 [800/1612 (50%)] Loss: 0.235337\n",
      "Train Epoch: 1761 [960/1612 (59%)] Loss: 0.177722\n",
      "Train Epoch: 1761 [1120/1612 (69%)] Loss: 0.466849\n",
      "Train Epoch: 1761 [1280/1612 (79%)] Loss: 0.367231\n",
      "Train Epoch: 1761 [1440/1612 (89%)] Loss: 0.353451\n",
      "Train Epoch: 1761 [1200/1612 (99%)] Loss: 0.216116\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1762 [0/1612 (0%)] Loss: 0.227508\n",
      "Train Epoch: 1762 [160/1612 (10%)] Loss: 0.266538\n",
      "Train Epoch: 1762 [320/1612 (20%)] Loss: 0.236797\n",
      "Train Epoch: 1762 [480/1612 (30%)] Loss: 0.299056\n",
      "Train Epoch: 1762 [640/1612 (40%)] Loss: 0.299045\n",
      "Train Epoch: 1762 [800/1612 (50%)] Loss: 0.182218\n",
      "Train Epoch: 1762 [960/1612 (59%)] Loss: 0.121109\n",
      "Train Epoch: 1762 [1120/1612 (69%)] Loss: 0.428382\n",
      "Train Epoch: 1762 [1280/1612 (79%)] Loss: 0.302588\n",
      "Train Epoch: 1762 [1440/1612 (89%)] Loss: 0.486382\n",
      "Train Epoch: 1762 [1200/1612 (99%)] Loss: 0.297013\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1763 [0/1612 (0%)] Loss: 0.221875\n",
      "Train Epoch: 1763 [160/1612 (10%)] Loss: 0.177038\n",
      "Train Epoch: 1763 [320/1612 (20%)] Loss: 0.246207\n",
      "Train Epoch: 1763 [480/1612 (30%)] Loss: 0.414026\n",
      "Train Epoch: 1763 [640/1612 (40%)] Loss: 0.167215\n",
      "Train Epoch: 1763 [800/1612 (50%)] Loss: 0.168457\n",
      "Train Epoch: 1763 [960/1612 (59%)] Loss: 0.173374\n",
      "Train Epoch: 1763 [1120/1612 (69%)] Loss: 0.266405\n",
      "Train Epoch: 1763 [1280/1612 (79%)] Loss: 0.187458\n",
      "Train Epoch: 1763 [1440/1612 (89%)] Loss: 0.227890\n",
      "Train Epoch: 1763 [1200/1612 (99%)] Loss: 0.360803\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1764 [0/1612 (0%)] Loss: 0.238706\n",
      "Train Epoch: 1764 [160/1612 (10%)] Loss: 0.295658\n",
      "Train Epoch: 1764 [320/1612 (20%)] Loss: 0.281573\n",
      "Train Epoch: 1764 [480/1612 (30%)] Loss: 0.150194\n",
      "Train Epoch: 1764 [640/1612 (40%)] Loss: 0.211367\n",
      "Train Epoch: 1764 [800/1612 (50%)] Loss: 0.477145\n",
      "Train Epoch: 1764 [960/1612 (59%)] Loss: 0.323208\n",
      "Train Epoch: 1764 [1120/1612 (69%)] Loss: 0.267991\n",
      "Train Epoch: 1764 [1280/1612 (79%)] Loss: 0.249415\n",
      "Train Epoch: 1764 [1440/1612 (89%)] Loss: 0.438751\n",
      "Train Epoch: 1764 [1200/1612 (99%)] Loss: 0.291559\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1765 [0/1612 (0%)] Loss: 0.163663\n",
      "Train Epoch: 1765 [160/1612 (10%)] Loss: 0.086525\n",
      "Train Epoch: 1765 [320/1612 (20%)] Loss: 0.361053\n",
      "Train Epoch: 1765 [480/1612 (30%)] Loss: 0.558272\n",
      "Train Epoch: 1765 [640/1612 (40%)] Loss: 0.255637\n",
      "Train Epoch: 1765 [800/1612 (50%)] Loss: 0.397451\n",
      "Train Epoch: 1765 [960/1612 (59%)] Loss: 0.326442\n",
      "Train Epoch: 1765 [1120/1612 (69%)] Loss: 0.121305\n",
      "Train Epoch: 1765 [1280/1612 (79%)] Loss: 0.227768\n",
      "Train Epoch: 1765 [1440/1612 (89%)] Loss: 0.165690\n",
      "Train Epoch: 1765 [1200/1612 (99%)] Loss: 0.362013\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1766 [0/1612 (0%)] Loss: 0.246436\n",
      "Train Epoch: 1766 [160/1612 (10%)] Loss: 0.383530\n",
      "Train Epoch: 1766 [320/1612 (20%)] Loss: 0.114684\n",
      "Train Epoch: 1766 [480/1612 (30%)] Loss: 0.192311\n",
      "Train Epoch: 1766 [640/1612 (40%)] Loss: 0.110986\n",
      "Train Epoch: 1766 [800/1612 (50%)] Loss: 0.333194\n",
      "Train Epoch: 1766 [960/1612 (59%)] Loss: 0.557425\n",
      "Train Epoch: 1766 [1120/1612 (69%)] Loss: 0.511036\n",
      "Train Epoch: 1766 [1280/1612 (79%)] Loss: 0.400955\n",
      "Train Epoch: 1766 [1440/1612 (89%)] Loss: 0.478066\n",
      "Train Epoch: 1766 [1200/1612 (99%)] Loss: 0.164686\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1767 [0/1612 (0%)] Loss: 0.275224\n",
      "Train Epoch: 1767 [160/1612 (10%)] Loss: 0.312502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1767 [320/1612 (20%)] Loss: 0.467310\n",
      "Train Epoch: 1767 [480/1612 (30%)] Loss: 0.360488\n",
      "Train Epoch: 1767 [640/1612 (40%)] Loss: 0.550044\n",
      "Train Epoch: 1767 [800/1612 (50%)] Loss: 0.342342\n",
      "Train Epoch: 1767 [960/1612 (59%)] Loss: 0.398217\n",
      "Train Epoch: 1767 [1120/1612 (69%)] Loss: 0.422228\n",
      "Train Epoch: 1767 [1280/1612 (79%)] Loss: 0.255600\n",
      "Train Epoch: 1767 [1440/1612 (89%)] Loss: 0.208702\n",
      "Train Epoch: 1767 [1200/1612 (99%)] Loss: 0.194953\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1768 [0/1612 (0%)] Loss: 0.216184\n",
      "Train Epoch: 1768 [160/1612 (10%)] Loss: 0.319739\n",
      "Train Epoch: 1768 [320/1612 (20%)] Loss: 0.283916\n",
      "Train Epoch: 1768 [480/1612 (30%)] Loss: 0.243174\n",
      "Train Epoch: 1768 [640/1612 (40%)] Loss: 0.267238\n",
      "Train Epoch: 1768 [800/1612 (50%)] Loss: 0.174714\n",
      "Train Epoch: 1768 [960/1612 (59%)] Loss: 0.333443\n",
      "Train Epoch: 1768 [1120/1612 (69%)] Loss: 0.226905\n",
      "Train Epoch: 1768 [1280/1612 (79%)] Loss: 0.192244\n",
      "Train Epoch: 1768 [1440/1612 (89%)] Loss: 0.215523\n",
      "Train Epoch: 1768 [1200/1612 (99%)] Loss: 0.220580\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1769 [0/1612 (0%)] Loss: 0.194992\n",
      "Train Epoch: 1769 [160/1612 (10%)] Loss: 0.514814\n",
      "Train Epoch: 1769 [320/1612 (20%)] Loss: 0.104205\n",
      "Train Epoch: 1769 [480/1612 (30%)] Loss: 0.266609\n",
      "Train Epoch: 1769 [640/1612 (40%)] Loss: 0.428077\n",
      "Train Epoch: 1769 [800/1612 (50%)] Loss: 0.233179\n",
      "Train Epoch: 1769 [960/1612 (59%)] Loss: 0.375244\n",
      "Train Epoch: 1769 [1120/1612 (69%)] Loss: 0.077597\n",
      "Train Epoch: 1769 [1280/1612 (79%)] Loss: 0.473305\n",
      "Train Epoch: 1769 [1440/1612 (89%)] Loss: 0.325673\n",
      "Train Epoch: 1769 [1200/1612 (99%)] Loss: 0.112114\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1770 [0/1612 (0%)] Loss: 0.189375\n",
      "Train Epoch: 1770 [160/1612 (10%)] Loss: 0.236251\n",
      "Train Epoch: 1770 [320/1612 (20%)] Loss: 0.190469\n",
      "Train Epoch: 1770 [480/1612 (30%)] Loss: 0.303032\n",
      "Train Epoch: 1770 [640/1612 (40%)] Loss: 0.381906\n",
      "Train Epoch: 1770 [800/1612 (50%)] Loss: 0.323040\n",
      "Train Epoch: 1770 [960/1612 (59%)] Loss: 0.220703\n",
      "Train Epoch: 1770 [1120/1612 (69%)] Loss: 0.306213\n",
      "Train Epoch: 1770 [1280/1612 (79%)] Loss: 0.337176\n",
      "Train Epoch: 1770 [1440/1612 (89%)] Loss: 0.230834\n",
      "Train Epoch: 1770 [1200/1612 (99%)] Loss: 0.344209\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1771 [0/1612 (0%)] Loss: 0.475321\n",
      "Train Epoch: 1771 [160/1612 (10%)] Loss: 0.236193\n",
      "Train Epoch: 1771 [320/1612 (20%)] Loss: 0.268471\n",
      "Train Epoch: 1771 [480/1612 (30%)] Loss: 0.415130\n",
      "Train Epoch: 1771 [640/1612 (40%)] Loss: 0.222737\n",
      "Train Epoch: 1771 [800/1612 (50%)] Loss: 0.251344\n",
      "Train Epoch: 1771 [960/1612 (59%)] Loss: 0.199102\n",
      "Train Epoch: 1771 [1120/1612 (69%)] Loss: 0.151855\n",
      "Train Epoch: 1771 [1280/1612 (79%)] Loss: 0.346808\n",
      "Train Epoch: 1771 [1440/1612 (89%)] Loss: 0.274698\n",
      "Train Epoch: 1771 [1200/1612 (99%)] Loss: 0.653724\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1772 [0/1612 (0%)] Loss: 0.334888\n",
      "Train Epoch: 1772 [160/1612 (10%)] Loss: 0.327361\n",
      "Train Epoch: 1772 [320/1612 (20%)] Loss: 0.302279\n",
      "Train Epoch: 1772 [480/1612 (30%)] Loss: 0.354163\n",
      "Train Epoch: 1772 [640/1612 (40%)] Loss: 0.154817\n",
      "Train Epoch: 1772 [800/1612 (50%)] Loss: 0.379032\n",
      "Train Epoch: 1772 [960/1612 (59%)] Loss: 0.157170\n",
      "Train Epoch: 1772 [1120/1612 (69%)] Loss: 0.275015\n",
      "Train Epoch: 1772 [1280/1612 (79%)] Loss: 0.480047\n",
      "Train Epoch: 1772 [1440/1612 (89%)] Loss: 0.277018\n",
      "Train Epoch: 1772 [1200/1612 (99%)] Loss: 0.102072\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1773 [0/1612 (0%)] Loss: 0.116146\n",
      "Train Epoch: 1773 [160/1612 (10%)] Loss: 0.366849\n",
      "Train Epoch: 1773 [320/1612 (20%)] Loss: 0.474683\n",
      "Train Epoch: 1773 [480/1612 (30%)] Loss: 0.414329\n",
      "Train Epoch: 1773 [640/1612 (40%)] Loss: 0.360717\n",
      "Train Epoch: 1773 [800/1612 (50%)] Loss: 0.167381\n",
      "Train Epoch: 1773 [960/1612 (59%)] Loss: 0.081833\n",
      "Train Epoch: 1773 [1120/1612 (69%)] Loss: 0.479379\n",
      "Train Epoch: 1773 [1280/1612 (79%)] Loss: 0.164317\n",
      "Train Epoch: 1773 [1440/1612 (89%)] Loss: 0.423949\n",
      "Train Epoch: 1773 [1200/1612 (99%)] Loss: 0.130388\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1774 [0/1612 (0%)] Loss: 0.365753\n",
      "Train Epoch: 1774 [160/1612 (10%)] Loss: 0.181668\n",
      "Train Epoch: 1774 [320/1612 (20%)] Loss: 0.394502\n",
      "Train Epoch: 1774 [480/1612 (30%)] Loss: 0.300597\n",
      "Train Epoch: 1774 [640/1612 (40%)] Loss: 0.285120\n",
      "Train Epoch: 1774 [800/1612 (50%)] Loss: 0.372495\n",
      "Train Epoch: 1774 [960/1612 (59%)] Loss: 0.348030\n",
      "Train Epoch: 1774 [1120/1612 (69%)] Loss: 0.294964\n",
      "Train Epoch: 1774 [1280/1612 (79%)] Loss: 0.256254\n",
      "Train Epoch: 1774 [1440/1612 (89%)] Loss: 0.302650\n",
      "Train Epoch: 1774 [1200/1612 (99%)] Loss: 0.197975\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1775 [0/1612 (0%)] Loss: 0.265981\n",
      "Train Epoch: 1775 [160/1612 (10%)] Loss: 0.251062\n",
      "Train Epoch: 1775 [320/1612 (20%)] Loss: 0.309327\n",
      "Train Epoch: 1775 [480/1612 (30%)] Loss: 0.236920\n",
      "Train Epoch: 1775 [640/1612 (40%)] Loss: 0.465470\n",
      "Train Epoch: 1775 [800/1612 (50%)] Loss: 0.107013\n",
      "Train Epoch: 1775 [960/1612 (59%)] Loss: 0.174383\n",
      "Train Epoch: 1775 [1120/1612 (69%)] Loss: 0.248727\n",
      "Train Epoch: 1775 [1280/1612 (79%)] Loss: 0.567847\n",
      "Train Epoch: 1775 [1440/1612 (89%)] Loss: 0.260647\n",
      "Train Epoch: 1775 [1200/1612 (99%)] Loss: 0.158750\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1776 [0/1612 (0%)] Loss: 0.107521\n",
      "Train Epoch: 1776 [160/1612 (10%)] Loss: 0.626119\n",
      "Train Epoch: 1776 [320/1612 (20%)] Loss: 0.366262\n",
      "Train Epoch: 1776 [480/1612 (30%)] Loss: 0.351238\n",
      "Train Epoch: 1776 [640/1612 (40%)] Loss: 0.303051\n",
      "Train Epoch: 1776 [800/1612 (50%)] Loss: 0.511775\n",
      "Train Epoch: 1776 [960/1612 (59%)] Loss: 0.299134\n",
      "Train Epoch: 1776 [1120/1612 (69%)] Loss: 0.420148\n",
      "Train Epoch: 1776 [1280/1612 (79%)] Loss: 0.275795\n",
      "Train Epoch: 1776 [1440/1612 (89%)] Loss: 0.277099\n",
      "Train Epoch: 1776 [1200/1612 (99%)] Loss: 0.422527\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1777 [0/1612 (0%)] Loss: 0.216505\n",
      "Train Epoch: 1777 [160/1612 (10%)] Loss: 0.192804\n",
      "Train Epoch: 1777 [320/1612 (20%)] Loss: 0.493951\n",
      "Train Epoch: 1777 [480/1612 (30%)] Loss: 0.250920\n",
      "Train Epoch: 1777 [640/1612 (40%)] Loss: 0.203301\n",
      "Train Epoch: 1777 [800/1612 (50%)] Loss: 0.275597\n",
      "Train Epoch: 1777 [960/1612 (59%)] Loss: 0.397805\n",
      "Train Epoch: 1777 [1120/1612 (69%)] Loss: 0.120133\n",
      "Train Epoch: 1777 [1280/1612 (79%)] Loss: 0.314469\n",
      "Train Epoch: 1777 [1440/1612 (89%)] Loss: 0.424243\n",
      "Train Epoch: 1777 [1200/1612 (99%)] Loss: 0.435319\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1778 [0/1612 (0%)] Loss: 0.379431\n",
      "Train Epoch: 1778 [160/1612 (10%)] Loss: 0.441588\n",
      "Train Epoch: 1778 [320/1612 (20%)] Loss: 0.327457\n",
      "Train Epoch: 1778 [480/1612 (30%)] Loss: 0.188299\n",
      "Train Epoch: 1778 [640/1612 (40%)] Loss: 0.237937\n",
      "Train Epoch: 1778 [800/1612 (50%)] Loss: 0.039075\n",
      "Train Epoch: 1778 [960/1612 (59%)] Loss: 0.255021\n",
      "Train Epoch: 1778 [1120/1612 (69%)] Loss: 0.297737\n",
      "Train Epoch: 1778 [1280/1612 (79%)] Loss: 0.326086\n",
      "Train Epoch: 1778 [1440/1612 (89%)] Loss: 0.267456\n",
      "Train Epoch: 1778 [1200/1612 (99%)] Loss: 0.127620\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1779 [0/1612 (0%)] Loss: 0.273400\n",
      "Train Epoch: 1779 [160/1612 (10%)] Loss: 0.403233\n",
      "Train Epoch: 1779 [320/1612 (20%)] Loss: 0.292662\n",
      "Train Epoch: 1779 [480/1612 (30%)] Loss: 0.381501\n",
      "Train Epoch: 1779 [640/1612 (40%)] Loss: 0.295503\n",
      "Train Epoch: 1779 [800/1612 (50%)] Loss: 0.100665\n",
      "Train Epoch: 1779 [960/1612 (59%)] Loss: 0.304670\n",
      "Train Epoch: 1779 [1120/1612 (69%)] Loss: 0.149379\n",
      "Train Epoch: 1779 [1280/1612 (79%)] Loss: 0.470071\n",
      "Train Epoch: 1779 [1440/1612 (89%)] Loss: 0.438187\n",
      "Train Epoch: 1779 [1200/1612 (99%)] Loss: 0.152511\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1780 [0/1612 (0%)] Loss: 0.171272\n",
      "Train Epoch: 1780 [160/1612 (10%)] Loss: 0.133108\n",
      "Train Epoch: 1780 [320/1612 (20%)] Loss: 0.120226\n",
      "Train Epoch: 1780 [480/1612 (30%)] Loss: 0.249103\n",
      "Train Epoch: 1780 [640/1612 (40%)] Loss: 0.218364\n",
      "Train Epoch: 1780 [800/1612 (50%)] Loss: 0.200304\n",
      "Train Epoch: 1780 [960/1612 (59%)] Loss: 0.309891\n",
      "Train Epoch: 1780 [1120/1612 (69%)] Loss: 0.314298\n",
      "Train Epoch: 1780 [1280/1612 (79%)] Loss: 0.494796\n",
      "Train Epoch: 1780 [1440/1612 (89%)] Loss: 0.112824\n",
      "Train Epoch: 1780 [1200/1612 (99%)] Loss: 0.181029\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1781 [0/1612 (0%)] Loss: 0.317316\n",
      "Train Epoch: 1781 [160/1612 (10%)] Loss: 0.484380\n",
      "Train Epoch: 1781 [320/1612 (20%)] Loss: 0.221581\n",
      "Train Epoch: 1781 [480/1612 (30%)] Loss: 0.092220\n",
      "Train Epoch: 1781 [640/1612 (40%)] Loss: 0.130277\n",
      "Train Epoch: 1781 [800/1612 (50%)] Loss: 0.343118\n",
      "Train Epoch: 1781 [960/1612 (59%)] Loss: 0.300010\n",
      "Train Epoch: 1781 [1120/1612 (69%)] Loss: 0.214062\n",
      "Train Epoch: 1781 [1280/1612 (79%)] Loss: 0.419277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1781 [1440/1612 (89%)] Loss: 0.272004\n",
      "Train Epoch: 1781 [1200/1612 (99%)] Loss: 0.106344\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1782 [0/1612 (0%)] Loss: 0.218157\n",
      "Train Epoch: 1782 [160/1612 (10%)] Loss: 0.183451\n",
      "Train Epoch: 1782 [320/1612 (20%)] Loss: 0.201123\n",
      "Train Epoch: 1782 [480/1612 (30%)] Loss: 0.320734\n",
      "Train Epoch: 1782 [640/1612 (40%)] Loss: 0.544181\n",
      "Train Epoch: 1782 [800/1612 (50%)] Loss: 0.255228\n",
      "Train Epoch: 1782 [960/1612 (59%)] Loss: 0.304063\n",
      "Train Epoch: 1782 [1120/1612 (69%)] Loss: 0.382753\n",
      "Train Epoch: 1782 [1280/1612 (79%)] Loss: 0.321224\n",
      "Train Epoch: 1782 [1440/1612 (89%)] Loss: 0.411606\n",
      "Train Epoch: 1782 [1200/1612 (99%)] Loss: 0.350425\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1783 [0/1612 (0%)] Loss: 0.442094\n",
      "Train Epoch: 1783 [160/1612 (10%)] Loss: 0.282801\n",
      "Train Epoch: 1783 [320/1612 (20%)] Loss: 0.481004\n",
      "Train Epoch: 1783 [480/1612 (30%)] Loss: 0.229748\n",
      "Train Epoch: 1783 [640/1612 (40%)] Loss: 0.217021\n",
      "Train Epoch: 1783 [800/1612 (50%)] Loss: 0.241187\n",
      "Train Epoch: 1783 [960/1612 (59%)] Loss: 0.243269\n",
      "Train Epoch: 1783 [1120/1612 (69%)] Loss: 0.411697\n",
      "Train Epoch: 1783 [1280/1612 (79%)] Loss: 0.259145\n",
      "Train Epoch: 1783 [1440/1612 (89%)] Loss: 0.221175\n",
      "Train Epoch: 1783 [1200/1612 (99%)] Loss: 0.290920\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1784 [0/1612 (0%)] Loss: 0.536364\n",
      "Train Epoch: 1784 [160/1612 (10%)] Loss: 0.168310\n",
      "Train Epoch: 1784 [320/1612 (20%)] Loss: 0.130200\n",
      "Train Epoch: 1784 [480/1612 (30%)] Loss: 0.318778\n",
      "Train Epoch: 1784 [640/1612 (40%)] Loss: 0.490480\n",
      "Train Epoch: 1784 [800/1612 (50%)] Loss: 0.371768\n",
      "Train Epoch: 1784 [960/1612 (59%)] Loss: 0.294394\n",
      "Train Epoch: 1784 [1120/1612 (69%)] Loss: 0.280851\n",
      "Train Epoch: 1784 [1280/1612 (79%)] Loss: 0.250221\n",
      "Train Epoch: 1784 [1440/1612 (89%)] Loss: 0.487023\n",
      "Train Epoch: 1784 [1200/1612 (99%)] Loss: 0.360881\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1785 [0/1612 (0%)] Loss: 0.302202\n",
      "Train Epoch: 1785 [160/1612 (10%)] Loss: 0.278025\n",
      "Train Epoch: 1785 [320/1612 (20%)] Loss: 0.256073\n",
      "Train Epoch: 1785 [480/1612 (30%)] Loss: 0.157117\n",
      "Train Epoch: 1785 [640/1612 (40%)] Loss: 0.413932\n",
      "Train Epoch: 1785 [800/1612 (50%)] Loss: 0.219899\n",
      "Train Epoch: 1785 [960/1612 (59%)] Loss: 0.370468\n",
      "Train Epoch: 1785 [1120/1612 (69%)] Loss: 0.331613\n",
      "Train Epoch: 1785 [1280/1612 (79%)] Loss: 0.254538\n",
      "Train Epoch: 1785 [1440/1612 (89%)] Loss: 0.506269\n",
      "Train Epoch: 1785 [1200/1612 (99%)] Loss: 0.468828\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1786 [0/1612 (0%)] Loss: 0.250179\n",
      "Train Epoch: 1786 [160/1612 (10%)] Loss: 0.164953\n",
      "Train Epoch: 1786 [320/1612 (20%)] Loss: 0.269020\n",
      "Train Epoch: 1786 [480/1612 (30%)] Loss: 0.199371\n",
      "Train Epoch: 1786 [640/1612 (40%)] Loss: 0.250052\n",
      "Train Epoch: 1786 [800/1612 (50%)] Loss: 0.565002\n",
      "Train Epoch: 1786 [960/1612 (59%)] Loss: 0.231734\n",
      "Train Epoch: 1786 [1120/1612 (69%)] Loss: 0.276679\n",
      "Train Epoch: 1786 [1280/1612 (79%)] Loss: 0.330102\n",
      "Train Epoch: 1786 [1440/1612 (89%)] Loss: 0.334435\n",
      "Train Epoch: 1786 [1200/1612 (99%)] Loss: 0.353101\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1787 [0/1612 (0%)] Loss: 0.081410\n",
      "Train Epoch: 1787 [160/1612 (10%)] Loss: 0.258818\n",
      "Train Epoch: 1787 [320/1612 (20%)] Loss: 0.219917\n",
      "Train Epoch: 1787 [480/1612 (30%)] Loss: 0.264191\n",
      "Train Epoch: 1787 [640/1612 (40%)] Loss: 0.395953\n",
      "Train Epoch: 1787 [800/1612 (50%)] Loss: 0.410792\n",
      "Train Epoch: 1787 [960/1612 (59%)] Loss: 0.149475\n",
      "Train Epoch: 1787 [1120/1612 (69%)] Loss: 0.401448\n",
      "Train Epoch: 1787 [1280/1612 (79%)] Loss: 0.268308\n",
      "Train Epoch: 1787 [1440/1612 (89%)] Loss: 0.228147\n",
      "Train Epoch: 1787 [1200/1612 (99%)] Loss: 0.138534\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1788 [0/1612 (0%)] Loss: 0.256844\n",
      "Train Epoch: 1788 [160/1612 (10%)] Loss: 0.222948\n",
      "Train Epoch: 1788 [320/1612 (20%)] Loss: 0.397883\n",
      "Train Epoch: 1788 [480/1612 (30%)] Loss: 0.418253\n",
      "Train Epoch: 1788 [640/1612 (40%)] Loss: 0.437017\n",
      "Train Epoch: 1788 [800/1612 (50%)] Loss: 0.192103\n",
      "Train Epoch: 1788 [960/1612 (59%)] Loss: 0.231753\n",
      "Train Epoch: 1788 [1120/1612 (69%)] Loss: 0.421767\n",
      "Train Epoch: 1788 [1280/1612 (79%)] Loss: 0.435004\n",
      "Train Epoch: 1788 [1440/1612 (89%)] Loss: 0.453006\n",
      "Train Epoch: 1788 [1200/1612 (99%)] Loss: 0.380687\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1789 [0/1612 (0%)] Loss: 0.189522\n",
      "Train Epoch: 1789 [160/1612 (10%)] Loss: 0.290577\n",
      "Train Epoch: 1789 [320/1612 (20%)] Loss: 0.132939\n",
      "Train Epoch: 1789 [480/1612 (30%)] Loss: 0.337819\n",
      "Train Epoch: 1789 [640/1612 (40%)] Loss: 0.127566\n",
      "Train Epoch: 1789 [800/1612 (50%)] Loss: 0.225702\n",
      "Train Epoch: 1789 [960/1612 (59%)] Loss: 0.261674\n",
      "Train Epoch: 1789 [1120/1612 (69%)] Loss: 0.216249\n",
      "Train Epoch: 1789 [1280/1612 (79%)] Loss: 0.243090\n",
      "Train Epoch: 1789 [1440/1612 (89%)] Loss: 0.246229\n",
      "Train Epoch: 1789 [1200/1612 (99%)] Loss: 0.360578\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1790 [0/1612 (0%)] Loss: 0.221911\n",
      "Train Epoch: 1790 [160/1612 (10%)] Loss: 0.337836\n",
      "Train Epoch: 1790 [320/1612 (20%)] Loss: 0.233796\n",
      "Train Epoch: 1790 [480/1612 (30%)] Loss: 0.241690\n",
      "Train Epoch: 1790 [640/1612 (40%)] Loss: 0.370346\n",
      "Train Epoch: 1790 [800/1612 (50%)] Loss: 0.198028\n",
      "Train Epoch: 1790 [960/1612 (59%)] Loss: 0.190593\n",
      "Train Epoch: 1790 [1120/1612 (69%)] Loss: 0.370881\n",
      "Train Epoch: 1790 [1280/1612 (79%)] Loss: 0.179046\n",
      "Train Epoch: 1790 [1440/1612 (89%)] Loss: 0.155942\n",
      "Train Epoch: 1790 [1200/1612 (99%)] Loss: 0.117319\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1791 [0/1612 (0%)] Loss: 0.097768\n",
      "Train Epoch: 1791 [160/1612 (10%)] Loss: 0.288574\n",
      "Train Epoch: 1791 [320/1612 (20%)] Loss: 0.149205\n",
      "Train Epoch: 1791 [480/1612 (30%)] Loss: 0.216989\n",
      "Train Epoch: 1791 [640/1612 (40%)] Loss: 0.265253\n",
      "Train Epoch: 1791 [800/1612 (50%)] Loss: 0.160502\n",
      "Train Epoch: 1791 [960/1612 (59%)] Loss: 0.334900\n",
      "Train Epoch: 1791 [1120/1612 (69%)] Loss: 0.532482\n",
      "Train Epoch: 1791 [1280/1612 (79%)] Loss: 0.362357\n",
      "Train Epoch: 1791 [1440/1612 (89%)] Loss: 0.559246\n",
      "Train Epoch: 1791 [1200/1612 (99%)] Loss: 0.356706\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1792 [0/1612 (0%)] Loss: 0.526293\n",
      "Train Epoch: 1792 [160/1612 (10%)] Loss: 0.249765\n",
      "Train Epoch: 1792 [320/1612 (20%)] Loss: 0.403031\n",
      "Train Epoch: 1792 [480/1612 (30%)] Loss: 0.181273\n",
      "Train Epoch: 1792 [640/1612 (40%)] Loss: 0.170154\n",
      "Train Epoch: 1792 [800/1612 (50%)] Loss: 0.200702\n",
      "Train Epoch: 1792 [960/1612 (59%)] Loss: 0.279597\n",
      "Train Epoch: 1792 [1120/1612 (69%)] Loss: 0.280751\n",
      "Train Epoch: 1792 [1280/1612 (79%)] Loss: 0.173409\n",
      "Train Epoch: 1792 [1440/1612 (89%)] Loss: 0.296826\n",
      "Train Epoch: 1792 [1200/1612 (99%)] Loss: 0.113028\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1793 [0/1612 (0%)] Loss: 0.312499\n",
      "Train Epoch: 1793 [160/1612 (10%)] Loss: 0.436881\n",
      "Train Epoch: 1793 [320/1612 (20%)] Loss: 0.417992\n",
      "Train Epoch: 1793 [480/1612 (30%)] Loss: 0.483372\n",
      "Train Epoch: 1793 [640/1612 (40%)] Loss: 0.384726\n",
      "Train Epoch: 1793 [800/1612 (50%)] Loss: 0.459501\n",
      "Train Epoch: 1793 [960/1612 (59%)] Loss: 0.318192\n",
      "Train Epoch: 1793 [1120/1612 (69%)] Loss: 0.136691\n",
      "Train Epoch: 1793 [1280/1612 (79%)] Loss: 0.296184\n",
      "Train Epoch: 1793 [1440/1612 (89%)] Loss: 0.110988\n",
      "Train Epoch: 1793 [1200/1612 (99%)] Loss: 0.199905\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1794 [0/1612 (0%)] Loss: 0.413695\n",
      "Train Epoch: 1794 [160/1612 (10%)] Loss: 0.201444\n",
      "Train Epoch: 1794 [320/1612 (20%)] Loss: 0.194356\n",
      "Train Epoch: 1794 [480/1612 (30%)] Loss: 0.598110\n",
      "Train Epoch: 1794 [640/1612 (40%)] Loss: 0.245790\n",
      "Train Epoch: 1794 [800/1612 (50%)] Loss: 0.313344\n",
      "Train Epoch: 1794 [960/1612 (59%)] Loss: 0.218873\n",
      "Train Epoch: 1794 [1120/1612 (69%)] Loss: 0.164526\n",
      "Train Epoch: 1794 [1280/1612 (79%)] Loss: 0.281527\n",
      "Train Epoch: 1794 [1440/1612 (89%)] Loss: 0.216948\n",
      "Train Epoch: 1794 [1200/1612 (99%)] Loss: 0.370042\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1795 [0/1612 (0%)] Loss: 0.418148\n",
      "Train Epoch: 1795 [160/1612 (10%)] Loss: 0.329819\n",
      "Train Epoch: 1795 [320/1612 (20%)] Loss: 0.430796\n",
      "Train Epoch: 1795 [480/1612 (30%)] Loss: 0.179647\n",
      "Train Epoch: 1795 [640/1612 (40%)] Loss: 0.256168\n",
      "Train Epoch: 1795 [800/1612 (50%)] Loss: 0.437431\n",
      "Train Epoch: 1795 [960/1612 (59%)] Loss: 0.231573\n",
      "Train Epoch: 1795 [1120/1612 (69%)] Loss: 0.197999\n",
      "Train Epoch: 1795 [1280/1612 (79%)] Loss: 0.361616\n",
      "Train Epoch: 1795 [1440/1612 (89%)] Loss: 0.244349\n",
      "Train Epoch: 1795 [1200/1612 (99%)] Loss: 0.250185\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1796 [0/1612 (0%)] Loss: 0.235572\n",
      "Train Epoch: 1796 [160/1612 (10%)] Loss: 0.526432\n",
      "Train Epoch: 1796 [320/1612 (20%)] Loss: 0.510989\n",
      "Train Epoch: 1796 [480/1612 (30%)] Loss: 0.319306\n",
      "Train Epoch: 1796 [640/1612 (40%)] Loss: 0.182951\n",
      "Train Epoch: 1796 [800/1612 (50%)] Loss: 0.369249\n",
      "Train Epoch: 1796 [960/1612 (59%)] Loss: 0.110391\n",
      "Train Epoch: 1796 [1120/1612 (69%)] Loss: 0.360615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1796 [1280/1612 (79%)] Loss: 0.424004\n",
      "Train Epoch: 1796 [1440/1612 (89%)] Loss: 0.101277\n",
      "Train Epoch: 1796 [1200/1612 (99%)] Loss: 0.359438\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1797 [0/1612 (0%)] Loss: 0.187220\n",
      "Train Epoch: 1797 [160/1612 (10%)] Loss: 0.354694\n",
      "Train Epoch: 1797 [320/1612 (20%)] Loss: 0.348001\n",
      "Train Epoch: 1797 [480/1612 (30%)] Loss: 0.309521\n",
      "Train Epoch: 1797 [640/1612 (40%)] Loss: 0.308903\n",
      "Train Epoch: 1797 [800/1612 (50%)] Loss: 0.189516\n",
      "Train Epoch: 1797 [960/1612 (59%)] Loss: 0.446656\n",
      "Train Epoch: 1797 [1120/1612 (69%)] Loss: 0.359871\n",
      "Train Epoch: 1797 [1280/1612 (79%)] Loss: 0.277982\n",
      "Train Epoch: 1797 [1440/1612 (89%)] Loss: 0.346538\n",
      "Train Epoch: 1797 [1200/1612 (99%)] Loss: 0.569380\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1798 [0/1612 (0%)] Loss: 0.185858\n",
      "Train Epoch: 1798 [160/1612 (10%)] Loss: 0.288940\n",
      "Train Epoch: 1798 [320/1612 (20%)] Loss: 0.400560\n",
      "Train Epoch: 1798 [480/1612 (30%)] Loss: 0.283083\n",
      "Train Epoch: 1798 [640/1612 (40%)] Loss: 0.177276\n",
      "Train Epoch: 1798 [800/1612 (50%)] Loss: 0.211354\n",
      "Train Epoch: 1798 [960/1612 (59%)] Loss: 0.443571\n",
      "Train Epoch: 1798 [1120/1612 (69%)] Loss: 0.462540\n",
      "Train Epoch: 1798 [1280/1612 (79%)] Loss: 0.333907\n",
      "Train Epoch: 1798 [1440/1612 (89%)] Loss: 0.276074\n",
      "Train Epoch: 1798 [1200/1612 (99%)] Loss: 0.142407\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1799 [0/1612 (0%)] Loss: 0.443715\n",
      "Train Epoch: 1799 [160/1612 (10%)] Loss: 0.260846\n",
      "Train Epoch: 1799 [320/1612 (20%)] Loss: 0.345054\n",
      "Train Epoch: 1799 [480/1612 (30%)] Loss: 0.232486\n",
      "Train Epoch: 1799 [640/1612 (40%)] Loss: 0.255071\n",
      "Train Epoch: 1799 [800/1612 (50%)] Loss: 0.275376\n",
      "Train Epoch: 1799 [960/1612 (59%)] Loss: 0.279042\n",
      "Train Epoch: 1799 [1120/1612 (69%)] Loss: 0.138489\n",
      "Train Epoch: 1799 [1280/1612 (79%)] Loss: 0.192534\n",
      "Train Epoch: 1799 [1440/1612 (89%)] Loss: 0.465042\n",
      "Train Epoch: 1799 [1200/1612 (99%)] Loss: 0.326576\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1800 [0/1612 (0%)] Loss: 0.316717\n",
      "Train Epoch: 1800 [160/1612 (10%)] Loss: 0.339882\n",
      "Train Epoch: 1800 [320/1612 (20%)] Loss: 0.283809\n",
      "Train Epoch: 1800 [480/1612 (30%)] Loss: 0.486584\n",
      "Train Epoch: 1800 [640/1612 (40%)] Loss: 0.216258\n",
      "Train Epoch: 1800 [800/1612 (50%)] Loss: 0.344612\n",
      "Train Epoch: 1800 [960/1612 (59%)] Loss: 0.219991\n",
      "Train Epoch: 1800 [1120/1612 (69%)] Loss: 0.309627\n",
      "Train Epoch: 1800 [1280/1612 (79%)] Loss: 0.201503\n",
      "Train Epoch: 1800 [1440/1612 (89%)] Loss: 0.164499\n",
      "Train Epoch: 1800 [1200/1612 (99%)] Loss: 0.355720\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1801 [0/1612 (0%)] Loss: 0.225991\n",
      "Train Epoch: 1801 [160/1612 (10%)] Loss: 0.282853\n",
      "Train Epoch: 1801 [320/1612 (20%)] Loss: 0.175246\n",
      "Train Epoch: 1801 [480/1612 (30%)] Loss: 0.293713\n",
      "Train Epoch: 1801 [640/1612 (40%)] Loss: 0.238718\n",
      "Train Epoch: 1801 [800/1612 (50%)] Loss: 0.330541\n",
      "Train Epoch: 1801 [960/1612 (59%)] Loss: 0.173737\n",
      "Train Epoch: 1801 [1120/1612 (69%)] Loss: 0.182562\n",
      "Train Epoch: 1801 [1280/1612 (79%)] Loss: 0.406117\n",
      "Train Epoch: 1801 [1440/1612 (89%)] Loss: 0.473179\n",
      "Train Epoch: 1801 [1200/1612 (99%)] Loss: 0.458444\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1802 [0/1612 (0%)] Loss: 0.549325\n",
      "Train Epoch: 1802 [160/1612 (10%)] Loss: 0.326956\n",
      "Train Epoch: 1802 [320/1612 (20%)] Loss: 0.437676\n",
      "Train Epoch: 1802 [480/1612 (30%)] Loss: 0.394575\n",
      "Train Epoch: 1802 [640/1612 (40%)] Loss: 0.299866\n",
      "Train Epoch: 1802 [800/1612 (50%)] Loss: 0.228810\n",
      "Train Epoch: 1802 [960/1612 (59%)] Loss: 0.329246\n",
      "Train Epoch: 1802 [1120/1612 (69%)] Loss: 0.325650\n",
      "Train Epoch: 1802 [1280/1612 (79%)] Loss: 0.361167\n",
      "Train Epoch: 1802 [1440/1612 (89%)] Loss: 0.203057\n",
      "Train Epoch: 1802 [1200/1612 (99%)] Loss: 0.135387\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1803 [0/1612 (0%)] Loss: 0.454059\n",
      "Train Epoch: 1803 [160/1612 (10%)] Loss: 0.347144\n",
      "Train Epoch: 1803 [320/1612 (20%)] Loss: 0.284404\n",
      "Train Epoch: 1803 [480/1612 (30%)] Loss: 0.185841\n",
      "Train Epoch: 1803 [640/1612 (40%)] Loss: 0.347758\n",
      "Train Epoch: 1803 [800/1612 (50%)] Loss: 0.164313\n",
      "Train Epoch: 1803 [960/1612 (59%)] Loss: 0.265059\n",
      "Train Epoch: 1803 [1120/1612 (69%)] Loss: 0.322150\n",
      "Train Epoch: 1803 [1280/1612 (79%)] Loss: 0.166877\n",
      "Train Epoch: 1803 [1440/1612 (89%)] Loss: 0.179118\n",
      "Train Epoch: 1803 [1200/1612 (99%)] Loss: 0.357592\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1804 [0/1612 (0%)] Loss: 0.175148\n",
      "Train Epoch: 1804 [160/1612 (10%)] Loss: 0.267552\n",
      "Train Epoch: 1804 [320/1612 (20%)] Loss: 0.196507\n",
      "Train Epoch: 1804 [480/1612 (30%)] Loss: 0.245224\n",
      "Train Epoch: 1804 [640/1612 (40%)] Loss: 0.211477\n",
      "Train Epoch: 1804 [800/1612 (50%)] Loss: 0.466772\n",
      "Train Epoch: 1804 [960/1612 (59%)] Loss: 0.209628\n",
      "Train Epoch: 1804 [1120/1612 (69%)] Loss: 0.366928\n",
      "Train Epoch: 1804 [1280/1612 (79%)] Loss: 0.277402\n",
      "Train Epoch: 1804 [1440/1612 (89%)] Loss: 0.215149\n",
      "Train Epoch: 1804 [1200/1612 (99%)] Loss: 0.205541\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1805 [0/1612 (0%)] Loss: 0.178586\n",
      "Train Epoch: 1805 [160/1612 (10%)] Loss: 0.297119\n",
      "Train Epoch: 1805 [320/1612 (20%)] Loss: 0.175890\n",
      "Train Epoch: 1805 [480/1612 (30%)] Loss: 0.265859\n",
      "Train Epoch: 1805 [640/1612 (40%)] Loss: 0.083558\n",
      "Train Epoch: 1805 [800/1612 (50%)] Loss: 0.138436\n",
      "Train Epoch: 1805 [960/1612 (59%)] Loss: 0.241346\n",
      "Train Epoch: 1805 [1120/1612 (69%)] Loss: 0.357768\n",
      "Train Epoch: 1805 [1280/1612 (79%)] Loss: 0.313647\n",
      "Train Epoch: 1805 [1440/1612 (89%)] Loss: 0.296846\n",
      "Train Epoch: 1805 [1200/1612 (99%)] Loss: 0.425322\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1806 [0/1612 (0%)] Loss: 0.276454\n",
      "Train Epoch: 1806 [160/1612 (10%)] Loss: 0.264438\n",
      "Train Epoch: 1806 [320/1612 (20%)] Loss: 0.186916\n",
      "Train Epoch: 1806 [480/1612 (30%)] Loss: 0.127357\n",
      "Train Epoch: 1806 [640/1612 (40%)] Loss: 0.247588\n",
      "Train Epoch: 1806 [800/1612 (50%)] Loss: 0.452014\n",
      "Train Epoch: 1806 [960/1612 (59%)] Loss: 0.153291\n",
      "Train Epoch: 1806 [1120/1612 (69%)] Loss: 0.280514\n",
      "Train Epoch: 1806 [1280/1612 (79%)] Loss: 0.218744\n",
      "Train Epoch: 1806 [1440/1612 (89%)] Loss: 0.304871\n",
      "Train Epoch: 1806 [1200/1612 (99%)] Loss: 0.246842\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1807 [0/1612 (0%)] Loss: 0.334101\n",
      "Train Epoch: 1807 [160/1612 (10%)] Loss: 0.283594\n",
      "Train Epoch: 1807 [320/1612 (20%)] Loss: 0.135132\n",
      "Train Epoch: 1807 [480/1612 (30%)] Loss: 0.140939\n",
      "Train Epoch: 1807 [640/1612 (40%)] Loss: 0.137466\n",
      "Train Epoch: 1807 [800/1612 (50%)] Loss: 0.209773\n",
      "Train Epoch: 1807 [960/1612 (59%)] Loss: 0.168399\n",
      "Train Epoch: 1807 [1120/1612 (69%)] Loss: 0.441195\n",
      "Train Epoch: 1807 [1280/1612 (79%)] Loss: 0.499078\n",
      "Train Epoch: 1807 [1440/1612 (89%)] Loss: 0.235560\n",
      "Train Epoch: 1807 [1200/1612 (99%)] Loss: 0.254441\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1808 [0/1612 (0%)] Loss: 0.271165\n",
      "Train Epoch: 1808 [160/1612 (10%)] Loss: 0.496067\n",
      "Train Epoch: 1808 [320/1612 (20%)] Loss: 0.346093\n",
      "Train Epoch: 1808 [480/1612 (30%)] Loss: 0.192156\n",
      "Train Epoch: 1808 [640/1612 (40%)] Loss: 0.224089\n",
      "Train Epoch: 1808 [800/1612 (50%)] Loss: 0.428091\n",
      "Train Epoch: 1808 [960/1612 (59%)] Loss: 0.395365\n",
      "Train Epoch: 1808 [1120/1612 (69%)] Loss: 0.292861\n",
      "Train Epoch: 1808 [1280/1612 (79%)] Loss: 0.121978\n",
      "Train Epoch: 1808 [1440/1612 (89%)] Loss: 0.223405\n",
      "Train Epoch: 1808 [1200/1612 (99%)] Loss: 0.426674\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1809 [0/1612 (0%)] Loss: 0.171588\n",
      "Train Epoch: 1809 [160/1612 (10%)] Loss: 0.173135\n",
      "Train Epoch: 1809 [320/1612 (20%)] Loss: 0.607445\n",
      "Train Epoch: 1809 [480/1612 (30%)] Loss: 0.354731\n",
      "Train Epoch: 1809 [640/1612 (40%)] Loss: 0.287421\n",
      "Train Epoch: 1809 [800/1612 (50%)] Loss: 0.467472\n",
      "Train Epoch: 1809 [960/1612 (59%)] Loss: 0.421752\n",
      "Train Epoch: 1809 [1120/1612 (69%)] Loss: 0.368637\n",
      "Train Epoch: 1809 [1280/1612 (79%)] Loss: 0.268840\n",
      "Train Epoch: 1809 [1440/1612 (89%)] Loss: 0.381471\n",
      "Train Epoch: 1809 [1200/1612 (99%)] Loss: 0.317775\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1810 [0/1612 (0%)] Loss: 0.225023\n",
      "Train Epoch: 1810 [160/1612 (10%)] Loss: 0.414787\n",
      "Train Epoch: 1810 [320/1612 (20%)] Loss: 0.318699\n",
      "Train Epoch: 1810 [480/1612 (30%)] Loss: 0.230281\n",
      "Train Epoch: 1810 [640/1612 (40%)] Loss: 0.216507\n",
      "Train Epoch: 1810 [800/1612 (50%)] Loss: 0.234804\n",
      "Train Epoch: 1810 [960/1612 (59%)] Loss: 0.441829\n",
      "Train Epoch: 1810 [1120/1612 (69%)] Loss: 0.207391\n",
      "Train Epoch: 1810 [1280/1612 (79%)] Loss: 0.359944\n",
      "Train Epoch: 1810 [1440/1612 (89%)] Loss: 0.601782\n",
      "Train Epoch: 1810 [1200/1612 (99%)] Loss: 0.278246\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1811 [0/1612 (0%)] Loss: 0.471199\n",
      "Train Epoch: 1811 [160/1612 (10%)] Loss: 0.199428\n",
      "Train Epoch: 1811 [320/1612 (20%)] Loss: 0.352728\n",
      "Train Epoch: 1811 [480/1612 (30%)] Loss: 0.160845\n",
      "Train Epoch: 1811 [640/1612 (40%)] Loss: 0.249754\n",
      "Train Epoch: 1811 [800/1612 (50%)] Loss: 0.272025\n",
      "Train Epoch: 1811 [960/1612 (59%)] Loss: 0.115302\n",
      "Train Epoch: 1811 [1120/1612 (69%)] Loss: 0.300326\n",
      "Train Epoch: 1811 [1280/1612 (79%)] Loss: 0.341586\n",
      "Train Epoch: 1811 [1440/1612 (89%)] Loss: 0.273626\n",
      "Train Epoch: 1811 [1200/1612 (99%)] Loss: 0.449759\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1812 [0/1612 (0%)] Loss: 0.298758\n",
      "Train Epoch: 1812 [160/1612 (10%)] Loss: 0.246458\n",
      "Train Epoch: 1812 [320/1612 (20%)] Loss: 0.450478\n",
      "Train Epoch: 1812 [480/1612 (30%)] Loss: 0.232608\n",
      "Train Epoch: 1812 [640/1612 (40%)] Loss: 0.300630\n",
      "Train Epoch: 1812 [800/1612 (50%)] Loss: 0.362979\n",
      "Train Epoch: 1812 [960/1612 (59%)] Loss: 0.368772\n",
      "Train Epoch: 1812 [1120/1612 (69%)] Loss: 0.266803\n",
      "Train Epoch: 1812 [1280/1612 (79%)] Loss: 0.201677\n",
      "Train Epoch: 1812 [1440/1612 (89%)] Loss: 0.226073\n",
      "Train Epoch: 1812 [1200/1612 (99%)] Loss: 0.136667\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1813 [0/1612 (0%)] Loss: 0.277626\n",
      "Train Epoch: 1813 [160/1612 (10%)] Loss: 0.376365\n",
      "Train Epoch: 1813 [320/1612 (20%)] Loss: 0.244436\n",
      "Train Epoch: 1813 [480/1612 (30%)] Loss: 0.202043\n",
      "Train Epoch: 1813 [640/1612 (40%)] Loss: 0.485731\n",
      "Train Epoch: 1813 [800/1612 (50%)] Loss: 0.366860\n",
      "Train Epoch: 1813 [960/1612 (59%)] Loss: 0.146049\n",
      "Train Epoch: 1813 [1120/1612 (69%)] Loss: 0.296844\n",
      "Train Epoch: 1813 [1280/1612 (79%)] Loss: 0.411204\n",
      "Train Epoch: 1813 [1440/1612 (89%)] Loss: 0.243924\n",
      "Train Epoch: 1813 [1200/1612 (99%)] Loss: 0.469997\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1814 [0/1612 (0%)] Loss: 0.425733\n",
      "Train Epoch: 1814 [160/1612 (10%)] Loss: 0.330225\n",
      "Train Epoch: 1814 [320/1612 (20%)] Loss: 0.170817\n",
      "Train Epoch: 1814 [480/1612 (30%)] Loss: 0.110966\n",
      "Train Epoch: 1814 [640/1612 (40%)] Loss: 0.515764\n",
      "Train Epoch: 1814 [800/1612 (50%)] Loss: 0.221149\n",
      "Train Epoch: 1814 [960/1612 (59%)] Loss: 0.346534\n",
      "Train Epoch: 1814 [1120/1612 (69%)] Loss: 0.336736\n",
      "Train Epoch: 1814 [1280/1612 (79%)] Loss: 0.369561\n",
      "Train Epoch: 1814 [1440/1612 (89%)] Loss: 0.256011\n",
      "Train Epoch: 1814 [1200/1612 (99%)] Loss: 0.429926\n",
      "\n",
      "Test set: Average loss: 0.0251, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1815 [0/1612 (0%)] Loss: 0.247567\n",
      "Train Epoch: 1815 [160/1612 (10%)] Loss: 0.399671\n",
      "Train Epoch: 1815 [320/1612 (20%)] Loss: 0.417732\n",
      "Train Epoch: 1815 [480/1612 (30%)] Loss: 0.190071\n",
      "Train Epoch: 1815 [640/1612 (40%)] Loss: 0.313680\n",
      "Train Epoch: 1815 [800/1612 (50%)] Loss: 0.314689\n",
      "Train Epoch: 1815 [960/1612 (59%)] Loss: 0.301626\n",
      "Train Epoch: 1815 [1120/1612 (69%)] Loss: 0.274423\n",
      "Train Epoch: 1815 [1280/1612 (79%)] Loss: 0.383846\n",
      "Train Epoch: 1815 [1440/1612 (89%)] Loss: 0.201198\n",
      "Train Epoch: 1815 [1200/1612 (99%)] Loss: 0.373523\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1816 [0/1612 (0%)] Loss: 0.313279\n",
      "Train Epoch: 1816 [160/1612 (10%)] Loss: 0.276365\n",
      "Train Epoch: 1816 [320/1612 (20%)] Loss: 0.259689\n",
      "Train Epoch: 1816 [480/1612 (30%)] Loss: 0.248404\n",
      "Train Epoch: 1816 [640/1612 (40%)] Loss: 0.261816\n",
      "Train Epoch: 1816 [800/1612 (50%)] Loss: 0.310157\n",
      "Train Epoch: 1816 [960/1612 (59%)] Loss: 0.466478\n",
      "Train Epoch: 1816 [1120/1612 (69%)] Loss: 0.281932\n",
      "Train Epoch: 1816 [1280/1612 (79%)] Loss: 0.396626\n",
      "Train Epoch: 1816 [1440/1612 (89%)] Loss: 0.221196\n",
      "Train Epoch: 1816 [1200/1612 (99%)] Loss: 0.080170\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1817 [0/1612 (0%)] Loss: 0.194792\n",
      "Train Epoch: 1817 [160/1612 (10%)] Loss: 0.251282\n",
      "Train Epoch: 1817 [320/1612 (20%)] Loss: 0.186819\n",
      "Train Epoch: 1817 [480/1612 (30%)] Loss: 0.214056\n",
      "Train Epoch: 1817 [640/1612 (40%)] Loss: 0.158817\n",
      "Train Epoch: 1817 [800/1612 (50%)] Loss: 0.368027\n",
      "Train Epoch: 1817 [960/1612 (59%)] Loss: 0.301484\n",
      "Train Epoch: 1817 [1120/1612 (69%)] Loss: 0.283825\n",
      "Train Epoch: 1817 [1280/1612 (79%)] Loss: 0.309792\n",
      "Train Epoch: 1817 [1440/1612 (89%)] Loss: 0.486840\n",
      "Train Epoch: 1817 [1200/1612 (99%)] Loss: 0.277890\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1818 [0/1612 (0%)] Loss: 0.225532\n",
      "Train Epoch: 1818 [160/1612 (10%)] Loss: 0.318237\n",
      "Train Epoch: 1818 [320/1612 (20%)] Loss: 0.227694\n",
      "Train Epoch: 1818 [480/1612 (30%)] Loss: 0.465840\n",
      "Train Epoch: 1818 [640/1612 (40%)] Loss: 0.237051\n",
      "Train Epoch: 1818 [800/1612 (50%)] Loss: 0.333629\n",
      "Train Epoch: 1818 [960/1612 (59%)] Loss: 0.155956\n",
      "Train Epoch: 1818 [1120/1612 (69%)] Loss: 0.188181\n",
      "Train Epoch: 1818 [1280/1612 (79%)] Loss: 0.302588\n",
      "Train Epoch: 1818 [1440/1612 (89%)] Loss: 0.301499\n",
      "Train Epoch: 1818 [1200/1612 (99%)] Loss: 0.172470\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1819 [0/1612 (0%)] Loss: 0.313603\n",
      "Train Epoch: 1819 [160/1612 (10%)] Loss: 0.347194\n",
      "Train Epoch: 1819 [320/1612 (20%)] Loss: 0.171090\n",
      "Train Epoch: 1819 [480/1612 (30%)] Loss: 0.268828\n",
      "Train Epoch: 1819 [640/1612 (40%)] Loss: 0.185864\n",
      "Train Epoch: 1819 [800/1612 (50%)] Loss: 0.403167\n",
      "Train Epoch: 1819 [960/1612 (59%)] Loss: 0.220977\n",
      "Train Epoch: 1819 [1120/1612 (69%)] Loss: 0.415503\n",
      "Train Epoch: 1819 [1280/1612 (79%)] Loss: 0.457978\n",
      "Train Epoch: 1819 [1440/1612 (89%)] Loss: 0.401535\n",
      "Train Epoch: 1819 [1200/1612 (99%)] Loss: 0.344884\n",
      "\n",
      "Test set: Average loss: 0.0290, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1820 [0/1612 (0%)] Loss: 0.382692\n",
      "Train Epoch: 1820 [160/1612 (10%)] Loss: 0.351111\n",
      "Train Epoch: 1820 [320/1612 (20%)] Loss: 0.130046\n",
      "Train Epoch: 1820 [480/1612 (30%)] Loss: 0.153832\n",
      "Train Epoch: 1820 [640/1612 (40%)] Loss: 0.506142\n",
      "Train Epoch: 1820 [800/1612 (50%)] Loss: 0.122790\n",
      "Train Epoch: 1820 [960/1612 (59%)] Loss: 0.295019\n",
      "Train Epoch: 1820 [1120/1612 (69%)] Loss: 0.374691\n",
      "Train Epoch: 1820 [1280/1612 (79%)] Loss: 0.251292\n",
      "Train Epoch: 1820 [1440/1612 (89%)] Loss: 0.261803\n",
      "Train Epoch: 1820 [1200/1612 (99%)] Loss: 0.461342\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1821 [0/1612 (0%)] Loss: 0.170877\n",
      "Train Epoch: 1821 [160/1612 (10%)] Loss: 0.269988\n",
      "Train Epoch: 1821 [320/1612 (20%)] Loss: 0.215777\n",
      "Train Epoch: 1821 [480/1612 (30%)] Loss: 0.564629\n",
      "Train Epoch: 1821 [640/1612 (40%)] Loss: 0.199131\n",
      "Train Epoch: 1821 [800/1612 (50%)] Loss: 0.386769\n",
      "Train Epoch: 1821 [960/1612 (59%)] Loss: 0.353874\n",
      "Train Epoch: 1821 [1120/1612 (69%)] Loss: 0.242162\n",
      "Train Epoch: 1821 [1280/1612 (79%)] Loss: 0.397388\n",
      "Train Epoch: 1821 [1440/1612 (89%)] Loss: 0.240304\n",
      "Train Epoch: 1821 [1200/1612 (99%)] Loss: 0.427627\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1822 [0/1612 (0%)] Loss: 0.349389\n",
      "Train Epoch: 1822 [160/1612 (10%)] Loss: 0.127544\n",
      "Train Epoch: 1822 [320/1612 (20%)] Loss: 0.452908\n",
      "Train Epoch: 1822 [480/1612 (30%)] Loss: 0.318467\n",
      "Train Epoch: 1822 [640/1612 (40%)] Loss: 0.291660\n",
      "Train Epoch: 1822 [800/1612 (50%)] Loss: 0.176148\n",
      "Train Epoch: 1822 [960/1612 (59%)] Loss: 0.433757\n",
      "Train Epoch: 1822 [1120/1612 (69%)] Loss: 0.286599\n",
      "Train Epoch: 1822 [1280/1612 (79%)] Loss: 0.314267\n",
      "Train Epoch: 1822 [1440/1612 (89%)] Loss: 0.211686\n",
      "Train Epoch: 1822 [1200/1612 (99%)] Loss: 0.223536\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1823 [0/1612 (0%)] Loss: 0.290258\n",
      "Train Epoch: 1823 [160/1612 (10%)] Loss: 0.179965\n",
      "Train Epoch: 1823 [320/1612 (20%)] Loss: 0.548530\n",
      "Train Epoch: 1823 [480/1612 (30%)] Loss: 0.245127\n",
      "Train Epoch: 1823 [640/1612 (40%)] Loss: 0.301986\n",
      "Train Epoch: 1823 [800/1612 (50%)] Loss: 0.245561\n",
      "Train Epoch: 1823 [960/1612 (59%)] Loss: 0.238419\n",
      "Train Epoch: 1823 [1120/1612 (69%)] Loss: 0.295667\n",
      "Train Epoch: 1823 [1280/1612 (79%)] Loss: 0.243924\n",
      "Train Epoch: 1823 [1440/1612 (89%)] Loss: 0.746489\n",
      "Train Epoch: 1823 [1200/1612 (99%)] Loss: 0.140437\n",
      "\n",
      "Test set: Average loss: 0.0301, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1824 [0/1612 (0%)] Loss: 0.448363\n",
      "Train Epoch: 1824 [160/1612 (10%)] Loss: 0.303523\n",
      "Train Epoch: 1824 [320/1612 (20%)] Loss: 0.227442\n",
      "Train Epoch: 1824 [480/1612 (30%)] Loss: 0.353100\n",
      "Train Epoch: 1824 [640/1612 (40%)] Loss: 0.231750\n",
      "Train Epoch: 1824 [800/1612 (50%)] Loss: 0.363355\n",
      "Train Epoch: 1824 [960/1612 (59%)] Loss: 0.103033\n",
      "Train Epoch: 1824 [1120/1612 (69%)] Loss: 0.304657\n",
      "Train Epoch: 1824 [1280/1612 (79%)] Loss: 0.211990\n",
      "Train Epoch: 1824 [1440/1612 (89%)] Loss: 0.297786\n",
      "Train Epoch: 1824 [1200/1612 (99%)] Loss: 0.188791\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1825 [0/1612 (0%)] Loss: 0.156620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1825 [160/1612 (10%)] Loss: 0.305983\n",
      "Train Epoch: 1825 [320/1612 (20%)] Loss: 0.165807\n",
      "Train Epoch: 1825 [480/1612 (30%)] Loss: 0.320041\n",
      "Train Epoch: 1825 [640/1612 (40%)] Loss: 0.239513\n",
      "Train Epoch: 1825 [800/1612 (50%)] Loss: 0.188690\n",
      "Train Epoch: 1825 [960/1612 (59%)] Loss: 0.261712\n",
      "Train Epoch: 1825 [1120/1612 (69%)] Loss: 0.274953\n",
      "Train Epoch: 1825 [1280/1612 (79%)] Loss: 0.342774\n",
      "Train Epoch: 1825 [1440/1612 (89%)] Loss: 0.203659\n",
      "Train Epoch: 1825 [1200/1612 (99%)] Loss: 0.398949\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1826 [0/1612 (0%)] Loss: 0.380863\n",
      "Train Epoch: 1826 [160/1612 (10%)] Loss: 0.213252\n",
      "Train Epoch: 1826 [320/1612 (20%)] Loss: 0.416426\n",
      "Train Epoch: 1826 [480/1612 (30%)] Loss: 0.379266\n",
      "Train Epoch: 1826 [640/1612 (40%)] Loss: 0.280808\n",
      "Train Epoch: 1826 [800/1612 (50%)] Loss: 0.312552\n",
      "Train Epoch: 1826 [960/1612 (59%)] Loss: 0.166565\n",
      "Train Epoch: 1826 [1120/1612 (69%)] Loss: 0.213974\n",
      "Train Epoch: 1826 [1280/1612 (79%)] Loss: 0.220425\n",
      "Train Epoch: 1826 [1440/1612 (89%)] Loss: 0.450835\n",
      "Train Epoch: 1826 [1200/1612 (99%)] Loss: 0.396577\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1827 [0/1612 (0%)] Loss: 0.389202\n",
      "Train Epoch: 1827 [160/1612 (10%)] Loss: 0.295767\n",
      "Train Epoch: 1827 [320/1612 (20%)] Loss: 0.285442\n",
      "Train Epoch: 1827 [480/1612 (30%)] Loss: 0.303814\n",
      "Train Epoch: 1827 [640/1612 (40%)] Loss: 0.496960\n",
      "Train Epoch: 1827 [800/1612 (50%)] Loss: 0.399503\n",
      "Train Epoch: 1827 [960/1612 (59%)] Loss: 0.355819\n",
      "Train Epoch: 1827 [1120/1612 (69%)] Loss: 0.222133\n",
      "Train Epoch: 1827 [1280/1612 (79%)] Loss: 0.389863\n",
      "Train Epoch: 1827 [1440/1612 (89%)] Loss: 0.457812\n",
      "Train Epoch: 1827 [1200/1612 (99%)] Loss: 0.077376\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1828 [0/1612 (0%)] Loss: 0.211311\n",
      "Train Epoch: 1828 [160/1612 (10%)] Loss: 0.120911\n",
      "Train Epoch: 1828 [320/1612 (20%)] Loss: 0.117571\n",
      "Train Epoch: 1828 [480/1612 (30%)] Loss: 0.295625\n",
      "Train Epoch: 1828 [640/1612 (40%)] Loss: 0.233087\n",
      "Train Epoch: 1828 [800/1612 (50%)] Loss: 0.358717\n",
      "Train Epoch: 1828 [960/1612 (59%)] Loss: 0.140569\n",
      "Train Epoch: 1828 [1120/1612 (69%)] Loss: 0.163925\n",
      "Train Epoch: 1828 [1280/1612 (79%)] Loss: 0.181235\n",
      "Train Epoch: 1828 [1440/1612 (89%)] Loss: 0.178127\n",
      "Train Epoch: 1828 [1200/1612 (99%)] Loss: 0.564764\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1829 [0/1612 (0%)] Loss: 0.366978\n",
      "Train Epoch: 1829 [160/1612 (10%)] Loss: 0.300539\n",
      "Train Epoch: 1829 [320/1612 (20%)] Loss: 0.319317\n",
      "Train Epoch: 1829 [480/1612 (30%)] Loss: 0.532916\n",
      "Train Epoch: 1829 [640/1612 (40%)] Loss: 0.329349\n",
      "Train Epoch: 1829 [800/1612 (50%)] Loss: 0.489246\n",
      "Train Epoch: 1829 [960/1612 (59%)] Loss: 0.533556\n",
      "Train Epoch: 1829 [1120/1612 (69%)] Loss: 0.176578\n",
      "Train Epoch: 1829 [1280/1612 (79%)] Loss: 0.111978\n",
      "Train Epoch: 1829 [1440/1612 (89%)] Loss: 0.199312\n",
      "Train Epoch: 1829 [1200/1612 (99%)] Loss: 0.265576\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1830 [0/1612 (0%)] Loss: 0.364811\n",
      "Train Epoch: 1830 [160/1612 (10%)] Loss: 0.273769\n",
      "Train Epoch: 1830 [320/1612 (20%)] Loss: 0.273090\n",
      "Train Epoch: 1830 [480/1612 (30%)] Loss: 0.232649\n",
      "Train Epoch: 1830 [640/1612 (40%)] Loss: 0.235950\n",
      "Train Epoch: 1830 [800/1612 (50%)] Loss: 0.423292\n",
      "Train Epoch: 1830 [960/1612 (59%)] Loss: 0.438336\n",
      "Train Epoch: 1830 [1120/1612 (69%)] Loss: 0.344812\n",
      "Train Epoch: 1830 [1280/1612 (79%)] Loss: 0.152984\n",
      "Train Epoch: 1830 [1440/1612 (89%)] Loss: 0.195912\n",
      "Train Epoch: 1830 [1200/1612 (99%)] Loss: 0.098664\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1831 [0/1612 (0%)] Loss: 0.372130\n",
      "Train Epoch: 1831 [160/1612 (10%)] Loss: 0.273446\n",
      "Train Epoch: 1831 [320/1612 (20%)] Loss: 0.197602\n",
      "Train Epoch: 1831 [480/1612 (30%)] Loss: 0.262443\n",
      "Train Epoch: 1831 [640/1612 (40%)] Loss: 0.260709\n",
      "Train Epoch: 1831 [800/1612 (50%)] Loss: 0.215183\n",
      "Train Epoch: 1831 [960/1612 (59%)] Loss: 0.363429\n",
      "Train Epoch: 1831 [1120/1612 (69%)] Loss: 0.295269\n",
      "Train Epoch: 1831 [1280/1612 (79%)] Loss: 0.214551\n",
      "Train Epoch: 1831 [1440/1612 (89%)] Loss: 0.169434\n",
      "Train Epoch: 1831 [1200/1612 (99%)] Loss: 0.671690\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1832 [0/1612 (0%)] Loss: 0.136110\n",
      "Train Epoch: 1832 [160/1612 (10%)] Loss: 0.111094\n",
      "Train Epoch: 1832 [320/1612 (20%)] Loss: 0.343479\n",
      "Train Epoch: 1832 [480/1612 (30%)] Loss: 0.469405\n",
      "Train Epoch: 1832 [640/1612 (40%)] Loss: 0.277564\n",
      "Train Epoch: 1832 [800/1612 (50%)] Loss: 0.272018\n",
      "Train Epoch: 1832 [960/1612 (59%)] Loss: 0.318157\n",
      "Train Epoch: 1832 [1120/1612 (69%)] Loss: 0.516782\n",
      "Train Epoch: 1832 [1280/1612 (79%)] Loss: 0.100595\n",
      "Train Epoch: 1832 [1440/1612 (89%)] Loss: 0.298199\n",
      "Train Epoch: 1832 [1200/1612 (99%)] Loss: 0.299096\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1833 [0/1612 (0%)] Loss: 0.397615\n",
      "Train Epoch: 1833 [160/1612 (10%)] Loss: 0.356800\n",
      "Train Epoch: 1833 [320/1612 (20%)] Loss: 0.147295\n",
      "Train Epoch: 1833 [480/1612 (30%)] Loss: 0.331963\n",
      "Train Epoch: 1833 [640/1612 (40%)] Loss: 0.629095\n",
      "Train Epoch: 1833 [800/1612 (50%)] Loss: 0.401036\n",
      "Train Epoch: 1833 [960/1612 (59%)] Loss: 0.433801\n",
      "Train Epoch: 1833 [1120/1612 (69%)] Loss: 0.123659\n",
      "Train Epoch: 1833 [1280/1612 (79%)] Loss: 0.459358\n",
      "Train Epoch: 1833 [1440/1612 (89%)] Loss: 0.115149\n",
      "Train Epoch: 1833 [1200/1612 (99%)] Loss: 0.305244\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1834 [0/1612 (0%)] Loss: 0.676053\n",
      "Train Epoch: 1834 [160/1612 (10%)] Loss: 0.267164\n",
      "Train Epoch: 1834 [320/1612 (20%)] Loss: 0.510456\n",
      "Train Epoch: 1834 [480/1612 (30%)] Loss: 0.430486\n",
      "Train Epoch: 1834 [640/1612 (40%)] Loss: 0.215065\n",
      "Train Epoch: 1834 [800/1612 (50%)] Loss: 0.124236\n",
      "Train Epoch: 1834 [960/1612 (59%)] Loss: 0.221798\n",
      "Train Epoch: 1834 [1120/1612 (69%)] Loss: 0.177518\n",
      "Train Epoch: 1834 [1280/1612 (79%)] Loss: 0.227857\n",
      "Train Epoch: 1834 [1440/1612 (89%)] Loss: 0.252656\n",
      "Train Epoch: 1834 [1200/1612 (99%)] Loss: 0.356962\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1835 [0/1612 (0%)] Loss: 0.367082\n",
      "Train Epoch: 1835 [160/1612 (10%)] Loss: 0.713397\n",
      "Train Epoch: 1835 [320/1612 (20%)] Loss: 0.354170\n",
      "Train Epoch: 1835 [480/1612 (30%)] Loss: 0.235291\n",
      "Train Epoch: 1835 [640/1612 (40%)] Loss: 0.261776\n",
      "Train Epoch: 1835 [800/1612 (50%)] Loss: 0.364953\n",
      "Train Epoch: 1835 [960/1612 (59%)] Loss: 0.386196\n",
      "Train Epoch: 1835 [1120/1612 (69%)] Loss: 0.152320\n",
      "Train Epoch: 1835 [1280/1612 (79%)] Loss: 0.161645\n",
      "Train Epoch: 1835 [1440/1612 (89%)] Loss: 0.236370\n",
      "Train Epoch: 1835 [1200/1612 (99%)] Loss: 0.199082\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1836 [0/1612 (0%)] Loss: 0.239228\n",
      "Train Epoch: 1836 [160/1612 (10%)] Loss: 0.238217\n",
      "Train Epoch: 1836 [320/1612 (20%)] Loss: 0.241749\n",
      "Train Epoch: 1836 [480/1612 (30%)] Loss: 0.176468\n",
      "Train Epoch: 1836 [640/1612 (40%)] Loss: 0.359175\n",
      "Train Epoch: 1836 [800/1612 (50%)] Loss: 0.201057\n",
      "Train Epoch: 1836 [960/1612 (59%)] Loss: 0.678513\n",
      "Train Epoch: 1836 [1120/1612 (69%)] Loss: 0.236560\n",
      "Train Epoch: 1836 [1280/1612 (79%)] Loss: 0.163194\n",
      "Train Epoch: 1836 [1440/1612 (89%)] Loss: 0.385406\n",
      "Train Epoch: 1836 [1200/1612 (99%)] Loss: 0.534812\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1837 [0/1612 (0%)] Loss: 0.348014\n",
      "Train Epoch: 1837 [160/1612 (10%)] Loss: 0.193600\n",
      "Train Epoch: 1837 [320/1612 (20%)] Loss: 0.478137\n",
      "Train Epoch: 1837 [480/1612 (30%)] Loss: 0.378534\n",
      "Train Epoch: 1837 [640/1612 (40%)] Loss: 0.132606\n",
      "Train Epoch: 1837 [800/1612 (50%)] Loss: 0.184518\n",
      "Train Epoch: 1837 [960/1612 (59%)] Loss: 0.530229\n",
      "Train Epoch: 1837 [1120/1612 (69%)] Loss: 0.289708\n",
      "Train Epoch: 1837 [1280/1612 (79%)] Loss: 0.385614\n",
      "Train Epoch: 1837 [1440/1612 (89%)] Loss: 0.309497\n",
      "Train Epoch: 1837 [1200/1612 (99%)] Loss: 0.262532\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1838 [0/1612 (0%)] Loss: 0.276500\n",
      "Train Epoch: 1838 [160/1612 (10%)] Loss: 0.218144\n",
      "Train Epoch: 1838 [320/1612 (20%)] Loss: 0.174054\n",
      "Train Epoch: 1838 [480/1612 (30%)] Loss: 0.199741\n",
      "Train Epoch: 1838 [640/1612 (40%)] Loss: 0.439666\n",
      "Train Epoch: 1838 [800/1612 (50%)] Loss: 0.246703\n",
      "Train Epoch: 1838 [960/1612 (59%)] Loss: 0.116603\n",
      "Train Epoch: 1838 [1120/1612 (69%)] Loss: 0.288651\n",
      "Train Epoch: 1838 [1280/1612 (79%)] Loss: 0.635513\n",
      "Train Epoch: 1838 [1440/1612 (89%)] Loss: 0.451694\n",
      "Train Epoch: 1838 [1200/1612 (99%)] Loss: 0.691947\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1839 [0/1612 (0%)] Loss: 0.335526\n",
      "Train Epoch: 1839 [160/1612 (10%)] Loss: 0.181838\n",
      "Train Epoch: 1839 [320/1612 (20%)] Loss: 0.472485\n",
      "Train Epoch: 1839 [480/1612 (30%)] Loss: 0.290843\n",
      "Train Epoch: 1839 [640/1612 (40%)] Loss: 0.270364\n",
      "Train Epoch: 1839 [800/1612 (50%)] Loss: 0.242229\n",
      "Train Epoch: 1839 [960/1612 (59%)] Loss: 0.337926\n",
      "Train Epoch: 1839 [1120/1612 (69%)] Loss: 0.364866\n",
      "Train Epoch: 1839 [1280/1612 (79%)] Loss: 0.336809\n",
      "Train Epoch: 1839 [1440/1612 (89%)] Loss: 0.389662\n",
      "Train Epoch: 1839 [1200/1612 (99%)] Loss: 0.272269\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1840 [0/1612 (0%)] Loss: 0.309579\n",
      "Train Epoch: 1840 [160/1612 (10%)] Loss: 0.270984\n",
      "Train Epoch: 1840 [320/1612 (20%)] Loss: 0.354214\n",
      "Train Epoch: 1840 [480/1612 (30%)] Loss: 0.345154\n",
      "Train Epoch: 1840 [640/1612 (40%)] Loss: 0.281557\n",
      "Train Epoch: 1840 [800/1612 (50%)] Loss: 0.287233\n",
      "Train Epoch: 1840 [960/1612 (59%)] Loss: 0.173506\n",
      "Train Epoch: 1840 [1120/1612 (69%)] Loss: 0.530349\n",
      "Train Epoch: 1840 [1280/1612 (79%)] Loss: 0.261101\n",
      "Train Epoch: 1840 [1440/1612 (89%)] Loss: 0.340109\n",
      "Train Epoch: 1840 [1200/1612 (99%)] Loss: 0.192113\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1841 [0/1612 (0%)] Loss: 0.097796\n",
      "Train Epoch: 1841 [160/1612 (10%)] Loss: 0.268297\n",
      "Train Epoch: 1841 [320/1612 (20%)] Loss: 0.359311\n",
      "Train Epoch: 1841 [480/1612 (30%)] Loss: 0.202252\n",
      "Train Epoch: 1841 [640/1612 (40%)] Loss: 0.210921\n",
      "Train Epoch: 1841 [800/1612 (50%)] Loss: 0.348471\n",
      "Train Epoch: 1841 [960/1612 (59%)] Loss: 0.430862\n",
      "Train Epoch: 1841 [1120/1612 (69%)] Loss: 0.279807\n",
      "Train Epoch: 1841 [1280/1612 (79%)] Loss: 0.449692\n",
      "Train Epoch: 1841 [1440/1612 (89%)] Loss: 0.402531\n",
      "Train Epoch: 1841 [1200/1612 (99%)] Loss: 0.418772\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1842 [0/1612 (0%)] Loss: 0.145816\n",
      "Train Epoch: 1842 [160/1612 (10%)] Loss: 0.182150\n",
      "Train Epoch: 1842 [320/1612 (20%)] Loss: 0.227172\n",
      "Train Epoch: 1842 [480/1612 (30%)] Loss: 0.180486\n",
      "Train Epoch: 1842 [640/1612 (40%)] Loss: 0.559926\n",
      "Train Epoch: 1842 [800/1612 (50%)] Loss: 0.204535\n",
      "Train Epoch: 1842 [960/1612 (59%)] Loss: 0.414656\n",
      "Train Epoch: 1842 [1120/1612 (69%)] Loss: 0.121857\n",
      "Train Epoch: 1842 [1280/1612 (79%)] Loss: 0.108786\n",
      "Train Epoch: 1842 [1440/1612 (89%)] Loss: 0.251683\n",
      "Train Epoch: 1842 [1200/1612 (99%)] Loss: 0.334538\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1843 [0/1612 (0%)] Loss: 0.212958\n",
      "Train Epoch: 1843 [160/1612 (10%)] Loss: 0.426498\n",
      "Train Epoch: 1843 [320/1612 (20%)] Loss: 0.357275\n",
      "Train Epoch: 1843 [480/1612 (30%)] Loss: 0.087899\n",
      "Train Epoch: 1843 [640/1612 (40%)] Loss: 0.250979\n",
      "Train Epoch: 1843 [800/1612 (50%)] Loss: 0.141914\n",
      "Train Epoch: 1843 [960/1612 (59%)] Loss: 0.275232\n",
      "Train Epoch: 1843 [1120/1612 (69%)] Loss: 0.248960\n",
      "Train Epoch: 1843 [1280/1612 (79%)] Loss: 0.400719\n",
      "Train Epoch: 1843 [1440/1612 (89%)] Loss: 0.202531\n",
      "Train Epoch: 1843 [1200/1612 (99%)] Loss: 0.470438\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1844 [0/1612 (0%)] Loss: 0.308993\n",
      "Train Epoch: 1844 [160/1612 (10%)] Loss: 0.381355\n",
      "Train Epoch: 1844 [320/1612 (20%)] Loss: 0.295463\n",
      "Train Epoch: 1844 [480/1612 (30%)] Loss: 0.403147\n",
      "Train Epoch: 1844 [640/1612 (40%)] Loss: 0.183746\n",
      "Train Epoch: 1844 [800/1612 (50%)] Loss: 0.361482\n",
      "Train Epoch: 1844 [960/1612 (59%)] Loss: 0.261993\n",
      "Train Epoch: 1844 [1120/1612 (69%)] Loss: 0.317873\n",
      "Train Epoch: 1844 [1280/1612 (79%)] Loss: 0.288550\n",
      "Train Epoch: 1844 [1440/1612 (89%)] Loss: 0.287270\n",
      "Train Epoch: 1844 [1200/1612 (99%)] Loss: 0.101660\n",
      "\n",
      "Test set: Average loss: 0.0340, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1845 [0/1612 (0%)] Loss: 0.236646\n",
      "Train Epoch: 1845 [160/1612 (10%)] Loss: 0.135849\n",
      "Train Epoch: 1845 [320/1612 (20%)] Loss: 0.462953\n",
      "Train Epoch: 1845 [480/1612 (30%)] Loss: 0.186316\n",
      "Train Epoch: 1845 [640/1612 (40%)] Loss: 0.273014\n",
      "Train Epoch: 1845 [800/1612 (50%)] Loss: 0.357915\n",
      "Train Epoch: 1845 [960/1612 (59%)] Loss: 0.296044\n",
      "Train Epoch: 1845 [1120/1612 (69%)] Loss: 0.288226\n",
      "Train Epoch: 1845 [1280/1612 (79%)] Loss: 0.317422\n",
      "Train Epoch: 1845 [1440/1612 (89%)] Loss: 0.264993\n",
      "Train Epoch: 1845 [1200/1612 (99%)] Loss: 0.380657\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1846 [0/1612 (0%)] Loss: 0.276919\n",
      "Train Epoch: 1846 [160/1612 (10%)] Loss: 0.651723\n",
      "Train Epoch: 1846 [320/1612 (20%)] Loss: 0.275883\n",
      "Train Epoch: 1846 [480/1612 (30%)] Loss: 0.487230\n",
      "Train Epoch: 1846 [640/1612 (40%)] Loss: 0.369123\n",
      "Train Epoch: 1846 [800/1612 (50%)] Loss: 0.272252\n",
      "Train Epoch: 1846 [960/1612 (59%)] Loss: 0.164455\n",
      "Train Epoch: 1846 [1120/1612 (69%)] Loss: 0.316465\n",
      "Train Epoch: 1846 [1280/1612 (79%)] Loss: 0.263875\n",
      "Train Epoch: 1846 [1440/1612 (89%)] Loss: 0.218456\n",
      "Train Epoch: 1846 [1200/1612 (99%)] Loss: 0.274714\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1847 [0/1612 (0%)] Loss: 0.376644\n",
      "Train Epoch: 1847 [160/1612 (10%)] Loss: 0.222928\n",
      "Train Epoch: 1847 [320/1612 (20%)] Loss: 0.287967\n",
      "Train Epoch: 1847 [480/1612 (30%)] Loss: 0.207451\n",
      "Train Epoch: 1847 [640/1612 (40%)] Loss: 0.314921\n",
      "Train Epoch: 1847 [800/1612 (50%)] Loss: 0.336035\n",
      "Train Epoch: 1847 [960/1612 (59%)] Loss: 0.279847\n",
      "Train Epoch: 1847 [1120/1612 (69%)] Loss: 0.140471\n",
      "Train Epoch: 1847 [1280/1612 (79%)] Loss: 0.260429\n",
      "Train Epoch: 1847 [1440/1612 (89%)] Loss: 0.576312\n",
      "Train Epoch: 1847 [1200/1612 (99%)] Loss: 0.309724\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1848 [0/1612 (0%)] Loss: 0.239603\n",
      "Train Epoch: 1848 [160/1612 (10%)] Loss: 0.242803\n",
      "Train Epoch: 1848 [320/1612 (20%)] Loss: 0.298894\n",
      "Train Epoch: 1848 [480/1612 (30%)] Loss: 0.347149\n",
      "Train Epoch: 1848 [640/1612 (40%)] Loss: 0.170273\n",
      "Train Epoch: 1848 [800/1612 (50%)] Loss: 0.310686\n",
      "Train Epoch: 1848 [960/1612 (59%)] Loss: 0.262078\n",
      "Train Epoch: 1848 [1120/1612 (69%)] Loss: 0.379940\n",
      "Train Epoch: 1848 [1280/1612 (79%)] Loss: 0.112025\n",
      "Train Epoch: 1848 [1440/1612 (89%)] Loss: 0.376907\n",
      "Train Epoch: 1848 [1200/1612 (99%)] Loss: 0.272731\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1849 [0/1612 (0%)] Loss: 0.299915\n",
      "Train Epoch: 1849 [160/1612 (10%)] Loss: 0.358412\n",
      "Train Epoch: 1849 [320/1612 (20%)] Loss: 0.272254\n",
      "Train Epoch: 1849 [480/1612 (30%)] Loss: 0.171712\n",
      "Train Epoch: 1849 [640/1612 (40%)] Loss: 0.570080\n",
      "Train Epoch: 1849 [800/1612 (50%)] Loss: 0.289872\n",
      "Train Epoch: 1849 [960/1612 (59%)] Loss: 0.153490\n",
      "Train Epoch: 1849 [1120/1612 (69%)] Loss: 0.344314\n",
      "Train Epoch: 1849 [1280/1612 (79%)] Loss: 0.215186\n",
      "Train Epoch: 1849 [1440/1612 (89%)] Loss: 0.387137\n",
      "Train Epoch: 1849 [1200/1612 (99%)] Loss: 0.476232\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1850 [0/1612 (0%)] Loss: 0.287858\n",
      "Train Epoch: 1850 [160/1612 (10%)] Loss: 0.220648\n",
      "Train Epoch: 1850 [320/1612 (20%)] Loss: 0.307770\n",
      "Train Epoch: 1850 [480/1612 (30%)] Loss: 0.155561\n",
      "Train Epoch: 1850 [640/1612 (40%)] Loss: 0.239903\n",
      "Train Epoch: 1850 [800/1612 (50%)] Loss: 0.326285\n",
      "Train Epoch: 1850 [960/1612 (59%)] Loss: 0.227751\n",
      "Train Epoch: 1850 [1120/1612 (69%)] Loss: 0.148176\n",
      "Train Epoch: 1850 [1280/1612 (79%)] Loss: 0.247166\n",
      "Train Epoch: 1850 [1440/1612 (89%)] Loss: 0.451187\n",
      "Train Epoch: 1850 [1200/1612 (99%)] Loss: 0.534565\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1851 [0/1612 (0%)] Loss: 0.147508\n",
      "Train Epoch: 1851 [160/1612 (10%)] Loss: 0.305918\n",
      "Train Epoch: 1851 [320/1612 (20%)] Loss: 0.348178\n",
      "Train Epoch: 1851 [480/1612 (30%)] Loss: 0.275011\n",
      "Train Epoch: 1851 [640/1612 (40%)] Loss: 0.343558\n",
      "Train Epoch: 1851 [800/1612 (50%)] Loss: 0.249885\n",
      "Train Epoch: 1851 [960/1612 (59%)] Loss: 0.253343\n",
      "Train Epoch: 1851 [1120/1612 (69%)] Loss: 0.232336\n",
      "Train Epoch: 1851 [1280/1612 (79%)] Loss: 0.287142\n",
      "Train Epoch: 1851 [1440/1612 (89%)] Loss: 0.097672\n",
      "Train Epoch: 1851 [1200/1612 (99%)] Loss: 0.165564\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1852 [0/1612 (0%)] Loss: 0.231105\n",
      "Train Epoch: 1852 [160/1612 (10%)] Loss: 0.494710\n",
      "Train Epoch: 1852 [320/1612 (20%)] Loss: 0.269658\n",
      "Train Epoch: 1852 [480/1612 (30%)] Loss: 0.207287\n",
      "Train Epoch: 1852 [640/1612 (40%)] Loss: 0.419431\n",
      "Train Epoch: 1852 [800/1612 (50%)] Loss: 0.132315\n",
      "Train Epoch: 1852 [960/1612 (59%)] Loss: 0.219850\n",
      "Train Epoch: 1852 [1120/1612 (69%)] Loss: 0.219786\n",
      "Train Epoch: 1852 [1280/1612 (79%)] Loss: 0.317245\n",
      "Train Epoch: 1852 [1440/1612 (89%)] Loss: 0.243526\n",
      "Train Epoch: 1852 [1200/1612 (99%)] Loss: 0.422012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1853 [0/1612 (0%)] Loss: 0.533561\n",
      "Train Epoch: 1853 [160/1612 (10%)] Loss: 0.314203\n",
      "Train Epoch: 1853 [320/1612 (20%)] Loss: 0.473913\n",
      "Train Epoch: 1853 [480/1612 (30%)] Loss: 0.216180\n",
      "Train Epoch: 1853 [640/1612 (40%)] Loss: 0.195601\n",
      "Train Epoch: 1853 [800/1612 (50%)] Loss: 0.377202\n",
      "Train Epoch: 1853 [960/1612 (59%)] Loss: 0.543223\n",
      "Train Epoch: 1853 [1120/1612 (69%)] Loss: 0.236594\n",
      "Train Epoch: 1853 [1280/1612 (79%)] Loss: 0.402565\n",
      "Train Epoch: 1853 [1440/1612 (89%)] Loss: 0.520643\n",
      "Train Epoch: 1853 [1200/1612 (99%)] Loss: 0.482145\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1854 [0/1612 (0%)] Loss: 0.539388\n",
      "Train Epoch: 1854 [160/1612 (10%)] Loss: 0.349834\n",
      "Train Epoch: 1854 [320/1612 (20%)] Loss: 0.127207\n",
      "Train Epoch: 1854 [480/1612 (30%)] Loss: 0.321496\n",
      "Train Epoch: 1854 [640/1612 (40%)] Loss: 0.367334\n",
      "Train Epoch: 1854 [800/1612 (50%)] Loss: 0.307135\n",
      "Train Epoch: 1854 [960/1612 (59%)] Loss: 0.394890\n",
      "Train Epoch: 1854 [1120/1612 (69%)] Loss: 0.393261\n",
      "Train Epoch: 1854 [1280/1612 (79%)] Loss: 0.253621\n",
      "Train Epoch: 1854 [1440/1612 (89%)] Loss: 0.187800\n",
      "Train Epoch: 1854 [1200/1612 (99%)] Loss: 0.867021\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1855 [0/1612 (0%)] Loss: 0.218430\n",
      "Train Epoch: 1855 [160/1612 (10%)] Loss: 0.324162\n",
      "Train Epoch: 1855 [320/1612 (20%)] Loss: 0.214844\n",
      "Train Epoch: 1855 [480/1612 (30%)] Loss: 0.337905\n",
      "Train Epoch: 1855 [640/1612 (40%)] Loss: 0.397747\n",
      "Train Epoch: 1855 [800/1612 (50%)] Loss: 0.310135\n",
      "Train Epoch: 1855 [960/1612 (59%)] Loss: 0.182369\n",
      "Train Epoch: 1855 [1120/1612 (69%)] Loss: 0.426764\n",
      "Train Epoch: 1855 [1280/1612 (79%)] Loss: 0.439109\n",
      "Train Epoch: 1855 [1440/1612 (89%)] Loss: 0.342506\n",
      "Train Epoch: 1855 [1200/1612 (99%)] Loss: 0.102867\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1856 [0/1612 (0%)] Loss: 0.474928\n",
      "Train Epoch: 1856 [160/1612 (10%)] Loss: 0.249760\n",
      "Train Epoch: 1856 [320/1612 (20%)] Loss: 0.218769\n",
      "Train Epoch: 1856 [480/1612 (30%)] Loss: 0.347312\n",
      "Train Epoch: 1856 [640/1612 (40%)] Loss: 0.415921\n",
      "Train Epoch: 1856 [800/1612 (50%)] Loss: 0.283742\n",
      "Train Epoch: 1856 [960/1612 (59%)] Loss: 0.124851\n",
      "Train Epoch: 1856 [1120/1612 (69%)] Loss: 0.367875\n",
      "Train Epoch: 1856 [1280/1612 (79%)] Loss: 0.600174\n",
      "Train Epoch: 1856 [1440/1612 (89%)] Loss: 0.308705\n",
      "Train Epoch: 1856 [1200/1612 (99%)] Loss: 0.455945\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1857 [0/1612 (0%)] Loss: 0.163966\n",
      "Train Epoch: 1857 [160/1612 (10%)] Loss: 0.265740\n",
      "Train Epoch: 1857 [320/1612 (20%)] Loss: 0.329727\n",
      "Train Epoch: 1857 [480/1612 (30%)] Loss: 0.312157\n",
      "Train Epoch: 1857 [640/1612 (40%)] Loss: 0.333121\n",
      "Train Epoch: 1857 [800/1612 (50%)] Loss: 0.223880\n",
      "Train Epoch: 1857 [960/1612 (59%)] Loss: 0.352893\n",
      "Train Epoch: 1857 [1120/1612 (69%)] Loss: 0.330641\n",
      "Train Epoch: 1857 [1280/1612 (79%)] Loss: 0.297892\n",
      "Train Epoch: 1857 [1440/1612 (89%)] Loss: 0.250811\n",
      "Train Epoch: 1857 [1200/1612 (99%)] Loss: 0.082838\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1858 [0/1612 (0%)] Loss: 0.323015\n",
      "Train Epoch: 1858 [160/1612 (10%)] Loss: 0.348528\n",
      "Train Epoch: 1858 [320/1612 (20%)] Loss: 0.175198\n",
      "Train Epoch: 1858 [480/1612 (30%)] Loss: 0.460326\n",
      "Train Epoch: 1858 [640/1612 (40%)] Loss: 0.192198\n",
      "Train Epoch: 1858 [800/1612 (50%)] Loss: 0.301989\n",
      "Train Epoch: 1858 [960/1612 (59%)] Loss: 0.136094\n",
      "Train Epoch: 1858 [1120/1612 (69%)] Loss: 0.127830\n",
      "Train Epoch: 1858 [1280/1612 (79%)] Loss: 0.280493\n",
      "Train Epoch: 1858 [1440/1612 (89%)] Loss: 0.373018\n",
      "Train Epoch: 1858 [1200/1612 (99%)] Loss: 0.258544\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1859 [0/1612 (0%)] Loss: 0.337686\n",
      "Train Epoch: 1859 [160/1612 (10%)] Loss: 0.241727\n",
      "Train Epoch: 1859 [320/1612 (20%)] Loss: 0.296344\n",
      "Train Epoch: 1859 [480/1612 (30%)] Loss: 0.265861\n",
      "Train Epoch: 1859 [640/1612 (40%)] Loss: 0.589556\n",
      "Train Epoch: 1859 [800/1612 (50%)] Loss: 0.197146\n",
      "Train Epoch: 1859 [960/1612 (59%)] Loss: 0.210447\n",
      "Train Epoch: 1859 [1120/1612 (69%)] Loss: 0.151074\n",
      "Train Epoch: 1859 [1280/1612 (79%)] Loss: 0.334865\n",
      "Train Epoch: 1859 [1440/1612 (89%)] Loss: 0.280022\n",
      "Train Epoch: 1859 [1200/1612 (99%)] Loss: 0.457540\n",
      "\n",
      "Test set: Average loss: 0.0294, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1860 [0/1612 (0%)] Loss: 0.393820\n",
      "Train Epoch: 1860 [160/1612 (10%)] Loss: 0.141150\n",
      "Train Epoch: 1860 [320/1612 (20%)] Loss: 0.326675\n",
      "Train Epoch: 1860 [480/1612 (30%)] Loss: 0.144889\n",
      "Train Epoch: 1860 [640/1612 (40%)] Loss: 0.146420\n",
      "Train Epoch: 1860 [800/1612 (50%)] Loss: 0.321828\n",
      "Train Epoch: 1860 [960/1612 (59%)] Loss: 0.344270\n",
      "Train Epoch: 1860 [1120/1612 (69%)] Loss: 0.268002\n",
      "Train Epoch: 1860 [1280/1612 (79%)] Loss: 0.260614\n",
      "Train Epoch: 1860 [1440/1612 (89%)] Loss: 0.155075\n",
      "Train Epoch: 1860 [1200/1612 (99%)] Loss: 0.206047\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1861 [0/1612 (0%)] Loss: 0.469051\n",
      "Train Epoch: 1861 [160/1612 (10%)] Loss: 0.263610\n",
      "Train Epoch: 1861 [320/1612 (20%)] Loss: 0.240354\n",
      "Train Epoch: 1861 [480/1612 (30%)] Loss: 0.361904\n",
      "Train Epoch: 1861 [640/1612 (40%)] Loss: 0.317803\n",
      "Train Epoch: 1861 [800/1612 (50%)] Loss: 0.343647\n",
      "Train Epoch: 1861 [960/1612 (59%)] Loss: 0.174910\n",
      "Train Epoch: 1861 [1120/1612 (69%)] Loss: 0.084971\n",
      "Train Epoch: 1861 [1280/1612 (79%)] Loss: 0.323931\n",
      "Train Epoch: 1861 [1440/1612 (89%)] Loss: 0.410599\n",
      "Train Epoch: 1861 [1200/1612 (99%)] Loss: 0.337317\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1862 [0/1612 (0%)] Loss: 0.367680\n",
      "Train Epoch: 1862 [160/1612 (10%)] Loss: 0.229325\n",
      "Train Epoch: 1862 [320/1612 (20%)] Loss: 0.224013\n",
      "Train Epoch: 1862 [480/1612 (30%)] Loss: 0.314336\n",
      "Train Epoch: 1862 [640/1612 (40%)] Loss: 0.326784\n",
      "Train Epoch: 1862 [800/1612 (50%)] Loss: 0.185462\n",
      "Train Epoch: 1862 [960/1612 (59%)] Loss: 0.468195\n",
      "Train Epoch: 1862 [1120/1612 (69%)] Loss: 0.357572\n",
      "Train Epoch: 1862 [1280/1612 (79%)] Loss: 0.532429\n",
      "Train Epoch: 1862 [1440/1612 (89%)] Loss: 0.444029\n",
      "Train Epoch: 1862 [1200/1612 (99%)] Loss: 0.294120\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1863 [0/1612 (0%)] Loss: 0.378985\n",
      "Train Epoch: 1863 [160/1612 (10%)] Loss: 0.379931\n",
      "Train Epoch: 1863 [320/1612 (20%)] Loss: 0.185861\n",
      "Train Epoch: 1863 [480/1612 (30%)] Loss: 0.292044\n",
      "Train Epoch: 1863 [640/1612 (40%)] Loss: 0.126438\n",
      "Train Epoch: 1863 [800/1612 (50%)] Loss: 0.360060\n",
      "Train Epoch: 1863 [960/1612 (59%)] Loss: 0.258635\n",
      "Train Epoch: 1863 [1120/1612 (69%)] Loss: 0.240640\n",
      "Train Epoch: 1863 [1280/1612 (79%)] Loss: 0.253859\n",
      "Train Epoch: 1863 [1440/1612 (89%)] Loss: 0.309195\n",
      "Train Epoch: 1863 [1200/1612 (99%)] Loss: 0.106032\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1864 [0/1612 (0%)] Loss: 0.191142\n",
      "Train Epoch: 1864 [160/1612 (10%)] Loss: 0.205602\n",
      "Train Epoch: 1864 [320/1612 (20%)] Loss: 0.391297\n",
      "Train Epoch: 1864 [480/1612 (30%)] Loss: 0.328708\n",
      "Train Epoch: 1864 [640/1612 (40%)] Loss: 0.177897\n",
      "Train Epoch: 1864 [800/1612 (50%)] Loss: 0.238648\n",
      "Train Epoch: 1864 [960/1612 (59%)] Loss: 0.241715\n",
      "Train Epoch: 1864 [1120/1612 (69%)] Loss: 0.387894\n",
      "Train Epoch: 1864 [1280/1612 (79%)] Loss: 0.345975\n",
      "Train Epoch: 1864 [1440/1612 (89%)] Loss: 0.321439\n",
      "Train Epoch: 1864 [1200/1612 (99%)] Loss: 0.420420\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1865 [0/1612 (0%)] Loss: 0.258515\n",
      "Train Epoch: 1865 [160/1612 (10%)] Loss: 0.596754\n",
      "Train Epoch: 1865 [320/1612 (20%)] Loss: 0.280057\n",
      "Train Epoch: 1865 [480/1612 (30%)] Loss: 0.426698\n",
      "Train Epoch: 1865 [640/1612 (40%)] Loss: 0.177916\n",
      "Train Epoch: 1865 [800/1612 (50%)] Loss: 0.474856\n",
      "Train Epoch: 1865 [960/1612 (59%)] Loss: 0.317304\n",
      "Train Epoch: 1865 [1120/1612 (69%)] Loss: 0.248862\n",
      "Train Epoch: 1865 [1280/1612 (79%)] Loss: 0.270916\n",
      "Train Epoch: 1865 [1440/1612 (89%)] Loss: 0.425777\n",
      "Train Epoch: 1865 [1200/1612 (99%)] Loss: 0.424842\n",
      "\n",
      "Test set: Average loss: 0.0299, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1866 [0/1612 (0%)] Loss: 0.267997\n",
      "Train Epoch: 1866 [160/1612 (10%)] Loss: 0.392870\n",
      "Train Epoch: 1866 [320/1612 (20%)] Loss: 0.352204\n",
      "Train Epoch: 1866 [480/1612 (30%)] Loss: 0.356238\n",
      "Train Epoch: 1866 [640/1612 (40%)] Loss: 0.323019\n",
      "Train Epoch: 1866 [800/1612 (50%)] Loss: 0.164273\n",
      "Train Epoch: 1866 [960/1612 (59%)] Loss: 0.199711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1866 [1120/1612 (69%)] Loss: 0.618544\n",
      "Train Epoch: 1866 [1280/1612 (79%)] Loss: 0.260827\n",
      "Train Epoch: 1866 [1440/1612 (89%)] Loss: 0.244727\n",
      "Train Epoch: 1866 [1200/1612 (99%)] Loss: 0.659101\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1867 [0/1612 (0%)] Loss: 0.575072\n",
      "Train Epoch: 1867 [160/1612 (10%)] Loss: 0.328549\n",
      "Train Epoch: 1867 [320/1612 (20%)] Loss: 0.299640\n",
      "Train Epoch: 1867 [480/1612 (30%)] Loss: 0.401671\n",
      "Train Epoch: 1867 [640/1612 (40%)] Loss: 0.147995\n",
      "Train Epoch: 1867 [800/1612 (50%)] Loss: 0.152695\n",
      "Train Epoch: 1867 [960/1612 (59%)] Loss: 0.229610\n",
      "Train Epoch: 1867 [1120/1612 (69%)] Loss: 0.272099\n",
      "Train Epoch: 1867 [1280/1612 (79%)] Loss: 0.238169\n",
      "Train Epoch: 1867 [1440/1612 (89%)] Loss: 0.202735\n",
      "Train Epoch: 1867 [1200/1612 (99%)] Loss: 0.124793\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1868 [0/1612 (0%)] Loss: 0.143139\n",
      "Train Epoch: 1868 [160/1612 (10%)] Loss: 0.086641\n",
      "Train Epoch: 1868 [320/1612 (20%)] Loss: 0.227151\n",
      "Train Epoch: 1868 [480/1612 (30%)] Loss: 0.368661\n",
      "Train Epoch: 1868 [640/1612 (40%)] Loss: 0.349595\n",
      "Train Epoch: 1868 [800/1612 (50%)] Loss: 0.174058\n",
      "Train Epoch: 1868 [960/1612 (59%)] Loss: 0.275047\n",
      "Train Epoch: 1868 [1120/1612 (69%)] Loss: 0.148892\n",
      "Train Epoch: 1868 [1280/1612 (79%)] Loss: 0.395744\n",
      "Train Epoch: 1868 [1440/1612 (89%)] Loss: 0.493879\n",
      "Train Epoch: 1868 [1200/1612 (99%)] Loss: 0.394068\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1869 [0/1612 (0%)] Loss: 0.223228\n",
      "Train Epoch: 1869 [160/1612 (10%)] Loss: 0.294307\n",
      "Train Epoch: 1869 [320/1612 (20%)] Loss: 0.440921\n",
      "Train Epoch: 1869 [480/1612 (30%)] Loss: 0.207287\n",
      "Train Epoch: 1869 [640/1612 (40%)] Loss: 0.116373\n",
      "Train Epoch: 1869 [800/1612 (50%)] Loss: 0.303187\n",
      "Train Epoch: 1869 [960/1612 (59%)] Loss: 0.155947\n",
      "Train Epoch: 1869 [1120/1612 (69%)] Loss: 0.227493\n",
      "Train Epoch: 1869 [1280/1612 (79%)] Loss: 0.412148\n",
      "Train Epoch: 1869 [1440/1612 (89%)] Loss: 0.154585\n",
      "Train Epoch: 1869 [1200/1612 (99%)] Loss: 0.380593\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1870 [0/1612 (0%)] Loss: 0.202373\n",
      "Train Epoch: 1870 [160/1612 (10%)] Loss: 0.122987\n",
      "Train Epoch: 1870 [320/1612 (20%)] Loss: 0.213867\n",
      "Train Epoch: 1870 [480/1612 (30%)] Loss: 0.341128\n",
      "Train Epoch: 1870 [640/1612 (40%)] Loss: 0.258011\n",
      "Train Epoch: 1870 [800/1612 (50%)] Loss: 0.154460\n",
      "Train Epoch: 1870 [960/1612 (59%)] Loss: 0.318351\n",
      "Train Epoch: 1870 [1120/1612 (69%)] Loss: 0.361388\n",
      "Train Epoch: 1870 [1280/1612 (79%)] Loss: 0.399277\n",
      "Train Epoch: 1870 [1440/1612 (89%)] Loss: 0.313758\n",
      "Train Epoch: 1870 [1200/1612 (99%)] Loss: 0.321758\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1871 [0/1612 (0%)] Loss: 0.276406\n",
      "Train Epoch: 1871 [160/1612 (10%)] Loss: 0.334527\n",
      "Train Epoch: 1871 [320/1612 (20%)] Loss: 0.151859\n",
      "Train Epoch: 1871 [480/1612 (30%)] Loss: 0.174285\n",
      "Train Epoch: 1871 [640/1612 (40%)] Loss: 0.336458\n",
      "Train Epoch: 1871 [800/1612 (50%)] Loss: 0.415204\n",
      "Train Epoch: 1871 [960/1612 (59%)] Loss: 0.112496\n",
      "Train Epoch: 1871 [1120/1612 (69%)] Loss: 0.165533\n",
      "Train Epoch: 1871 [1280/1612 (79%)] Loss: 0.180064\n",
      "Train Epoch: 1871 [1440/1612 (89%)] Loss: 0.167248\n",
      "Train Epoch: 1871 [1200/1612 (99%)] Loss: 0.381229\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1872 [0/1612 (0%)] Loss: 0.207416\n",
      "Train Epoch: 1872 [160/1612 (10%)] Loss: 0.165752\n",
      "Train Epoch: 1872 [320/1612 (20%)] Loss: 0.275523\n",
      "Train Epoch: 1872 [480/1612 (30%)] Loss: 0.241329\n",
      "Train Epoch: 1872 [640/1612 (40%)] Loss: 0.227921\n",
      "Train Epoch: 1872 [800/1612 (50%)] Loss: 0.369058\n",
      "Train Epoch: 1872 [960/1612 (59%)] Loss: 0.405525\n",
      "Train Epoch: 1872 [1120/1612 (69%)] Loss: 0.236588\n",
      "Train Epoch: 1872 [1280/1612 (79%)] Loss: 0.228543\n",
      "Train Epoch: 1872 [1440/1612 (89%)] Loss: 0.421467\n",
      "Train Epoch: 1872 [1200/1612 (99%)] Loss: 0.569471\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1873 [0/1612 (0%)] Loss: 0.297757\n",
      "Train Epoch: 1873 [160/1612 (10%)] Loss: 0.178213\n",
      "Train Epoch: 1873 [320/1612 (20%)] Loss: 0.274346\n",
      "Train Epoch: 1873 [480/1612 (30%)] Loss: 0.282057\n",
      "Train Epoch: 1873 [640/1612 (40%)] Loss: 0.281763\n",
      "Train Epoch: 1873 [800/1612 (50%)] Loss: 0.321383\n",
      "Train Epoch: 1873 [960/1612 (59%)] Loss: 0.283917\n",
      "Train Epoch: 1873 [1120/1612 (69%)] Loss: 0.412915\n",
      "Train Epoch: 1873 [1280/1612 (79%)] Loss: 0.185633\n",
      "Train Epoch: 1873 [1440/1612 (89%)] Loss: 0.321409\n",
      "Train Epoch: 1873 [1200/1612 (99%)] Loss: 0.328338\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1874 [0/1612 (0%)] Loss: 0.345896\n",
      "Train Epoch: 1874 [160/1612 (10%)] Loss: 0.211004\n",
      "Train Epoch: 1874 [320/1612 (20%)] Loss: 0.258151\n",
      "Train Epoch: 1874 [480/1612 (30%)] Loss: 0.398698\n",
      "Train Epoch: 1874 [640/1612 (40%)] Loss: 0.132732\n",
      "Train Epoch: 1874 [800/1612 (50%)] Loss: 0.327921\n",
      "Train Epoch: 1874 [960/1612 (59%)] Loss: 0.317748\n",
      "Train Epoch: 1874 [1120/1612 (69%)] Loss: 0.424835\n",
      "Train Epoch: 1874 [1280/1612 (79%)] Loss: 0.449330\n",
      "Train Epoch: 1874 [1440/1612 (89%)] Loss: 0.212718\n",
      "Train Epoch: 1874 [1200/1612 (99%)] Loss: 0.253891\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1875 [0/1612 (0%)] Loss: 0.207469\n",
      "Train Epoch: 1875 [160/1612 (10%)] Loss: 0.085399\n",
      "Train Epoch: 1875 [320/1612 (20%)] Loss: 0.261196\n",
      "Train Epoch: 1875 [480/1612 (30%)] Loss: 0.222291\n",
      "Train Epoch: 1875 [640/1612 (40%)] Loss: 0.435595\n",
      "Train Epoch: 1875 [800/1612 (50%)] Loss: 0.155881\n",
      "Train Epoch: 1875 [960/1612 (59%)] Loss: 0.348972\n",
      "Train Epoch: 1875 [1120/1612 (69%)] Loss: 0.335033\n",
      "Train Epoch: 1875 [1280/1612 (79%)] Loss: 0.406823\n",
      "Train Epoch: 1875 [1440/1612 (89%)] Loss: 0.466914\n",
      "Train Epoch: 1875 [1200/1612 (99%)] Loss: 0.343143\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1876 [0/1612 (0%)] Loss: 0.298904\n",
      "Train Epoch: 1876 [160/1612 (10%)] Loss: 0.262875\n",
      "Train Epoch: 1876 [320/1612 (20%)] Loss: 0.230558\n",
      "Train Epoch: 1876 [480/1612 (30%)] Loss: 0.464577\n",
      "Train Epoch: 1876 [640/1612 (40%)] Loss: 0.082721\n",
      "Train Epoch: 1876 [800/1612 (50%)] Loss: 0.337588\n",
      "Train Epoch: 1876 [960/1612 (59%)] Loss: 0.436369\n",
      "Train Epoch: 1876 [1120/1612 (69%)] Loss: 0.276802\n",
      "Train Epoch: 1876 [1280/1612 (79%)] Loss: 0.185514\n",
      "Train Epoch: 1876 [1440/1612 (89%)] Loss: 0.221270\n",
      "Train Epoch: 1876 [1200/1612 (99%)] Loss: 0.328487\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1877 [0/1612 (0%)] Loss: 0.265790\n",
      "Train Epoch: 1877 [160/1612 (10%)] Loss: 0.442817\n",
      "Train Epoch: 1877 [320/1612 (20%)] Loss: 0.119434\n",
      "Train Epoch: 1877 [480/1612 (30%)] Loss: 0.203101\n",
      "Train Epoch: 1877 [640/1612 (40%)] Loss: 0.257047\n",
      "Train Epoch: 1877 [800/1612 (50%)] Loss: 0.239047\n",
      "Train Epoch: 1877 [960/1612 (59%)] Loss: 0.305851\n",
      "Train Epoch: 1877 [1120/1612 (69%)] Loss: 0.232913\n",
      "Train Epoch: 1877 [1280/1612 (79%)] Loss: 0.478042\n",
      "Train Epoch: 1877 [1440/1612 (89%)] Loss: 0.652162\n",
      "Train Epoch: 1877 [1200/1612 (99%)] Loss: 0.263643\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1878 [0/1612 (0%)] Loss: 0.257571\n",
      "Train Epoch: 1878 [160/1612 (10%)] Loss: 0.414862\n",
      "Train Epoch: 1878 [320/1612 (20%)] Loss: 0.506351\n",
      "Train Epoch: 1878 [480/1612 (30%)] Loss: 0.181203\n",
      "Train Epoch: 1878 [640/1612 (40%)] Loss: 0.342393\n",
      "Train Epoch: 1878 [800/1612 (50%)] Loss: 0.320548\n",
      "Train Epoch: 1878 [960/1612 (59%)] Loss: 0.517422\n",
      "Train Epoch: 1878 [1120/1612 (69%)] Loss: 0.386120\n",
      "Train Epoch: 1878 [1280/1612 (79%)] Loss: 0.256798\n",
      "Train Epoch: 1878 [1440/1612 (89%)] Loss: 0.547727\n",
      "Train Epoch: 1878 [1200/1612 (99%)] Loss: 0.248005\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1879 [0/1612 (0%)] Loss: 0.294130\n",
      "Train Epoch: 1879 [160/1612 (10%)] Loss: 0.464584\n",
      "Train Epoch: 1879 [320/1612 (20%)] Loss: 0.221225\n",
      "Train Epoch: 1879 [480/1612 (30%)] Loss: 0.246608\n",
      "Train Epoch: 1879 [640/1612 (40%)] Loss: 0.313152\n",
      "Train Epoch: 1879 [800/1612 (50%)] Loss: 0.153790\n",
      "Train Epoch: 1879 [960/1612 (59%)] Loss: 0.184687\n",
      "Train Epoch: 1879 [1120/1612 (69%)] Loss: 0.300524\n",
      "Train Epoch: 1879 [1280/1612 (79%)] Loss: 0.152216\n",
      "Train Epoch: 1879 [1440/1612 (89%)] Loss: 0.175707\n",
      "Train Epoch: 1879 [1200/1612 (99%)] Loss: 0.339323\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1880 [0/1612 (0%)] Loss: 0.270828\n",
      "Train Epoch: 1880 [160/1612 (10%)] Loss: 0.190339\n",
      "Train Epoch: 1880 [320/1612 (20%)] Loss: 0.246591\n",
      "Train Epoch: 1880 [480/1612 (30%)] Loss: 0.301222\n",
      "Train Epoch: 1880 [640/1612 (40%)] Loss: 0.146858\n",
      "Train Epoch: 1880 [800/1612 (50%)] Loss: 0.246785\n",
      "Train Epoch: 1880 [960/1612 (59%)] Loss: 0.371658\n",
      "Train Epoch: 1880 [1120/1612 (69%)] Loss: 0.152724\n",
      "Train Epoch: 1880 [1280/1612 (79%)] Loss: 0.356576\n",
      "Train Epoch: 1880 [1440/1612 (89%)] Loss: 0.200866\n",
      "Train Epoch: 1880 [1200/1612 (99%)] Loss: 0.321565\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1881 [0/1612 (0%)] Loss: 0.263617\n",
      "Train Epoch: 1881 [160/1612 (10%)] Loss: 0.458981\n",
      "Train Epoch: 1881 [320/1612 (20%)] Loss: 0.172795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1881 [480/1612 (30%)] Loss: 0.214243\n",
      "Train Epoch: 1881 [640/1612 (40%)] Loss: 0.224287\n",
      "Train Epoch: 1881 [800/1612 (50%)] Loss: 0.361731\n",
      "Train Epoch: 1881 [960/1612 (59%)] Loss: 0.159716\n",
      "Train Epoch: 1881 [1120/1612 (69%)] Loss: 0.181067\n",
      "Train Epoch: 1881 [1280/1612 (79%)] Loss: 0.475765\n",
      "Train Epoch: 1881 [1440/1612 (89%)] Loss: 0.140595\n",
      "Train Epoch: 1881 [1200/1612 (99%)] Loss: 0.300371\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1882 [0/1612 (0%)] Loss: 0.571852\n",
      "Train Epoch: 1882 [160/1612 (10%)] Loss: 0.154490\n",
      "Train Epoch: 1882 [320/1612 (20%)] Loss: 0.407592\n",
      "Train Epoch: 1882 [480/1612 (30%)] Loss: 0.264295\n",
      "Train Epoch: 1882 [640/1612 (40%)] Loss: 0.165864\n",
      "Train Epoch: 1882 [800/1612 (50%)] Loss: 0.232604\n",
      "Train Epoch: 1882 [960/1612 (59%)] Loss: 0.228643\n",
      "Train Epoch: 1882 [1120/1612 (69%)] Loss: 0.274343\n",
      "Train Epoch: 1882 [1280/1612 (79%)] Loss: 0.317842\n",
      "Train Epoch: 1882 [1440/1612 (89%)] Loss: 0.317128\n",
      "Train Epoch: 1882 [1200/1612 (99%)] Loss: 0.200522\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1883 [0/1612 (0%)] Loss: 0.327765\n",
      "Train Epoch: 1883 [160/1612 (10%)] Loss: 0.144735\n",
      "Train Epoch: 1883 [320/1612 (20%)] Loss: 0.432892\n",
      "Train Epoch: 1883 [480/1612 (30%)] Loss: 0.448047\n",
      "Train Epoch: 1883 [640/1612 (40%)] Loss: 0.275203\n",
      "Train Epoch: 1883 [800/1612 (50%)] Loss: 0.211608\n",
      "Train Epoch: 1883 [960/1612 (59%)] Loss: 0.395610\n",
      "Train Epoch: 1883 [1120/1612 (69%)] Loss: 0.430817\n",
      "Train Epoch: 1883 [1280/1612 (79%)] Loss: 0.326271\n",
      "Train Epoch: 1883 [1440/1612 (89%)] Loss: 0.270038\n",
      "Train Epoch: 1883 [1200/1612 (99%)] Loss: 0.418089\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1884 [0/1612 (0%)] Loss: 0.177875\n",
      "Train Epoch: 1884 [160/1612 (10%)] Loss: 0.255452\n",
      "Train Epoch: 1884 [320/1612 (20%)] Loss: 0.474573\n",
      "Train Epoch: 1884 [480/1612 (30%)] Loss: 0.141955\n",
      "Train Epoch: 1884 [640/1612 (40%)] Loss: 0.637948\n",
      "Train Epoch: 1884 [800/1612 (50%)] Loss: 0.331938\n",
      "Train Epoch: 1884 [960/1612 (59%)] Loss: 0.181989\n",
      "Train Epoch: 1884 [1120/1612 (69%)] Loss: 0.311359\n",
      "Train Epoch: 1884 [1280/1612 (79%)] Loss: 0.365349\n",
      "Train Epoch: 1884 [1440/1612 (89%)] Loss: 0.465949\n",
      "Train Epoch: 1884 [1200/1612 (99%)] Loss: 0.255078\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1885 [0/1612 (0%)] Loss: 0.473065\n",
      "Train Epoch: 1885 [160/1612 (10%)] Loss: 0.322618\n",
      "Train Epoch: 1885 [320/1612 (20%)] Loss: 0.419270\n",
      "Train Epoch: 1885 [480/1612 (30%)] Loss: 0.176308\n",
      "Train Epoch: 1885 [640/1612 (40%)] Loss: 0.324822\n",
      "Train Epoch: 1885 [800/1612 (50%)] Loss: 0.121174\n",
      "Train Epoch: 1885 [960/1612 (59%)] Loss: 0.230518\n",
      "Train Epoch: 1885 [1120/1612 (69%)] Loss: 0.127217\n",
      "Train Epoch: 1885 [1280/1612 (79%)] Loss: 0.212966\n",
      "Train Epoch: 1885 [1440/1612 (89%)] Loss: 0.157524\n",
      "Train Epoch: 1885 [1200/1612 (99%)] Loss: 0.239103\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1886 [0/1612 (0%)] Loss: 0.322004\n",
      "Train Epoch: 1886 [160/1612 (10%)] Loss: 0.187748\n",
      "Train Epoch: 1886 [320/1612 (20%)] Loss: 0.168148\n",
      "Train Epoch: 1886 [480/1612 (30%)] Loss: 0.542226\n",
      "Train Epoch: 1886 [640/1612 (40%)] Loss: 0.361348\n",
      "Train Epoch: 1886 [800/1612 (50%)] Loss: 0.309173\n",
      "Train Epoch: 1886 [960/1612 (59%)] Loss: 0.303741\n",
      "Train Epoch: 1886 [1120/1612 (69%)] Loss: 0.247536\n",
      "Train Epoch: 1886 [1280/1612 (79%)] Loss: 0.181998\n",
      "Train Epoch: 1886 [1440/1612 (89%)] Loss: 0.186985\n",
      "Train Epoch: 1886 [1200/1612 (99%)] Loss: 0.189410\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1887 [0/1612 (0%)] Loss: 0.234694\n",
      "Train Epoch: 1887 [160/1612 (10%)] Loss: 0.290334\n",
      "Train Epoch: 1887 [320/1612 (20%)] Loss: 0.534048\n",
      "Train Epoch: 1887 [480/1612 (30%)] Loss: 0.172309\n",
      "Train Epoch: 1887 [640/1612 (40%)] Loss: 0.318870\n",
      "Train Epoch: 1887 [800/1612 (50%)] Loss: 0.458480\n",
      "Train Epoch: 1887 [960/1612 (59%)] Loss: 0.213647\n",
      "Train Epoch: 1887 [1120/1612 (69%)] Loss: 0.098379\n",
      "Train Epoch: 1887 [1280/1612 (79%)] Loss: 0.295747\n",
      "Train Epoch: 1887 [1440/1612 (89%)] Loss: 0.306471\n",
      "Train Epoch: 1887 [1200/1612 (99%)] Loss: 0.522334\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1888 [0/1612 (0%)] Loss: 0.237418\n",
      "Train Epoch: 1888 [160/1612 (10%)] Loss: 0.285327\n",
      "Train Epoch: 1888 [320/1612 (20%)] Loss: 0.292882\n",
      "Train Epoch: 1888 [480/1612 (30%)] Loss: 0.190401\n",
      "Train Epoch: 1888 [640/1612 (40%)] Loss: 0.339298\n",
      "Train Epoch: 1888 [800/1612 (50%)] Loss: 0.352152\n",
      "Train Epoch: 1888 [960/1612 (59%)] Loss: 0.318907\n",
      "Train Epoch: 1888 [1120/1612 (69%)] Loss: 0.270123\n",
      "Train Epoch: 1888 [1280/1612 (79%)] Loss: 0.179147\n",
      "Train Epoch: 1888 [1440/1612 (89%)] Loss: 0.177702\n",
      "Train Epoch: 1888 [1200/1612 (99%)] Loss: 0.229903\n",
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1889 [0/1612 (0%)] Loss: 0.257353\n",
      "Train Epoch: 1889 [160/1612 (10%)] Loss: 0.609060\n",
      "Train Epoch: 1889 [320/1612 (20%)] Loss: 0.376489\n",
      "Train Epoch: 1889 [480/1612 (30%)] Loss: 0.292665\n",
      "Train Epoch: 1889 [640/1612 (40%)] Loss: 0.123026\n",
      "Train Epoch: 1889 [800/1612 (50%)] Loss: 0.165553\n",
      "Train Epoch: 1889 [960/1612 (59%)] Loss: 0.340538\n",
      "Train Epoch: 1889 [1120/1612 (69%)] Loss: 0.289195\n",
      "Train Epoch: 1889 [1280/1612 (79%)] Loss: 0.205226\n",
      "Train Epoch: 1889 [1440/1612 (89%)] Loss: 0.668988\n",
      "Train Epoch: 1889 [1200/1612 (99%)] Loss: 0.213227\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1890 [0/1612 (0%)] Loss: 0.350796\n",
      "Train Epoch: 1890 [160/1612 (10%)] Loss: 0.216561\n",
      "Train Epoch: 1890 [320/1612 (20%)] Loss: 0.120276\n",
      "Train Epoch: 1890 [480/1612 (30%)] Loss: 0.237172\n",
      "Train Epoch: 1890 [640/1612 (40%)] Loss: 0.192418\n",
      "Train Epoch: 1890 [800/1612 (50%)] Loss: 0.291961\n",
      "Train Epoch: 1890 [960/1612 (59%)] Loss: 0.322848\n",
      "Train Epoch: 1890 [1120/1612 (69%)] Loss: 0.319162\n",
      "Train Epoch: 1890 [1280/1612 (79%)] Loss: 0.130661\n",
      "Train Epoch: 1890 [1440/1612 (89%)] Loss: 0.197671\n",
      "Train Epoch: 1890 [1200/1612 (99%)] Loss: 0.181967\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1891 [0/1612 (0%)] Loss: 0.144267\n",
      "Train Epoch: 1891 [160/1612 (10%)] Loss: 0.336663\n",
      "Train Epoch: 1891 [320/1612 (20%)] Loss: 0.430777\n",
      "Train Epoch: 1891 [480/1612 (30%)] Loss: 0.262684\n",
      "Train Epoch: 1891 [640/1612 (40%)] Loss: 0.174517\n",
      "Train Epoch: 1891 [800/1612 (50%)] Loss: 0.309488\n",
      "Train Epoch: 1891 [960/1612 (59%)] Loss: 0.382837\n",
      "Train Epoch: 1891 [1120/1612 (69%)] Loss: 0.422933\n",
      "Train Epoch: 1891 [1280/1612 (79%)] Loss: 0.134693\n",
      "Train Epoch: 1891 [1440/1612 (89%)] Loss: 0.302292\n",
      "Train Epoch: 1891 [1200/1612 (99%)] Loss: 0.328939\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1892 [0/1612 (0%)] Loss: 0.398885\n",
      "Train Epoch: 1892 [160/1612 (10%)] Loss: 0.309082\n",
      "Train Epoch: 1892 [320/1612 (20%)] Loss: 0.217604\n",
      "Train Epoch: 1892 [480/1612 (30%)] Loss: 0.285796\n",
      "Train Epoch: 1892 [640/1612 (40%)] Loss: 0.243318\n",
      "Train Epoch: 1892 [800/1612 (50%)] Loss: 0.312880\n",
      "Train Epoch: 1892 [960/1612 (59%)] Loss: 0.159257\n",
      "Train Epoch: 1892 [1120/1612 (69%)] Loss: 0.395339\n",
      "Train Epoch: 1892 [1280/1612 (79%)] Loss: 0.289611\n",
      "Train Epoch: 1892 [1440/1612 (89%)] Loss: 0.385164\n",
      "Train Epoch: 1892 [1200/1612 (99%)] Loss: 0.299006\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1893 [0/1612 (0%)] Loss: 0.185068\n",
      "Train Epoch: 1893 [160/1612 (10%)] Loss: 0.413433\n",
      "Train Epoch: 1893 [320/1612 (20%)] Loss: 0.289544\n",
      "Train Epoch: 1893 [480/1612 (30%)] Loss: 0.109189\n",
      "Train Epoch: 1893 [640/1612 (40%)] Loss: 0.286493\n",
      "Train Epoch: 1893 [800/1612 (50%)] Loss: 0.496837\n",
      "Train Epoch: 1893 [960/1612 (59%)] Loss: 0.211680\n",
      "Train Epoch: 1893 [1120/1612 (69%)] Loss: 0.230575\n",
      "Train Epoch: 1893 [1280/1612 (79%)] Loss: 0.253286\n",
      "Train Epoch: 1893 [1440/1612 (89%)] Loss: 0.520052\n",
      "Train Epoch: 1893 [1200/1612 (99%)] Loss: 0.262475\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1894 [0/1612 (0%)] Loss: 0.222213\n",
      "Train Epoch: 1894 [160/1612 (10%)] Loss: 0.225823\n",
      "Train Epoch: 1894 [320/1612 (20%)] Loss: 0.347226\n",
      "Train Epoch: 1894 [480/1612 (30%)] Loss: 0.250795\n",
      "Train Epoch: 1894 [640/1612 (40%)] Loss: 0.341679\n",
      "Train Epoch: 1894 [800/1612 (50%)] Loss: 0.314197\n",
      "Train Epoch: 1894 [960/1612 (59%)] Loss: 0.265076\n",
      "Train Epoch: 1894 [1120/1612 (69%)] Loss: 0.460244\n",
      "Train Epoch: 1894 [1280/1612 (79%)] Loss: 0.225431\n",
      "Train Epoch: 1894 [1440/1612 (89%)] Loss: 0.317949\n",
      "Train Epoch: 1894 [1200/1612 (99%)] Loss: 0.300638\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1895 [0/1612 (0%)] Loss: 0.234617\n",
      "Train Epoch: 1895 [160/1612 (10%)] Loss: 0.324121\n",
      "Train Epoch: 1895 [320/1612 (20%)] Loss: 0.387509\n",
      "Train Epoch: 1895 [480/1612 (30%)] Loss: 0.192092\n",
      "Train Epoch: 1895 [640/1612 (40%)] Loss: 0.350145\n",
      "Train Epoch: 1895 [800/1612 (50%)] Loss: 0.340361\n",
      "Train Epoch: 1895 [960/1612 (59%)] Loss: 0.276833\n",
      "Train Epoch: 1895 [1120/1612 (69%)] Loss: 0.156232\n",
      "Train Epoch: 1895 [1280/1612 (79%)] Loss: 0.271095\n",
      "Train Epoch: 1895 [1440/1612 (89%)] Loss: 0.147513\n",
      "Train Epoch: 1895 [1200/1612 (99%)] Loss: 0.255085\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1896 [0/1612 (0%)] Loss: 0.146589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1896 [160/1612 (10%)] Loss: 0.231779\n",
      "Train Epoch: 1896 [320/1612 (20%)] Loss: 0.170768\n",
      "Train Epoch: 1896 [480/1612 (30%)] Loss: 0.316981\n",
      "Train Epoch: 1896 [640/1612 (40%)] Loss: 0.640046\n",
      "Train Epoch: 1896 [800/1612 (50%)] Loss: 0.279739\n",
      "Train Epoch: 1896 [960/1612 (59%)] Loss: 0.094593\n",
      "Train Epoch: 1896 [1120/1612 (69%)] Loss: 0.074536\n",
      "Train Epoch: 1896 [1280/1612 (79%)] Loss: 0.131594\n",
      "Train Epoch: 1896 [1440/1612 (89%)] Loss: 0.236394\n",
      "Train Epoch: 1896 [1200/1612 (99%)] Loss: 0.381928\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1897 [0/1612 (0%)] Loss: 0.153585\n",
      "Train Epoch: 1897 [160/1612 (10%)] Loss: 0.335286\n",
      "Train Epoch: 1897 [320/1612 (20%)] Loss: 0.342514\n",
      "Train Epoch: 1897 [480/1612 (30%)] Loss: 0.503787\n",
      "Train Epoch: 1897 [640/1612 (40%)] Loss: 0.289410\n",
      "Train Epoch: 1897 [800/1612 (50%)] Loss: 0.199899\n",
      "Train Epoch: 1897 [960/1612 (59%)] Loss: 0.174360\n",
      "Train Epoch: 1897 [1120/1612 (69%)] Loss: 0.345980\n",
      "Train Epoch: 1897 [1280/1612 (79%)] Loss: 0.345937\n",
      "Train Epoch: 1897 [1440/1612 (89%)] Loss: 0.227842\n",
      "Train Epoch: 1897 [1200/1612 (99%)] Loss: 0.161648\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1898 [0/1612 (0%)] Loss: 0.195098\n",
      "Train Epoch: 1898 [160/1612 (10%)] Loss: 0.271049\n",
      "Train Epoch: 1898 [320/1612 (20%)] Loss: 0.340521\n",
      "Train Epoch: 1898 [480/1612 (30%)] Loss: 0.293350\n",
      "Train Epoch: 1898 [640/1612 (40%)] Loss: 0.519768\n",
      "Train Epoch: 1898 [800/1612 (50%)] Loss: 0.330051\n",
      "Train Epoch: 1898 [960/1612 (59%)] Loss: 0.647393\n",
      "Train Epoch: 1898 [1120/1612 (69%)] Loss: 0.193938\n",
      "Train Epoch: 1898 [1280/1612 (79%)] Loss: 0.263388\n",
      "Train Epoch: 1898 [1440/1612 (89%)] Loss: 0.416073\n",
      "Train Epoch: 1898 [1200/1612 (99%)] Loss: 0.335542\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1899 [0/1612 (0%)] Loss: 0.223951\n",
      "Train Epoch: 1899 [160/1612 (10%)] Loss: 0.345717\n",
      "Train Epoch: 1899 [320/1612 (20%)] Loss: 0.254295\n",
      "Train Epoch: 1899 [480/1612 (30%)] Loss: 0.302628\n",
      "Train Epoch: 1899 [640/1612 (40%)] Loss: 0.241562\n",
      "Train Epoch: 1899 [800/1612 (50%)] Loss: 0.242699\n",
      "Train Epoch: 1899 [960/1612 (59%)] Loss: 0.135790\n",
      "Train Epoch: 1899 [1120/1612 (69%)] Loss: 0.121457\n",
      "Train Epoch: 1899 [1280/1612 (79%)] Loss: 0.259268\n",
      "Train Epoch: 1899 [1440/1612 (89%)] Loss: 0.302702\n",
      "Train Epoch: 1899 [1200/1612 (99%)] Loss: 0.386184\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1900 [0/1612 (0%)] Loss: 0.228363\n",
      "Train Epoch: 1900 [160/1612 (10%)] Loss: 0.251589\n",
      "Train Epoch: 1900 [320/1612 (20%)] Loss: 0.170133\n",
      "Train Epoch: 1900 [480/1612 (30%)] Loss: 0.310320\n",
      "Train Epoch: 1900 [640/1612 (40%)] Loss: 0.521094\n",
      "Train Epoch: 1900 [800/1612 (50%)] Loss: 0.297104\n",
      "Train Epoch: 1900 [960/1612 (59%)] Loss: 0.132666\n",
      "Train Epoch: 1900 [1120/1612 (69%)] Loss: 0.250043\n",
      "Train Epoch: 1900 [1280/1612 (79%)] Loss: 0.292064\n",
      "Train Epoch: 1900 [1440/1612 (89%)] Loss: 0.257224\n",
      "Train Epoch: 1900 [1200/1612 (99%)] Loss: 0.208022\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1901 [0/1612 (0%)] Loss: 0.197349\n",
      "Train Epoch: 1901 [160/1612 (10%)] Loss: 0.128140\n",
      "Train Epoch: 1901 [320/1612 (20%)] Loss: 0.162353\n",
      "Train Epoch: 1901 [480/1612 (30%)] Loss: 0.370010\n",
      "Train Epoch: 1901 [640/1612 (40%)] Loss: 0.576608\n",
      "Train Epoch: 1901 [800/1612 (50%)] Loss: 0.196978\n",
      "Train Epoch: 1901 [960/1612 (59%)] Loss: 0.242194\n",
      "Train Epoch: 1901 [1120/1612 (69%)] Loss: 0.319525\n",
      "Train Epoch: 1901 [1280/1612 (79%)] Loss: 0.392352\n",
      "Train Epoch: 1901 [1440/1612 (89%)] Loss: 0.072575\n",
      "Train Epoch: 1901 [1200/1612 (99%)] Loss: 0.571669\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1902 [0/1612 (0%)] Loss: 0.239053\n",
      "Train Epoch: 1902 [160/1612 (10%)] Loss: 0.391228\n",
      "Train Epoch: 1902 [320/1612 (20%)] Loss: 0.093422\n",
      "Train Epoch: 1902 [480/1612 (30%)] Loss: 0.233414\n",
      "Train Epoch: 1902 [640/1612 (40%)] Loss: 0.150913\n",
      "Train Epoch: 1902 [800/1612 (50%)] Loss: 0.367537\n",
      "Train Epoch: 1902 [960/1612 (59%)] Loss: 0.741232\n",
      "Train Epoch: 1902 [1120/1612 (69%)] Loss: 0.212113\n",
      "Train Epoch: 1902 [1280/1612 (79%)] Loss: 0.582610\n",
      "Train Epoch: 1902 [1440/1612 (89%)] Loss: 0.651008\n",
      "Train Epoch: 1902 [1200/1612 (99%)] Loss: 0.475459\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1903 [0/1612 (0%)] Loss: 0.299851\n",
      "Train Epoch: 1903 [160/1612 (10%)] Loss: 0.328842\n",
      "Train Epoch: 1903 [320/1612 (20%)] Loss: 0.114310\n",
      "Train Epoch: 1903 [480/1612 (30%)] Loss: 0.087145\n",
      "Train Epoch: 1903 [640/1612 (40%)] Loss: 0.365313\n",
      "Train Epoch: 1903 [800/1612 (50%)] Loss: 0.292023\n",
      "Train Epoch: 1903 [960/1612 (59%)] Loss: 0.447168\n",
      "Train Epoch: 1903 [1120/1612 (69%)] Loss: 0.309450\n",
      "Train Epoch: 1903 [1280/1612 (79%)] Loss: 0.195791\n",
      "Train Epoch: 1903 [1440/1612 (89%)] Loss: 0.226878\n",
      "Train Epoch: 1903 [1200/1612 (99%)] Loss: 0.339747\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1904 [0/1612 (0%)] Loss: 0.229120\n",
      "Train Epoch: 1904 [160/1612 (10%)] Loss: 0.132726\n",
      "Train Epoch: 1904 [320/1612 (20%)] Loss: 0.245556\n",
      "Train Epoch: 1904 [480/1612 (30%)] Loss: 0.225968\n",
      "Train Epoch: 1904 [640/1612 (40%)] Loss: 0.218306\n",
      "Train Epoch: 1904 [800/1612 (50%)] Loss: 0.349717\n",
      "Train Epoch: 1904 [960/1612 (59%)] Loss: 0.341332\n",
      "Train Epoch: 1904 [1120/1612 (69%)] Loss: 0.400137\n",
      "Train Epoch: 1904 [1280/1612 (79%)] Loss: 0.635693\n",
      "Train Epoch: 1904 [1440/1612 (89%)] Loss: 0.139906\n",
      "Train Epoch: 1904 [1200/1612 (99%)] Loss: 0.271151\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1905 [0/1612 (0%)] Loss: 0.151147\n",
      "Train Epoch: 1905 [160/1612 (10%)] Loss: 0.233650\n",
      "Train Epoch: 1905 [320/1612 (20%)] Loss: 0.328486\n",
      "Train Epoch: 1905 [480/1612 (30%)] Loss: 0.348115\n",
      "Train Epoch: 1905 [640/1612 (40%)] Loss: 0.249853\n",
      "Train Epoch: 1905 [800/1612 (50%)] Loss: 0.322262\n",
      "Train Epoch: 1905 [960/1612 (59%)] Loss: 0.191312\n",
      "Train Epoch: 1905 [1120/1612 (69%)] Loss: 0.648825\n",
      "Train Epoch: 1905 [1280/1612 (79%)] Loss: 0.455767\n",
      "Train Epoch: 1905 [1440/1612 (89%)] Loss: 0.394033\n",
      "Train Epoch: 1905 [1200/1612 (99%)] Loss: 0.349566\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1906 [0/1612 (0%)] Loss: 0.390034\n",
      "Train Epoch: 1906 [160/1612 (10%)] Loss: 0.412136\n",
      "Train Epoch: 1906 [320/1612 (20%)] Loss: 0.280421\n",
      "Train Epoch: 1906 [480/1612 (30%)] Loss: 0.336501\n",
      "Train Epoch: 1906 [640/1612 (40%)] Loss: 0.467327\n",
      "Train Epoch: 1906 [800/1612 (50%)] Loss: 0.225483\n",
      "Train Epoch: 1906 [960/1612 (59%)] Loss: 0.217815\n",
      "Train Epoch: 1906 [1120/1612 (69%)] Loss: 0.089748\n",
      "Train Epoch: 1906 [1280/1612 (79%)] Loss: 0.423899\n",
      "Train Epoch: 1906 [1440/1612 (89%)] Loss: 0.224747\n",
      "Train Epoch: 1906 [1200/1612 (99%)] Loss: 0.173483\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1907 [0/1612 (0%)] Loss: 0.182932\n",
      "Train Epoch: 1907 [160/1612 (10%)] Loss: 0.302621\n",
      "Train Epoch: 1907 [320/1612 (20%)] Loss: 0.284391\n",
      "Train Epoch: 1907 [480/1612 (30%)] Loss: 0.693368\n",
      "Train Epoch: 1907 [640/1612 (40%)] Loss: 0.112869\n",
      "Train Epoch: 1907 [800/1612 (50%)] Loss: 0.377220\n",
      "Train Epoch: 1907 [960/1612 (59%)] Loss: 0.150431\n",
      "Train Epoch: 1907 [1120/1612 (69%)] Loss: 0.170745\n",
      "Train Epoch: 1907 [1280/1612 (79%)] Loss: 0.230052\n",
      "Train Epoch: 1907 [1440/1612 (89%)] Loss: 0.307113\n",
      "Train Epoch: 1907 [1200/1612 (99%)] Loss: 0.345332\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1908 [0/1612 (0%)] Loss: 0.298903\n",
      "Train Epoch: 1908 [160/1612 (10%)] Loss: 0.234655\n",
      "Train Epoch: 1908 [320/1612 (20%)] Loss: 0.235724\n",
      "Train Epoch: 1908 [480/1612 (30%)] Loss: 0.444182\n",
      "Train Epoch: 1908 [640/1612 (40%)] Loss: 0.300520\n",
      "Train Epoch: 1908 [800/1612 (50%)] Loss: 0.174193\n",
      "Train Epoch: 1908 [960/1612 (59%)] Loss: 0.217041\n",
      "Train Epoch: 1908 [1120/1612 (69%)] Loss: 0.694110\n",
      "Train Epoch: 1908 [1280/1612 (79%)] Loss: 0.174383\n",
      "Train Epoch: 1908 [1440/1612 (89%)] Loss: 0.348854\n",
      "Train Epoch: 1908 [1200/1612 (99%)] Loss: 0.276645\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1909 [0/1612 (0%)] Loss: 0.274358\n",
      "Train Epoch: 1909 [160/1612 (10%)] Loss: 0.255924\n",
      "Train Epoch: 1909 [320/1612 (20%)] Loss: 0.116423\n",
      "Train Epoch: 1909 [480/1612 (30%)] Loss: 0.383016\n",
      "Train Epoch: 1909 [640/1612 (40%)] Loss: 0.254708\n",
      "Train Epoch: 1909 [800/1612 (50%)] Loss: 0.280588\n",
      "Train Epoch: 1909 [960/1612 (59%)] Loss: 0.333901\n",
      "Train Epoch: 1909 [1120/1612 (69%)] Loss: 0.154925\n",
      "Train Epoch: 1909 [1280/1612 (79%)] Loss: 0.146501\n",
      "Train Epoch: 1909 [1440/1612 (89%)] Loss: 0.307948\n",
      "Train Epoch: 1909 [1200/1612 (99%)] Loss: 0.185076\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1910 [0/1612 (0%)] Loss: 0.302040\n",
      "Train Epoch: 1910 [160/1612 (10%)] Loss: 0.613501\n",
      "Train Epoch: 1910 [320/1612 (20%)] Loss: 0.372940\n",
      "Train Epoch: 1910 [480/1612 (30%)] Loss: 0.109180\n",
      "Train Epoch: 1910 [640/1612 (40%)] Loss: 0.234664\n",
      "Train Epoch: 1910 [800/1612 (50%)] Loss: 0.255654\n",
      "Train Epoch: 1910 [960/1612 (59%)] Loss: 0.098193\n",
      "Train Epoch: 1910 [1120/1612 (69%)] Loss: 0.140279\n",
      "Train Epoch: 1910 [1280/1612 (79%)] Loss: 0.154310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1910 [1440/1612 (89%)] Loss: 0.166700\n",
      "Train Epoch: 1910 [1200/1612 (99%)] Loss: 0.348339\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1911 [0/1612 (0%)] Loss: 0.360187\n",
      "Train Epoch: 1911 [160/1612 (10%)] Loss: 0.229396\n",
      "Train Epoch: 1911 [320/1612 (20%)] Loss: 0.474688\n",
      "Train Epoch: 1911 [480/1612 (30%)] Loss: 0.183890\n",
      "Train Epoch: 1911 [640/1612 (40%)] Loss: 0.459402\n",
      "Train Epoch: 1911 [800/1612 (50%)] Loss: 0.584715\n",
      "Train Epoch: 1911 [960/1612 (59%)] Loss: 0.338654\n",
      "Train Epoch: 1911 [1120/1612 (69%)] Loss: 0.553396\n",
      "Train Epoch: 1911 [1280/1612 (79%)] Loss: 0.347923\n",
      "Train Epoch: 1911 [1440/1612 (89%)] Loss: 0.245965\n",
      "Train Epoch: 1911 [1200/1612 (99%)] Loss: 0.287282\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1912 [0/1612 (0%)] Loss: 0.429400\n",
      "Train Epoch: 1912 [160/1612 (10%)] Loss: 0.233325\n",
      "Train Epoch: 1912 [320/1612 (20%)] Loss: 0.304612\n",
      "Train Epoch: 1912 [480/1612 (30%)] Loss: 0.198226\n",
      "Train Epoch: 1912 [640/1612 (40%)] Loss: 0.312656\n",
      "Train Epoch: 1912 [800/1612 (50%)] Loss: 0.500006\n",
      "Train Epoch: 1912 [960/1612 (59%)] Loss: 0.131362\n",
      "Train Epoch: 1912 [1120/1612 (69%)] Loss: 0.392802\n",
      "Train Epoch: 1912 [1280/1612 (79%)] Loss: 0.331896\n",
      "Train Epoch: 1912 [1440/1612 (89%)] Loss: 0.506304\n",
      "Train Epoch: 1912 [1200/1612 (99%)] Loss: 0.306190\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1913 [0/1612 (0%)] Loss: 0.266745\n",
      "Train Epoch: 1913 [160/1612 (10%)] Loss: 0.411356\n",
      "Train Epoch: 1913 [320/1612 (20%)] Loss: 0.387197\n",
      "Train Epoch: 1913 [480/1612 (30%)] Loss: 0.370538\n",
      "Train Epoch: 1913 [640/1612 (40%)] Loss: 0.303129\n",
      "Train Epoch: 1913 [800/1612 (50%)] Loss: 0.190645\n",
      "Train Epoch: 1913 [960/1612 (59%)] Loss: 0.303068\n",
      "Train Epoch: 1913 [1120/1612 (69%)] Loss: 0.315287\n",
      "Train Epoch: 1913 [1280/1612 (79%)] Loss: 0.388442\n",
      "Train Epoch: 1913 [1440/1612 (89%)] Loss: 0.490572\n",
      "Train Epoch: 1913 [1200/1612 (99%)] Loss: 0.289339\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1914 [0/1612 (0%)] Loss: 0.194738\n",
      "Train Epoch: 1914 [160/1612 (10%)] Loss: 0.299858\n",
      "Train Epoch: 1914 [320/1612 (20%)] Loss: 0.294723\n",
      "Train Epoch: 1914 [480/1612 (30%)] Loss: 0.304120\n",
      "Train Epoch: 1914 [640/1612 (40%)] Loss: 0.350362\n",
      "Train Epoch: 1914 [800/1612 (50%)] Loss: 0.320156\n",
      "Train Epoch: 1914 [960/1612 (59%)] Loss: 0.382610\n",
      "Train Epoch: 1914 [1120/1612 (69%)] Loss: 0.322768\n",
      "Train Epoch: 1914 [1280/1612 (79%)] Loss: 0.227203\n",
      "Train Epoch: 1914 [1440/1612 (89%)] Loss: 0.688800\n",
      "Train Epoch: 1914 [1200/1612 (99%)] Loss: 0.219573\n",
      "\n",
      "Test set: Average loss: 0.0278, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1915 [0/1612 (0%)] Loss: 0.385776\n",
      "Train Epoch: 1915 [160/1612 (10%)] Loss: 0.270838\n",
      "Train Epoch: 1915 [320/1612 (20%)] Loss: 0.431614\n",
      "Train Epoch: 1915 [480/1612 (30%)] Loss: 0.113111\n",
      "Train Epoch: 1915 [640/1612 (40%)] Loss: 0.269696\n",
      "Train Epoch: 1915 [800/1612 (50%)] Loss: 0.175815\n",
      "Train Epoch: 1915 [960/1612 (59%)] Loss: 0.239599\n",
      "Train Epoch: 1915 [1120/1612 (69%)] Loss: 0.241072\n",
      "Train Epoch: 1915 [1280/1612 (79%)] Loss: 0.540110\n",
      "Train Epoch: 1915 [1440/1612 (89%)] Loss: 0.212910\n",
      "Train Epoch: 1915 [1200/1612 (99%)] Loss: 0.079590\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1916 [0/1612 (0%)] Loss: 0.377172\n",
      "Train Epoch: 1916 [160/1612 (10%)] Loss: 0.476263\n",
      "Train Epoch: 1916 [320/1612 (20%)] Loss: 0.196206\n",
      "Train Epoch: 1916 [480/1612 (30%)] Loss: 0.179635\n",
      "Train Epoch: 1916 [640/1612 (40%)] Loss: 0.573076\n",
      "Train Epoch: 1916 [800/1612 (50%)] Loss: 0.423746\n",
      "Train Epoch: 1916 [960/1612 (59%)] Loss: 0.200749\n",
      "Train Epoch: 1916 [1120/1612 (69%)] Loss: 0.595969\n",
      "Train Epoch: 1916 [1280/1612 (79%)] Loss: 0.109631\n",
      "Train Epoch: 1916 [1440/1612 (89%)] Loss: 0.186577\n",
      "Train Epoch: 1916 [1200/1612 (99%)] Loss: 0.327174\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1917 [0/1612 (0%)] Loss: 0.206123\n",
      "Train Epoch: 1917 [160/1612 (10%)] Loss: 0.305537\n",
      "Train Epoch: 1917 [320/1612 (20%)] Loss: 0.331182\n",
      "Train Epoch: 1917 [480/1612 (30%)] Loss: 0.403966\n",
      "Train Epoch: 1917 [640/1612 (40%)] Loss: 0.388110\n",
      "Train Epoch: 1917 [800/1612 (50%)] Loss: 0.219732\n",
      "Train Epoch: 1917 [960/1612 (59%)] Loss: 0.699409\n",
      "Train Epoch: 1917 [1120/1612 (69%)] Loss: 0.293778\n",
      "Train Epoch: 1917 [1280/1612 (79%)] Loss: 0.428317\n",
      "Train Epoch: 1917 [1440/1612 (89%)] Loss: 0.128481\n",
      "Train Epoch: 1917 [1200/1612 (99%)] Loss: 0.216030\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1918 [0/1612 (0%)] Loss: 0.193105\n",
      "Train Epoch: 1918 [160/1612 (10%)] Loss: 0.348794\n",
      "Train Epoch: 1918 [320/1612 (20%)] Loss: 0.520776\n",
      "Train Epoch: 1918 [480/1612 (30%)] Loss: 0.392433\n",
      "Train Epoch: 1918 [640/1612 (40%)] Loss: 0.300274\n",
      "Train Epoch: 1918 [800/1612 (50%)] Loss: 0.322510\n",
      "Train Epoch: 1918 [960/1612 (59%)] Loss: 0.369951\n",
      "Train Epoch: 1918 [1120/1612 (69%)] Loss: 0.379190\n",
      "Train Epoch: 1918 [1280/1612 (79%)] Loss: 0.252949\n",
      "Train Epoch: 1918 [1440/1612 (89%)] Loss: 0.356462\n",
      "Train Epoch: 1918 [1200/1612 (99%)] Loss: 0.179989\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1919 [0/1612 (0%)] Loss: 0.343313\n",
      "Train Epoch: 1919 [160/1612 (10%)] Loss: 0.275297\n",
      "Train Epoch: 1919 [320/1612 (20%)] Loss: 0.208086\n",
      "Train Epoch: 1919 [480/1612 (30%)] Loss: 0.203368\n",
      "Train Epoch: 1919 [640/1612 (40%)] Loss: 0.571225\n",
      "Train Epoch: 1919 [800/1612 (50%)] Loss: 0.542797\n",
      "Train Epoch: 1919 [960/1612 (59%)] Loss: 0.281170\n",
      "Train Epoch: 1919 [1120/1612 (69%)] Loss: 0.297647\n",
      "Train Epoch: 1919 [1280/1612 (79%)] Loss: 0.303662\n",
      "Train Epoch: 1919 [1440/1612 (89%)] Loss: 0.376024\n",
      "Train Epoch: 1919 [1200/1612 (99%)] Loss: 0.420192\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1920 [0/1612 (0%)] Loss: 0.408734\n",
      "Train Epoch: 1920 [160/1612 (10%)] Loss: 0.245620\n",
      "Train Epoch: 1920 [320/1612 (20%)] Loss: 0.359134\n",
      "Train Epoch: 1920 [480/1612 (30%)] Loss: 0.404133\n",
      "Train Epoch: 1920 [640/1612 (40%)] Loss: 0.310605\n",
      "Train Epoch: 1920 [800/1612 (50%)] Loss: 0.419392\n",
      "Train Epoch: 1920 [960/1612 (59%)] Loss: 0.212429\n",
      "Train Epoch: 1920 [1120/1612 (69%)] Loss: 0.246600\n",
      "Train Epoch: 1920 [1280/1612 (79%)] Loss: 0.191732\n",
      "Train Epoch: 1920 [1440/1612 (89%)] Loss: 0.106765\n",
      "Train Epoch: 1920 [1200/1612 (99%)] Loss: 0.476971\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1921 [0/1612 (0%)] Loss: 0.128138\n",
      "Train Epoch: 1921 [160/1612 (10%)] Loss: 0.103344\n",
      "Train Epoch: 1921 [320/1612 (20%)] Loss: 0.179055\n",
      "Train Epoch: 1921 [480/1612 (30%)] Loss: 0.285158\n",
      "Train Epoch: 1921 [640/1612 (40%)] Loss: 0.101005\n",
      "Train Epoch: 1921 [800/1612 (50%)] Loss: 0.192245\n",
      "Train Epoch: 1921 [960/1612 (59%)] Loss: 0.132802\n",
      "Train Epoch: 1921 [1120/1612 (69%)] Loss: 0.510132\n",
      "Train Epoch: 1921 [1280/1612 (79%)] Loss: 0.629514\n",
      "Train Epoch: 1921 [1440/1612 (89%)] Loss: 0.126869\n",
      "Train Epoch: 1921 [1200/1612 (99%)] Loss: 0.590129\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1922 [0/1612 (0%)] Loss: 0.288806\n",
      "Train Epoch: 1922 [160/1612 (10%)] Loss: 0.403413\n",
      "Train Epoch: 1922 [320/1612 (20%)] Loss: 0.356682\n",
      "Train Epoch: 1922 [480/1612 (30%)] Loss: 0.188621\n",
      "Train Epoch: 1922 [640/1612 (40%)] Loss: 0.502896\n",
      "Train Epoch: 1922 [800/1612 (50%)] Loss: 0.311360\n",
      "Train Epoch: 1922 [960/1612 (59%)] Loss: 0.374135\n",
      "Train Epoch: 1922 [1120/1612 (69%)] Loss: 0.433857\n",
      "Train Epoch: 1922 [1280/1612 (79%)] Loss: 0.449457\n",
      "Train Epoch: 1922 [1440/1612 (89%)] Loss: 0.323492\n",
      "Train Epoch: 1922 [1200/1612 (99%)] Loss: 0.148908\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1923 [0/1612 (0%)] Loss: 0.235802\n",
      "Train Epoch: 1923 [160/1612 (10%)] Loss: 0.139770\n",
      "Train Epoch: 1923 [320/1612 (20%)] Loss: 0.539935\n",
      "Train Epoch: 1923 [480/1612 (30%)] Loss: 0.361506\n",
      "Train Epoch: 1923 [640/1612 (40%)] Loss: 0.262935\n",
      "Train Epoch: 1923 [800/1612 (50%)] Loss: 0.229160\n",
      "Train Epoch: 1923 [960/1612 (59%)] Loss: 0.402011\n",
      "Train Epoch: 1923 [1120/1612 (69%)] Loss: 0.257008\n",
      "Train Epoch: 1923 [1280/1612 (79%)] Loss: 0.186583\n",
      "Train Epoch: 1923 [1440/1612 (89%)] Loss: 0.317395\n",
      "Train Epoch: 1923 [1200/1612 (99%)] Loss: 0.397946\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1924 [0/1612 (0%)] Loss: 0.283539\n",
      "Train Epoch: 1924 [160/1612 (10%)] Loss: 0.186554\n",
      "Train Epoch: 1924 [320/1612 (20%)] Loss: 0.288826\n",
      "Train Epoch: 1924 [480/1612 (30%)] Loss: 0.220217\n",
      "Train Epoch: 1924 [640/1612 (40%)] Loss: 0.286458\n",
      "Train Epoch: 1924 [800/1612 (50%)] Loss: 0.197825\n",
      "Train Epoch: 1924 [960/1612 (59%)] Loss: 0.127306\n",
      "Train Epoch: 1924 [1120/1612 (69%)] Loss: 0.200433\n",
      "Train Epoch: 1924 [1280/1612 (79%)] Loss: 0.326379\n",
      "Train Epoch: 1924 [1440/1612 (89%)] Loss: 0.392517\n",
      "Train Epoch: 1924 [1200/1612 (99%)] Loss: 0.312037\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1925 [0/1612 (0%)] Loss: 0.075621\n",
      "Train Epoch: 1925 [160/1612 (10%)] Loss: 0.766229\n",
      "Train Epoch: 1925 [320/1612 (20%)] Loss: 0.254679\n",
      "Train Epoch: 1925 [480/1612 (30%)] Loss: 0.302998\n",
      "Train Epoch: 1925 [640/1612 (40%)] Loss: 0.282274\n",
      "Train Epoch: 1925 [800/1612 (50%)] Loss: 0.188487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1925 [960/1612 (59%)] Loss: 0.488714\n",
      "Train Epoch: 1925 [1120/1612 (69%)] Loss: 0.265849\n",
      "Train Epoch: 1925 [1280/1612 (79%)] Loss: 0.207457\n",
      "Train Epoch: 1925 [1440/1612 (89%)] Loss: 0.212532\n",
      "Train Epoch: 1925 [1200/1612 (99%)] Loss: 0.434382\n",
      "\n",
      "Test set: Average loss: 0.0254, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1926 [0/1612 (0%)] Loss: 0.364512\n",
      "Train Epoch: 1926 [160/1612 (10%)] Loss: 0.569297\n",
      "Train Epoch: 1926 [320/1612 (20%)] Loss: 0.371782\n",
      "Train Epoch: 1926 [480/1612 (30%)] Loss: 0.377102\n",
      "Train Epoch: 1926 [640/1612 (40%)] Loss: 0.288901\n",
      "Train Epoch: 1926 [800/1612 (50%)] Loss: 0.530709\n",
      "Train Epoch: 1926 [960/1612 (59%)] Loss: 0.279065\n",
      "Train Epoch: 1926 [1120/1612 (69%)] Loss: 0.213118\n",
      "Train Epoch: 1926 [1280/1612 (79%)] Loss: 0.247708\n",
      "Train Epoch: 1926 [1440/1612 (89%)] Loss: 0.296369\n",
      "Train Epoch: 1926 [1200/1612 (99%)] Loss: 0.204715\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1927 [0/1612 (0%)] Loss: 0.166961\n",
      "Train Epoch: 1927 [160/1612 (10%)] Loss: 0.505223\n",
      "Train Epoch: 1927 [320/1612 (20%)] Loss: 0.402602\n",
      "Train Epoch: 1927 [480/1612 (30%)] Loss: 0.158963\n",
      "Train Epoch: 1927 [640/1612 (40%)] Loss: 0.361321\n",
      "Train Epoch: 1927 [800/1612 (50%)] Loss: 0.241391\n",
      "Train Epoch: 1927 [960/1612 (59%)] Loss: 0.274863\n",
      "Train Epoch: 1927 [1120/1612 (69%)] Loss: 0.405896\n",
      "Train Epoch: 1927 [1280/1612 (79%)] Loss: 0.312009\n",
      "Train Epoch: 1927 [1440/1612 (89%)] Loss: 0.257112\n",
      "Train Epoch: 1927 [1200/1612 (99%)] Loss: 0.129537\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1928 [0/1612 (0%)] Loss: 0.404570\n",
      "Train Epoch: 1928 [160/1612 (10%)] Loss: 0.212566\n",
      "Train Epoch: 1928 [320/1612 (20%)] Loss: 0.277929\n",
      "Train Epoch: 1928 [480/1612 (30%)] Loss: 0.226918\n",
      "Train Epoch: 1928 [640/1612 (40%)] Loss: 0.499699\n",
      "Train Epoch: 1928 [800/1612 (50%)] Loss: 0.428355\n",
      "Train Epoch: 1928 [960/1612 (59%)] Loss: 0.256112\n",
      "Train Epoch: 1928 [1120/1612 (69%)] Loss: 0.356777\n",
      "Train Epoch: 1928 [1280/1612 (79%)] Loss: 0.170602\n",
      "Train Epoch: 1928 [1440/1612 (89%)] Loss: 0.110356\n",
      "Train Epoch: 1928 [1200/1612 (99%)] Loss: 0.291424\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1929 [0/1612 (0%)] Loss: 0.439110\n",
      "Train Epoch: 1929 [160/1612 (10%)] Loss: 0.166715\n",
      "Train Epoch: 1929 [320/1612 (20%)] Loss: 0.136104\n",
      "Train Epoch: 1929 [480/1612 (30%)] Loss: 0.279109\n",
      "Train Epoch: 1929 [640/1612 (40%)] Loss: 0.226737\n",
      "Train Epoch: 1929 [800/1612 (50%)] Loss: 0.224099\n",
      "Train Epoch: 1929 [960/1612 (59%)] Loss: 0.416957\n",
      "Train Epoch: 1929 [1120/1612 (69%)] Loss: 0.205986\n",
      "Train Epoch: 1929 [1280/1612 (79%)] Loss: 0.293388\n",
      "Train Epoch: 1929 [1440/1612 (89%)] Loss: 0.258528\n",
      "Train Epoch: 1929 [1200/1612 (99%)] Loss: 0.215013\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1930 [0/1612 (0%)] Loss: 0.352612\n",
      "Train Epoch: 1930 [160/1612 (10%)] Loss: 0.191541\n",
      "Train Epoch: 1930 [320/1612 (20%)] Loss: 0.341182\n",
      "Train Epoch: 1930 [480/1612 (30%)] Loss: 0.180417\n",
      "Train Epoch: 1930 [640/1612 (40%)] Loss: 0.310595\n",
      "Train Epoch: 1930 [800/1612 (50%)] Loss: 0.229591\n",
      "Train Epoch: 1930 [960/1612 (59%)] Loss: 0.170603\n",
      "Train Epoch: 1930 [1120/1612 (69%)] Loss: 0.129704\n",
      "Train Epoch: 1930 [1280/1612 (79%)] Loss: 0.228643\n",
      "Train Epoch: 1930 [1440/1612 (89%)] Loss: 0.276104\n",
      "Train Epoch: 1930 [1200/1612 (99%)] Loss: 0.346265\n",
      "\n",
      "Test set: Average loss: 0.0285, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1931 [0/1612 (0%)] Loss: 0.451059\n",
      "Train Epoch: 1931 [160/1612 (10%)] Loss: 0.374833\n",
      "Train Epoch: 1931 [320/1612 (20%)] Loss: 0.545035\n",
      "Train Epoch: 1931 [480/1612 (30%)] Loss: 0.384972\n",
      "Train Epoch: 1931 [640/1612 (40%)] Loss: 0.259820\n",
      "Train Epoch: 1931 [800/1612 (50%)] Loss: 0.399979\n",
      "Train Epoch: 1931 [960/1612 (59%)] Loss: 0.401985\n",
      "Train Epoch: 1931 [1120/1612 (69%)] Loss: 0.322030\n",
      "Train Epoch: 1931 [1280/1612 (79%)] Loss: 0.208448\n",
      "Train Epoch: 1931 [1440/1612 (89%)] Loss: 0.189701\n",
      "Train Epoch: 1931 [1200/1612 (99%)] Loss: 0.368733\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1932 [0/1612 (0%)] Loss: 0.267613\n",
      "Train Epoch: 1932 [160/1612 (10%)] Loss: 0.227077\n",
      "Train Epoch: 1932 [320/1612 (20%)] Loss: 0.335814\n",
      "Train Epoch: 1932 [480/1612 (30%)] Loss: 0.251758\n",
      "Train Epoch: 1932 [640/1612 (40%)] Loss: 0.210244\n",
      "Train Epoch: 1932 [800/1612 (50%)] Loss: 0.292458\n",
      "Train Epoch: 1932 [960/1612 (59%)] Loss: 0.387939\n",
      "Train Epoch: 1932 [1120/1612 (69%)] Loss: 0.192364\n",
      "Train Epoch: 1932 [1280/1612 (79%)] Loss: 0.363286\n",
      "Train Epoch: 1932 [1440/1612 (89%)] Loss: 0.413718\n",
      "Train Epoch: 1932 [1200/1612 (99%)] Loss: 0.367197\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1933 [0/1612 (0%)] Loss: 0.223532\n",
      "Train Epoch: 1933 [160/1612 (10%)] Loss: 0.422231\n",
      "Train Epoch: 1933 [320/1612 (20%)] Loss: 0.221946\n",
      "Train Epoch: 1933 [480/1612 (30%)] Loss: 0.502621\n",
      "Train Epoch: 1933 [640/1612 (40%)] Loss: 0.354912\n",
      "Train Epoch: 1933 [800/1612 (50%)] Loss: 0.275568\n",
      "Train Epoch: 1933 [960/1612 (59%)] Loss: 0.337444\n",
      "Train Epoch: 1933 [1120/1612 (69%)] Loss: 0.445352\n",
      "Train Epoch: 1933 [1280/1612 (79%)] Loss: 0.363045\n",
      "Train Epoch: 1933 [1440/1612 (89%)] Loss: 0.289472\n",
      "Train Epoch: 1933 [1200/1612 (99%)] Loss: 0.219609\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1934 [0/1612 (0%)] Loss: 0.284092\n",
      "Train Epoch: 1934 [160/1612 (10%)] Loss: 0.245561\n",
      "Train Epoch: 1934 [320/1612 (20%)] Loss: 0.275355\n",
      "Train Epoch: 1934 [480/1612 (30%)] Loss: 0.584272\n",
      "Train Epoch: 1934 [640/1612 (40%)] Loss: 0.526647\n",
      "Train Epoch: 1934 [800/1612 (50%)] Loss: 0.250067\n",
      "Train Epoch: 1934 [960/1612 (59%)] Loss: 0.234013\n",
      "Train Epoch: 1934 [1120/1612 (69%)] Loss: 0.362611\n",
      "Train Epoch: 1934 [1280/1612 (79%)] Loss: 0.268038\n",
      "Train Epoch: 1934 [1440/1612 (89%)] Loss: 0.183709\n",
      "Train Epoch: 1934 [1200/1612 (99%)] Loss: 0.201019\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1935 [0/1612 (0%)] Loss: 0.330536\n",
      "Train Epoch: 1935 [160/1612 (10%)] Loss: 0.191819\n",
      "Train Epoch: 1935 [320/1612 (20%)] Loss: 0.270239\n",
      "Train Epoch: 1935 [480/1612 (30%)] Loss: 0.194138\n",
      "Train Epoch: 1935 [640/1612 (40%)] Loss: 0.310693\n",
      "Train Epoch: 1935 [800/1612 (50%)] Loss: 0.342275\n",
      "Train Epoch: 1935 [960/1612 (59%)] Loss: 0.198799\n",
      "Train Epoch: 1935 [1120/1612 (69%)] Loss: 0.471859\n",
      "Train Epoch: 1935 [1280/1612 (79%)] Loss: 0.249781\n",
      "Train Epoch: 1935 [1440/1612 (89%)] Loss: 0.337279\n",
      "Train Epoch: 1935 [1200/1612 (99%)] Loss: 0.171607\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1936 [0/1612 (0%)] Loss: 0.175849\n",
      "Train Epoch: 1936 [160/1612 (10%)] Loss: 0.382086\n",
      "Train Epoch: 1936 [320/1612 (20%)] Loss: 0.279701\n",
      "Train Epoch: 1936 [480/1612 (30%)] Loss: 0.323052\n",
      "Train Epoch: 1936 [640/1612 (40%)] Loss: 0.222092\n",
      "Train Epoch: 1936 [800/1612 (50%)] Loss: 0.350434\n",
      "Train Epoch: 1936 [960/1612 (59%)] Loss: 0.544578\n",
      "Train Epoch: 1936 [1120/1612 (69%)] Loss: 0.381614\n",
      "Train Epoch: 1936 [1280/1612 (79%)] Loss: 0.380710\n",
      "Train Epoch: 1936 [1440/1612 (89%)] Loss: 0.445382\n",
      "Train Epoch: 1936 [1200/1612 (99%)] Loss: 0.116233\n",
      "\n",
      "Test set: Average loss: 0.0257, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1937 [0/1612 (0%)] Loss: 0.461380\n",
      "Train Epoch: 1937 [160/1612 (10%)] Loss: 0.296946\n",
      "Train Epoch: 1937 [320/1612 (20%)] Loss: 0.148998\n",
      "Train Epoch: 1937 [480/1612 (30%)] Loss: 0.285168\n",
      "Train Epoch: 1937 [640/1612 (40%)] Loss: 0.342281\n",
      "Train Epoch: 1937 [800/1612 (50%)] Loss: 0.383100\n",
      "Train Epoch: 1937 [960/1612 (59%)] Loss: 0.278691\n",
      "Train Epoch: 1937 [1120/1612 (69%)] Loss: 0.211093\n",
      "Train Epoch: 1937 [1280/1612 (79%)] Loss: 0.276475\n",
      "Train Epoch: 1937 [1440/1612 (89%)] Loss: 0.145396\n",
      "Train Epoch: 1937 [1200/1612 (99%)] Loss: 0.211286\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1938 [0/1612 (0%)] Loss: 0.235698\n",
      "Train Epoch: 1938 [160/1612 (10%)] Loss: 0.536591\n",
      "Train Epoch: 1938 [320/1612 (20%)] Loss: 0.195207\n",
      "Train Epoch: 1938 [480/1612 (30%)] Loss: 0.283742\n",
      "Train Epoch: 1938 [640/1612 (40%)] Loss: 0.372153\n",
      "Train Epoch: 1938 [800/1612 (50%)] Loss: 0.249958\n",
      "Train Epoch: 1938 [960/1612 (59%)] Loss: 0.480402\n",
      "Train Epoch: 1938 [1120/1612 (69%)] Loss: 0.376585\n",
      "Train Epoch: 1938 [1280/1612 (79%)] Loss: 0.451414\n",
      "Train Epoch: 1938 [1440/1612 (89%)] Loss: 0.285874\n",
      "Train Epoch: 1938 [1200/1612 (99%)] Loss: 0.329717\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1939 [0/1612 (0%)] Loss: 0.336177\n",
      "Train Epoch: 1939 [160/1612 (10%)] Loss: 0.320828\n",
      "Train Epoch: 1939 [320/1612 (20%)] Loss: 0.403574\n",
      "Train Epoch: 1939 [480/1612 (30%)] Loss: 0.222641\n",
      "Train Epoch: 1939 [640/1612 (40%)] Loss: 0.372459\n",
      "Train Epoch: 1939 [800/1612 (50%)] Loss: 0.532565\n",
      "Train Epoch: 1939 [960/1612 (59%)] Loss: 0.217513\n",
      "Train Epoch: 1939 [1120/1612 (69%)] Loss: 0.275237\n",
      "Train Epoch: 1939 [1280/1612 (79%)] Loss: 0.307170\n",
      "Train Epoch: 1939 [1440/1612 (89%)] Loss: 0.301441\n",
      "Train Epoch: 1939 [1200/1612 (99%)] Loss: 0.232745\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1940 [0/1612 (0%)] Loss: 0.277331\n",
      "Train Epoch: 1940 [160/1612 (10%)] Loss: 0.176228\n",
      "Train Epoch: 1940 [320/1612 (20%)] Loss: 0.138129\n",
      "Train Epoch: 1940 [480/1612 (30%)] Loss: 0.266234\n",
      "Train Epoch: 1940 [640/1612 (40%)] Loss: 0.187548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1940 [800/1612 (50%)] Loss: 0.444944\n",
      "Train Epoch: 1940 [960/1612 (59%)] Loss: 0.202922\n",
      "Train Epoch: 1940 [1120/1612 (69%)] Loss: 0.265557\n",
      "Train Epoch: 1940 [1280/1612 (79%)] Loss: 0.332164\n",
      "Train Epoch: 1940 [1440/1612 (89%)] Loss: 0.228797\n",
      "Train Epoch: 1940 [1200/1612 (99%)] Loss: 0.258807\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1941 [0/1612 (0%)] Loss: 0.245221\n",
      "Train Epoch: 1941 [160/1612 (10%)] Loss: 0.274608\n",
      "Train Epoch: 1941 [320/1612 (20%)] Loss: 0.311436\n",
      "Train Epoch: 1941 [480/1612 (30%)] Loss: 0.160207\n",
      "Train Epoch: 1941 [640/1612 (40%)] Loss: 0.230720\n",
      "Train Epoch: 1941 [800/1612 (50%)] Loss: 0.226489\n",
      "Train Epoch: 1941 [960/1612 (59%)] Loss: 0.271855\n",
      "Train Epoch: 1941 [1120/1612 (69%)] Loss: 0.168359\n",
      "Train Epoch: 1941 [1280/1612 (79%)] Loss: 0.320727\n",
      "Train Epoch: 1941 [1440/1612 (89%)] Loss: 0.212622\n",
      "Train Epoch: 1941 [1200/1612 (99%)] Loss: 0.160149\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1942 [0/1612 (0%)] Loss: 0.234273\n",
      "Train Epoch: 1942 [160/1612 (10%)] Loss: 0.320822\n",
      "Train Epoch: 1942 [320/1612 (20%)] Loss: 0.272470\n",
      "Train Epoch: 1942 [480/1612 (30%)] Loss: 0.296195\n",
      "Train Epoch: 1942 [640/1612 (40%)] Loss: 0.423240\n",
      "Train Epoch: 1942 [800/1612 (50%)] Loss: 0.108542\n",
      "Train Epoch: 1942 [960/1612 (59%)] Loss: 0.326082\n",
      "Train Epoch: 1942 [1120/1612 (69%)] Loss: 0.351151\n",
      "Train Epoch: 1942 [1280/1612 (79%)] Loss: 0.328805\n",
      "Train Epoch: 1942 [1440/1612 (89%)] Loss: 0.356492\n",
      "Train Epoch: 1942 [1200/1612 (99%)] Loss: 0.192977\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1943 [0/1612 (0%)] Loss: 0.265297\n",
      "Train Epoch: 1943 [160/1612 (10%)] Loss: 0.280504\n",
      "Train Epoch: 1943 [320/1612 (20%)] Loss: 0.159301\n",
      "Train Epoch: 1943 [480/1612 (30%)] Loss: 0.059125\n",
      "Train Epoch: 1943 [640/1612 (40%)] Loss: 0.648333\n",
      "Train Epoch: 1943 [800/1612 (50%)] Loss: 0.333741\n",
      "Train Epoch: 1943 [960/1612 (59%)] Loss: 0.329087\n",
      "Train Epoch: 1943 [1120/1612 (69%)] Loss: 0.474426\n",
      "Train Epoch: 1943 [1280/1612 (79%)] Loss: 0.185816\n",
      "Train Epoch: 1943 [1440/1612 (89%)] Loss: 0.375426\n",
      "Train Epoch: 1943 [1200/1612 (99%)] Loss: 0.145598\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1944 [0/1612 (0%)] Loss: 0.345191\n",
      "Train Epoch: 1944 [160/1612 (10%)] Loss: 0.224902\n",
      "Train Epoch: 1944 [320/1612 (20%)] Loss: 0.179778\n",
      "Train Epoch: 1944 [480/1612 (30%)] Loss: 0.330979\n",
      "Train Epoch: 1944 [640/1612 (40%)] Loss: 0.386064\n",
      "Train Epoch: 1944 [800/1612 (50%)] Loss: 0.355681\n",
      "Train Epoch: 1944 [960/1612 (59%)] Loss: 0.166841\n",
      "Train Epoch: 1944 [1120/1612 (69%)] Loss: 0.102997\n",
      "Train Epoch: 1944 [1280/1612 (79%)] Loss: 0.649306\n",
      "Train Epoch: 1944 [1440/1612 (89%)] Loss: 0.166314\n",
      "Train Epoch: 1944 [1200/1612 (99%)] Loss: 0.244602\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1945 [0/1612 (0%)] Loss: 0.225488\n",
      "Train Epoch: 1945 [160/1612 (10%)] Loss: 0.213324\n",
      "Train Epoch: 1945 [320/1612 (20%)] Loss: 0.534768\n",
      "Train Epoch: 1945 [480/1612 (30%)] Loss: 0.248688\n",
      "Train Epoch: 1945 [640/1612 (40%)] Loss: 0.368919\n",
      "Train Epoch: 1945 [800/1612 (50%)] Loss: 0.415632\n",
      "Train Epoch: 1945 [960/1612 (59%)] Loss: 0.287604\n",
      "Train Epoch: 1945 [1120/1612 (69%)] Loss: 0.464689\n",
      "Train Epoch: 1945 [1280/1612 (79%)] Loss: 0.505594\n",
      "Train Epoch: 1945 [1440/1612 (89%)] Loss: 0.226033\n",
      "Train Epoch: 1945 [1200/1612 (99%)] Loss: 0.284945\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1946 [0/1612 (0%)] Loss: 0.235448\n",
      "Train Epoch: 1946 [160/1612 (10%)] Loss: 0.152267\n",
      "Train Epoch: 1946 [320/1612 (20%)] Loss: 0.188088\n",
      "Train Epoch: 1946 [480/1612 (30%)] Loss: 0.500219\n",
      "Train Epoch: 1946 [640/1612 (40%)] Loss: 0.378292\n",
      "Train Epoch: 1946 [800/1612 (50%)] Loss: 0.184299\n",
      "Train Epoch: 1946 [960/1612 (59%)] Loss: 0.381744\n",
      "Train Epoch: 1946 [1120/1612 (69%)] Loss: 0.403131\n",
      "Train Epoch: 1946 [1280/1612 (79%)] Loss: 0.346993\n",
      "Train Epoch: 1946 [1440/1612 (89%)] Loss: 0.365372\n",
      "Train Epoch: 1946 [1200/1612 (99%)] Loss: 0.266232\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1947 [0/1612 (0%)] Loss: 0.274704\n",
      "Train Epoch: 1947 [160/1612 (10%)] Loss: 0.298366\n",
      "Train Epoch: 1947 [320/1612 (20%)] Loss: 0.339135\n",
      "Train Epoch: 1947 [480/1612 (30%)] Loss: 0.365246\n",
      "Train Epoch: 1947 [640/1612 (40%)] Loss: 0.459092\n",
      "Train Epoch: 1947 [800/1612 (50%)] Loss: 0.330551\n",
      "Train Epoch: 1947 [960/1612 (59%)] Loss: 0.237499\n",
      "Train Epoch: 1947 [1120/1612 (69%)] Loss: 0.199550\n",
      "Train Epoch: 1947 [1280/1612 (79%)] Loss: 0.181003\n",
      "Train Epoch: 1947 [1440/1612 (89%)] Loss: 0.131734\n",
      "Train Epoch: 1947 [1200/1612 (99%)] Loss: 0.273099\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1948 [0/1612 (0%)] Loss: 0.393867\n",
      "Train Epoch: 1948 [160/1612 (10%)] Loss: 0.270451\n",
      "Train Epoch: 1948 [320/1612 (20%)] Loss: 0.239534\n",
      "Train Epoch: 1948 [480/1612 (30%)] Loss: 0.084948\n",
      "Train Epoch: 1948 [640/1612 (40%)] Loss: 0.480373\n",
      "Train Epoch: 1948 [800/1612 (50%)] Loss: 0.243105\n",
      "Train Epoch: 1948 [960/1612 (59%)] Loss: 0.190292\n",
      "Train Epoch: 1948 [1120/1612 (69%)] Loss: 0.173646\n",
      "Train Epoch: 1948 [1280/1612 (79%)] Loss: 0.201790\n",
      "Train Epoch: 1948 [1440/1612 (89%)] Loss: 0.367462\n",
      "Train Epoch: 1948 [1200/1612 (99%)] Loss: 0.193225\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1949 [0/1612 (0%)] Loss: 0.187331\n",
      "Train Epoch: 1949 [160/1612 (10%)] Loss: 0.158467\n",
      "Train Epoch: 1949 [320/1612 (20%)] Loss: 0.402365\n",
      "Train Epoch: 1949 [480/1612 (30%)] Loss: 0.294384\n",
      "Train Epoch: 1949 [640/1612 (40%)] Loss: 0.296498\n",
      "Train Epoch: 1949 [800/1612 (50%)] Loss: 0.219280\n",
      "Train Epoch: 1949 [960/1612 (59%)] Loss: 0.300488\n",
      "Train Epoch: 1949 [1120/1612 (69%)] Loss: 0.312835\n",
      "Train Epoch: 1949 [1280/1612 (79%)] Loss: 0.308060\n",
      "Train Epoch: 1949 [1440/1612 (89%)] Loss: 0.319616\n",
      "Train Epoch: 1949 [1200/1612 (99%)] Loss: 0.375131\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1950 [0/1612 (0%)] Loss: 0.364396\n",
      "Train Epoch: 1950 [160/1612 (10%)] Loss: 0.125424\n",
      "Train Epoch: 1950 [320/1612 (20%)] Loss: 0.391307\n",
      "Train Epoch: 1950 [480/1612 (30%)] Loss: 0.262886\n",
      "Train Epoch: 1950 [640/1612 (40%)] Loss: 0.504837\n",
      "Train Epoch: 1950 [800/1612 (50%)] Loss: 0.252321\n",
      "Train Epoch: 1950 [960/1612 (59%)] Loss: 0.277428\n",
      "Train Epoch: 1950 [1120/1612 (69%)] Loss: 0.294501\n",
      "Train Epoch: 1950 [1280/1612 (79%)] Loss: 0.410661\n",
      "Train Epoch: 1950 [1440/1612 (89%)] Loss: 0.448457\n",
      "Train Epoch: 1950 [1200/1612 (99%)] Loss: 0.325740\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1951 [0/1612 (0%)] Loss: 0.261911\n",
      "Train Epoch: 1951 [160/1612 (10%)] Loss: 0.284870\n",
      "Train Epoch: 1951 [320/1612 (20%)] Loss: 0.130128\n",
      "Train Epoch: 1951 [480/1612 (30%)] Loss: 0.143771\n",
      "Train Epoch: 1951 [640/1612 (40%)] Loss: 0.262961\n",
      "Train Epoch: 1951 [800/1612 (50%)] Loss: 0.647918\n",
      "Train Epoch: 1951 [960/1612 (59%)] Loss: 0.188740\n",
      "Train Epoch: 1951 [1120/1612 (69%)] Loss: 0.241444\n",
      "Train Epoch: 1951 [1280/1612 (79%)] Loss: 0.106471\n",
      "Train Epoch: 1951 [1440/1612 (89%)] Loss: 0.388477\n",
      "Train Epoch: 1951 [1200/1612 (99%)] Loss: 0.432074\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1952 [0/1612 (0%)] Loss: 0.232693\n",
      "Train Epoch: 1952 [160/1612 (10%)] Loss: 0.158047\n",
      "Train Epoch: 1952 [320/1612 (20%)] Loss: 0.370135\n",
      "Train Epoch: 1952 [480/1612 (30%)] Loss: 0.279916\n",
      "Train Epoch: 1952 [640/1612 (40%)] Loss: 0.288898\n",
      "Train Epoch: 1952 [800/1612 (50%)] Loss: 0.125414\n",
      "Train Epoch: 1952 [960/1612 (59%)] Loss: 0.271928\n",
      "Train Epoch: 1952 [1120/1612 (69%)] Loss: 0.362056\n",
      "Train Epoch: 1952 [1280/1612 (79%)] Loss: 0.196397\n",
      "Train Epoch: 1952 [1440/1612 (89%)] Loss: 0.261945\n",
      "Train Epoch: 1952 [1200/1612 (99%)] Loss: 0.261106\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1953 [0/1612 (0%)] Loss: 0.543597\n",
      "Train Epoch: 1953 [160/1612 (10%)] Loss: 0.389716\n",
      "Train Epoch: 1953 [320/1612 (20%)] Loss: 0.622554\n",
      "Train Epoch: 1953 [480/1612 (30%)] Loss: 0.205142\n",
      "Train Epoch: 1953 [640/1612 (40%)] Loss: 0.377958\n",
      "Train Epoch: 1953 [800/1612 (50%)] Loss: 0.141755\n",
      "Train Epoch: 1953 [960/1612 (59%)] Loss: 0.197521\n",
      "Train Epoch: 1953 [1120/1612 (69%)] Loss: 0.263571\n",
      "Train Epoch: 1953 [1280/1612 (79%)] Loss: 0.292408\n",
      "Train Epoch: 1953 [1440/1612 (89%)] Loss: 0.230506\n",
      "Train Epoch: 1953 [1200/1612 (99%)] Loss: 0.276538\n",
      "\n",
      "Test set: Average loss: 0.0302, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1954 [0/1612 (0%)] Loss: 0.415199\n",
      "Train Epoch: 1954 [160/1612 (10%)] Loss: 0.252293\n",
      "Train Epoch: 1954 [320/1612 (20%)] Loss: 0.456297\n",
      "Train Epoch: 1954 [480/1612 (30%)] Loss: 0.186737\n",
      "Train Epoch: 1954 [640/1612 (40%)] Loss: 0.257480\n",
      "Train Epoch: 1954 [800/1612 (50%)] Loss: 0.278291\n",
      "Train Epoch: 1954 [960/1612 (59%)] Loss: 0.297819\n",
      "Train Epoch: 1954 [1120/1612 (69%)] Loss: 0.301739\n",
      "Train Epoch: 1954 [1280/1612 (79%)] Loss: 0.203968\n",
      "Train Epoch: 1954 [1440/1612 (89%)] Loss: 0.441651\n",
      "Train Epoch: 1954 [1200/1612 (99%)] Loss: 0.253512\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1955 [0/1612 (0%)] Loss: 0.221332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1955 [160/1612 (10%)] Loss: 0.269492\n",
      "Train Epoch: 1955 [320/1612 (20%)] Loss: 0.222132\n",
      "Train Epoch: 1955 [480/1612 (30%)] Loss: 0.460659\n",
      "Train Epoch: 1955 [640/1612 (40%)] Loss: 0.247214\n",
      "Train Epoch: 1955 [800/1612 (50%)] Loss: 0.374410\n",
      "Train Epoch: 1955 [960/1612 (59%)] Loss: 0.174325\n",
      "Train Epoch: 1955 [1120/1612 (69%)] Loss: 0.282094\n",
      "Train Epoch: 1955 [1280/1612 (79%)] Loss: 0.314652\n",
      "Train Epoch: 1955 [1440/1612 (89%)] Loss: 0.196281\n",
      "Train Epoch: 1955 [1200/1612 (99%)] Loss: 0.388063\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1956 [0/1612 (0%)] Loss: 0.308066\n",
      "Train Epoch: 1956 [160/1612 (10%)] Loss: 0.330532\n",
      "Train Epoch: 1956 [320/1612 (20%)] Loss: 0.472924\n",
      "Train Epoch: 1956 [480/1612 (30%)] Loss: 0.245493\n",
      "Train Epoch: 1956 [640/1612 (40%)] Loss: 0.155676\n",
      "Train Epoch: 1956 [800/1612 (50%)] Loss: 0.337396\n",
      "Train Epoch: 1956 [960/1612 (59%)] Loss: 0.290772\n",
      "Train Epoch: 1956 [1120/1612 (69%)] Loss: 0.258642\n",
      "Train Epoch: 1956 [1280/1612 (79%)] Loss: 0.384384\n",
      "Train Epoch: 1956 [1440/1612 (89%)] Loss: 0.485513\n",
      "Train Epoch: 1956 [1200/1612 (99%)] Loss: 0.182261\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1957 [0/1612 (0%)] Loss: 0.288530\n",
      "Train Epoch: 1957 [160/1612 (10%)] Loss: 0.177193\n",
      "Train Epoch: 1957 [320/1612 (20%)] Loss: 0.291515\n",
      "Train Epoch: 1957 [480/1612 (30%)] Loss: 0.304395\n",
      "Train Epoch: 1957 [640/1612 (40%)] Loss: 0.246779\n",
      "Train Epoch: 1957 [800/1612 (50%)] Loss: 0.202250\n",
      "Train Epoch: 1957 [960/1612 (59%)] Loss: 0.211351\n",
      "Train Epoch: 1957 [1120/1612 (69%)] Loss: 0.375620\n",
      "Train Epoch: 1957 [1280/1612 (79%)] Loss: 0.366767\n",
      "Train Epoch: 1957 [1440/1612 (89%)] Loss: 0.252677\n",
      "Train Epoch: 1957 [1200/1612 (99%)] Loss: 0.417253\n",
      "\n",
      "Test set: Average loss: 0.0276, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1958 [0/1612 (0%)] Loss: 0.159220\n",
      "Train Epoch: 1958 [160/1612 (10%)] Loss: 0.505375\n",
      "Train Epoch: 1958 [320/1612 (20%)] Loss: 0.234404\n",
      "Train Epoch: 1958 [480/1612 (30%)] Loss: 0.295651\n",
      "Train Epoch: 1958 [640/1612 (40%)] Loss: 0.378323\n",
      "Train Epoch: 1958 [800/1612 (50%)] Loss: 0.377873\n",
      "Train Epoch: 1958 [960/1612 (59%)] Loss: 0.454877\n",
      "Train Epoch: 1958 [1120/1612 (69%)] Loss: 0.339873\n",
      "Train Epoch: 1958 [1280/1612 (79%)] Loss: 0.093964\n",
      "Train Epoch: 1958 [1440/1612 (89%)] Loss: 0.141580\n",
      "Train Epoch: 1958 [1200/1612 (99%)] Loss: 0.130986\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1959 [0/1612 (0%)] Loss: 0.280059\n",
      "Train Epoch: 1959 [160/1612 (10%)] Loss: 0.233488\n",
      "Train Epoch: 1959 [320/1612 (20%)] Loss: 0.260012\n",
      "Train Epoch: 1959 [480/1612 (30%)] Loss: 0.086756\n",
      "Train Epoch: 1959 [640/1612 (40%)] Loss: 0.231164\n",
      "Train Epoch: 1959 [800/1612 (50%)] Loss: 0.163950\n",
      "Train Epoch: 1959 [960/1612 (59%)] Loss: 0.134820\n",
      "Train Epoch: 1959 [1120/1612 (69%)] Loss: 0.185292\n",
      "Train Epoch: 1959 [1280/1612 (79%)] Loss: 0.446578\n",
      "Train Epoch: 1959 [1440/1612 (89%)] Loss: 0.303188\n",
      "Train Epoch: 1959 [1200/1612 (99%)] Loss: 0.255748\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1960 [0/1612 (0%)] Loss: 0.330016\n",
      "Train Epoch: 1960 [160/1612 (10%)] Loss: 0.280873\n",
      "Train Epoch: 1960 [320/1612 (20%)] Loss: 0.207784\n",
      "Train Epoch: 1960 [480/1612 (30%)] Loss: 0.449388\n",
      "Train Epoch: 1960 [640/1612 (40%)] Loss: 0.142000\n",
      "Train Epoch: 1960 [800/1612 (50%)] Loss: 0.431349\n",
      "Train Epoch: 1960 [960/1612 (59%)] Loss: 0.256481\n",
      "Train Epoch: 1960 [1120/1612 (69%)] Loss: 0.420565\n",
      "Train Epoch: 1960 [1280/1612 (79%)] Loss: 0.363564\n",
      "Train Epoch: 1960 [1440/1612 (89%)] Loss: 0.153026\n",
      "Train Epoch: 1960 [1200/1612 (99%)] Loss: 0.343627\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1961 [0/1612 (0%)] Loss: 0.225655\n",
      "Train Epoch: 1961 [160/1612 (10%)] Loss: 0.433125\n",
      "Train Epoch: 1961 [320/1612 (20%)] Loss: 0.334411\n",
      "Train Epoch: 1961 [480/1612 (30%)] Loss: 0.269584\n",
      "Train Epoch: 1961 [640/1612 (40%)] Loss: 0.156710\n",
      "Train Epoch: 1961 [800/1612 (50%)] Loss: 0.099081\n",
      "Train Epoch: 1961 [960/1612 (59%)] Loss: 0.269355\n",
      "Train Epoch: 1961 [1120/1612 (69%)] Loss: 0.347464\n",
      "Train Epoch: 1961 [1280/1612 (79%)] Loss: 0.233573\n",
      "Train Epoch: 1961 [1440/1612 (89%)] Loss: 0.161920\n",
      "Train Epoch: 1961 [1200/1612 (99%)] Loss: 0.342163\n",
      "\n",
      "Test set: Average loss: 0.0269, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1962 [0/1612 (0%)] Loss: 0.403395\n",
      "Train Epoch: 1962 [160/1612 (10%)] Loss: 0.262600\n",
      "Train Epoch: 1962 [320/1612 (20%)] Loss: 0.455642\n",
      "Train Epoch: 1962 [480/1612 (30%)] Loss: 0.343783\n",
      "Train Epoch: 1962 [640/1612 (40%)] Loss: 0.147204\n",
      "Train Epoch: 1962 [800/1612 (50%)] Loss: 0.247236\n",
      "Train Epoch: 1962 [960/1612 (59%)] Loss: 0.349218\n",
      "Train Epoch: 1962 [1120/1612 (69%)] Loss: 0.279000\n",
      "Train Epoch: 1962 [1280/1612 (79%)] Loss: 0.403686\n",
      "Train Epoch: 1962 [1440/1612 (89%)] Loss: 0.351435\n",
      "Train Epoch: 1962 [1200/1612 (99%)] Loss: 0.182267\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1963 [0/1612 (0%)] Loss: 0.477889\n",
      "Train Epoch: 1963 [160/1612 (10%)] Loss: 0.251161\n",
      "Train Epoch: 1963 [320/1612 (20%)] Loss: 0.357403\n",
      "Train Epoch: 1963 [480/1612 (30%)] Loss: 0.228423\n",
      "Train Epoch: 1963 [640/1612 (40%)] Loss: 0.178885\n",
      "Train Epoch: 1963 [800/1612 (50%)] Loss: 0.410103\n",
      "Train Epoch: 1963 [960/1612 (59%)] Loss: 0.144983\n",
      "Train Epoch: 1963 [1120/1612 (69%)] Loss: 0.390568\n",
      "Train Epoch: 1963 [1280/1612 (79%)] Loss: 0.300414\n",
      "Train Epoch: 1963 [1440/1612 (89%)] Loss: 0.088939\n",
      "Train Epoch: 1963 [1200/1612 (99%)] Loss: 0.337103\n",
      "\n",
      "Test set: Average loss: 0.0293, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1964 [0/1612 (0%)] Loss: 0.191116\n",
      "Train Epoch: 1964 [160/1612 (10%)] Loss: 0.191234\n",
      "Train Epoch: 1964 [320/1612 (20%)] Loss: 0.366819\n",
      "Train Epoch: 1964 [480/1612 (30%)] Loss: 0.296999\n",
      "Train Epoch: 1964 [640/1612 (40%)] Loss: 0.443604\n",
      "Train Epoch: 1964 [800/1612 (50%)] Loss: 0.334972\n",
      "Train Epoch: 1964 [960/1612 (59%)] Loss: 0.442260\n",
      "Train Epoch: 1964 [1120/1612 (69%)] Loss: 0.270758\n",
      "Train Epoch: 1964 [1280/1612 (79%)] Loss: 0.300156\n",
      "Train Epoch: 1964 [1440/1612 (89%)] Loss: 0.250919\n",
      "Train Epoch: 1964 [1200/1612 (99%)] Loss: 0.301967\n",
      "\n",
      "Test set: Average loss: 0.0317, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1965 [0/1612 (0%)] Loss: 0.270570\n",
      "Train Epoch: 1965 [160/1612 (10%)] Loss: 0.384869\n",
      "Train Epoch: 1965 [320/1612 (20%)] Loss: 0.316608\n",
      "Train Epoch: 1965 [480/1612 (30%)] Loss: 0.264709\n",
      "Train Epoch: 1965 [640/1612 (40%)] Loss: 0.433311\n",
      "Train Epoch: 1965 [800/1612 (50%)] Loss: 0.278706\n",
      "Train Epoch: 1965 [960/1612 (59%)] Loss: 0.252795\n",
      "Train Epoch: 1965 [1120/1612 (69%)] Loss: 0.283035\n",
      "Train Epoch: 1965 [1280/1612 (79%)] Loss: 0.447121\n",
      "Train Epoch: 1965 [1440/1612 (89%)] Loss: 0.403965\n",
      "Train Epoch: 1965 [1200/1612 (99%)] Loss: 0.192009\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1966 [0/1612 (0%)] Loss: 0.279449\n",
      "Train Epoch: 1966 [160/1612 (10%)] Loss: 0.197259\n",
      "Train Epoch: 1966 [320/1612 (20%)] Loss: 0.188994\n",
      "Train Epoch: 1966 [480/1612 (30%)] Loss: 0.443324\n",
      "Train Epoch: 1966 [640/1612 (40%)] Loss: 0.187501\n",
      "Train Epoch: 1966 [800/1612 (50%)] Loss: 0.208017\n",
      "Train Epoch: 1966 [960/1612 (59%)] Loss: 0.394041\n",
      "Train Epoch: 1966 [1120/1612 (69%)] Loss: 0.173090\n",
      "Train Epoch: 1966 [1280/1612 (79%)] Loss: 0.226487\n",
      "Train Epoch: 1966 [1440/1612 (89%)] Loss: 0.278848\n",
      "Train Epoch: 1966 [1200/1612 (99%)] Loss: 0.104403\n",
      "\n",
      "Test set: Average loss: 0.0270, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1967 [0/1612 (0%)] Loss: 0.151460\n",
      "Train Epoch: 1967 [160/1612 (10%)] Loss: 0.323601\n",
      "Train Epoch: 1967 [320/1612 (20%)] Loss: 0.635397\n",
      "Train Epoch: 1967 [480/1612 (30%)] Loss: 0.193868\n",
      "Train Epoch: 1967 [640/1612 (40%)] Loss: 0.310269\n",
      "Train Epoch: 1967 [800/1612 (50%)] Loss: 0.309085\n",
      "Train Epoch: 1967 [960/1612 (59%)] Loss: 0.312327\n",
      "Train Epoch: 1967 [1120/1612 (69%)] Loss: 0.262309\n",
      "Train Epoch: 1967 [1280/1612 (79%)] Loss: 0.126965\n",
      "Train Epoch: 1967 [1440/1612 (89%)] Loss: 0.063566\n",
      "Train Epoch: 1967 [1200/1612 (99%)] Loss: 0.322545\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1968 [0/1612 (0%)] Loss: 0.215809\n",
      "Train Epoch: 1968 [160/1612 (10%)] Loss: 0.240439\n",
      "Train Epoch: 1968 [320/1612 (20%)] Loss: 0.429639\n",
      "Train Epoch: 1968 [480/1612 (30%)] Loss: 0.323584\n",
      "Train Epoch: 1968 [640/1612 (40%)] Loss: 0.326353\n",
      "Train Epoch: 1968 [800/1612 (50%)] Loss: 0.272214\n",
      "Train Epoch: 1968 [960/1612 (59%)] Loss: 0.253502\n",
      "Train Epoch: 1968 [1120/1612 (69%)] Loss: 0.784512\n",
      "Train Epoch: 1968 [1280/1612 (79%)] Loss: 0.529101\n",
      "Train Epoch: 1968 [1440/1612 (89%)] Loss: 0.270091\n",
      "Train Epoch: 1968 [1200/1612 (99%)] Loss: 0.077182\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1969 [0/1612 (0%)] Loss: 0.380863\n",
      "Train Epoch: 1969 [160/1612 (10%)] Loss: 0.265237\n",
      "Train Epoch: 1969 [320/1612 (20%)] Loss: 0.231469\n",
      "Train Epoch: 1969 [480/1612 (30%)] Loss: 0.123564\n",
      "Train Epoch: 1969 [640/1612 (40%)] Loss: 0.196058\n",
      "Train Epoch: 1969 [800/1612 (50%)] Loss: 0.230242\n",
      "Train Epoch: 1969 [960/1612 (59%)] Loss: 0.364774\n",
      "Train Epoch: 1969 [1120/1612 (69%)] Loss: 0.178226\n",
      "Train Epoch: 1969 [1280/1612 (79%)] Loss: 0.348276\n",
      "Train Epoch: 1969 [1440/1612 (89%)] Loss: 0.708162\n",
      "Train Epoch: 1969 [1200/1612 (99%)] Loss: 0.074179\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1970 [0/1612 (0%)] Loss: 0.316730\n",
      "Train Epoch: 1970 [160/1612 (10%)] Loss: 0.422854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1970 [320/1612 (20%)] Loss: 0.325463\n",
      "Train Epoch: 1970 [480/1612 (30%)] Loss: 0.426633\n",
      "Train Epoch: 1970 [640/1612 (40%)] Loss: 0.124968\n",
      "Train Epoch: 1970 [800/1612 (50%)] Loss: 0.212517\n",
      "Train Epoch: 1970 [960/1612 (59%)] Loss: 0.242200\n",
      "Train Epoch: 1970 [1120/1612 (69%)] Loss: 0.336765\n",
      "Train Epoch: 1970 [1280/1612 (79%)] Loss: 0.228686\n",
      "Train Epoch: 1970 [1440/1612 (89%)] Loss: 0.288072\n",
      "Train Epoch: 1970 [1200/1612 (99%)] Loss: 0.477913\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1971 [0/1612 (0%)] Loss: 0.388638\n",
      "Train Epoch: 1971 [160/1612 (10%)] Loss: 0.464357\n",
      "Train Epoch: 1971 [320/1612 (20%)] Loss: 0.274937\n",
      "Train Epoch: 1971 [480/1612 (30%)] Loss: 0.248238\n",
      "Train Epoch: 1971 [640/1612 (40%)] Loss: 0.238500\n",
      "Train Epoch: 1971 [800/1612 (50%)] Loss: 0.406198\n",
      "Train Epoch: 1971 [960/1612 (59%)] Loss: 0.098499\n",
      "Train Epoch: 1971 [1120/1612 (69%)] Loss: 0.208416\n",
      "Train Epoch: 1971 [1280/1612 (79%)] Loss: 0.400823\n",
      "Train Epoch: 1971 [1440/1612 (89%)] Loss: 0.182235\n",
      "Train Epoch: 1971 [1200/1612 (99%)] Loss: 0.284191\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1972 [0/1612 (0%)] Loss: 0.458549\n",
      "Train Epoch: 1972 [160/1612 (10%)] Loss: 0.189069\n",
      "Train Epoch: 1972 [320/1612 (20%)] Loss: 0.500949\n",
      "Train Epoch: 1972 [480/1612 (30%)] Loss: 0.112927\n",
      "Train Epoch: 1972 [640/1612 (40%)] Loss: 0.271660\n",
      "Train Epoch: 1972 [800/1612 (50%)] Loss: 0.398538\n",
      "Train Epoch: 1972 [960/1612 (59%)] Loss: 0.116098\n",
      "Train Epoch: 1972 [1120/1612 (69%)] Loss: 0.357882\n",
      "Train Epoch: 1972 [1280/1612 (79%)] Loss: 0.398520\n",
      "Train Epoch: 1972 [1440/1612 (89%)] Loss: 0.294135\n",
      "Train Epoch: 1972 [1200/1612 (99%)] Loss: 0.315583\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1973 [0/1612 (0%)] Loss: 0.206266\n",
      "Train Epoch: 1973 [160/1612 (10%)] Loss: 0.338424\n",
      "Train Epoch: 1973 [320/1612 (20%)] Loss: 0.166674\n",
      "Train Epoch: 1973 [480/1612 (30%)] Loss: 0.234760\n",
      "Train Epoch: 1973 [640/1612 (40%)] Loss: 0.345111\n",
      "Train Epoch: 1973 [800/1612 (50%)] Loss: 0.268541\n",
      "Train Epoch: 1973 [960/1612 (59%)] Loss: 0.264171\n",
      "Train Epoch: 1973 [1120/1612 (69%)] Loss: 0.361580\n",
      "Train Epoch: 1973 [1280/1612 (79%)] Loss: 0.305043\n",
      "Train Epoch: 1973 [1440/1612 (89%)] Loss: 0.299369\n",
      "Train Epoch: 1973 [1200/1612 (99%)] Loss: 0.314679\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1974 [0/1612 (0%)] Loss: 0.276183\n",
      "Train Epoch: 1974 [160/1612 (10%)] Loss: 0.257788\n",
      "Train Epoch: 1974 [320/1612 (20%)] Loss: 0.489335\n",
      "Train Epoch: 1974 [480/1612 (30%)] Loss: 0.341305\n",
      "Train Epoch: 1974 [640/1612 (40%)] Loss: 0.384714\n",
      "Train Epoch: 1974 [800/1612 (50%)] Loss: 0.384730\n",
      "Train Epoch: 1974 [960/1612 (59%)] Loss: 0.425832\n",
      "Train Epoch: 1974 [1120/1612 (69%)] Loss: 0.404189\n",
      "Train Epoch: 1974 [1280/1612 (79%)] Loss: 0.327022\n",
      "Train Epoch: 1974 [1440/1612 (89%)] Loss: 0.547492\n",
      "Train Epoch: 1974 [1200/1612 (99%)] Loss: 0.148115\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1975 [0/1612 (0%)] Loss: 0.172085\n",
      "Train Epoch: 1975 [160/1612 (10%)] Loss: 0.200845\n",
      "Train Epoch: 1975 [320/1612 (20%)] Loss: 0.242661\n",
      "Train Epoch: 1975 [480/1612 (30%)] Loss: 0.168671\n",
      "Train Epoch: 1975 [640/1612 (40%)] Loss: 0.328426\n",
      "Train Epoch: 1975 [800/1612 (50%)] Loss: 0.287573\n",
      "Train Epoch: 1975 [960/1612 (59%)] Loss: 0.196367\n",
      "Train Epoch: 1975 [1120/1612 (69%)] Loss: 0.301932\n",
      "Train Epoch: 1975 [1280/1612 (79%)] Loss: 0.126899\n",
      "Train Epoch: 1975 [1440/1612 (89%)] Loss: 0.346224\n",
      "Train Epoch: 1975 [1200/1612 (99%)] Loss: 0.312335\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1976 [0/1612 (0%)] Loss: 0.350420\n",
      "Train Epoch: 1976 [160/1612 (10%)] Loss: 0.449764\n",
      "Train Epoch: 1976 [320/1612 (20%)] Loss: 0.327507\n",
      "Train Epoch: 1976 [480/1612 (30%)] Loss: 0.333091\n",
      "Train Epoch: 1976 [640/1612 (40%)] Loss: 0.173078\n",
      "Train Epoch: 1976 [800/1612 (50%)] Loss: 0.331508\n",
      "Train Epoch: 1976 [960/1612 (59%)] Loss: 0.389335\n",
      "Train Epoch: 1976 [1120/1612 (69%)] Loss: 0.116417\n",
      "Train Epoch: 1976 [1280/1612 (79%)] Loss: 0.356204\n",
      "Train Epoch: 1976 [1440/1612 (89%)] Loss: 0.356987\n",
      "Train Epoch: 1976 [1200/1612 (99%)] Loss: 0.347121\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1977 [0/1612 (0%)] Loss: 0.424629\n",
      "Train Epoch: 1977 [160/1612 (10%)] Loss: 0.405234\n",
      "Train Epoch: 1977 [320/1612 (20%)] Loss: 0.338073\n",
      "Train Epoch: 1977 [480/1612 (30%)] Loss: 0.365144\n",
      "Train Epoch: 1977 [640/1612 (40%)] Loss: 0.372125\n",
      "Train Epoch: 1977 [800/1612 (50%)] Loss: 0.212209\n",
      "Train Epoch: 1977 [960/1612 (59%)] Loss: 0.099054\n",
      "Train Epoch: 1977 [1120/1612 (69%)] Loss: 0.617944\n",
      "Train Epoch: 1977 [1280/1612 (79%)] Loss: 0.186116\n",
      "Train Epoch: 1977 [1440/1612 (89%)] Loss: 0.216719\n",
      "Train Epoch: 1977 [1200/1612 (99%)] Loss: 0.302784\n",
      "\n",
      "Test set: Average loss: 0.0268, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1978 [0/1612 (0%)] Loss: 0.429080\n",
      "Train Epoch: 1978 [160/1612 (10%)] Loss: 0.551691\n",
      "Train Epoch: 1978 [320/1612 (20%)] Loss: 0.256377\n",
      "Train Epoch: 1978 [480/1612 (30%)] Loss: 0.350754\n",
      "Train Epoch: 1978 [640/1612 (40%)] Loss: 0.235184\n",
      "Train Epoch: 1978 [800/1612 (50%)] Loss: 0.436378\n",
      "Train Epoch: 1978 [960/1612 (59%)] Loss: 0.224099\n",
      "Train Epoch: 1978 [1120/1612 (69%)] Loss: 0.470798\n",
      "Train Epoch: 1978 [1280/1612 (79%)] Loss: 0.098694\n",
      "Train Epoch: 1978 [1440/1612 (89%)] Loss: 0.363181\n",
      "Train Epoch: 1978 [1200/1612 (99%)] Loss: 0.154883\n",
      "\n",
      "Test set: Average loss: 0.0274, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1979 [0/1612 (0%)] Loss: 0.301341\n",
      "Train Epoch: 1979 [160/1612 (10%)] Loss: 0.577462\n",
      "Train Epoch: 1979 [320/1612 (20%)] Loss: 0.220927\n",
      "Train Epoch: 1979 [480/1612 (30%)] Loss: 0.273791\n",
      "Train Epoch: 1979 [640/1612 (40%)] Loss: 0.270584\n",
      "Train Epoch: 1979 [800/1612 (50%)] Loss: 0.339122\n",
      "Train Epoch: 1979 [960/1612 (59%)] Loss: 0.286304\n",
      "Train Epoch: 1979 [1120/1612 (69%)] Loss: 0.190761\n",
      "Train Epoch: 1979 [1280/1612 (79%)] Loss: 0.313643\n",
      "Train Epoch: 1979 [1440/1612 (89%)] Loss: 0.639389\n",
      "Train Epoch: 1979 [1200/1612 (99%)] Loss: 0.262165\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1980 [0/1612 (0%)] Loss: 0.575090\n",
      "Train Epoch: 1980 [160/1612 (10%)] Loss: 0.373958\n",
      "Train Epoch: 1980 [320/1612 (20%)] Loss: 0.314243\n",
      "Train Epoch: 1980 [480/1612 (30%)] Loss: 0.307416\n",
      "Train Epoch: 1980 [640/1612 (40%)] Loss: 0.303914\n",
      "Train Epoch: 1980 [800/1612 (50%)] Loss: 0.168288\n",
      "Train Epoch: 1980 [960/1612 (59%)] Loss: 0.127769\n",
      "Train Epoch: 1980 [1120/1612 (69%)] Loss: 0.360110\n",
      "Train Epoch: 1980 [1280/1612 (79%)] Loss: 0.341461\n",
      "Train Epoch: 1980 [1440/1612 (89%)] Loss: 0.257882\n",
      "Train Epoch: 1980 [1200/1612 (99%)] Loss: 0.274361\n",
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1981 [0/1612 (0%)] Loss: 0.138294\n",
      "Train Epoch: 1981 [160/1612 (10%)] Loss: 0.253865\n",
      "Train Epoch: 1981 [320/1612 (20%)] Loss: 0.305349\n",
      "Train Epoch: 1981 [480/1612 (30%)] Loss: 0.186992\n",
      "Train Epoch: 1981 [640/1612 (40%)] Loss: 0.164430\n",
      "Train Epoch: 1981 [800/1612 (50%)] Loss: 0.563301\n",
      "Train Epoch: 1981 [960/1612 (59%)] Loss: 0.301537\n",
      "Train Epoch: 1981 [1120/1612 (69%)] Loss: 0.424138\n",
      "Train Epoch: 1981 [1280/1612 (79%)] Loss: 0.326714\n",
      "Train Epoch: 1981 [1440/1612 (89%)] Loss: 0.197645\n",
      "Train Epoch: 1981 [1200/1612 (99%)] Loss: 0.221381\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1982 [0/1612 (0%)] Loss: 0.477889\n",
      "Train Epoch: 1982 [160/1612 (10%)] Loss: 0.260441\n",
      "Train Epoch: 1982 [320/1612 (20%)] Loss: 0.219820\n",
      "Train Epoch: 1982 [480/1612 (30%)] Loss: 0.343537\n",
      "Train Epoch: 1982 [640/1612 (40%)] Loss: 0.192200\n",
      "Train Epoch: 1982 [800/1612 (50%)] Loss: 0.403472\n",
      "Train Epoch: 1982 [960/1612 (59%)] Loss: 0.247259\n",
      "Train Epoch: 1982 [1120/1612 (69%)] Loss: 0.277286\n",
      "Train Epoch: 1982 [1280/1612 (79%)] Loss: 0.231794\n",
      "Train Epoch: 1982 [1440/1612 (89%)] Loss: 0.301268\n",
      "Train Epoch: 1982 [1200/1612 (99%)] Loss: 0.401004\n",
      "\n",
      "Test set: Average loss: 0.0258, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1983 [0/1612 (0%)] Loss: 0.087556\n",
      "Train Epoch: 1983 [160/1612 (10%)] Loss: 0.292997\n",
      "Train Epoch: 1983 [320/1612 (20%)] Loss: 0.204252\n",
      "Train Epoch: 1983 [480/1612 (30%)] Loss: 0.470026\n",
      "Train Epoch: 1983 [640/1612 (40%)] Loss: 0.066223\n",
      "Train Epoch: 1983 [800/1612 (50%)] Loss: 0.151418\n",
      "Train Epoch: 1983 [960/1612 (59%)] Loss: 0.300311\n",
      "Train Epoch: 1983 [1120/1612 (69%)] Loss: 0.616937\n",
      "Train Epoch: 1983 [1280/1612 (79%)] Loss: 0.271772\n",
      "Train Epoch: 1983 [1440/1612 (89%)] Loss: 0.247293\n",
      "Train Epoch: 1983 [1200/1612 (99%)] Loss: 0.126627\n",
      "\n",
      "Test set: Average loss: 0.0295, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1984 [0/1612 (0%)] Loss: 0.065728\n",
      "Train Epoch: 1984 [160/1612 (10%)] Loss: 0.250617\n",
      "Train Epoch: 1984 [320/1612 (20%)] Loss: 0.258783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1984 [480/1612 (30%)] Loss: 0.442551\n",
      "Train Epoch: 1984 [640/1612 (40%)] Loss: 0.273590\n",
      "Train Epoch: 1984 [800/1612 (50%)] Loss: 0.262959\n",
      "Train Epoch: 1984 [960/1612 (59%)] Loss: 0.248245\n",
      "Train Epoch: 1984 [1120/1612 (69%)] Loss: 0.240777\n",
      "Train Epoch: 1984 [1280/1612 (79%)] Loss: 0.601648\n",
      "Train Epoch: 1984 [1440/1612 (89%)] Loss: 0.107226\n",
      "Train Epoch: 1984 [1200/1612 (99%)] Loss: 0.655440\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1985 [0/1612 (0%)] Loss: 0.326612\n",
      "Train Epoch: 1985 [160/1612 (10%)] Loss: 0.135550\n",
      "Train Epoch: 1985 [320/1612 (20%)] Loss: 0.159183\n",
      "Train Epoch: 1985 [480/1612 (30%)] Loss: 0.229602\n",
      "Train Epoch: 1985 [640/1612 (40%)] Loss: 0.455851\n",
      "Train Epoch: 1985 [800/1612 (50%)] Loss: 0.125063\n",
      "Train Epoch: 1985 [960/1612 (59%)] Loss: 0.451563\n",
      "Train Epoch: 1985 [1120/1612 (69%)] Loss: 0.331870\n",
      "Train Epoch: 1985 [1280/1612 (79%)] Loss: 0.189848\n",
      "Train Epoch: 1985 [1440/1612 (89%)] Loss: 0.255950\n",
      "Train Epoch: 1985 [1200/1612 (99%)] Loss: 0.587553\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1986 [0/1612 (0%)] Loss: 0.246744\n",
      "Train Epoch: 1986 [160/1612 (10%)] Loss: 0.356673\n",
      "Train Epoch: 1986 [320/1612 (20%)] Loss: 0.239253\n",
      "Train Epoch: 1986 [480/1612 (30%)] Loss: 0.207096\n",
      "Train Epoch: 1986 [640/1612 (40%)] Loss: 0.296944\n",
      "Train Epoch: 1986 [800/1612 (50%)] Loss: 0.386516\n",
      "Train Epoch: 1986 [960/1612 (59%)] Loss: 0.580020\n",
      "Train Epoch: 1986 [1120/1612 (69%)] Loss: 0.214340\n",
      "Train Epoch: 1986 [1280/1612 (79%)] Loss: 0.243785\n",
      "Train Epoch: 1986 [1440/1612 (89%)] Loss: 0.328114\n",
      "Train Epoch: 1986 [1200/1612 (99%)] Loss: 0.527443\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1987 [0/1612 (0%)] Loss: 0.492318\n",
      "Train Epoch: 1987 [160/1612 (10%)] Loss: 0.198799\n",
      "Train Epoch: 1987 [320/1612 (20%)] Loss: 0.340837\n",
      "Train Epoch: 1987 [480/1612 (30%)] Loss: 0.171736\n",
      "Train Epoch: 1987 [640/1612 (40%)] Loss: 0.294608\n",
      "Train Epoch: 1987 [800/1612 (50%)] Loss: 0.387113\n",
      "Train Epoch: 1987 [960/1612 (59%)] Loss: 0.387033\n",
      "Train Epoch: 1987 [1120/1612 (69%)] Loss: 0.329713\n",
      "Train Epoch: 1987 [1280/1612 (79%)] Loss: 0.329206\n",
      "Train Epoch: 1987 [1440/1612 (89%)] Loss: 0.250711\n",
      "Train Epoch: 1987 [1200/1612 (99%)] Loss: 0.436837\n",
      "\n",
      "Test set: Average loss: 0.0265, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1988 [0/1612 (0%)] Loss: 0.145130\n",
      "Train Epoch: 1988 [160/1612 (10%)] Loss: 0.167221\n",
      "Train Epoch: 1988 [320/1612 (20%)] Loss: 0.313422\n",
      "Train Epoch: 1988 [480/1612 (30%)] Loss: 0.428327\n",
      "Train Epoch: 1988 [640/1612 (40%)] Loss: 0.062712\n",
      "Train Epoch: 1988 [800/1612 (50%)] Loss: 0.382755\n",
      "Train Epoch: 1988 [960/1612 (59%)] Loss: 0.338887\n",
      "Train Epoch: 1988 [1120/1612 (69%)] Loss: 0.346876\n",
      "Train Epoch: 1988 [1280/1612 (79%)] Loss: 0.332250\n",
      "Train Epoch: 1988 [1440/1612 (89%)] Loss: 0.371605\n",
      "Train Epoch: 1988 [1200/1612 (99%)] Loss: 0.440442\n",
      "\n",
      "Test set: Average loss: 0.0279, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1989 [0/1612 (0%)] Loss: 0.261675\n",
      "Train Epoch: 1989 [160/1612 (10%)] Loss: 0.316984\n",
      "Train Epoch: 1989 [320/1612 (20%)] Loss: 0.450900\n",
      "Train Epoch: 1989 [480/1612 (30%)] Loss: 0.387330\n",
      "Train Epoch: 1989 [640/1612 (40%)] Loss: 0.163242\n",
      "Train Epoch: 1989 [800/1612 (50%)] Loss: 0.235244\n",
      "Train Epoch: 1989 [960/1612 (59%)] Loss: 0.422967\n",
      "Train Epoch: 1989 [1120/1612 (69%)] Loss: 0.268135\n",
      "Train Epoch: 1989 [1280/1612 (79%)] Loss: 0.209499\n",
      "Train Epoch: 1989 [1440/1612 (89%)] Loss: 0.276166\n",
      "Train Epoch: 1989 [1200/1612 (99%)] Loss: 0.335281\n",
      "\n",
      "Test set: Average loss: 0.0284, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1990 [0/1612 (0%)] Loss: 0.592207\n",
      "Train Epoch: 1990 [160/1612 (10%)] Loss: 0.433990\n",
      "Train Epoch: 1990 [320/1612 (20%)] Loss: 0.281121\n",
      "Train Epoch: 1990 [480/1612 (30%)] Loss: 0.386135\n",
      "Train Epoch: 1990 [640/1612 (40%)] Loss: 0.143369\n",
      "Train Epoch: 1990 [800/1612 (50%)] Loss: 0.194952\n",
      "Train Epoch: 1990 [960/1612 (59%)] Loss: 0.193346\n",
      "Train Epoch: 1990 [1120/1612 (69%)] Loss: 0.106426\n",
      "Train Epoch: 1990 [1280/1612 (79%)] Loss: 0.209888\n",
      "Train Epoch: 1990 [1440/1612 (89%)] Loss: 0.501583\n",
      "Train Epoch: 1990 [1200/1612 (99%)] Loss: 0.344815\n",
      "\n",
      "Test set: Average loss: 0.0311, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1991 [0/1612 (0%)] Loss: 0.231406\n",
      "Train Epoch: 1991 [160/1612 (10%)] Loss: 0.278794\n",
      "Train Epoch: 1991 [320/1612 (20%)] Loss: 0.332435\n",
      "Train Epoch: 1991 [480/1612 (30%)] Loss: 0.305153\n",
      "Train Epoch: 1991 [640/1612 (40%)] Loss: 0.222728\n",
      "Train Epoch: 1991 [800/1612 (50%)] Loss: 0.211050\n",
      "Train Epoch: 1991 [960/1612 (59%)] Loss: 0.240533\n",
      "Train Epoch: 1991 [1120/1612 (69%)] Loss: 0.418395\n",
      "Train Epoch: 1991 [1280/1612 (79%)] Loss: 0.588227\n",
      "Train Epoch: 1991 [1440/1612 (89%)] Loss: 0.265550\n",
      "Train Epoch: 1991 [1200/1612 (99%)] Loss: 0.222033\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1992 [0/1612 (0%)] Loss: 0.291339\n",
      "Train Epoch: 1992 [160/1612 (10%)] Loss: 0.241110\n",
      "Train Epoch: 1992 [320/1612 (20%)] Loss: 0.349440\n",
      "Train Epoch: 1992 [480/1612 (30%)] Loss: 0.237524\n",
      "Train Epoch: 1992 [640/1612 (40%)] Loss: 0.083590\n",
      "Train Epoch: 1992 [800/1612 (50%)] Loss: 0.162332\n",
      "Train Epoch: 1992 [960/1612 (59%)] Loss: 0.329415\n",
      "Train Epoch: 1992 [1120/1612 (69%)] Loss: 0.079819\n",
      "Train Epoch: 1992 [1280/1612 (79%)] Loss: 0.393356\n",
      "Train Epoch: 1992 [1440/1612 (89%)] Loss: 0.278512\n",
      "Train Epoch: 1992 [1200/1612 (99%)] Loss: 0.358540\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1993 [0/1612 (0%)] Loss: 0.112118\n",
      "Train Epoch: 1993 [160/1612 (10%)] Loss: 0.166806\n",
      "Train Epoch: 1993 [320/1612 (20%)] Loss: 0.138770\n",
      "Train Epoch: 1993 [480/1612 (30%)] Loss: 0.293435\n",
      "Train Epoch: 1993 [640/1612 (40%)] Loss: 0.222047\n",
      "Train Epoch: 1993 [800/1612 (50%)] Loss: 0.444600\n",
      "Train Epoch: 1993 [960/1612 (59%)] Loss: 0.386076\n",
      "Train Epoch: 1993 [1120/1612 (69%)] Loss: 0.233586\n",
      "Train Epoch: 1993 [1280/1612 (79%)] Loss: 0.450241\n",
      "Train Epoch: 1993 [1440/1612 (89%)] Loss: 0.288434\n",
      "Train Epoch: 1993 [1200/1612 (99%)] Loss: 0.604335\n",
      "\n",
      "Test set: Average loss: 0.0255, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1994 [0/1612 (0%)] Loss: 0.150842\n",
      "Train Epoch: 1994 [160/1612 (10%)] Loss: 0.240488\n",
      "Train Epoch: 1994 [320/1612 (20%)] Loss: 0.409184\n",
      "Train Epoch: 1994 [480/1612 (30%)] Loss: 0.217922\n",
      "Train Epoch: 1994 [640/1612 (40%)] Loss: 0.488239\n",
      "Train Epoch: 1994 [800/1612 (50%)] Loss: 0.302607\n",
      "Train Epoch: 1994 [960/1612 (59%)] Loss: 0.456276\n",
      "Train Epoch: 1994 [1120/1612 (69%)] Loss: 0.191230\n",
      "Train Epoch: 1994 [1280/1612 (79%)] Loss: 0.201008\n",
      "Train Epoch: 1994 [1440/1612 (89%)] Loss: 0.307383\n",
      "Train Epoch: 1994 [1200/1612 (99%)] Loss: 0.184911\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1995 [0/1612 (0%)] Loss: 0.529263\n",
      "Train Epoch: 1995 [160/1612 (10%)] Loss: 0.267920\n",
      "Train Epoch: 1995 [320/1612 (20%)] Loss: 0.273836\n",
      "Train Epoch: 1995 [480/1612 (30%)] Loss: 0.190276\n",
      "Train Epoch: 1995 [640/1612 (40%)] Loss: 0.341805\n",
      "Train Epoch: 1995 [800/1612 (50%)] Loss: 0.480627\n",
      "Train Epoch: 1995 [960/1612 (59%)] Loss: 0.394666\n",
      "Train Epoch: 1995 [1120/1612 (69%)] Loss: 0.237458\n",
      "Train Epoch: 1995 [1280/1612 (79%)] Loss: 0.170714\n",
      "Train Epoch: 1995 [1440/1612 (89%)] Loss: 0.424799\n",
      "Train Epoch: 1995 [1200/1612 (99%)] Loss: 0.220260\n",
      "\n",
      "Test set: Average loss: 0.0288, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1996 [0/1612 (0%)] Loss: 0.476733\n",
      "Train Epoch: 1996 [160/1612 (10%)] Loss: 0.200203\n",
      "Train Epoch: 1996 [320/1612 (20%)] Loss: 0.388057\n",
      "Train Epoch: 1996 [480/1612 (30%)] Loss: 0.291422\n",
      "Train Epoch: 1996 [640/1612 (40%)] Loss: 0.534028\n",
      "Train Epoch: 1996 [800/1612 (50%)] Loss: 0.393161\n",
      "Train Epoch: 1996 [960/1612 (59%)] Loss: 0.289656\n",
      "Train Epoch: 1996 [1120/1612 (69%)] Loss: 0.252217\n",
      "Train Epoch: 1996 [1280/1612 (79%)] Loss: 0.185158\n",
      "Train Epoch: 1996 [1440/1612 (89%)] Loss: 0.360436\n",
      "Train Epoch: 1996 [1200/1612 (99%)] Loss: 0.283845\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1997 [0/1612 (0%)] Loss: 0.479169\n",
      "Train Epoch: 1997 [160/1612 (10%)] Loss: 0.327421\n",
      "Train Epoch: 1997 [320/1612 (20%)] Loss: 0.210095\n",
      "Train Epoch: 1997 [480/1612 (30%)] Loss: 0.260334\n",
      "Train Epoch: 1997 [640/1612 (40%)] Loss: 0.466477\n",
      "Train Epoch: 1997 [800/1612 (50%)] Loss: 0.401848\n",
      "Train Epoch: 1997 [960/1612 (59%)] Loss: 0.178604\n",
      "Train Epoch: 1997 [1120/1612 (69%)] Loss: 0.130509\n",
      "Train Epoch: 1997 [1280/1612 (79%)] Loss: 0.291443\n",
      "Train Epoch: 1997 [1440/1612 (89%)] Loss: 0.191383\n",
      "Train Epoch: 1997 [1200/1612 (99%)] Loss: 0.434795\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1998 [0/1612 (0%)] Loss: 0.481786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1998 [160/1612 (10%)] Loss: 0.217189\n",
      "Train Epoch: 1998 [320/1612 (20%)] Loss: 0.284311\n",
      "Train Epoch: 1998 [480/1612 (30%)] Loss: 0.464973\n",
      "Train Epoch: 1998 [640/1612 (40%)] Loss: 0.447959\n",
      "Train Epoch: 1998 [800/1612 (50%)] Loss: 0.128926\n",
      "Train Epoch: 1998 [960/1612 (59%)] Loss: 0.231497\n",
      "Train Epoch: 1998 [1120/1612 (69%)] Loss: 0.206198\n",
      "Train Epoch: 1998 [1280/1612 (79%)] Loss: 0.339127\n",
      "Train Epoch: 1998 [1440/1612 (89%)] Loss: 0.228940\n",
      "Train Epoch: 1998 [1200/1612 (99%)] Loss: 0.304893\n",
      "\n",
      "Test set: Average loss: 0.0250, Accuracy: 197/403 (49%)\n",
      "\n",
      "Train Epoch: 1999 [0/1612 (0%)] Loss: 0.154276\n",
      "Train Epoch: 1999 [160/1612 (10%)] Loss: 0.126545\n",
      "Train Epoch: 1999 [320/1612 (20%)] Loss: 0.156123\n",
      "Train Epoch: 1999 [480/1612 (30%)] Loss: 0.487289\n",
      "Train Epoch: 1999 [640/1612 (40%)] Loss: 0.239631\n",
      "Train Epoch: 1999 [800/1612 (50%)] Loss: 0.278450\n",
      "Train Epoch: 1999 [960/1612 (59%)] Loss: 0.287799\n",
      "Train Epoch: 1999 [1120/1612 (69%)] Loss: 0.149487\n",
      "Train Epoch: 1999 [1280/1612 (79%)] Loss: 0.270710\n",
      "Train Epoch: 1999 [1440/1612 (89%)] Loss: 0.356819\n",
      "Train Epoch: 1999 [1200/1612 (99%)] Loss: 0.308717\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 197/403 (49%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "for epoch in range(1, 2000):\n",
    "    loss.append(train(epoch))\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(1,2000), loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss with epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
